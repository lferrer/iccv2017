I0407 11:00:56.710790  6158 caffe.cpp:217] Using GPUs 1
I0407 11:00:56.868124  6158 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0407 11:00:57.803287  6158 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 1e-08
display: 20
max_iter: 143010
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
stepsize: 14301
snapshot: 1000
snapshot_prefix: "c3d_ucf101"
solver_mode: GPU
device_id: 1
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-val"
}
I0407 11:00:57.803746  6158 solver.cpp:91] Creating training net from net file: train_test.prototxt
I0407 11:00:57.806412  6158 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0407 11:00:57.807155  6158 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/train"
    batch_size: 18
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "TripletLoss"
  bottom: "fc7"
  bottom: "fc7_pos"
  bottom: "fc7_neg"
  top: "loss"
  threshold_param {
    threshold: 1
  }
}
I0407 11:00:57.807476  6158 layer_factory.hpp:77] Creating layer data
I0407 11:00:57.808933  6158 net.cpp:100] Creating Layer data
I0407 11:00:57.808948  6158 net.cpp:408] data -> triplet
I0407 11:00:57.911578  6164 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/train
I0407 11:00:58.075693  6158 data_layer.cpp:41] output data size: 18,144,112,112
I0407 11:00:58.352646  6158 net.cpp:150] Setting up data
I0407 11:00:58.352948  6158 net.cpp:157] Top shape: 18 144 112 112 (32514048)
I0407 11:00:58.352963  6158 net.cpp:165] Memory required for data: 130056192
I0407 11:00:58.352989  6158 layer_factory.hpp:77] Creating layer slicer
I0407 11:00:58.353098  6158 net.cpp:100] Creating Layer slicer
I0407 11:00:58.353107  6158 net.cpp:434] slicer <- triplet
I0407 11:00:58.353123  6158 net.cpp:408] slicer -> anchor_stacked
I0407 11:00:58.353137  6158 net.cpp:408] slicer -> positive_stacked
I0407 11:00:58.353152  6158 net.cpp:408] slicer -> negative_stacked
I0407 11:00:58.353369  6158 net.cpp:150] Setting up slicer
I0407 11:00:58.353379  6158 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0407 11:00:58.353384  6158 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0407 11:00:58.353387  6158 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0407 11:00:58.353390  6158 net.cpp:165] Memory required for data: 260112384
I0407 11:00:58.353394  6158 layer_factory.hpp:77] Creating layer reshape_anchor
I0407 11:00:58.364855  6158 net.cpp:100] Creating Layer reshape_anchor
I0407 11:00:58.364886  6158 net.cpp:434] reshape_anchor <- anchor_stacked
I0407 11:00:58.364903  6158 net.cpp:408] reshape_anchor -> anchor
I0407 11:00:58.385588  6158 net.cpp:150] Setting up reshape_anchor
I0407 11:00:58.385639  6158 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0407 11:00:58.385643  6158 net.cpp:165] Memory required for data: 303464448
I0407 11:00:58.385650  6158 layer_factory.hpp:77] Creating layer reshape_positive
I0407 11:00:58.385675  6158 net.cpp:100] Creating Layer reshape_positive
I0407 11:00:58.385691  6158 net.cpp:434] reshape_positive <- positive_stacked
I0407 11:00:58.385700  6158 net.cpp:408] reshape_positive -> positive
I0407 11:00:58.385745  6158 net.cpp:150] Setting up reshape_positive
I0407 11:00:58.385751  6158 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0407 11:00:58.385754  6158 net.cpp:165] Memory required for data: 346816512
I0407 11:00:58.385757  6158 layer_factory.hpp:77] Creating layer reshape_negative
I0407 11:00:58.385797  6158 net.cpp:100] Creating Layer reshape_negative
I0407 11:00:58.385802  6158 net.cpp:434] reshape_negative <- negative_stacked
I0407 11:00:58.385812  6158 net.cpp:408] reshape_negative -> negative
I0407 11:00:58.385844  6158 net.cpp:150] Setting up reshape_negative
I0407 11:00:58.385854  6158 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0407 11:00:58.385859  6158 net.cpp:165] Memory required for data: 390168576
I0407 11:00:58.385881  6158 layer_factory.hpp:77] Creating layer conv1a
I0407 11:00:58.385905  6158 net.cpp:100] Creating Layer conv1a
I0407 11:00:58.385913  6158 net.cpp:434] conv1a <- anchor
I0407 11:00:58.385926  6158 net.cpp:408] conv1a -> conv1a
I0407 11:00:58.433719  6165 blocking_queue.cpp:50] Waiting for data
I0407 11:00:59.096806  6158 net.cpp:150] Setting up conv1a
I0407 11:00:59.096858  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:00:59.096864  6158 net.cpp:165] Memory required for data: 1315012608
I0407 11:00:59.096900  6158 layer_factory.hpp:77] Creating layer relu1a
I0407 11:00:59.096946  6158 net.cpp:100] Creating Layer relu1a
I0407 11:00:59.096956  6158 net.cpp:434] relu1a <- conv1a
I0407 11:00:59.096967  6158 net.cpp:395] relu1a -> conv1a (in-place)
I0407 11:00:59.102648  6158 net.cpp:150] Setting up relu1a
I0407 11:00:59.102674  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:00:59.102679  6158 net.cpp:165] Memory required for data: 2239856640
I0407 11:00:59.102686  6158 layer_factory.hpp:77] Creating layer pool1
I0407 11:00:59.102716  6158 net.cpp:100] Creating Layer pool1
I0407 11:00:59.102722  6158 net.cpp:434] pool1 <- conv1a
I0407 11:00:59.102733  6158 net.cpp:408] pool1 -> pool1
I0407 11:00:59.103744  6158 net.cpp:150] Setting up pool1
I0407 11:00:59.103766  6158 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0407 11:00:59.103773  6158 net.cpp:165] Memory required for data: 2471067648
I0407 11:00:59.103780  6158 layer_factory.hpp:77] Creating layer conv2a
I0407 11:00:59.103814  6158 net.cpp:100] Creating Layer conv2a
I0407 11:00:59.103821  6158 net.cpp:434] conv2a <- pool1
I0407 11:00:59.103832  6158 net.cpp:408] conv2a -> conv2a
I0407 11:00:59.119005  6158 net.cpp:150] Setting up conv2a
I0407 11:00:59.119029  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:00:59.119035  6158 net.cpp:165] Memory required for data: 2933489664
I0407 11:00:59.119052  6158 layer_factory.hpp:77] Creating layer relu2a
I0407 11:00:59.119063  6158 net.cpp:100] Creating Layer relu2a
I0407 11:00:59.119069  6158 net.cpp:434] relu2a <- conv2a
I0407 11:00:59.119077  6158 net.cpp:395] relu2a -> conv2a (in-place)
I0407 11:00:59.120270  6158 net.cpp:150] Setting up relu2a
I0407 11:00:59.120287  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:00:59.120292  6158 net.cpp:165] Memory required for data: 3395911680
I0407 11:00:59.120298  6158 layer_factory.hpp:77] Creating layer pool2
I0407 11:00:59.120308  6158 net.cpp:100] Creating Layer pool2
I0407 11:00:59.120313  6158 net.cpp:434] pool2 <- conv2a
I0407 11:00:59.120322  6158 net.cpp:408] pool2 -> pool2
I0407 11:00:59.120630  6158 net.cpp:150] Setting up pool2
I0407 11:00:59.120645  6158 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0407 11:00:59.120648  6158 net.cpp:165] Memory required for data: 3453714432
I0407 11:00:59.120653  6158 layer_factory.hpp:77] Creating layer conv3a
I0407 11:00:59.120671  6158 net.cpp:100] Creating Layer conv3a
I0407 11:00:59.120676  6158 net.cpp:434] conv3a <- pool2
I0407 11:00:59.120687  6158 net.cpp:408] conv3a -> conv3a
I0407 11:00:59.160802  6158 net.cpp:150] Setting up conv3a
I0407 11:00:59.160851  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:00:59.160857  6158 net.cpp:165] Memory required for data: 3569319936
I0407 11:00:59.160877  6158 layer_factory.hpp:77] Creating layer relu3a
I0407 11:00:59.160889  6158 net.cpp:100] Creating Layer relu3a
I0407 11:00:59.160895  6158 net.cpp:434] relu3a <- conv3a
I0407 11:00:59.160905  6158 net.cpp:395] relu3a -> conv3a (in-place)
I0407 11:00:59.161978  6158 net.cpp:150] Setting up relu3a
I0407 11:00:59.162015  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:00:59.162020  6158 net.cpp:165] Memory required for data: 3684925440
I0407 11:00:59.162027  6158 layer_factory.hpp:77] Creating layer pool3
I0407 11:00:59.162039  6158 net.cpp:100] Creating Layer pool3
I0407 11:00:59.162044  6158 net.cpp:434] pool3 <- conv3a
I0407 11:00:59.162050  6158 net.cpp:408] pool3 -> pool3
I0407 11:00:59.162328  6158 net.cpp:150] Setting up pool3
I0407 11:00:59.162341  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.162345  6158 net.cpp:165] Memory required for data: 3699376128
I0407 11:00:59.162349  6158 layer_factory.hpp:77] Creating layer conv4a
I0407 11:00:59.162365  6158 net.cpp:100] Creating Layer conv4a
I0407 11:00:59.162374  6158 net.cpp:434] conv4a <- pool3
I0407 11:00:59.162380  6158 net.cpp:408] conv4a -> conv4a
I0407 11:00:59.228222  6158 net.cpp:150] Setting up conv4a
I0407 11:00:59.228255  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.228260  6158 net.cpp:165] Memory required for data: 3713826816
I0407 11:00:59.228271  6158 layer_factory.hpp:77] Creating layer relu4a
I0407 11:00:59.228283  6158 net.cpp:100] Creating Layer relu4a
I0407 11:00:59.228288  6158 net.cpp:434] relu4a <- conv4a
I0407 11:00:59.228296  6158 net.cpp:395] relu4a -> conv4a (in-place)
I0407 11:00:59.228507  6158 net.cpp:150] Setting up relu4a
I0407 11:00:59.228518  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.228521  6158 net.cpp:165] Memory required for data: 3728277504
I0407 11:00:59.228526  6158 layer_factory.hpp:77] Creating layer pool4
I0407 11:00:59.228556  6158 net.cpp:100] Creating Layer pool4
I0407 11:00:59.228562  6158 net.cpp:434] pool4 <- conv4a
I0407 11:00:59.228569  6158 net.cpp:408] pool4 -> pool4
I0407 11:00:59.231806  6158 net.cpp:150] Setting up pool4
I0407 11:00:59.231824  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:00:59.231828  6158 net.cpp:165] Memory required for data: 3730083840
I0407 11:00:59.231833  6158 layer_factory.hpp:77] Creating layer conv5a
I0407 11:00:59.231844  6158 net.cpp:100] Creating Layer conv5a
I0407 11:00:59.231849  6158 net.cpp:434] conv5a <- pool4
I0407 11:00:59.231858  6158 net.cpp:408] conv5a -> conv5a
I0407 11:00:59.298511  6158 net.cpp:150] Setting up conv5a
I0407 11:00:59.298568  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:00:59.298585  6158 net.cpp:165] Memory required for data: 3731890176
I0407 11:00:59.298631  6158 layer_factory.hpp:77] Creating layer relu5a
I0407 11:00:59.298656  6158 net.cpp:100] Creating Layer relu5a
I0407 11:00:59.298671  6158 net.cpp:434] relu5a <- conv5a
I0407 11:00:59.298683  6158 net.cpp:395] relu5a -> conv5a (in-place)
I0407 11:00:59.299098  6158 net.cpp:150] Setting up relu5a
I0407 11:00:59.299116  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:00:59.299124  6158 net.cpp:165] Memory required for data: 3733696512
I0407 11:00:59.299131  6158 layer_factory.hpp:77] Creating layer pool5
I0407 11:00:59.299155  6158 net.cpp:100] Creating Layer pool5
I0407 11:00:59.299162  6158 net.cpp:434] pool5 <- conv5a
I0407 11:00:59.299175  6158 net.cpp:408] pool5 -> pool5
I0407 11:00:59.300981  6158 net.cpp:150] Setting up pool5
I0407 11:00:59.301010  6158 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0407 11:00:59.301017  6158 net.cpp:165] Memory required for data: 3733991424
I0407 11:00:59.301024  6158 layer_factory.hpp:77] Creating layer fc6
I0407 11:00:59.312485  6158 net.cpp:100] Creating Layer fc6
I0407 11:00:59.312506  6158 net.cpp:434] fc6 <- pool5
I0407 11:00:59.312520  6158 net.cpp:408] fc6 -> fc6
I0407 11:00:59.654774  6158 net.cpp:150] Setting up fc6
I0407 11:00:59.654834  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.654842  6158 net.cpp:165] Memory required for data: 3734138880
I0407 11:00:59.654860  6158 layer_factory.hpp:77] Creating layer relu6
I0407 11:00:59.654878  6158 net.cpp:100] Creating Layer relu6
I0407 11:00:59.654887  6158 net.cpp:434] relu6 <- fc6
I0407 11:00:59.654899  6158 net.cpp:395] relu6 -> fc6 (in-place)
I0407 11:00:59.655308  6158 net.cpp:150] Setting up relu6
I0407 11:00:59.655321  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.655325  6158 net.cpp:165] Memory required for data: 3734286336
I0407 11:00:59.655329  6158 layer_factory.hpp:77] Creating layer drop6
I0407 11:00:59.655354  6158 net.cpp:100] Creating Layer drop6
I0407 11:00:59.655359  6158 net.cpp:434] drop6 <- fc6
I0407 11:00:59.655366  6158 net.cpp:395] drop6 -> fc6 (in-place)
I0407 11:00:59.655401  6158 net.cpp:150] Setting up drop6
I0407 11:00:59.655410  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.655413  6158 net.cpp:165] Memory required for data: 3734433792
I0407 11:00:59.655416  6158 layer_factory.hpp:77] Creating layer fc7
I0407 11:00:59.655431  6158 net.cpp:100] Creating Layer fc7
I0407 11:00:59.655437  6158 net.cpp:434] fc7 <- fc6
I0407 11:00:59.655443  6158 net.cpp:408] fc7 -> fc7
I0407 11:00:59.826632  6158 net.cpp:150] Setting up fc7
I0407 11:00:59.826688  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.826694  6158 net.cpp:165] Memory required for data: 3734581248
I0407 11:00:59.826711  6158 layer_factory.hpp:77] Creating layer relu7
I0407 11:00:59.826728  6158 net.cpp:100] Creating Layer relu7
I0407 11:00:59.826735  6158 net.cpp:434] relu7 <- fc7
I0407 11:00:59.826745  6158 net.cpp:395] relu7 -> fc7 (in-place)
I0407 11:00:59.828006  6158 net.cpp:150] Setting up relu7
I0407 11:00:59.828028  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.828033  6158 net.cpp:165] Memory required for data: 3734728704
I0407 11:00:59.828039  6158 layer_factory.hpp:77] Creating layer drop7
I0407 11:00:59.828053  6158 net.cpp:100] Creating Layer drop7
I0407 11:00:59.828058  6158 net.cpp:434] drop7 <- fc7
I0407 11:00:59.828068  6158 net.cpp:395] drop7 -> fc7 (in-place)
I0407 11:00:59.828115  6158 net.cpp:150] Setting up drop7
I0407 11:00:59.828124  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:00:59.828126  6158 net.cpp:165] Memory required for data: 3734876160
I0407 11:00:59.828130  6158 layer_factory.hpp:77] Creating layer conv1a_pos
I0407 11:00:59.828152  6158 net.cpp:100] Creating Layer conv1a_pos
I0407 11:00:59.828158  6158 net.cpp:434] conv1a_pos <- positive
I0407 11:00:59.828166  6158 net.cpp:408] conv1a_pos -> conv1a_pos
I0407 11:00:59.841378  6158 net.cpp:150] Setting up conv1a_pos
I0407 11:00:59.841425  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:00:59.841431  6158 net.cpp:165] Memory required for data: 4659720192
I0407 11:00:59.841444  6158 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0407 11:00:59.841454  6158 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0407 11:00:59.841462  6158 layer_factory.hpp:77] Creating layer relu1a_pos
I0407 11:00:59.841478  6158 net.cpp:100] Creating Layer relu1a_pos
I0407 11:00:59.841487  6158 net.cpp:434] relu1a_pos <- conv1a_pos
I0407 11:00:59.841500  6158 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0407 11:00:59.841856  6158 net.cpp:150] Setting up relu1a_pos
I0407 11:00:59.841902  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:00:59.841914  6158 net.cpp:165] Memory required for data: 5584564224
I0407 11:00:59.841919  6158 layer_factory.hpp:77] Creating layer pool1_pos
I0407 11:00:59.841933  6158 net.cpp:100] Creating Layer pool1_pos
I0407 11:00:59.841939  6158 net.cpp:434] pool1_pos <- conv1a_pos
I0407 11:00:59.841948  6158 net.cpp:408] pool1_pos -> pool1_pos
I0407 11:00:59.843300  6158 net.cpp:150] Setting up pool1_pos
I0407 11:00:59.843327  6158 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0407 11:00:59.843334  6158 net.cpp:165] Memory required for data: 5815775232
I0407 11:00:59.843343  6158 layer_factory.hpp:77] Creating layer conv2a_pos
I0407 11:00:59.843367  6158 net.cpp:100] Creating Layer conv2a_pos
I0407 11:00:59.843377  6158 net.cpp:434] conv2a_pos <- pool1_pos
I0407 11:00:59.843392  6158 net.cpp:408] conv2a_pos -> conv2a_pos
I0407 11:00:59.857626  6158 net.cpp:150] Setting up conv2a_pos
I0407 11:00:59.857666  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:00:59.857707  6158 net.cpp:165] Memory required for data: 6278197248
I0407 11:00:59.857723  6158 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0407 11:00:59.857733  6158 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0407 11:00:59.857743  6158 layer_factory.hpp:77] Creating layer relu2a_pos
I0407 11:00:59.857758  6158 net.cpp:100] Creating Layer relu2a_pos
I0407 11:00:59.857764  6158 net.cpp:434] relu2a_pos <- conv2a_pos
I0407 11:00:59.857772  6158 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0407 11:00:59.858008  6158 net.cpp:150] Setting up relu2a_pos
I0407 11:00:59.858022  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:00:59.858026  6158 net.cpp:165] Memory required for data: 6740619264
I0407 11:00:59.858031  6158 layer_factory.hpp:77] Creating layer pool2_pos
I0407 11:00:59.858042  6158 net.cpp:100] Creating Layer pool2_pos
I0407 11:00:59.858044  6158 net.cpp:434] pool2_pos <- conv2a_pos
I0407 11:00:59.858052  6158 net.cpp:408] pool2_pos -> pool2_pos
I0407 11:00:59.859092  6158 net.cpp:150] Setting up pool2_pos
I0407 11:00:59.859107  6158 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0407 11:00:59.859112  6158 net.cpp:165] Memory required for data: 6798422016
I0407 11:00:59.859117  6158 layer_factory.hpp:77] Creating layer conv3a_pos
I0407 11:00:59.859139  6158 net.cpp:100] Creating Layer conv3a_pos
I0407 11:00:59.859145  6158 net.cpp:434] conv3a_pos <- pool2_pos
I0407 11:00:59.859154  6158 net.cpp:408] conv3a_pos -> conv3a_pos
I0407 11:00:59.894263  6158 net.cpp:150] Setting up conv3a_pos
I0407 11:00:59.894309  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:00:59.894317  6158 net.cpp:165] Memory required for data: 6914027520
I0407 11:00:59.894330  6158 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0407 11:00:59.894340  6158 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0407 11:00:59.894371  6158 layer_factory.hpp:77] Creating layer relu3a_pos
I0407 11:00:59.894393  6158 net.cpp:100] Creating Layer relu3a_pos
I0407 11:00:59.894404  6158 net.cpp:434] relu3a_pos <- conv3a_pos
I0407 11:00:59.894418  6158 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0407 11:00:59.896108  6158 net.cpp:150] Setting up relu3a_pos
I0407 11:00:59.896134  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:00:59.896144  6158 net.cpp:165] Memory required for data: 7029633024
I0407 11:00:59.896153  6158 layer_factory.hpp:77] Creating layer pool3_pos
I0407 11:00:59.896184  6158 net.cpp:100] Creating Layer pool3_pos
I0407 11:00:59.896198  6158 net.cpp:434] pool3_pos <- conv3a_pos
I0407 11:00:59.896212  6158 net.cpp:408] pool3_pos -> pool3_pos
I0407 11:00:59.899660  6158 net.cpp:150] Setting up pool3_pos
I0407 11:00:59.899705  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.899709  6158 net.cpp:165] Memory required for data: 7044083712
I0407 11:00:59.899716  6158 layer_factory.hpp:77] Creating layer conv4a_pos
I0407 11:00:59.899737  6158 net.cpp:100] Creating Layer conv4a_pos
I0407 11:00:59.899747  6158 net.cpp:434] conv4a_pos <- pool3_pos
I0407 11:00:59.899758  6158 net.cpp:408] conv4a_pos -> conv4a_pos
I0407 11:00:59.953719  6158 net.cpp:150] Setting up conv4a_pos
I0407 11:00:59.953764  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.953769  6158 net.cpp:165] Memory required for data: 7058534400
I0407 11:00:59.953778  6158 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0407 11:00:59.953783  6158 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0407 11:00:59.953788  6158 layer_factory.hpp:77] Creating layer relu4a_pos
I0407 11:00:59.953814  6158 net.cpp:100] Creating Layer relu4a_pos
I0407 11:00:59.953820  6158 net.cpp:434] relu4a_pos <- conv4a_pos
I0407 11:00:59.953829  6158 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0407 11:00:59.954753  6158 net.cpp:150] Setting up relu4a_pos
I0407 11:00:59.954792  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:00:59.954797  6158 net.cpp:165] Memory required for data: 7072985088
I0407 11:00:59.954800  6158 layer_factory.hpp:77] Creating layer pool4_pos
I0407 11:00:59.954812  6158 net.cpp:100] Creating Layer pool4_pos
I0407 11:00:59.954814  6158 net.cpp:434] pool4_pos <- conv4a_pos
I0407 11:00:59.954821  6158 net.cpp:408] pool4_pos -> pool4_pos
I0407 11:00:59.955056  6158 net.cpp:150] Setting up pool4_pos
I0407 11:00:59.955067  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:00:59.955070  6158 net.cpp:165] Memory required for data: 7074791424
I0407 11:00:59.955073  6158 layer_factory.hpp:77] Creating layer conv5a_pos
I0407 11:00:59.955085  6158 net.cpp:100] Creating Layer conv5a_pos
I0407 11:00:59.955087  6158 net.cpp:434] conv5a_pos <- pool4_pos
I0407 11:00:59.955096  6158 net.cpp:408] conv5a_pos -> conv5a_pos
I0407 11:01:00.011126  6158 net.cpp:150] Setting up conv5a_pos
I0407 11:01:00.011174  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:01:00.011179  6158 net.cpp:165] Memory required for data: 7076597760
I0407 11:01:00.011188  6158 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0407 11:01:00.011194  6158 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0407 11:01:00.011199  6158 layer_factory.hpp:77] Creating layer relu5a_pos
I0407 11:01:00.011216  6158 net.cpp:100] Creating Layer relu5a_pos
I0407 11:01:00.011222  6158 net.cpp:434] relu5a_pos <- conv5a_pos
I0407 11:01:00.011229  6158 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0407 11:01:00.012126  6158 net.cpp:150] Setting up relu5a_pos
I0407 11:01:00.012138  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:01:00.012152  6158 net.cpp:165] Memory required for data: 7078404096
I0407 11:01:00.012159  6158 layer_factory.hpp:77] Creating layer pool5_pos
I0407 11:01:00.012168  6158 net.cpp:100] Creating Layer pool5_pos
I0407 11:01:00.012172  6158 net.cpp:434] pool5_pos <- conv5a_pos
I0407 11:01:00.012181  6158 net.cpp:408] pool5_pos -> pool5_pos
I0407 11:01:00.012406  6158 net.cpp:150] Setting up pool5_pos
I0407 11:01:00.012418  6158 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0407 11:01:00.012420  6158 net.cpp:165] Memory required for data: 7078699008
I0407 11:01:00.012423  6158 layer_factory.hpp:77] Creating layer fc6_pos
I0407 11:01:00.012434  6158 net.cpp:100] Creating Layer fc6_pos
I0407 11:01:00.012437  6158 net.cpp:434] fc6_pos <- pool5_pos
I0407 11:01:00.012444  6158 net.cpp:408] fc6_pos -> fc6_pos
I0407 11:01:00.328744  6158 net.cpp:150] Setting up fc6_pos
I0407 11:01:00.328778  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.328783  6158 net.cpp:165] Memory required for data: 7078846464
I0407 11:01:00.328794  6158 layer_factory.hpp:77] Creating layer relu6_pos
I0407 11:01:00.328827  6158 net.cpp:100] Creating Layer relu6_pos
I0407 11:01:00.328836  6158 net.cpp:434] relu6_pos <- fc6_pos
I0407 11:01:00.328843  6158 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0407 11:01:00.329975  6158 net.cpp:150] Setting up relu6_pos
I0407 11:01:00.329990  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.329994  6158 net.cpp:165] Memory required for data: 7078993920
I0407 11:01:00.329998  6158 layer_factory.hpp:77] Creating layer drop6_pos
I0407 11:01:00.330024  6158 net.cpp:100] Creating Layer drop6_pos
I0407 11:01:00.330029  6158 net.cpp:434] drop6_pos <- fc6_pos
I0407 11:01:00.330034  6158 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0407 11:01:00.330070  6158 net.cpp:150] Setting up drop6_pos
I0407 11:01:00.330077  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.330080  6158 net.cpp:165] Memory required for data: 7079141376
I0407 11:01:00.330085  6158 layer_factory.hpp:77] Creating layer fc7_pos
I0407 11:01:00.330093  6158 net.cpp:100] Creating Layer fc7_pos
I0407 11:01:00.330096  6158 net.cpp:434] fc7_pos <- fc6_pos
I0407 11:01:00.330102  6158 net.cpp:408] fc7_pos -> fc7_pos
I0407 11:01:00.479984  6158 net.cpp:150] Setting up fc7_pos
I0407 11:01:00.480043  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.480048  6158 net.cpp:165] Memory required for data: 7079288832
I0407 11:01:00.480062  6158 layer_factory.hpp:77] Creating layer relu7_pos
I0407 11:01:00.480089  6158 net.cpp:100] Creating Layer relu7_pos
I0407 11:01:00.480096  6158 net.cpp:434] relu7_pos <- fc7_pos
I0407 11:01:00.480104  6158 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0407 11:01:00.480375  6158 net.cpp:150] Setting up relu7_pos
I0407 11:01:00.480384  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.480388  6158 net.cpp:165] Memory required for data: 7079436288
I0407 11:01:00.480391  6158 layer_factory.hpp:77] Creating layer drop7_pos
I0407 11:01:00.480401  6158 net.cpp:100] Creating Layer drop7_pos
I0407 11:01:00.480404  6158 net.cpp:434] drop7_pos <- fc7_pos
I0407 11:01:00.480410  6158 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0407 11:01:00.480444  6158 net.cpp:150] Setting up drop7_pos
I0407 11:01:00.480450  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.480454  6158 net.cpp:165] Memory required for data: 7079583744
I0407 11:01:00.480458  6158 layer_factory.hpp:77] Creating layer conv1a_neg
I0407 11:01:00.480478  6158 net.cpp:100] Creating Layer conv1a_neg
I0407 11:01:00.480481  6158 net.cpp:434] conv1a_neg <- negative
I0407 11:01:00.480489  6158 net.cpp:408] conv1a_neg -> conv1a_neg
I0407 11:01:00.483805  6158 net.cpp:150] Setting up conv1a_neg
I0407 11:01:00.483821  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:01:00.483825  6158 net.cpp:165] Memory required for data: 8004427776
I0407 11:01:00.483831  6158 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0407 11:01:00.483837  6158 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0407 11:01:00.483841  6158 layer_factory.hpp:77] Creating layer relu1a_neg
I0407 11:01:00.483860  6158 net.cpp:100] Creating Layer relu1a_neg
I0407 11:01:00.483865  6158 net.cpp:434] relu1a_neg <- conv1a_neg
I0407 11:01:00.483871  6158 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0407 11:01:00.484776  6158 net.cpp:150] Setting up relu1a_neg
I0407 11:01:00.484791  6158 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0407 11:01:00.484796  6158 net.cpp:165] Memory required for data: 8929271808
I0407 11:01:00.484799  6158 layer_factory.hpp:77] Creating layer pool1_neg
I0407 11:01:00.484807  6158 net.cpp:100] Creating Layer pool1_neg
I0407 11:01:00.484812  6158 net.cpp:434] pool1_neg <- conv1a_neg
I0407 11:01:00.484818  6158 net.cpp:408] pool1_neg -> pool1_neg
I0407 11:01:00.485056  6158 net.cpp:150] Setting up pool1_neg
I0407 11:01:00.485067  6158 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0407 11:01:00.485072  6158 net.cpp:165] Memory required for data: 9160482816
I0407 11:01:00.485075  6158 layer_factory.hpp:77] Creating layer conv2a_neg
I0407 11:01:00.485093  6158 net.cpp:100] Creating Layer conv2a_neg
I0407 11:01:00.485098  6158 net.cpp:434] conv2a_neg <- pool1_neg
I0407 11:01:00.485106  6158 net.cpp:408] conv2a_neg -> conv2a_neg
I0407 11:01:00.501109  6158 net.cpp:150] Setting up conv2a_neg
I0407 11:01:00.501148  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:01:00.501154  6158 net.cpp:165] Memory required for data: 9622904832
I0407 11:01:00.501164  6158 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0407 11:01:00.501173  6158 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0407 11:01:00.501179  6158 layer_factory.hpp:77] Creating layer relu2a_neg
I0407 11:01:00.501199  6158 net.cpp:100] Creating Layer relu2a_neg
I0407 11:01:00.501209  6158 net.cpp:434] relu2a_neg <- conv2a_neg
I0407 11:01:00.501219  6158 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0407 11:01:00.502596  6158 net.cpp:150] Setting up relu2a_neg
I0407 11:01:00.502615  6158 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0407 11:01:00.502622  6158 net.cpp:165] Memory required for data: 10085326848
I0407 11:01:00.502629  6158 layer_factory.hpp:77] Creating layer pool2_neg
I0407 11:01:00.502673  6158 net.cpp:100] Creating Layer pool2_neg
I0407 11:01:00.502681  6158 net.cpp:434] pool2_neg <- conv2a_neg
I0407 11:01:00.502692  6158 net.cpp:408] pool2_neg -> pool2_neg
I0407 11:01:00.503027  6158 net.cpp:150] Setting up pool2_neg
I0407 11:01:00.503042  6158 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0407 11:01:00.503056  6158 net.cpp:165] Memory required for data: 10143129600
I0407 11:01:00.503060  6158 layer_factory.hpp:77] Creating layer conv3a_neg
I0407 11:01:00.503082  6158 net.cpp:100] Creating Layer conv3a_neg
I0407 11:01:00.503088  6158 net.cpp:434] conv3a_neg <- pool2_neg
I0407 11:01:00.503100  6158 net.cpp:408] conv3a_neg -> conv3a_neg
I0407 11:01:00.547031  6158 net.cpp:150] Setting up conv3a_neg
I0407 11:01:00.547065  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:01:00.547068  6158 net.cpp:165] Memory required for data: 10258735104
I0407 11:01:00.547091  6158 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0407 11:01:00.547114  6158 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0407 11:01:00.547122  6158 layer_factory.hpp:77] Creating layer relu3a_neg
I0407 11:01:00.547134  6158 net.cpp:100] Creating Layer relu3a_neg
I0407 11:01:00.547142  6158 net.cpp:434] relu3a_neg <- conv3a_neg
I0407 11:01:00.547148  6158 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0407 11:01:00.547361  6158 net.cpp:150] Setting up relu3a_neg
I0407 11:01:00.547372  6158 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0407 11:01:00.547376  6158 net.cpp:165] Memory required for data: 10374340608
I0407 11:01:00.547380  6158 layer_factory.hpp:77] Creating layer pool3_neg
I0407 11:01:00.547389  6158 net.cpp:100] Creating Layer pool3_neg
I0407 11:01:00.547395  6158 net.cpp:434] pool3_neg <- conv3a_neg
I0407 11:01:00.547401  6158 net.cpp:408] pool3_neg -> pool3_neg
I0407 11:01:00.549064  6158 net.cpp:150] Setting up pool3_neg
I0407 11:01:00.549082  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:01:00.549088  6158 net.cpp:165] Memory required for data: 10388791296
I0407 11:01:00.549093  6158 layer_factory.hpp:77] Creating layer conv4a_neg
I0407 11:01:00.549132  6158 net.cpp:100] Creating Layer conv4a_neg
I0407 11:01:00.549139  6158 net.cpp:434] conv4a_neg <- pool3_neg
I0407 11:01:00.549147  6158 net.cpp:408] conv4a_neg -> conv4a_neg
I0407 11:01:00.616055  6158 net.cpp:150] Setting up conv4a_neg
I0407 11:01:00.616091  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:01:00.616096  6158 net.cpp:165] Memory required for data: 10403241984
I0407 11:01:00.616106  6158 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0407 11:01:00.616114  6158 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0407 11:01:00.616123  6158 layer_factory.hpp:77] Creating layer relu4a_neg
I0407 11:01:00.616137  6158 net.cpp:100] Creating Layer relu4a_neg
I0407 11:01:00.616143  6158 net.cpp:434] relu4a_neg <- conv4a_neg
I0407 11:01:00.616153  6158 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0407 11:01:00.616363  6158 net.cpp:150] Setting up relu4a_neg
I0407 11:01:00.616372  6158 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0407 11:01:00.616379  6158 net.cpp:165] Memory required for data: 10417692672
I0407 11:01:00.616384  6158 layer_factory.hpp:77] Creating layer pool4_neg
I0407 11:01:00.616394  6158 net.cpp:100] Creating Layer pool4_neg
I0407 11:01:00.616400  6158 net.cpp:434] pool4_neg <- conv4a_neg
I0407 11:01:00.616407  6158 net.cpp:408] pool4_neg -> pool4_neg
I0407 11:01:00.617460  6158 net.cpp:150] Setting up pool4_neg
I0407 11:01:00.617475  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:01:00.617478  6158 net.cpp:165] Memory required for data: 10419499008
I0407 11:01:00.617485  6158 layer_factory.hpp:77] Creating layer conv5a_neg
I0407 11:01:00.617512  6158 net.cpp:100] Creating Layer conv5a_neg
I0407 11:01:00.617518  6158 net.cpp:434] conv5a_neg <- pool4_neg
I0407 11:01:00.617527  6158 net.cpp:408] conv5a_neg -> conv5a_neg
I0407 11:01:00.680145  6158 net.cpp:150] Setting up conv5a_neg
I0407 11:01:00.680178  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:01:00.680182  6158 net.cpp:165] Memory required for data: 10421305344
I0407 11:01:00.680191  6158 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0407 11:01:00.680198  6158 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0407 11:01:00.680203  6158 layer_factory.hpp:77] Creating layer relu5a_neg
I0407 11:01:00.680214  6158 net.cpp:100] Creating Layer relu5a_neg
I0407 11:01:00.680220  6158 net.cpp:434] relu5a_neg <- conv5a_neg
I0407 11:01:00.680228  6158 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0407 11:01:00.680434  6158 net.cpp:150] Setting up relu5a_neg
I0407 11:01:00.680445  6158 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0407 11:01:00.680449  6158 net.cpp:165] Memory required for data: 10423111680
I0407 11:01:00.680454  6158 layer_factory.hpp:77] Creating layer pool5_neg
I0407 11:01:00.680469  6158 net.cpp:100] Creating Layer pool5_neg
I0407 11:01:00.680472  6158 net.cpp:434] pool5_neg <- conv5a_neg
I0407 11:01:00.680480  6158 net.cpp:408] pool5_neg -> pool5_neg
I0407 11:01:00.681473  6158 net.cpp:150] Setting up pool5_neg
I0407 11:01:00.681486  6158 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0407 11:01:00.681490  6158 net.cpp:165] Memory required for data: 10423406592
I0407 11:01:00.681494  6158 layer_factory.hpp:77] Creating layer fc6_neg
I0407 11:01:00.681504  6158 net.cpp:100] Creating Layer fc6_neg
I0407 11:01:00.681509  6158 net.cpp:434] fc6_neg <- pool5_neg
I0407 11:01:00.681516  6158 net.cpp:408] fc6_neg -> fc6_neg
I0407 11:01:00.996145  6158 net.cpp:150] Setting up fc6_neg
I0407 11:01:00.996177  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.996182  6158 net.cpp:165] Memory required for data: 10423554048
I0407 11:01:00.996193  6158 layer_factory.hpp:77] Creating layer relu6_neg
I0407 11:01:00.996214  6158 net.cpp:100] Creating Layer relu6_neg
I0407 11:01:00.996222  6158 net.cpp:434] relu6_neg <- fc6_neg
I0407 11:01:00.996228  6158 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0407 11:01:00.996507  6158 net.cpp:150] Setting up relu6_neg
I0407 11:01:00.996518  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.996522  6158 net.cpp:165] Memory required for data: 10423701504
I0407 11:01:00.996526  6158 layer_factory.hpp:77] Creating layer drop6_neg
I0407 11:01:00.996544  6158 net.cpp:100] Creating Layer drop6_neg
I0407 11:01:00.996551  6158 net.cpp:434] drop6_neg <- fc6_neg
I0407 11:01:00.996556  6158 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0407 11:01:00.996593  6158 net.cpp:150] Setting up drop6_neg
I0407 11:01:00.996601  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:00.996604  6158 net.cpp:165] Memory required for data: 10423848960
I0407 11:01:00.996609  6158 layer_factory.hpp:77] Creating layer fc7_neg
I0407 11:01:00.996623  6158 net.cpp:100] Creating Layer fc7_neg
I0407 11:01:00.996628  6158 net.cpp:434] fc7_neg <- fc6_neg
I0407 11:01:00.996634  6158 net.cpp:408] fc7_neg -> fc7_neg
I0407 11:01:01.148486  6158 net.cpp:150] Setting up fc7_neg
I0407 11:01:01.148527  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:01.148535  6158 net.cpp:165] Memory required for data: 10423996416
I0407 11:01:01.148552  6158 layer_factory.hpp:77] Creating layer relu7_neg
I0407 11:01:01.148567  6158 net.cpp:100] Creating Layer relu7_neg
I0407 11:01:01.148576  6158 net.cpp:434] relu7_neg <- fc7_neg
I0407 11:01:01.148587  6158 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0407 11:01:01.149940  6158 net.cpp:150] Setting up relu7_neg
I0407 11:01:01.149955  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:01.149958  6158 net.cpp:165] Memory required for data: 10424143872
I0407 11:01:01.149963  6158 layer_factory.hpp:77] Creating layer drop7_neg
I0407 11:01:01.149986  6158 net.cpp:100] Creating Layer drop7_neg
I0407 11:01:01.149991  6158 net.cpp:434] drop7_neg <- fc7_neg
I0407 11:01:01.149996  6158 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0407 11:01:01.150063  6158 net.cpp:150] Setting up drop7_neg
I0407 11:01:01.150073  6158 net.cpp:157] Top shape: 18 2048 (36864)
I0407 11:01:01.150076  6158 net.cpp:165] Memory required for data: 10424291328
I0407 11:01:01.150079  6158 layer_factory.hpp:77] Creating layer loss
I0407 11:01:01.161432  6158 net.cpp:100] Creating Layer loss
I0407 11:01:01.161448  6158 net.cpp:434] loss <- fc7
I0407 11:01:01.161454  6158 net.cpp:434] loss <- fc7_pos
I0407 11:01:01.161458  6158 net.cpp:434] loss <- fc7_neg
I0407 11:01:01.161464  6158 net.cpp:408] loss -> loss
I0407 11:01:01.161552  6158 net.cpp:150] Setting up loss
I0407 11:01:01.161561  6158 net.cpp:157] Top shape: (1)
I0407 11:01:01.161566  6158 net.cpp:160]     with loss weight 1
I0407 11:01:01.161597  6158 net.cpp:165] Memory required for data: 10424291332
I0407 11:01:01.161600  6158 net.cpp:226] loss needs backward computation.
I0407 11:01:01.161604  6158 net.cpp:226] drop7_neg needs backward computation.
I0407 11:01:01.161607  6158 net.cpp:226] relu7_neg needs backward computation.
I0407 11:01:01.161610  6158 net.cpp:226] fc7_neg needs backward computation.
I0407 11:01:01.161614  6158 net.cpp:226] drop6_neg needs backward computation.
I0407 11:01:01.161617  6158 net.cpp:226] relu6_neg needs backward computation.
I0407 11:01:01.161622  6158 net.cpp:226] fc6_neg needs backward computation.
I0407 11:01:01.161625  6158 net.cpp:226] pool5_neg needs backward computation.
I0407 11:01:01.161628  6158 net.cpp:226] relu5a_neg needs backward computation.
I0407 11:01:01.161633  6158 net.cpp:226] conv5a_neg needs backward computation.
I0407 11:01:01.161635  6158 net.cpp:226] pool4_neg needs backward computation.
I0407 11:01:01.161639  6158 net.cpp:226] relu4a_neg needs backward computation.
I0407 11:01:01.161643  6158 net.cpp:226] conv4a_neg needs backward computation.
I0407 11:01:01.161646  6158 net.cpp:226] pool3_neg needs backward computation.
I0407 11:01:01.161649  6158 net.cpp:226] relu3a_neg needs backward computation.
I0407 11:01:01.161653  6158 net.cpp:226] conv3a_neg needs backward computation.
I0407 11:01:01.161662  6158 net.cpp:226] pool2_neg needs backward computation.
I0407 11:01:01.161665  6158 net.cpp:226] relu2a_neg needs backward computation.
I0407 11:01:01.161669  6158 net.cpp:226] conv2a_neg needs backward computation.
I0407 11:01:01.161674  6158 net.cpp:226] pool1_neg needs backward computation.
I0407 11:01:01.161676  6158 net.cpp:226] relu1a_neg needs backward computation.
I0407 11:01:01.161679  6158 net.cpp:226] conv1a_neg needs backward computation.
I0407 11:01:01.161684  6158 net.cpp:226] drop7_pos needs backward computation.
I0407 11:01:01.161686  6158 net.cpp:226] relu7_pos needs backward computation.
I0407 11:01:01.161690  6158 net.cpp:226] fc7_pos needs backward computation.
I0407 11:01:01.161694  6158 net.cpp:226] drop6_pos needs backward computation.
I0407 11:01:01.161697  6158 net.cpp:226] relu6_pos needs backward computation.
I0407 11:01:01.161700  6158 net.cpp:226] fc6_pos needs backward computation.
I0407 11:01:01.161705  6158 net.cpp:226] pool5_pos needs backward computation.
I0407 11:01:01.161708  6158 net.cpp:226] relu5a_pos needs backward computation.
I0407 11:01:01.161712  6158 net.cpp:226] conv5a_pos needs backward computation.
I0407 11:01:01.161715  6158 net.cpp:226] pool4_pos needs backward computation.
I0407 11:01:01.161720  6158 net.cpp:226] relu4a_pos needs backward computation.
I0407 11:01:01.161722  6158 net.cpp:226] conv4a_pos needs backward computation.
I0407 11:01:01.161726  6158 net.cpp:226] pool3_pos needs backward computation.
I0407 11:01:01.161731  6158 net.cpp:226] relu3a_pos needs backward computation.
I0407 11:01:01.161734  6158 net.cpp:226] conv3a_pos needs backward computation.
I0407 11:01:01.161738  6158 net.cpp:226] pool2_pos needs backward computation.
I0407 11:01:01.161742  6158 net.cpp:226] relu2a_pos needs backward computation.
I0407 11:01:01.161746  6158 net.cpp:226] conv2a_pos needs backward computation.
I0407 11:01:01.161749  6158 net.cpp:226] pool1_pos needs backward computation.
I0407 11:01:01.161753  6158 net.cpp:226] relu1a_pos needs backward computation.
I0407 11:01:01.161780  6158 net.cpp:226] conv1a_pos needs backward computation.
I0407 11:01:01.161785  6158 net.cpp:226] drop7 needs backward computation.
I0407 11:01:01.161788  6158 net.cpp:226] relu7 needs backward computation.
I0407 11:01:01.161792  6158 net.cpp:226] fc7 needs backward computation.
I0407 11:01:01.161795  6158 net.cpp:226] drop6 needs backward computation.
I0407 11:01:01.161799  6158 net.cpp:226] relu6 needs backward computation.
I0407 11:01:01.161803  6158 net.cpp:226] fc6 needs backward computation.
I0407 11:01:01.161808  6158 net.cpp:226] pool5 needs backward computation.
I0407 11:01:01.161811  6158 net.cpp:226] relu5a needs backward computation.
I0407 11:01:01.161814  6158 net.cpp:226] conv5a needs backward computation.
I0407 11:01:01.161818  6158 net.cpp:226] pool4 needs backward computation.
I0407 11:01:01.161823  6158 net.cpp:226] relu4a needs backward computation.
I0407 11:01:01.161825  6158 net.cpp:226] conv4a needs backward computation.
I0407 11:01:01.161829  6158 net.cpp:226] pool3 needs backward computation.
I0407 11:01:01.161834  6158 net.cpp:226] relu3a needs backward computation.
I0407 11:01:01.161837  6158 net.cpp:226] conv3a needs backward computation.
I0407 11:01:01.161841  6158 net.cpp:226] pool2 needs backward computation.
I0407 11:01:01.161845  6158 net.cpp:226] relu2a needs backward computation.
I0407 11:01:01.161849  6158 net.cpp:226] conv2a needs backward computation.
I0407 11:01:01.161854  6158 net.cpp:226] pool1 needs backward computation.
I0407 11:01:01.161857  6158 net.cpp:226] relu1a needs backward computation.
I0407 11:01:01.161861  6158 net.cpp:226] conv1a needs backward computation.
I0407 11:01:01.161883  6158 net.cpp:228] reshape_negative does not need backward computation.
I0407 11:01:01.161888  6158 net.cpp:228] reshape_positive does not need backward computation.
I0407 11:01:01.161893  6158 net.cpp:228] reshape_anchor does not need backward computation.
I0407 11:01:01.161898  6158 net.cpp:228] slicer does not need backward computation.
I0407 11:01:01.161902  6158 net.cpp:228] data does not need backward computation.
I0407 11:01:01.161906  6158 net.cpp:270] This network produces output loss
I0407 11:01:01.176964  6158 net.cpp:283] Network initialization done.
I0407 11:01:01.179769  6158 solver.cpp:181] Creating test net (#0) specified by net file: train_test.prototxt
I0407 11:01:01.179880  6158 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0407 11:01:01.180552  6158 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams"
state {
  phase: TEST
  stage: "test-on-val"
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  include {
    phase: TEST
    stage: "test-on-val"
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/val"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "TripletLoss"
  bottom: "fc7"
  bottom: "fc7_pos"
  bottom: "fc7_neg"
  top: "loss"
  threshold_param {
    threshold: 1
  }
}
I0407 11:01:01.180804  6158 layer_factory.hpp:77] Creating layer data
I0407 11:01:01.180878  6158 net.cpp:100] Creating Layer data
I0407 11:01:01.180886  6158 net.cpp:408] data -> triplet
I0407 11:01:01.213165  6166 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/val
I0407 11:01:01.334048  6158 data_layer.cpp:41] output data size: 1,144,112,112
I0407 11:01:01.351596  6158 net.cpp:150] Setting up data
I0407 11:01:01.351634  6158 net.cpp:157] Top shape: 1 144 112 112 (1806336)
I0407 11:01:01.351639  6158 net.cpp:165] Memory required for data: 7225344
I0407 11:01:01.351645  6158 layer_factory.hpp:77] Creating layer slicer
I0407 11:01:01.351696  6158 net.cpp:100] Creating Layer slicer
I0407 11:01:01.351708  6158 net.cpp:434] slicer <- triplet
I0407 11:01:01.351722  6158 net.cpp:408] slicer -> anchor_stacked
I0407 11:01:01.351738  6158 net.cpp:408] slicer -> positive_stacked
I0407 11:01:01.351752  6158 net.cpp:408] slicer -> negative_stacked
I0407 11:01:01.351907  6158 net.cpp:150] Setting up slicer
I0407 11:01:01.351918  6158 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0407 11:01:01.351923  6158 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0407 11:01:01.351927  6158 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0407 11:01:01.351932  6158 net.cpp:165] Memory required for data: 14450688
I0407 11:01:01.351938  6158 layer_factory.hpp:77] Creating layer reshape_anchor
I0407 11:01:01.351951  6158 net.cpp:100] Creating Layer reshape_anchor
I0407 11:01:01.351958  6158 net.cpp:434] reshape_anchor <- anchor_stacked
I0407 11:01:01.351968  6158 net.cpp:408] reshape_anchor -> anchor
I0407 11:01:01.352022  6158 net.cpp:150] Setting up reshape_anchor
I0407 11:01:01.352035  6158 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0407 11:01:01.352043  6158 net.cpp:165] Memory required for data: 16859136
I0407 11:01:01.352049  6158 layer_factory.hpp:77] Creating layer reshape_positive
I0407 11:01:01.352061  6158 net.cpp:100] Creating Layer reshape_positive
I0407 11:01:01.352093  6158 net.cpp:434] reshape_positive <- positive_stacked
I0407 11:01:01.352108  6158 net.cpp:408] reshape_positive -> positive
I0407 11:01:01.352162  6158 net.cpp:150] Setting up reshape_positive
I0407 11:01:01.352176  6158 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0407 11:01:01.352183  6158 net.cpp:165] Memory required for data: 19267584
I0407 11:01:01.352190  6158 layer_factory.hpp:77] Creating layer reshape_negative
I0407 11:01:01.352200  6158 net.cpp:100] Creating Layer reshape_negative
I0407 11:01:01.352208  6158 net.cpp:434] reshape_negative <- negative_stacked
I0407 11:01:01.352218  6158 net.cpp:408] reshape_negative -> negative
I0407 11:01:01.352268  6158 net.cpp:150] Setting up reshape_negative
I0407 11:01:01.352298  6158 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0407 11:01:01.352308  6158 net.cpp:165] Memory required for data: 21676032
I0407 11:01:01.352313  6158 layer_factory.hpp:77] Creating layer conv1a
I0407 11:01:01.352330  6158 net.cpp:100] Creating Layer conv1a
I0407 11:01:01.352336  6158 net.cpp:434] conv1a <- anchor
I0407 11:01:01.352347  6158 net.cpp:408] conv1a -> conv1a
I0407 11:01:01.358211  6158 net.cpp:150] Setting up conv1a
I0407 11:01:01.358245  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:01.358252  6158 net.cpp:165] Memory required for data: 73056256
I0407 11:01:01.358270  6158 layer_factory.hpp:77] Creating layer relu1a
I0407 11:01:01.358286  6158 net.cpp:100] Creating Layer relu1a
I0407 11:01:01.358294  6158 net.cpp:434] relu1a <- conv1a
I0407 11:01:01.358302  6158 net.cpp:395] relu1a -> conv1a (in-place)
I0407 11:01:01.358588  6158 net.cpp:150] Setting up relu1a
I0407 11:01:01.358602  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:01.358608  6158 net.cpp:165] Memory required for data: 124436480
I0407 11:01:01.358613  6158 layer_factory.hpp:77] Creating layer pool1
I0407 11:01:01.358625  6158 net.cpp:100] Creating Layer pool1
I0407 11:01:01.358633  6158 net.cpp:434] pool1 <- conv1a
I0407 11:01:01.358641  6158 net.cpp:408] pool1 -> pool1
I0407 11:01:01.359817  6158 net.cpp:150] Setting up pool1
I0407 11:01:01.359835  6158 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0407 11:01:01.359841  6158 net.cpp:165] Memory required for data: 137281536
I0407 11:01:01.359848  6158 layer_factory.hpp:77] Creating layer conv2a
I0407 11:01:01.359865  6158 net.cpp:100] Creating Layer conv2a
I0407 11:01:01.359874  6158 net.cpp:434] conv2a <- pool1
I0407 11:01:01.359884  6158 net.cpp:408] conv2a -> conv2a
I0407 11:01:01.371840  6158 net.cpp:150] Setting up conv2a
I0407 11:01:01.371870  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:01.371875  6158 net.cpp:165] Memory required for data: 162971648
I0407 11:01:01.371908  6158 layer_factory.hpp:77] Creating layer relu2a
I0407 11:01:01.371922  6158 net.cpp:100] Creating Layer relu2a
I0407 11:01:01.371927  6158 net.cpp:434] relu2a <- conv2a
I0407 11:01:01.371934  6158 net.cpp:395] relu2a -> conv2a (in-place)
I0407 11:01:01.378448  6158 net.cpp:150] Setting up relu2a
I0407 11:01:01.378469  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:01.378474  6158 net.cpp:165] Memory required for data: 188661760
I0407 11:01:01.378480  6158 layer_factory.hpp:77] Creating layer pool2
I0407 11:01:01.378494  6158 net.cpp:100] Creating Layer pool2
I0407 11:01:01.378499  6158 net.cpp:434] pool2 <- conv2a
I0407 11:01:01.378507  6158 net.cpp:408] pool2 -> pool2
I0407 11:01:01.381750  6158 net.cpp:150] Setting up pool2
I0407 11:01:01.381768  6158 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0407 11:01:01.381774  6158 net.cpp:165] Memory required for data: 191873024
I0407 11:01:01.381778  6158 layer_factory.hpp:77] Creating layer conv3a
I0407 11:01:01.381793  6158 net.cpp:100] Creating Layer conv3a
I0407 11:01:01.381798  6158 net.cpp:434] conv3a <- pool2
I0407 11:01:01.381805  6158 net.cpp:408] conv3a -> conv3a
I0407 11:01:01.416725  6158 net.cpp:150] Setting up conv3a
I0407 11:01:01.416759  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:01.416764  6158 net.cpp:165] Memory required for data: 198295552
I0407 11:01:01.416779  6158 layer_factory.hpp:77] Creating layer relu3a
I0407 11:01:01.416791  6158 net.cpp:100] Creating Layer relu3a
I0407 11:01:01.416797  6158 net.cpp:434] relu3a <- conv3a
I0407 11:01:01.416805  6158 net.cpp:395] relu3a -> conv3a (in-place)
I0407 11:01:01.417742  6158 net.cpp:150] Setting up relu3a
I0407 11:01:01.417755  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:01.417759  6158 net.cpp:165] Memory required for data: 204718080
I0407 11:01:01.417764  6158 layer_factory.hpp:77] Creating layer pool3
I0407 11:01:01.417775  6158 net.cpp:100] Creating Layer pool3
I0407 11:01:01.417780  6158 net.cpp:434] pool3 <- conv3a
I0407 11:01:01.417788  6158 net.cpp:408] pool3 -> pool3
I0407 11:01:01.418045  6158 net.cpp:150] Setting up pool3
I0407 11:01:01.418056  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:01.418059  6158 net.cpp:165] Memory required for data: 205520896
I0407 11:01:01.418063  6158 layer_factory.hpp:77] Creating layer conv4a
I0407 11:01:01.418073  6158 net.cpp:100] Creating Layer conv4a
I0407 11:01:01.418078  6158 net.cpp:434] conv4a <- pool3
I0407 11:01:01.418087  6158 net.cpp:408] conv4a -> conv4a
I0407 11:01:01.485337  6158 net.cpp:150] Setting up conv4a
I0407 11:01:01.485386  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:01.485391  6158 net.cpp:165] Memory required for data: 206323712
I0407 11:01:01.485406  6158 layer_factory.hpp:77] Creating layer relu4a
I0407 11:01:01.485421  6158 net.cpp:100] Creating Layer relu4a
I0407 11:01:01.485429  6158 net.cpp:434] relu4a <- conv4a
I0407 11:01:01.485436  6158 net.cpp:395] relu4a -> conv4a (in-place)
I0407 11:01:01.486634  6158 net.cpp:150] Setting up relu4a
I0407 11:01:01.486654  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:01.486660  6158 net.cpp:165] Memory required for data: 207126528
I0407 11:01:01.486665  6158 layer_factory.hpp:77] Creating layer pool4
I0407 11:01:01.486683  6158 net.cpp:100] Creating Layer pool4
I0407 11:01:01.486687  6158 net.cpp:434] pool4 <- conv4a
I0407 11:01:01.486696  6158 net.cpp:408] pool4 -> pool4
I0407 11:01:01.486948  6158 net.cpp:150] Setting up pool4
I0407 11:01:01.486956  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:01.486960  6158 net.cpp:165] Memory required for data: 207226880
I0407 11:01:01.486964  6158 layer_factory.hpp:77] Creating layer conv5a
I0407 11:01:01.486975  6158 net.cpp:100] Creating Layer conv5a
I0407 11:01:01.486979  6158 net.cpp:434] conv5a <- pool4
I0407 11:01:01.486986  6158 net.cpp:408] conv5a -> conv5a
I0407 11:01:01.564573  6158 net.cpp:150] Setting up conv5a
I0407 11:01:01.564604  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:01.564638  6158 net.cpp:165] Memory required for data: 207327232
I0407 11:01:01.564669  6158 layer_factory.hpp:77] Creating layer relu5a
I0407 11:01:01.564687  6158 net.cpp:100] Creating Layer relu5a
I0407 11:01:01.564694  6158 net.cpp:434] relu5a <- conv5a
I0407 11:01:01.564703  6158 net.cpp:395] relu5a -> conv5a (in-place)
I0407 11:01:01.565762  6158 net.cpp:150] Setting up relu5a
I0407 11:01:01.565781  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:01.565791  6158 net.cpp:165] Memory required for data: 207427584
I0407 11:01:01.565798  6158 layer_factory.hpp:77] Creating layer pool5
I0407 11:01:01.565814  6158 net.cpp:100] Creating Layer pool5
I0407 11:01:01.565822  6158 net.cpp:434] pool5 <- conv5a
I0407 11:01:01.565835  6158 net.cpp:408] pool5 -> pool5
I0407 11:01:01.566217  6158 net.cpp:150] Setting up pool5
I0407 11:01:01.566236  6158 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0407 11:01:01.566242  6158 net.cpp:165] Memory required for data: 207443968
I0407 11:01:01.566251  6158 layer_factory.hpp:77] Creating layer fc6
I0407 11:01:01.566268  6158 net.cpp:100] Creating Layer fc6
I0407 11:01:01.566277  6158 net.cpp:434] fc6 <- pool5
I0407 11:01:01.566287  6158 net.cpp:408] fc6 -> fc6
I0407 11:01:01.870568  6158 net.cpp:150] Setting up fc6
I0407 11:01:01.870602  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:01.870607  6158 net.cpp:165] Memory required for data: 207452160
I0407 11:01:01.870618  6158 layer_factory.hpp:77] Creating layer relu6
I0407 11:01:01.870630  6158 net.cpp:100] Creating Layer relu6
I0407 11:01:01.870635  6158 net.cpp:434] relu6 <- fc6
I0407 11:01:01.870643  6158 net.cpp:395] relu6 -> fc6 (in-place)
I0407 11:01:01.871855  6158 net.cpp:150] Setting up relu6
I0407 11:01:01.871871  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:01.871876  6158 net.cpp:165] Memory required for data: 207460352
I0407 11:01:01.871881  6158 layer_factory.hpp:77] Creating layer drop6
I0407 11:01:01.871889  6158 net.cpp:100] Creating Layer drop6
I0407 11:01:01.871893  6158 net.cpp:434] drop6 <- fc6
I0407 11:01:01.871899  6158 net.cpp:395] drop6 -> fc6 (in-place)
I0407 11:01:01.871948  6158 net.cpp:150] Setting up drop6
I0407 11:01:01.871955  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:01.871959  6158 net.cpp:165] Memory required for data: 207468544
I0407 11:01:01.871963  6158 layer_factory.hpp:77] Creating layer fc7
I0407 11:01:01.871978  6158 net.cpp:100] Creating Layer fc7
I0407 11:01:01.871984  6158 net.cpp:434] fc7 <- fc6
I0407 11:01:01.871991  6158 net.cpp:408] fc7 -> fc7
I0407 11:01:02.026332  6158 net.cpp:150] Setting up fc7
I0407 11:01:02.026367  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.026372  6158 net.cpp:165] Memory required for data: 207476736
I0407 11:01:02.026384  6158 layer_factory.hpp:77] Creating layer relu7
I0407 11:01:02.026396  6158 net.cpp:100] Creating Layer relu7
I0407 11:01:02.026401  6158 net.cpp:434] relu7 <- fc7
I0407 11:01:02.026408  6158 net.cpp:395] relu7 -> fc7 (in-place)
I0407 11:01:02.026726  6158 net.cpp:150] Setting up relu7
I0407 11:01:02.026739  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.026743  6158 net.cpp:165] Memory required for data: 207484928
I0407 11:01:02.026748  6158 layer_factory.hpp:77] Creating layer drop7
I0407 11:01:02.026762  6158 net.cpp:100] Creating Layer drop7
I0407 11:01:02.026767  6158 net.cpp:434] drop7 <- fc7
I0407 11:01:02.026772  6158 net.cpp:395] drop7 -> fc7 (in-place)
I0407 11:01:02.026813  6158 net.cpp:150] Setting up drop7
I0407 11:01:02.026821  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.026824  6158 net.cpp:165] Memory required for data: 207493120
I0407 11:01:02.026829  6158 layer_factory.hpp:77] Creating layer conv1a_pos
I0407 11:01:02.026839  6158 net.cpp:100] Creating Layer conv1a_pos
I0407 11:01:02.026845  6158 net.cpp:434] conv1a_pos <- positive
I0407 11:01:02.026854  6158 net.cpp:408] conv1a_pos -> conv1a_pos
I0407 11:01:02.030349  6158 net.cpp:150] Setting up conv1a_pos
I0407 11:01:02.030370  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:02.030397  6158 net.cpp:165] Memory required for data: 258873344
I0407 11:01:02.030405  6158 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0407 11:01:02.030411  6158 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0407 11:01:02.030414  6158 layer_factory.hpp:77] Creating layer relu1a_pos
I0407 11:01:02.030426  6158 net.cpp:100] Creating Layer relu1a_pos
I0407 11:01:02.030431  6158 net.cpp:434] relu1a_pos <- conv1a_pos
I0407 11:01:02.030437  6158 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0407 11:01:02.032039  6158 net.cpp:150] Setting up relu1a_pos
I0407 11:01:02.032057  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:02.032060  6158 net.cpp:165] Memory required for data: 310253568
I0407 11:01:02.032064  6158 layer_factory.hpp:77] Creating layer pool1_pos
I0407 11:01:02.032074  6158 net.cpp:100] Creating Layer pool1_pos
I0407 11:01:02.032078  6158 net.cpp:434] pool1_pos <- conv1a_pos
I0407 11:01:02.032085  6158 net.cpp:408] pool1_pos -> pool1_pos
I0407 11:01:02.032341  6158 net.cpp:150] Setting up pool1_pos
I0407 11:01:02.032352  6158 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0407 11:01:02.032356  6158 net.cpp:165] Memory required for data: 323098624
I0407 11:01:02.032359  6158 layer_factory.hpp:77] Creating layer conv2a_pos
I0407 11:01:02.032371  6158 net.cpp:100] Creating Layer conv2a_pos
I0407 11:01:02.032374  6158 net.cpp:434] conv2a_pos <- pool1_pos
I0407 11:01:02.032382  6158 net.cpp:408] conv2a_pos -> conv2a_pos
I0407 11:01:02.047170  6158 net.cpp:150] Setting up conv2a_pos
I0407 11:01:02.047197  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:02.047202  6158 net.cpp:165] Memory required for data: 348788736
I0407 11:01:02.047214  6158 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0407 11:01:02.047220  6158 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0407 11:01:02.047225  6158 layer_factory.hpp:77] Creating layer relu2a_pos
I0407 11:01:02.047245  6158 net.cpp:100] Creating Layer relu2a_pos
I0407 11:01:02.047251  6158 net.cpp:434] relu2a_pos <- conv2a_pos
I0407 11:01:02.047260  6158 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0407 11:01:02.047472  6158 net.cpp:150] Setting up relu2a_pos
I0407 11:01:02.047484  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:02.047488  6158 net.cpp:165] Memory required for data: 374478848
I0407 11:01:02.047494  6158 layer_factory.hpp:77] Creating layer pool2_pos
I0407 11:01:02.047504  6158 net.cpp:100] Creating Layer pool2_pos
I0407 11:01:02.047508  6158 net.cpp:434] pool2_pos <- conv2a_pos
I0407 11:01:02.047514  6158 net.cpp:408] pool2_pos -> pool2_pos
I0407 11:01:02.050745  6158 net.cpp:150] Setting up pool2_pos
I0407 11:01:02.050762  6158 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0407 11:01:02.050767  6158 net.cpp:165] Memory required for data: 377690112
I0407 11:01:02.050771  6158 layer_factory.hpp:77] Creating layer conv3a_pos
I0407 11:01:02.050794  6158 net.cpp:100] Creating Layer conv3a_pos
I0407 11:01:02.050801  6158 net.cpp:434] conv3a_pos <- pool2_pos
I0407 11:01:02.050809  6158 net.cpp:408] conv3a_pos -> conv3a_pos
I0407 11:01:02.084033  6158 net.cpp:150] Setting up conv3a_pos
I0407 11:01:02.084054  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:02.084059  6158 net.cpp:165] Memory required for data: 384112640
I0407 11:01:02.084064  6158 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0407 11:01:02.084070  6158 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0407 11:01:02.084074  6158 layer_factory.hpp:77] Creating layer relu3a_pos
I0407 11:01:02.084085  6158 net.cpp:100] Creating Layer relu3a_pos
I0407 11:01:02.084094  6158 net.cpp:434] relu3a_pos <- conv3a_pos
I0407 11:01:02.084102  6158 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0407 11:01:02.084317  6158 net.cpp:150] Setting up relu3a_pos
I0407 11:01:02.084347  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:02.084350  6158 net.cpp:165] Memory required for data: 390535168
I0407 11:01:02.084354  6158 layer_factory.hpp:77] Creating layer pool3_pos
I0407 11:01:02.084365  6158 net.cpp:100] Creating Layer pool3_pos
I0407 11:01:02.084370  6158 net.cpp:434] pool3_pos <- conv3a_pos
I0407 11:01:02.084378  6158 net.cpp:408] pool3_pos -> pool3_pos
I0407 11:01:02.085374  6158 net.cpp:150] Setting up pool3_pos
I0407 11:01:02.085388  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.085392  6158 net.cpp:165] Memory required for data: 391337984
I0407 11:01:02.085397  6158 layer_factory.hpp:77] Creating layer conv4a_pos
I0407 11:01:02.085407  6158 net.cpp:100] Creating Layer conv4a_pos
I0407 11:01:02.085412  6158 net.cpp:434] conv4a_pos <- pool3_pos
I0407 11:01:02.085420  6158 net.cpp:408] conv4a_pos -> conv4a_pos
I0407 11:01:02.152030  6158 net.cpp:150] Setting up conv4a_pos
I0407 11:01:02.152060  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.152065  6158 net.cpp:165] Memory required for data: 392140800
I0407 11:01:02.152072  6158 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0407 11:01:02.152078  6158 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0407 11:01:02.152082  6158 layer_factory.hpp:77] Creating layer relu4a_pos
I0407 11:01:02.152093  6158 net.cpp:100] Creating Layer relu4a_pos
I0407 11:01:02.152098  6158 net.cpp:434] relu4a_pos <- conv4a_pos
I0407 11:01:02.152106  6158 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0407 11:01:02.152313  6158 net.cpp:150] Setting up relu4a_pos
I0407 11:01:02.152328  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.152333  6158 net.cpp:165] Memory required for data: 392943616
I0407 11:01:02.152339  6158 layer_factory.hpp:77] Creating layer pool4_pos
I0407 11:01:02.152360  6158 net.cpp:100] Creating Layer pool4_pos
I0407 11:01:02.152365  6158 net.cpp:434] pool4_pos <- conv4a_pos
I0407 11:01:02.152374  6158 net.cpp:408] pool4_pos -> pool4_pos
I0407 11:01:02.153450  6158 net.cpp:150] Setting up pool4_pos
I0407 11:01:02.153478  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.153486  6158 net.cpp:165] Memory required for data: 393043968
I0407 11:01:02.153496  6158 layer_factory.hpp:77] Creating layer conv5a_pos
I0407 11:01:02.153522  6158 net.cpp:100] Creating Layer conv5a_pos
I0407 11:01:02.153530  6158 net.cpp:434] conv5a_pos <- pool4_pos
I0407 11:01:02.153548  6158 net.cpp:408] conv5a_pos -> conv5a_pos
I0407 11:01:02.233446  6158 net.cpp:150] Setting up conv5a_pos
I0407 11:01:02.233479  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.233484  6158 net.cpp:165] Memory required for data: 393144320
I0407 11:01:02.233496  6158 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0407 11:01:02.233505  6158 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0407 11:01:02.233508  6158 layer_factory.hpp:77] Creating layer relu5a_pos
I0407 11:01:02.233522  6158 net.cpp:100] Creating Layer relu5a_pos
I0407 11:01:02.233531  6158 net.cpp:434] relu5a_pos <- conv5a_pos
I0407 11:01:02.233541  6158 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0407 11:01:02.234504  6158 net.cpp:150] Setting up relu5a_pos
I0407 11:01:02.234519  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.234524  6158 net.cpp:165] Memory required for data: 393244672
I0407 11:01:02.234527  6158 layer_factory.hpp:77] Creating layer pool5_pos
I0407 11:01:02.234539  6158 net.cpp:100] Creating Layer pool5_pos
I0407 11:01:02.234542  6158 net.cpp:434] pool5_pos <- conv5a_pos
I0407 11:01:02.234552  6158 net.cpp:408] pool5_pos -> pool5_pos
I0407 11:01:02.235565  6158 net.cpp:150] Setting up pool5_pos
I0407 11:01:02.235580  6158 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0407 11:01:02.235584  6158 net.cpp:165] Memory required for data: 393261056
I0407 11:01:02.235589  6158 layer_factory.hpp:77] Creating layer fc6_pos
I0407 11:01:02.235627  6158 net.cpp:100] Creating Layer fc6_pos
I0407 11:01:02.235632  6158 net.cpp:434] fc6_pos <- pool5_pos
I0407 11:01:02.235643  6158 net.cpp:408] fc6_pos -> fc6_pos
I0407 11:01:02.521180  6158 net.cpp:150] Setting up fc6_pos
I0407 11:01:02.521212  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.521219  6158 net.cpp:165] Memory required for data: 393269248
I0407 11:01:02.521229  6158 layer_factory.hpp:77] Creating layer relu6_pos
I0407 11:01:02.521240  6158 net.cpp:100] Creating Layer relu6_pos
I0407 11:01:02.521246  6158 net.cpp:434] relu6_pos <- fc6_pos
I0407 11:01:02.521252  6158 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0407 11:01:02.521534  6158 net.cpp:150] Setting up relu6_pos
I0407 11:01:02.521546  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.521549  6158 net.cpp:165] Memory required for data: 393277440
I0407 11:01:02.521553  6158 layer_factory.hpp:77] Creating layer drop6_pos
I0407 11:01:02.521562  6158 net.cpp:100] Creating Layer drop6_pos
I0407 11:01:02.521567  6158 net.cpp:434] drop6_pos <- fc6_pos
I0407 11:01:02.521574  6158 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0407 11:01:02.521615  6158 net.cpp:150] Setting up drop6_pos
I0407 11:01:02.521623  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.521626  6158 net.cpp:165] Memory required for data: 393285632
I0407 11:01:02.521630  6158 layer_factory.hpp:77] Creating layer fc7_pos
I0407 11:01:02.521641  6158 net.cpp:100] Creating Layer fc7_pos
I0407 11:01:02.521646  6158 net.cpp:434] fc7_pos <- fc6_pos
I0407 11:01:02.521652  6158 net.cpp:408] fc7_pos -> fc7_pos
I0407 11:01:02.695389  6158 net.cpp:150] Setting up fc7_pos
I0407 11:01:02.695479  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.695488  6158 net.cpp:165] Memory required for data: 393293824
I0407 11:01:02.695528  6158 layer_factory.hpp:77] Creating layer relu7_pos
I0407 11:01:02.695565  6158 net.cpp:100] Creating Layer relu7_pos
I0407 11:01:02.695587  6158 net.cpp:434] relu7_pos <- fc7_pos
I0407 11:01:02.695618  6158 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0407 11:01:02.697638  6158 net.cpp:150] Setting up relu7_pos
I0407 11:01:02.697702  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.697710  6158 net.cpp:165] Memory required for data: 393302016
I0407 11:01:02.697726  6158 layer_factory.hpp:77] Creating layer drop7_pos
I0407 11:01:02.697758  6158 net.cpp:100] Creating Layer drop7_pos
I0407 11:01:02.697770  6158 net.cpp:434] drop7_pos <- fc7_pos
I0407 11:01:02.697790  6158 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0407 11:01:02.697953  6158 net.cpp:150] Setting up drop7_pos
I0407 11:01:02.697971  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:02.697980  6158 net.cpp:165] Memory required for data: 393310208
I0407 11:01:02.697989  6158 layer_factory.hpp:77] Creating layer conv1a_neg
I0407 11:01:02.698022  6158 net.cpp:100] Creating Layer conv1a_neg
I0407 11:01:02.698031  6158 net.cpp:434] conv1a_neg <- negative
I0407 11:01:02.698051  6158 net.cpp:408] conv1a_neg -> conv1a_neg
I0407 11:01:02.701751  6158 net.cpp:150] Setting up conv1a_neg
I0407 11:01:02.701788  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:02.701792  6158 net.cpp:165] Memory required for data: 444690432
I0407 11:01:02.701802  6158 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0407 11:01:02.701807  6158 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0407 11:01:02.701812  6158 layer_factory.hpp:77] Creating layer relu1a_neg
I0407 11:01:02.701825  6158 net.cpp:100] Creating Layer relu1a_neg
I0407 11:01:02.701829  6158 net.cpp:434] relu1a_neg <- conv1a_neg
I0407 11:01:02.701836  6158 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0407 11:01:02.702844  6158 net.cpp:150] Setting up relu1a_neg
I0407 11:01:02.702858  6158 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0407 11:01:02.702869  6158 net.cpp:165] Memory required for data: 496070656
I0407 11:01:02.702873  6158 layer_factory.hpp:77] Creating layer pool1_neg
I0407 11:01:02.702885  6158 net.cpp:100] Creating Layer pool1_neg
I0407 11:01:02.702920  6158 net.cpp:434] pool1_neg <- conv1a_neg
I0407 11:01:02.702930  6158 net.cpp:408] pool1_neg -> pool1_neg
I0407 11:01:02.703207  6158 net.cpp:150] Setting up pool1_neg
I0407 11:01:02.703219  6158 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0407 11:01:02.703223  6158 net.cpp:165] Memory required for data: 508915712
I0407 11:01:02.703227  6158 layer_factory.hpp:77] Creating layer conv2a_neg
I0407 11:01:02.703238  6158 net.cpp:100] Creating Layer conv2a_neg
I0407 11:01:02.703244  6158 net.cpp:434] conv2a_neg <- pool1_neg
I0407 11:01:02.703253  6158 net.cpp:408] conv2a_neg -> conv2a_neg
I0407 11:01:02.720367  6158 net.cpp:150] Setting up conv2a_neg
I0407 11:01:02.720438  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:02.720446  6158 net.cpp:165] Memory required for data: 534605824
I0407 11:01:02.720461  6158 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0407 11:01:02.720474  6158 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0407 11:01:02.720481  6158 layer_factory.hpp:77] Creating layer relu2a_neg
I0407 11:01:02.720504  6158 net.cpp:100] Creating Layer relu2a_neg
I0407 11:01:02.720513  6158 net.cpp:434] relu2a_neg <- conv2a_neg
I0407 11:01:02.720527  6158 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0407 11:01:02.722481  6158 net.cpp:150] Setting up relu2a_neg
I0407 11:01:02.722509  6158 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0407 11:01:02.722518  6158 net.cpp:165] Memory required for data: 560295936
I0407 11:01:02.722528  6158 layer_factory.hpp:77] Creating layer pool2_neg
I0407 11:01:02.722563  6158 net.cpp:100] Creating Layer pool2_neg
I0407 11:01:02.722576  6158 net.cpp:434] pool2_neg <- conv2a_neg
I0407 11:01:02.722600  6158 net.cpp:408] pool2_neg -> pool2_neg
I0407 11:01:02.723006  6158 net.cpp:150] Setting up pool2_neg
I0407 11:01:02.723026  6158 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0407 11:01:02.723033  6158 net.cpp:165] Memory required for data: 563507200
I0407 11:01:02.723044  6158 layer_factory.hpp:77] Creating layer conv3a_neg
I0407 11:01:02.723073  6158 net.cpp:100] Creating Layer conv3a_neg
I0407 11:01:02.723081  6158 net.cpp:434] conv3a_neg <- pool2_neg
I0407 11:01:02.723101  6158 net.cpp:408] conv3a_neg -> conv3a_neg
I0407 11:01:02.759171  6158 net.cpp:150] Setting up conv3a_neg
I0407 11:01:02.759225  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:02.759232  6158 net.cpp:165] Memory required for data: 569929728
I0407 11:01:02.759263  6158 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0407 11:01:02.759277  6158 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0407 11:01:02.759289  6158 layer_factory.hpp:77] Creating layer relu3a_neg
I0407 11:01:02.759322  6158 net.cpp:100] Creating Layer relu3a_neg
I0407 11:01:02.759335  6158 net.cpp:434] relu3a_neg <- conv3a_neg
I0407 11:01:02.759352  6158 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0407 11:01:02.761427  6158 net.cpp:150] Setting up relu3a_neg
I0407 11:01:02.761452  6158 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0407 11:01:02.761461  6158 net.cpp:165] Memory required for data: 576352256
I0407 11:01:02.761468  6158 layer_factory.hpp:77] Creating layer pool3_neg
I0407 11:01:02.761489  6158 net.cpp:100] Creating Layer pool3_neg
I0407 11:01:02.761497  6158 net.cpp:434] pool3_neg <- conv3a_neg
I0407 11:01:02.761513  6158 net.cpp:408] pool3_neg -> pool3_neg
I0407 11:01:02.761943  6158 net.cpp:150] Setting up pool3_neg
I0407 11:01:02.761967  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.761975  6158 net.cpp:165] Memory required for data: 577155072
I0407 11:01:02.761981  6158 layer_factory.hpp:77] Creating layer conv4a_neg
I0407 11:01:02.762003  6158 net.cpp:100] Creating Layer conv4a_neg
I0407 11:01:02.762011  6158 net.cpp:434] conv4a_neg <- pool3_neg
I0407 11:01:02.762027  6158 net.cpp:408] conv4a_neg -> conv4a_neg
I0407 11:01:02.829111  6158 net.cpp:150] Setting up conv4a_neg
I0407 11:01:02.829191  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.829197  6158 net.cpp:165] Memory required for data: 577957888
I0407 11:01:02.829210  6158 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0407 11:01:02.829218  6158 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0407 11:01:02.829229  6158 layer_factory.hpp:77] Creating layer relu4a_neg
I0407 11:01:02.829242  6158 net.cpp:100] Creating Layer relu4a_neg
I0407 11:01:02.829258  6158 net.cpp:434] relu4a_neg <- conv4a_neg
I0407 11:01:02.829267  6158 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0407 11:01:02.830286  6158 net.cpp:150] Setting up relu4a_neg
I0407 11:01:02.830302  6158 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0407 11:01:02.830312  6158 net.cpp:165] Memory required for data: 578760704
I0407 11:01:02.830315  6158 layer_factory.hpp:77] Creating layer pool4_neg
I0407 11:01:02.830328  6158 net.cpp:100] Creating Layer pool4_neg
I0407 11:01:02.830332  6158 net.cpp:434] pool4_neg <- conv4a_neg
I0407 11:01:02.830348  6158 net.cpp:408] pool4_neg -> pool4_neg
I0407 11:01:02.830642  6158 net.cpp:150] Setting up pool4_neg
I0407 11:01:02.830654  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.830658  6158 net.cpp:165] Memory required for data: 578861056
I0407 11:01:02.830664  6158 layer_factory.hpp:77] Creating layer conv5a_neg
I0407 11:01:02.830683  6158 net.cpp:100] Creating Layer conv5a_neg
I0407 11:01:02.830688  6158 net.cpp:434] conv5a_neg <- pool4_neg
I0407 11:01:02.830699  6158 net.cpp:408] conv5a_neg -> conv5a_neg
I0407 11:01:02.945199  6158 net.cpp:150] Setting up conv5a_neg
I0407 11:01:02.945258  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.945266  6158 net.cpp:165] Memory required for data: 578961408
I0407 11:01:02.945291  6158 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0407 11:01:02.945300  6158 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0407 11:01:02.945315  6158 layer_factory.hpp:77] Creating layer relu5a_neg
I0407 11:01:02.945338  6158 net.cpp:100] Creating Layer relu5a_neg
I0407 11:01:02.945350  6158 net.cpp:434] relu5a_neg <- conv5a_neg
I0407 11:01:02.945365  6158 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0407 11:01:02.945694  6158 net.cpp:150] Setting up relu5a_neg
I0407 11:01:02.945710  6158 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0407 11:01:02.945715  6158 net.cpp:165] Memory required for data: 579061760
I0407 11:01:02.945721  6158 layer_factory.hpp:77] Creating layer pool5_neg
I0407 11:01:02.945736  6158 net.cpp:100] Creating Layer pool5_neg
I0407 11:01:02.945745  6158 net.cpp:434] pool5_neg <- conv5a_neg
I0407 11:01:02.945757  6158 net.cpp:408] pool5_neg -> pool5_neg
I0407 11:01:02.947182  6158 net.cpp:150] Setting up pool5_neg
I0407 11:01:02.947203  6158 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0407 11:01:02.947208  6158 net.cpp:165] Memory required for data: 579078144
I0407 11:01:02.947216  6158 layer_factory.hpp:77] Creating layer fc6_neg
I0407 11:01:02.947239  6158 net.cpp:100] Creating Layer fc6_neg
I0407 11:01:02.947247  6158 net.cpp:434] fc6_neg <- pool5_neg
I0407 11:01:02.947259  6158 net.cpp:408] fc6_neg -> fc6_neg
I0407 11:01:03.271085  6158 net.cpp:150] Setting up fc6_neg
I0407 11:01:03.271140  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.271147  6158 net.cpp:165] Memory required for data: 579086336
I0407 11:01:03.271162  6158 layer_factory.hpp:77] Creating layer relu6_neg
I0407 11:01:03.271176  6158 net.cpp:100] Creating Layer relu6_neg
I0407 11:01:03.271184  6158 net.cpp:434] relu6_neg <- fc6_neg
I0407 11:01:03.271193  6158 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0407 11:01:03.271524  6158 net.cpp:150] Setting up relu6_neg
I0407 11:01:03.271536  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.271540  6158 net.cpp:165] Memory required for data: 579094528
I0407 11:01:03.271545  6158 layer_factory.hpp:77] Creating layer drop6_neg
I0407 11:01:03.271580  6158 net.cpp:100] Creating Layer drop6_neg
I0407 11:01:03.271610  6158 net.cpp:434] drop6_neg <- fc6_neg
I0407 11:01:03.271617  6158 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0407 11:01:03.271661  6158 net.cpp:150] Setting up drop6_neg
I0407 11:01:03.271668  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.271672  6158 net.cpp:165] Memory required for data: 579102720
I0407 11:01:03.271677  6158 layer_factory.hpp:77] Creating layer fc7_neg
I0407 11:01:03.271688  6158 net.cpp:100] Creating Layer fc7_neg
I0407 11:01:03.271694  6158 net.cpp:434] fc7_neg <- fc6_neg
I0407 11:01:03.271703  6158 net.cpp:408] fc7_neg -> fc7_neg
I0407 11:01:03.431135  6158 net.cpp:150] Setting up fc7_neg
I0407 11:01:03.431182  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.431188  6158 net.cpp:165] Memory required for data: 579110912
I0407 11:01:03.431201  6158 layer_factory.hpp:77] Creating layer relu7_neg
I0407 11:01:03.431221  6158 net.cpp:100] Creating Layer relu7_neg
I0407 11:01:03.431234  6158 net.cpp:434] relu7_neg <- fc7_neg
I0407 11:01:03.431243  6158 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0407 11:01:03.432446  6158 net.cpp:150] Setting up relu7_neg
I0407 11:01:03.432461  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.432472  6158 net.cpp:165] Memory required for data: 579119104
I0407 11:01:03.432476  6158 layer_factory.hpp:77] Creating layer drop7_neg
I0407 11:01:03.432485  6158 net.cpp:100] Creating Layer drop7_neg
I0407 11:01:03.432490  6158 net.cpp:434] drop7_neg <- fc7_neg
I0407 11:01:03.432497  6158 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0407 11:01:03.432540  6158 net.cpp:150] Setting up drop7_neg
I0407 11:01:03.432549  6158 net.cpp:157] Top shape: 1 2048 (2048)
I0407 11:01:03.432554  6158 net.cpp:165] Memory required for data: 579127296
I0407 11:01:03.432557  6158 layer_factory.hpp:77] Creating layer loss
I0407 11:01:03.432567  6158 net.cpp:100] Creating Layer loss
I0407 11:01:03.432576  6158 net.cpp:434] loss <- fc7
I0407 11:01:03.432581  6158 net.cpp:434] loss <- fc7_pos
I0407 11:01:03.432586  6158 net.cpp:434] loss <- fc7_neg
I0407 11:01:03.432593  6158 net.cpp:408] loss -> loss
I0407 11:01:03.432675  6158 net.cpp:150] Setting up loss
I0407 11:01:03.432685  6158 net.cpp:157] Top shape: (1)
I0407 11:01:03.432688  6158 net.cpp:160]     with loss weight 1
I0407 11:01:03.432708  6158 net.cpp:165] Memory required for data: 579127300
I0407 11:01:03.432713  6158 net.cpp:226] loss needs backward computation.
I0407 11:01:03.432718  6158 net.cpp:226] drop7_neg needs backward computation.
I0407 11:01:03.432720  6158 net.cpp:226] relu7_neg needs backward computation.
I0407 11:01:03.432723  6158 net.cpp:226] fc7_neg needs backward computation.
I0407 11:01:03.432727  6158 net.cpp:226] drop6_neg needs backward computation.
I0407 11:01:03.432730  6158 net.cpp:226] relu6_neg needs backward computation.
I0407 11:01:03.432734  6158 net.cpp:226] fc6_neg needs backward computation.
I0407 11:01:03.432739  6158 net.cpp:226] pool5_neg needs backward computation.
I0407 11:01:03.432742  6158 net.cpp:226] relu5a_neg needs backward computation.
I0407 11:01:03.432745  6158 net.cpp:226] conv5a_neg needs backward computation.
I0407 11:01:03.432749  6158 net.cpp:226] pool4_neg needs backward computation.
I0407 11:01:03.432754  6158 net.cpp:226] relu4a_neg needs backward computation.
I0407 11:01:03.432756  6158 net.cpp:226] conv4a_neg needs backward computation.
I0407 11:01:03.432760  6158 net.cpp:226] pool3_neg needs backward computation.
I0407 11:01:03.432765  6158 net.cpp:226] relu3a_neg needs backward computation.
I0407 11:01:03.432767  6158 net.cpp:226] conv3a_neg needs backward computation.
I0407 11:01:03.432771  6158 net.cpp:226] pool2_neg needs backward computation.
I0407 11:01:03.432775  6158 net.cpp:226] relu2a_neg needs backward computation.
I0407 11:01:03.432778  6158 net.cpp:226] conv2a_neg needs backward computation.
I0407 11:01:03.432782  6158 net.cpp:226] pool1_neg needs backward computation.
I0407 11:01:03.432787  6158 net.cpp:226] relu1a_neg needs backward computation.
I0407 11:01:03.432790  6158 net.cpp:226] conv1a_neg needs backward computation.
I0407 11:01:03.432819  6158 net.cpp:226] drop7_pos needs backward computation.
I0407 11:01:03.432823  6158 net.cpp:226] relu7_pos needs backward computation.
I0407 11:01:03.432826  6158 net.cpp:226] fc7_pos needs backward computation.
I0407 11:01:03.432831  6158 net.cpp:226] drop6_pos needs backward computation.
I0407 11:01:03.432834  6158 net.cpp:226] relu6_pos needs backward computation.
I0407 11:01:03.432837  6158 net.cpp:226] fc6_pos needs backward computation.
I0407 11:01:03.432842  6158 net.cpp:226] pool5_pos needs backward computation.
I0407 11:01:03.432845  6158 net.cpp:226] relu5a_pos needs backward computation.
I0407 11:01:03.432849  6158 net.cpp:226] conv5a_pos needs backward computation.
I0407 11:01:03.432853  6158 net.cpp:226] pool4_pos needs backward computation.
I0407 11:01:03.432857  6158 net.cpp:226] relu4a_pos needs backward computation.
I0407 11:01:03.432862  6158 net.cpp:226] conv4a_pos needs backward computation.
I0407 11:01:03.432865  6158 net.cpp:226] pool3_pos needs backward computation.
I0407 11:01:03.432869  6158 net.cpp:226] relu3a_pos needs backward computation.
I0407 11:01:03.432873  6158 net.cpp:226] conv3a_pos needs backward computation.
I0407 11:01:03.432876  6158 net.cpp:226] pool2_pos needs backward computation.
I0407 11:01:03.432881  6158 net.cpp:226] relu2a_pos needs backward computation.
I0407 11:01:03.432884  6158 net.cpp:226] conv2a_pos needs backward computation.
I0407 11:01:03.432888  6158 net.cpp:226] pool1_pos needs backward computation.
I0407 11:01:03.432893  6158 net.cpp:226] relu1a_pos needs backward computation.
I0407 11:01:03.432895  6158 net.cpp:226] conv1a_pos needs backward computation.
I0407 11:01:03.432899  6158 net.cpp:226] drop7 needs backward computation.
I0407 11:01:03.432904  6158 net.cpp:226] relu7 needs backward computation.
I0407 11:01:03.432906  6158 net.cpp:226] fc7 needs backward computation.
I0407 11:01:03.432910  6158 net.cpp:226] drop6 needs backward computation.
I0407 11:01:03.432914  6158 net.cpp:226] relu6 needs backward computation.
I0407 11:01:03.432917  6158 net.cpp:226] fc6 needs backward computation.
I0407 11:01:03.432922  6158 net.cpp:226] pool5 needs backward computation.
I0407 11:01:03.432926  6158 net.cpp:226] relu5a needs backward computation.
I0407 11:01:03.432930  6158 net.cpp:226] conv5a needs backward computation.
I0407 11:01:03.432935  6158 net.cpp:226] pool4 needs backward computation.
I0407 11:01:03.432940  6158 net.cpp:226] relu4a needs backward computation.
I0407 11:01:03.432942  6158 net.cpp:226] conv4a needs backward computation.
I0407 11:01:03.432946  6158 net.cpp:226] pool3 needs backward computation.
I0407 11:01:03.432950  6158 net.cpp:226] relu3a needs backward computation.
I0407 11:01:03.432955  6158 net.cpp:226] conv3a needs backward computation.
I0407 11:01:03.432958  6158 net.cpp:226] pool2 needs backward computation.
I0407 11:01:03.432962  6158 net.cpp:226] relu2a needs backward computation.
I0407 11:01:03.432966  6158 net.cpp:226] conv2a needs backward computation.
I0407 11:01:03.432971  6158 net.cpp:226] pool1 needs backward computation.
I0407 11:01:03.432976  6158 net.cpp:226] relu1a needs backward computation.
I0407 11:01:03.432981  6158 net.cpp:226] conv1a needs backward computation.
I0407 11:01:03.432986  6158 net.cpp:228] reshape_negative does not need backward computation.
I0407 11:01:03.432991  6158 net.cpp:228] reshape_positive does not need backward computation.
I0407 11:01:03.432996  6158 net.cpp:228] reshape_anchor does not need backward computation.
I0407 11:01:03.432999  6158 net.cpp:228] slicer does not need backward computation.
I0407 11:01:03.433004  6158 net.cpp:228] data does not need backward computation.
I0407 11:01:03.433007  6158 net.cpp:270] This network produces output loss
I0407 11:01:03.444151  6158 net.cpp:283] Network initialization done.
I0407 11:01:03.444595  6158 solver.cpp:60] Solver scaffolding done.
I0407 11:01:03.445896  6158 caffe.cpp:155] Finetuning from ../c3d_ucf101_iter_38000.caffemodel
I0407 11:01:03.675567  6158 net.cpp:761] Ignoring source layer fc8
I0407 11:01:03.800307  6158 net.cpp:761] Ignoring source layer fc8
I0407 11:01:03.803617  6158 caffe.cpp:251] Starting Optimization
I0407 11:01:03.803690  6158 solver.cpp:279] Solving C3D-Three-Streams
I0407 11:01:03.803699  6158 solver.cpp:280] Learning Rate Policy: step
I0407 11:01:03.819015  6158 solver.cpp:337] Iteration 0, Testing net (#0)
I0407 11:01:04.613803  6158 blocking_queue.cpp:50] Data layer prefetch queue empty
I0407 11:01:14.798540  6158 solver.cpp:404]     Test net output #0: loss = 78.4079 (* 1 = 78.4079 loss)
I0407 11:01:15.727819  6158 solver.cpp:228] Iteration 0, loss = 215.947
I0407 11:01:15.727872  6158 solver.cpp:244]     Train net output #0: loss = 215.947 (* 1 = 215.947 loss)
I0407 11:01:15.727897  6158 sgd_solver.cpp:106] Iteration 0, lr = 1e-08
I0407 11:02:07.869536  6158 solver.cpp:228] Iteration 20, loss = 0
I0407 11:02:07.869690  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:02:07.869704  6158 sgd_solver.cpp:106] Iteration 20, lr = 1e-08
I0407 11:03:00.746486  6158 solver.cpp:228] Iteration 40, loss = 18.0763
I0407 11:03:00.746734  6158 solver.cpp:244]     Train net output #0: loss = 18.0763 (* 1 = 18.0763 loss)
I0407 11:03:00.746747  6158 sgd_solver.cpp:106] Iteration 40, lr = 1e-08
I0407 11:03:53.005342  6158 solver.cpp:228] Iteration 60, loss = -3.8147e-06
I0407 11:03:53.005566  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:03:53.005599  6158 sgd_solver.cpp:106] Iteration 60, lr = 1e-08
I0407 11:04:45.246510  6158 solver.cpp:228] Iteration 80, loss = 16.2987
I0407 11:04:45.246724  6158 solver.cpp:244]     Train net output #0: loss = 16.2987 (* 1 = 16.2987 loss)
I0407 11:04:45.246752  6158 sgd_solver.cpp:106] Iteration 80, lr = 1e-08
I0407 11:05:34.866559  6158 solver.cpp:337] Iteration 100, Testing net (#0)
I0407 11:05:45.905649  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:05:46.769448  6158 solver.cpp:228] Iteration 100, loss = -3.8147e-06
I0407 11:05:46.769520  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:05:46.769546  6158 sgd_solver.cpp:106] Iteration 100, lr = 1e-08
I0407 11:06:38.820773  6158 solver.cpp:228] Iteration 120, loss = -3.8147e-06
I0407 11:06:38.820925  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:06:38.820938  6158 sgd_solver.cpp:106] Iteration 120, lr = 1e-08
I0407 11:07:30.983785  6158 solver.cpp:228] Iteration 140, loss = -3.8147e-06
I0407 11:07:30.984011  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:07:30.984035  6158 sgd_solver.cpp:106] Iteration 140, lr = 1e-08
I0407 11:08:23.099529  6158 solver.cpp:228] Iteration 160, loss = -3.8147e-06
I0407 11:08:23.100802  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:08:23.100828  6158 sgd_solver.cpp:106] Iteration 160, lr = 1e-08
I0407 11:09:15.251123  6158 solver.cpp:228] Iteration 180, loss = 3.90383
I0407 11:09:15.251340  6158 solver.cpp:244]     Train net output #0: loss = 3.90384 (* 1 = 3.90384 loss)
I0407 11:09:15.251380  6158 sgd_solver.cpp:106] Iteration 180, lr = 1e-08
I0407 11:10:04.746054  6158 solver.cpp:337] Iteration 200, Testing net (#0)
I0407 11:10:15.057087  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:10:15.924796  6158 solver.cpp:228] Iteration 200, loss = -3.8147e-06
I0407 11:10:15.924855  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:10:15.924867  6158 sgd_solver.cpp:106] Iteration 200, lr = 1e-08
I0407 11:11:08.206984  6158 solver.cpp:228] Iteration 220, loss = -3.8147e-06
I0407 11:11:08.207289  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:11:08.207324  6158 sgd_solver.cpp:106] Iteration 220, lr = 1e-08
I0407 11:12:00.426246  6158 solver.cpp:228] Iteration 240, loss = -3.8147e-06
I0407 11:12:00.429977  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:12:00.430073  6158 sgd_solver.cpp:106] Iteration 240, lr = 1e-08
I0407 11:12:52.579478  6158 solver.cpp:228] Iteration 260, loss = 21.4227
I0407 11:12:52.579731  6158 solver.cpp:244]     Train net output #0: loss = 21.4227 (* 1 = 21.4227 loss)
I0407 11:12:52.579772  6158 sgd_solver.cpp:106] Iteration 260, lr = 1e-08
I0407 11:13:44.641104  6158 solver.cpp:228] Iteration 280, loss = -3.8147e-06
I0407 11:13:44.641342  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:13:44.641360  6158 sgd_solver.cpp:106] Iteration 280, lr = 1e-08
I0407 11:14:34.014191  6158 solver.cpp:337] Iteration 300, Testing net (#0)
I0407 11:14:45.592692  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:14:46.458173  6158 solver.cpp:228] Iteration 300, loss = -3.8147e-06
I0407 11:14:46.458237  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:14:46.458250  6158 sgd_solver.cpp:106] Iteration 300, lr = 1e-08
I0407 11:15:38.478415  6158 solver.cpp:228] Iteration 320, loss = 11.9376
I0407 11:15:38.479197  6158 solver.cpp:244]     Train net output #0: loss = 11.9376 (* 1 = 11.9376 loss)
I0407 11:15:38.479220  6158 sgd_solver.cpp:106] Iteration 320, lr = 1e-08
I0407 11:16:30.475937  6158 solver.cpp:228] Iteration 340, loss = 15.333
I0407 11:16:30.476171  6158 solver.cpp:244]     Train net output #0: loss = 15.333 (* 1 = 15.333 loss)
I0407 11:16:30.476193  6158 sgd_solver.cpp:106] Iteration 340, lr = 1e-08
I0407 11:17:22.593272  6158 solver.cpp:228] Iteration 360, loss = -3.8147e-06
I0407 11:17:22.593498  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:17:22.593536  6158 sgd_solver.cpp:106] Iteration 360, lr = 1e-08
I0407 11:18:14.757098  6158 solver.cpp:228] Iteration 380, loss = -3.8147e-06
I0407 11:18:14.757446  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:18:14.757525  6158 sgd_solver.cpp:106] Iteration 380, lr = 1e-08
I0407 11:19:04.323132  6158 solver.cpp:337] Iteration 400, Testing net (#0)
I0407 11:19:15.293463  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:19:16.154965  6158 solver.cpp:228] Iteration 400, loss = -3.8147e-06
I0407 11:19:16.155021  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:19:16.155035  6158 sgd_solver.cpp:106] Iteration 400, lr = 1e-08
I0407 11:20:08.155128  6158 solver.cpp:228] Iteration 420, loss = -3.8147e-06
I0407 11:20:08.155908  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:20:08.155961  6158 sgd_solver.cpp:106] Iteration 420, lr = 1e-08
I0407 11:21:00.375233  6158 solver.cpp:228] Iteration 440, loss = -3.8147e-06
I0407 11:21:00.379691  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:21:00.379725  6158 sgd_solver.cpp:106] Iteration 440, lr = 1e-08
I0407 11:21:52.589454  6158 solver.cpp:228] Iteration 460, loss = -3.8147e-06
I0407 11:21:52.589730  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:21:52.589768  6158 sgd_solver.cpp:106] Iteration 460, lr = 1e-08
I0407 11:22:44.780460  6158 solver.cpp:228] Iteration 480, loss = 4.18324
I0407 11:22:44.782905  6158 solver.cpp:244]     Train net output #0: loss = 4.18324 (* 1 = 4.18324 loss)
I0407 11:22:44.782924  6158 sgd_solver.cpp:106] Iteration 480, lr = 1e-08
I0407 11:23:34.320111  6158 solver.cpp:337] Iteration 500, Testing net (#0)
I0407 11:23:45.683846  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:23:46.549171  6158 solver.cpp:228] Iteration 500, loss = -3.8147e-06
I0407 11:23:46.549221  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:23:46.549237  6158 sgd_solver.cpp:106] Iteration 500, lr = 1e-08
I0407 11:24:38.688418  6158 solver.cpp:228] Iteration 520, loss = 6.05208
I0407 11:24:38.690955  6158 solver.cpp:244]     Train net output #0: loss = 6.05208 (* 1 = 6.05208 loss)
I0407 11:24:38.690996  6158 sgd_solver.cpp:106] Iteration 520, lr = 1e-08
I0407 11:25:30.810983  6158 solver.cpp:228] Iteration 540, loss = -3.8147e-06
I0407 11:25:30.823521  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:25:30.823539  6158 sgd_solver.cpp:106] Iteration 540, lr = 1e-08
I0407 11:26:22.886396  6158 solver.cpp:228] Iteration 560, loss = -3.8147e-06
I0407 11:26:22.886615  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:26:22.886643  6158 sgd_solver.cpp:106] Iteration 560, lr = 1e-08
I0407 11:27:14.904201  6158 solver.cpp:228] Iteration 580, loss = -3.8147e-06
I0407 11:27:14.904393  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:27:14.904407  6158 sgd_solver.cpp:106] Iteration 580, lr = 1e-08
I0407 11:28:04.296324  6158 solver.cpp:337] Iteration 600, Testing net (#0)
I0407 11:28:14.850121  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:28:15.715970  6158 solver.cpp:228] Iteration 600, loss = -3.8147e-06
I0407 11:28:15.716027  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:28:15.716040  6158 sgd_solver.cpp:106] Iteration 600, lr = 1e-08
I0407 11:29:07.734149  6158 solver.cpp:228] Iteration 620, loss = 3.17385
I0407 11:29:07.737495  6158 solver.cpp:244]     Train net output #0: loss = 3.17386 (* 1 = 3.17386 loss)
I0407 11:29:07.737521  6158 sgd_solver.cpp:106] Iteration 620, lr = 1e-08
I0407 11:29:59.727293  6158 solver.cpp:228] Iteration 640, loss = -3.8147e-06
I0407 11:29:59.727558  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:29:59.727591  6158 sgd_solver.cpp:106] Iteration 640, lr = 1e-08
I0407 11:30:51.694851  6158 solver.cpp:228] Iteration 660, loss = -3.8147e-06
I0407 11:30:51.695526  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:30:51.695554  6158 sgd_solver.cpp:106] Iteration 660, lr = 1e-08
I0407 11:31:43.793923  6158 solver.cpp:228] Iteration 680, loss = -3.8147e-06
I0407 11:31:43.794152  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:31:43.794185  6158 sgd_solver.cpp:106] Iteration 680, lr = 1e-08
I0407 11:32:33.325904  6158 solver.cpp:337] Iteration 700, Testing net (#0)
I0407 11:32:42.968833  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:32:43.834916  6158 solver.cpp:228] Iteration 700, loss = -3.8147e-06
I0407 11:32:43.834959  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:32:43.834969  6158 sgd_solver.cpp:106] Iteration 700, lr = 1e-08
I0407 11:33:35.884428  6158 solver.cpp:228] Iteration 720, loss = -3.8147e-06
I0407 11:33:35.884769  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:33:35.884824  6158 sgd_solver.cpp:106] Iteration 720, lr = 1e-08
I0407 11:34:27.985883  6158 solver.cpp:228] Iteration 740, loss = -3.8147e-06
I0407 11:34:27.986137  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:34:27.986153  6158 sgd_solver.cpp:106] Iteration 740, lr = 1e-08
I0407 11:35:20.188102  6158 solver.cpp:228] Iteration 760, loss = -3.8147e-06
I0407 11:35:20.188350  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:35:20.188388  6158 sgd_solver.cpp:106] Iteration 760, lr = 1e-08
I0407 11:36:12.428735  6158 solver.cpp:228] Iteration 780, loss = -3.8147e-06
I0407 11:36:12.429293  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:36:12.429309  6158 sgd_solver.cpp:106] Iteration 780, lr = 1e-08
I0407 11:37:02.010476  6158 solver.cpp:337] Iteration 800, Testing net (#0)
I0407 11:37:10.826969  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:37:11.690312  6158 solver.cpp:228] Iteration 800, loss = 5.1987
I0407 11:37:11.690383  6158 solver.cpp:244]     Train net output #0: loss = 5.1987 (* 1 = 5.1987 loss)
I0407 11:37:11.690402  6158 sgd_solver.cpp:106] Iteration 800, lr = 1e-08
I0407 11:38:03.700654  6158 solver.cpp:228] Iteration 820, loss = -3.93391e-06
I0407 11:38:03.702109  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:38:03.702136  6158 sgd_solver.cpp:106] Iteration 820, lr = 1e-08
I0407 11:38:55.852385  6158 solver.cpp:228] Iteration 840, loss = -3.93391e-06
I0407 11:38:55.865522  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:38:55.865694  6158 sgd_solver.cpp:106] Iteration 840, lr = 1e-08
I0407 11:39:48.055488  6158 solver.cpp:228] Iteration 860, loss = -3.8147e-06
I0407 11:39:48.055685  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:39:48.055701  6158 sgd_solver.cpp:106] Iteration 860, lr = 1e-08
I0407 11:40:40.243937  6158 solver.cpp:228] Iteration 880, loss = -3.8147e-06
I0407 11:40:40.244319  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:40:40.244352  6158 sgd_solver.cpp:106] Iteration 880, lr = 1e-08
I0407 11:41:29.867156  6158 solver.cpp:337] Iteration 900, Testing net (#0)
I0407 11:41:39.755344  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:41:40.623894  6158 solver.cpp:228] Iteration 900, loss = -3.8147e-06
I0407 11:41:40.623942  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:41:40.623965  6158 sgd_solver.cpp:106] Iteration 900, lr = 1e-08
I0407 11:42:32.728706  6158 solver.cpp:228] Iteration 920, loss = -3.8147e-06
I0407 11:42:32.732810  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:42:32.732827  6158 sgd_solver.cpp:106] Iteration 920, lr = 1e-08
I0407 11:43:24.824640  6158 solver.cpp:228] Iteration 940, loss = 6.50561
I0407 11:43:24.824803  6158 solver.cpp:244]     Train net output #0: loss = 6.50562 (* 1 = 6.50562 loss)
I0407 11:43:24.824816  6158 sgd_solver.cpp:106] Iteration 940, lr = 1e-08
I0407 11:44:16.991394  6158 solver.cpp:228] Iteration 960, loss = 0.00946342
I0407 11:44:16.993211  6158 solver.cpp:244]     Train net output #0: loss = 0.00946723 (* 1 = 0.00946723 loss)
I0407 11:44:16.993232  6158 sgd_solver.cpp:106] Iteration 960, lr = 1e-08
I0407 11:45:09.197515  6158 solver.cpp:228] Iteration 980, loss = -3.8147e-06
I0407 11:45:09.197762  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:45:09.197803  6158 sgd_solver.cpp:106] Iteration 980, lr = 1e-08
I0407 11:45:58.709090  6158 solver.cpp:454] Snapshotting to binary proto file c3d_ucf101_iter_1000.caffemodel
I0407 11:46:08.156407  6158 sgd_solver.cpp:273] Snapshotting solver state to binary proto file c3d_ucf101_iter_1000.solverstate
I0407 11:46:08.313405  6158 solver.cpp:337] Iteration 1000, Testing net (#0)
I0407 11:46:18.232465  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:46:19.097285  6158 solver.cpp:228] Iteration 1000, loss = -3.8147e-06
I0407 11:46:19.097367  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:46:19.097394  6158 sgd_solver.cpp:106] Iteration 1000, lr = 1e-08
I0407 11:47:11.072902  6158 solver.cpp:228] Iteration 1020, loss = -3.8147e-06
I0407 11:47:11.073106  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:47:11.073120  6158 sgd_solver.cpp:106] Iteration 1020, lr = 1e-08
I0407 11:48:03.466703  6158 solver.cpp:228] Iteration 1040, loss = -3.8147e-06
I0407 11:48:03.466876  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:48:03.466891  6158 sgd_solver.cpp:106] Iteration 1040, lr = 1e-08
I0407 11:48:55.699960  6158 solver.cpp:228] Iteration 1060, loss = -3.8147e-06
I0407 11:48:55.700222  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:48:55.700251  6158 sgd_solver.cpp:106] Iteration 1060, lr = 1e-08
I0407 11:49:47.876091  6158 solver.cpp:228] Iteration 1080, loss = -3.8147e-06
I0407 11:49:47.879091  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:49:47.879159  6158 sgd_solver.cpp:106] Iteration 1080, lr = 1e-08
I0407 11:50:37.495709  6158 solver.cpp:337] Iteration 1100, Testing net (#0)
I0407 11:50:46.470963  6158 blocking_queue.cpp:50] Data layer prefetch queue empty
I0407 11:50:47.489676  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:50:48.354789  6158 solver.cpp:228] Iteration 1100, loss = -3.8147e-06
I0407 11:50:48.354851  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:50:48.354861  6158 sgd_solver.cpp:106] Iteration 1100, lr = 1e-08
I0407 11:51:40.371438  6158 solver.cpp:228] Iteration 1120, loss = -3.8147e-06
I0407 11:51:40.383823  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:51:40.383839  6158 sgd_solver.cpp:106] Iteration 1120, lr = 1e-08
I0407 11:52:32.515434  6158 solver.cpp:228] Iteration 1140, loss = -3.8147e-06
I0407 11:52:32.515599  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:52:32.515614  6158 sgd_solver.cpp:106] Iteration 1140, lr = 1e-08
I0407 11:53:24.726092  6158 solver.cpp:228] Iteration 1160, loss = -3.8147e-06
I0407 11:53:24.726358  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:53:24.726403  6158 sgd_solver.cpp:106] Iteration 1160, lr = 1e-08
I0407 11:54:16.939031  6158 solver.cpp:228] Iteration 1180, loss = -3.8147e-06
I0407 11:54:16.939312  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:54:16.939348  6158 sgd_solver.cpp:106] Iteration 1180, lr = 1e-08
I0407 11:55:06.539047  6158 solver.cpp:337] Iteration 1200, Testing net (#0)
I0407 11:55:17.618629  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:55:18.485466  6158 solver.cpp:228] Iteration 1200, loss = -3.8147e-06
I0407 11:55:18.485520  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:55:18.485532  6158 sgd_solver.cpp:106] Iteration 1200, lr = 1e-08
I0407 11:56:10.717854  6158 solver.cpp:228] Iteration 1220, loss = -3.8147e-06
I0407 11:56:10.718168  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:56:10.718219  6158 sgd_solver.cpp:106] Iteration 1220, lr = 1e-08
I0407 11:57:02.982168  6158 solver.cpp:228] Iteration 1240, loss = -3.8147e-06
I0407 11:57:02.982460  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:57:02.982476  6158 sgd_solver.cpp:106] Iteration 1240, lr = 1e-08
I0407 11:57:55.186178  6158 solver.cpp:228] Iteration 1260, loss = -3.8147e-06
I0407 11:57:55.186583  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:57:55.186643  6158 sgd_solver.cpp:106] Iteration 1260, lr = 1e-08
I0407 11:58:47.237756  6158 solver.cpp:228] Iteration 1280, loss = -3.8147e-06
I0407 11:58:47.237913  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:58:47.237926  6158 sgd_solver.cpp:106] Iteration 1280, lr = 1e-08
I0407 11:59:36.648216  6158 solver.cpp:337] Iteration 1300, Testing net (#0)
I0407 11:59:48.848500  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:59:49.716693  6158 solver.cpp:228] Iteration 1300, loss = -3.8147e-06
I0407 11:59:49.716756  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 11:59:49.716769  6158 sgd_solver.cpp:106] Iteration 1300, lr = 1e-08
I0407 12:00:41.909159  6158 solver.cpp:228] Iteration 1320, loss = -3.8147e-06
I0407 12:00:41.909298  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:00:41.909312  6158 sgd_solver.cpp:106] Iteration 1320, lr = 1e-08
I0407 12:01:34.014036  6158 solver.cpp:228] Iteration 1340, loss = -3.8147e-06
I0407 12:01:34.017060  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:01:34.017081  6158 sgd_solver.cpp:106] Iteration 1340, lr = 1e-08
I0407 12:02:26.027525  6158 solver.cpp:228] Iteration 1360, loss = -3.8147e-06
I0407 12:02:26.027793  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:02:26.027842  6158 sgd_solver.cpp:106] Iteration 1360, lr = 1e-08
I0407 12:03:18.046381  6158 solver.cpp:228] Iteration 1380, loss = -3.8147e-06
I0407 12:03:18.046566  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:03:18.046581  6158 sgd_solver.cpp:106] Iteration 1380, lr = 1e-08
I0407 12:04:07.646945  6158 solver.cpp:337] Iteration 1400, Testing net (#0)
I0407 12:04:18.713904  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:04:19.592597  6158 solver.cpp:228] Iteration 1400, loss = -3.8147e-06
I0407 12:04:19.592730  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:04:19.592762  6158 sgd_solver.cpp:106] Iteration 1400, lr = 1e-08
I0407 12:05:11.662534  6158 solver.cpp:228] Iteration 1420, loss = -3.8147e-06
I0407 12:05:11.662855  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:05:11.662910  6158 sgd_solver.cpp:106] Iteration 1420, lr = 1e-08
I0407 12:06:03.818429  6158 solver.cpp:228] Iteration 1440, loss = -3.8147e-06
I0407 12:06:03.818684  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:06:03.818737  6158 sgd_solver.cpp:106] Iteration 1440, lr = 1e-08
I0407 12:06:56.042683  6158 solver.cpp:228] Iteration 1460, loss = -3.8147e-06
I0407 12:06:56.042898  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:06:56.042924  6158 sgd_solver.cpp:106] Iteration 1460, lr = 1e-08
I0407 12:07:48.265359  6158 solver.cpp:228] Iteration 1480, loss = -3.8147e-06
I0407 12:07:48.265607  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:07:48.265640  6158 sgd_solver.cpp:106] Iteration 1480, lr = 1e-08
I0407 12:08:37.878415  6158 solver.cpp:337] Iteration 1500, Testing net (#0)
I0407 12:08:49.215533  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:08:50.078424  6158 solver.cpp:228] Iteration 1500, loss = -3.8147e-06
I0407 12:08:50.078475  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:08:50.078486  6158 sgd_solver.cpp:106] Iteration 1500, lr = 1e-08
I0407 12:09:42.208569  6158 solver.cpp:228] Iteration 1520, loss = -3.8147e-06
I0407 12:09:42.208889  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:09:42.208920  6158 sgd_solver.cpp:106] Iteration 1520, lr = 1e-08
I0407 12:10:34.390841  6158 solver.cpp:228] Iteration 1540, loss = -3.8147e-06
I0407 12:10:34.391574  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:10:34.391597  6158 sgd_solver.cpp:106] Iteration 1540, lr = 1e-08
I0407 12:11:26.559201  6158 solver.cpp:228] Iteration 1560, loss = -3.8147e-06
I0407 12:11:26.559368  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:11:26.559382  6158 sgd_solver.cpp:106] Iteration 1560, lr = 1e-08
I0407 12:12:18.592793  6158 solver.cpp:228] Iteration 1580, loss = -3.8147e-06
I0407 12:12:18.594858  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:12:18.594872  6158 sgd_solver.cpp:106] Iteration 1580, lr = 1e-08
I0407 12:13:07.986600  6158 solver.cpp:337] Iteration 1600, Testing net (#0)
I0407 12:13:19.192034  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:13:20.058746  6158 solver.cpp:228] Iteration 1600, loss = -3.8147e-06
I0407 12:13:20.058796  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:13:20.058809  6158 sgd_solver.cpp:106] Iteration 1600, lr = 1e-08
I0407 12:14:12.199272  6158 solver.cpp:228] Iteration 1620, loss = -3.8147e-06
I0407 12:14:12.199514  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:14:12.199544  6158 sgd_solver.cpp:106] Iteration 1620, lr = 1e-08
I0407 12:15:04.230988  6158 solver.cpp:228] Iteration 1640, loss = -3.8147e-06
I0407 12:15:04.231189  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:15:04.231204  6158 sgd_solver.cpp:106] Iteration 1640, lr = 1e-08
I0407 12:15:56.282510  6158 solver.cpp:228] Iteration 1660, loss = -3.8147e-06
I0407 12:15:56.282667  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:15:56.282680  6158 sgd_solver.cpp:106] Iteration 1660, lr = 1e-08
I0407 12:16:48.423295  6158 solver.cpp:228] Iteration 1680, loss = -3.8147e-06
I0407 12:16:48.435783  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:16:48.435817  6158 sgd_solver.cpp:106] Iteration 1680, lr = 1e-08
I0407 12:17:38.043920  6158 solver.cpp:337] Iteration 1700, Testing net (#0)
I0407 12:17:49.109081  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:17:49.980075  6158 solver.cpp:228] Iteration 1700, loss = -3.8147e-06
I0407 12:17:49.980187  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:17:49.980211  6158 sgd_solver.cpp:106] Iteration 1700, lr = 1e-08
I0407 12:18:42.077890  6158 solver.cpp:228] Iteration 1720, loss = -3.8147e-06
I0407 12:18:42.078168  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:18:42.078207  6158 sgd_solver.cpp:106] Iteration 1720, lr = 1e-08
I0407 12:19:34.300925  6158 solver.cpp:228] Iteration 1740, loss = -3.8147e-06
I0407 12:19:34.301210  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:19:34.301249  6158 sgd_solver.cpp:106] Iteration 1740, lr = 1e-08
I0407 12:20:26.527932  6158 solver.cpp:228] Iteration 1760, loss = -3.8147e-06
I0407 12:20:26.528170  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:20:26.528220  6158 sgd_solver.cpp:106] Iteration 1760, lr = 1e-08
I0407 12:21:18.708778  6158 solver.cpp:228] Iteration 1780, loss = -3.8147e-06
I0407 12:21:18.710674  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:21:18.710687  6158 sgd_solver.cpp:106] Iteration 1780, lr = 1e-08
I0407 12:22:08.246736  6158 solver.cpp:337] Iteration 1800, Testing net (#0)
I0407 12:22:18.699656  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:22:19.563215  6158 solver.cpp:228] Iteration 1800, loss = -3.8147e-06
I0407 12:22:19.563257  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:22:19.563280  6158 sgd_solver.cpp:106] Iteration 1800, lr = 1e-08
I0407 12:23:11.739826  6158 solver.cpp:228] Iteration 1820, loss = -3.8147e-06
I0407 12:23:11.740106  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:23:11.740147  6158 sgd_solver.cpp:106] Iteration 1820, lr = 1e-08
I0407 12:24:03.995118  6158 solver.cpp:228] Iteration 1840, loss = -3.8147e-06
I0407 12:24:03.995988  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:24:03.996033  6158 sgd_solver.cpp:106] Iteration 1840, lr = 1e-08
I0407 12:24:56.243887  6158 solver.cpp:228] Iteration 1860, loss = 1.21959
I0407 12:24:56.244071  6158 solver.cpp:244]     Train net output #0: loss = 1.21959 (* 1 = 1.21959 loss)
I0407 12:24:56.244091  6158 sgd_solver.cpp:106] Iteration 1860, lr = 1e-08
I0407 12:25:48.474969  6158 solver.cpp:228] Iteration 1880, loss = -3.8147e-06
I0407 12:25:48.475621  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:25:48.475639  6158 sgd_solver.cpp:106] Iteration 1880, lr = 1e-08
I0407 12:26:38.006289  6158 solver.cpp:337] Iteration 1900, Testing net (#0)
I0407 12:26:48.851996  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:26:49.717037  6158 solver.cpp:228] Iteration 1900, loss = -3.8147e-06
I0407 12:26:49.717080  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:26:49.717092  6158 sgd_solver.cpp:106] Iteration 1900, lr = 1e-08
I0407 12:27:41.852504  6158 solver.cpp:228] Iteration 1920, loss = -3.8147e-06
I0407 12:27:41.852761  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:27:41.852797  6158 sgd_solver.cpp:106] Iteration 1920, lr = 1e-08
I0407 12:28:33.959105  6158 solver.cpp:228] Iteration 1940, loss = -3.8147e-06
I0407 12:28:33.969939  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:28:33.969957  6158 sgd_solver.cpp:106] Iteration 1940, lr = 1e-08
I0407 12:29:26.061084  6158 solver.cpp:228] Iteration 1960, loss = -3.8147e-06
I0407 12:29:26.064673  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:29:26.064689  6158 sgd_solver.cpp:106] Iteration 1960, lr = 1e-08
I0407 12:30:18.222533  6158 solver.cpp:228] Iteration 1980, loss = -3.8147e-06
I0407 12:30:18.235010  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:30:18.235038  6158 sgd_solver.cpp:106] Iteration 1980, lr = 1e-08
I0407 12:31:07.789221  6158 solver.cpp:454] Snapshotting to binary proto file c3d_ucf101_iter_2000.caffemodel
I0407 12:31:10.889575  6158 sgd_solver.cpp:273] Snapshotting solver state to binary proto file c3d_ucf101_iter_2000.solverstate
I0407 12:31:11.063578  6158 solver.cpp:337] Iteration 2000, Testing net (#0)
I0407 12:31:20.820086  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:31:21.686058  6158 solver.cpp:228] Iteration 2000, loss = -3.8147e-06
I0407 12:31:21.686108  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:31:21.686122  6158 sgd_solver.cpp:106] Iteration 2000, lr = 1e-08
I0407 12:32:13.843451  6158 solver.cpp:228] Iteration 2020, loss = -3.8147e-06
I0407 12:32:13.843713  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:32:13.843765  6158 sgd_solver.cpp:106] Iteration 2020, lr = 1e-08
I0407 12:33:06.054955  6158 solver.cpp:228] Iteration 2040, loss = -3.8147e-06
I0407 12:33:06.057677  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:33:06.057706  6158 sgd_solver.cpp:106] Iteration 2040, lr = 1e-08
I0407 12:33:58.292760  6158 solver.cpp:228] Iteration 2060, loss = -3.8147e-06
I0407 12:33:58.293042  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:33:58.293069  6158 sgd_solver.cpp:106] Iteration 2060, lr = 1e-08
I0407 12:34:50.431180  6158 solver.cpp:228] Iteration 2080, loss = -3.8147e-06
I0407 12:34:50.431391  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:34:50.431408  6158 sgd_solver.cpp:106] Iteration 2080, lr = 1e-08
I0407 12:35:39.890772  6158 solver.cpp:337] Iteration 2100, Testing net (#0)
I0407 12:35:51.510308  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:35:52.375219  6158 solver.cpp:228] Iteration 2100, loss = -3.8147e-06
I0407 12:35:52.375275  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:35:52.375288  6158 sgd_solver.cpp:106] Iteration 2100, lr = 1e-08
I0407 12:36:44.576125  6158 solver.cpp:228] Iteration 2120, loss = -3.8147e-06
I0407 12:36:44.576900  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:36:44.576927  6158 sgd_solver.cpp:106] Iteration 2120, lr = 1e-08
I0407 12:37:36.782068  6158 solver.cpp:228] Iteration 2140, loss = -3.8147e-06
I0407 12:37:36.782269  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:37:36.782308  6158 sgd_solver.cpp:106] Iteration 2140, lr = 1e-08
I0407 12:38:28.928308  6158 solver.cpp:228] Iteration 2160, loss = -3.8147e-06
I0407 12:38:28.928537  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:38:28.928575  6158 sgd_solver.cpp:106] Iteration 2160, lr = 1e-08
I0407 12:39:20.969058  6158 solver.cpp:228] Iteration 2180, loss = -3.8147e-06
I0407 12:39:20.969370  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:39:20.969403  6158 sgd_solver.cpp:106] Iteration 2180, lr = 1e-08
I0407 12:40:10.407809  6158 solver.cpp:337] Iteration 2200, Testing net (#0)
I0407 12:40:21.787055  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:40:22.658932  6158 solver.cpp:228] Iteration 2200, loss = -3.8147e-06
I0407 12:40:22.659014  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:40:22.659039  6158 sgd_solver.cpp:106] Iteration 2200, lr = 1e-08
I0407 12:41:14.648716  6158 solver.cpp:228] Iteration 2220, loss = -3.8147e-06
I0407 12:41:14.649152  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:41:14.649178  6158 sgd_solver.cpp:106] Iteration 2220, lr = 1e-08
I0407 12:42:06.658882  6158 solver.cpp:228] Iteration 2240, loss = -3.8147e-06
I0407 12:42:06.659049  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:42:06.659065  6158 sgd_solver.cpp:106] Iteration 2240, lr = 1e-08
I0407 12:42:58.827198  6158 solver.cpp:228] Iteration 2260, loss = -3.8147e-06
I0407 12:42:58.827461  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:42:58.827488  6158 sgd_solver.cpp:106] Iteration 2260, lr = 1e-08
I0407 12:43:51.050142  6158 solver.cpp:228] Iteration 2280, loss = -3.8147e-06
I0407 12:43:51.050309  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:43:51.050324  6158 sgd_solver.cpp:106] Iteration 2280, lr = 1e-08
I0407 12:44:40.697751  6158 solver.cpp:337] Iteration 2300, Testing net (#0)
I0407 12:44:45.655684  6158 blocking_queue.cpp:50] Data layer prefetch queue empty
I0407 12:44:51.217905  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:44:52.081517  6158 solver.cpp:228] Iteration 2300, loss = -3.8147e-06
I0407 12:44:52.081570  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:44:52.081583  6158 sgd_solver.cpp:106] Iteration 2300, lr = 1e-08
I0407 12:45:44.078945  6158 solver.cpp:228] Iteration 2320, loss = -3.8147e-06
I0407 12:45:44.079115  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:45:44.079129  6158 sgd_solver.cpp:106] Iteration 2320, lr = 1e-08
I0407 12:46:36.104049  6158 solver.cpp:228] Iteration 2340, loss = -3.8147e-06
I0407 12:46:36.104274  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:46:36.104310  6158 sgd_solver.cpp:106] Iteration 2340, lr = 1e-08
I0407 12:47:28.207967  6158 solver.cpp:228] Iteration 2360, loss = -3.8147e-06
I0407 12:47:28.208204  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:47:28.208243  6158 sgd_solver.cpp:106] Iteration 2360, lr = 1e-08
I0407 12:48:20.366550  6158 solver.cpp:228] Iteration 2380, loss = -3.8147e-06
I0407 12:48:20.366755  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:48:20.366770  6158 sgd_solver.cpp:106] Iteration 2380, lr = 1e-08
I0407 12:49:09.924363  6158 solver.cpp:337] Iteration 2400, Testing net (#0)
I0407 12:49:21.111565  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:49:21.977475  6158 solver.cpp:228] Iteration 2400, loss = -3.8147e-06
I0407 12:49:21.977525  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:49:21.977540  6158 sgd_solver.cpp:106] Iteration 2400, lr = 1e-08
I0407 12:50:14.135917  6158 solver.cpp:228] Iteration 2420, loss = -3.8147e-06
I0407 12:50:14.136266  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:50:14.136281  6158 sgd_solver.cpp:106] Iteration 2420, lr = 1e-08
I0407 12:51:06.380735  6158 solver.cpp:228] Iteration 2440, loss = -3.8147e-06
I0407 12:51:06.381100  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:51:06.381114  6158 sgd_solver.cpp:106] Iteration 2440, lr = 1e-08
I0407 12:51:58.569330  6158 solver.cpp:228] Iteration 2460, loss = -3.8147e-06
I0407 12:51:58.569494  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:51:58.569514  6158 sgd_solver.cpp:106] Iteration 2460, lr = 1e-08
I0407 12:52:50.696750  6158 solver.cpp:228] Iteration 2480, loss = -3.8147e-06
I0407 12:52:50.696954  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:52:50.696969  6158 sgd_solver.cpp:106] Iteration 2480, lr = 1e-08
I0407 12:53:40.201398  6158 solver.cpp:337] Iteration 2500, Testing net (#0)
I0407 12:53:51.542043  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:53:52.407505  6158 solver.cpp:228] Iteration 2500, loss = -3.8147e-06
I0407 12:53:52.407564  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:53:52.407578  6158 sgd_solver.cpp:106] Iteration 2500, lr = 1e-08
I0407 12:54:44.530097  6158 solver.cpp:228] Iteration 2520, loss = -3.8147e-06
I0407 12:54:44.532106  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:54:44.532135  6158 sgd_solver.cpp:106] Iteration 2520, lr = 1e-08
I0407 12:55:36.689714  6158 solver.cpp:228] Iteration 2540, loss = -3.8147e-06
I0407 12:55:36.702162  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:55:36.702191  6158 sgd_solver.cpp:106] Iteration 2540, lr = 1e-08
I0407 12:56:28.835764  6158 solver.cpp:228] Iteration 2560, loss = -3.8147e-06
I0407 12:56:28.836009  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:56:28.836066  6158 sgd_solver.cpp:106] Iteration 2560, lr = 1e-08
I0407 12:57:20.982489  6158 solver.cpp:228] Iteration 2580, loss = -3.8147e-06
I0407 12:57:20.982748  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:57:20.982776  6158 sgd_solver.cpp:106] Iteration 2580, lr = 1e-08
I0407 12:58:10.588938  6158 solver.cpp:337] Iteration 2600, Testing net (#0)
I0407 12:58:20.871615  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:58:21.736851  6158 solver.cpp:228] Iteration 2600, loss = -3.8147e-06
I0407 12:58:21.736913  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:58:21.736928  6158 sgd_solver.cpp:106] Iteration 2600, lr = 1e-08
I0407 12:59:13.816155  6158 solver.cpp:228] Iteration 2620, loss = -3.8147e-06
I0407 12:59:13.816401  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 12:59:13.816447  6158 sgd_solver.cpp:106] Iteration 2620, lr = 1e-08
I0407 13:00:05.922353  6158 solver.cpp:228] Iteration 2640, loss = -3.8147e-06
I0407 13:00:05.922547  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:00:05.922564  6158 sgd_solver.cpp:106] Iteration 2640, lr = 1e-08
I0407 13:00:58.116992  6158 solver.cpp:228] Iteration 2660, loss = -3.8147e-06
I0407 13:00:58.117142  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:00:58.117171  6158 sgd_solver.cpp:106] Iteration 2660, lr = 1e-08
I0407 13:01:50.387166  6158 solver.cpp:228] Iteration 2680, loss = -3.8147e-06
I0407 13:01:50.388676  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:01:50.388705  6158 sgd_solver.cpp:106] Iteration 2680, lr = 1e-08
I0407 13:02:40.011443  6158 solver.cpp:337] Iteration 2700, Testing net (#0)
I0407 13:02:50.456488  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:02:51.321346  6158 solver.cpp:228] Iteration 2700, loss = -3.8147e-06
I0407 13:02:51.321406  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:02:51.321421  6158 sgd_solver.cpp:106] Iteration 2700, lr = 1e-08
I0407 13:03:43.525626  6158 solver.cpp:228] Iteration 2720, loss = -3.8147e-06
I0407 13:03:43.525919  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:03:43.525954  6158 sgd_solver.cpp:106] Iteration 2720, lr = 1e-08
I0407 13:04:35.737076  6158 solver.cpp:228] Iteration 2740, loss = -3.8147e-06
I0407 13:04:35.737237  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:04:35.737264  6158 sgd_solver.cpp:106] Iteration 2740, lr = 1e-08
I0407 13:05:27.923056  6158 solver.cpp:228] Iteration 2760, loss = -3.8147e-06
I0407 13:05:27.929949  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:05:27.929968  6158 sgd_solver.cpp:106] Iteration 2760, lr = 1e-08
I0407 13:06:20.090880  6158 solver.cpp:228] Iteration 2780, loss = -3.8147e-06
I0407 13:06:20.091694  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:06:20.091722  6158 sgd_solver.cpp:106] Iteration 2780, lr = 1e-08
I0407 13:07:09.592777  6158 solver.cpp:337] Iteration 2800, Testing net (#0)
I0407 13:07:18.658344  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:07:19.523368  6158 solver.cpp:228] Iteration 2800, loss = -3.8147e-06
I0407 13:07:19.523416  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:07:19.523442  6158 sgd_solver.cpp:106] Iteration 2800, lr = 1e-08
I0407 13:08:11.690650  6158 solver.cpp:228] Iteration 2820, loss = -3.8147e-06
I0407 13:08:11.703140  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:08:11.703157  6158 sgd_solver.cpp:106] Iteration 2820, lr = 1e-08
I0407 13:09:03.937999  6158 solver.cpp:228] Iteration 2840, loss = -3.8147e-06
I0407 13:09:03.938431  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:09:03.938490  6158 sgd_solver.cpp:106] Iteration 2840, lr = 1e-08
I0407 13:09:56.144129  6158 solver.cpp:228] Iteration 2860, loss = -3.8147e-06
I0407 13:09:56.144459  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:09:56.144502  6158 sgd_solver.cpp:106] Iteration 2860, lr = 1e-08
I0407 13:10:48.330145  6158 solver.cpp:228] Iteration 2880, loss = -3.8147e-06
I0407 13:10:48.330350  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:10:48.330368  6158 sgd_solver.cpp:106] Iteration 2880, lr = 1e-08
I0407 13:11:37.868518  6158 solver.cpp:337] Iteration 2900, Testing net (#0)
I0407 13:11:47.711613  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:11:48.575485  6158 solver.cpp:228] Iteration 2900, loss = -3.8147e-06
I0407 13:11:48.575551  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:11:48.575567  6158 sgd_solver.cpp:106] Iteration 2900, lr = 1e-08
I0407 13:12:40.640018  6158 solver.cpp:228] Iteration 2920, loss = -3.8147e-06
I0407 13:12:40.640195  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:12:40.640216  6158 sgd_solver.cpp:106] Iteration 2920, lr = 1e-08
I0407 13:13:32.703675  6158 solver.cpp:228] Iteration 2940, loss = -3.8147e-06
I0407 13:13:32.704005  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:13:32.704084  6158 sgd_solver.cpp:106] Iteration 2940, lr = 1e-08
I0407 13:14:24.700572  6158 solver.cpp:228] Iteration 2960, loss = -3.8147e-06
I0407 13:14:24.700870  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:14:24.700922  6158 sgd_solver.cpp:106] Iteration 2960, lr = 1e-08
I0407 13:15:16.731981  6158 solver.cpp:228] Iteration 2980, loss = -3.8147e-06
I0407 13:15:16.732586  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:15:16.732625  6158 sgd_solver.cpp:106] Iteration 2980, lr = 1e-08
I0407 13:16:06.297919  6158 solver.cpp:454] Snapshotting to binary proto file c3d_ucf101_iter_3000.caffemodel
I0407 13:16:14.325152  6158 sgd_solver.cpp:273] Snapshotting solver state to binary proto file c3d_ucf101_iter_3000.solverstate
I0407 13:16:14.470813  6158 solver.cpp:337] Iteration 3000, Testing net (#0)
I0407 13:16:22.973071  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:16:23.836884  6158 solver.cpp:228] Iteration 3000, loss = -3.8147e-06
I0407 13:16:23.836956  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:16:23.836972  6158 sgd_solver.cpp:106] Iteration 3000, lr = 1e-08
I0407 13:17:15.890398  6158 solver.cpp:228] Iteration 3020, loss = -3.8147e-06
I0407 13:17:15.892671  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:17:15.892709  6158 sgd_solver.cpp:106] Iteration 3020, lr = 1e-08
I0407 13:18:08.085289  6158 solver.cpp:228] Iteration 3040, loss = -3.8147e-06
I0407 13:18:08.085475  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:18:08.085491  6158 sgd_solver.cpp:106] Iteration 3040, lr = 1e-08
I0407 13:19:00.326299  6158 solver.cpp:228] Iteration 3060, loss = -3.8147e-06
I0407 13:19:00.326521  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:19:00.326539  6158 sgd_solver.cpp:106] Iteration 3060, lr = 1e-08
I0407 13:19:52.387686  6158 solver.cpp:228] Iteration 3080, loss = -3.8147e-06
I0407 13:19:52.389235  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:19:52.389259  6158 sgd_solver.cpp:106] Iteration 3080, lr = 1e-08
I0407 13:20:41.831542  6158 solver.cpp:337] Iteration 3100, Testing net (#0)
I0407 13:20:51.248459  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:20:52.117693  6158 solver.cpp:228] Iteration 3100, loss = -3.8147e-06
I0407 13:20:52.117751  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:20:52.117765  6158 sgd_solver.cpp:106] Iteration 3100, lr = 1e-08
I0407 13:21:44.166892  6158 solver.cpp:228] Iteration 3120, loss = -3.8147e-06
I0407 13:21:44.179586  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:21:44.179644  6158 sgd_solver.cpp:106] Iteration 3120, lr = 1e-08
I0407 13:22:36.177280  6158 solver.cpp:228] Iteration 3140, loss = -3.8147e-06
I0407 13:22:36.178733  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:22:36.178778  6158 sgd_solver.cpp:106] Iteration 3140, lr = 1e-08
I0407 13:23:28.167600  6158 solver.cpp:228] Iteration 3160, loss = -3.8147e-06
I0407 13:23:28.167811  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:23:28.167827  6158 sgd_solver.cpp:106] Iteration 3160, lr = 1e-08
I0407 13:24:20.164588  6158 solver.cpp:228] Iteration 3180, loss = -3.8147e-06
I0407 13:24:20.164798  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:24:20.164827  6158 sgd_solver.cpp:106] Iteration 3180, lr = 1e-08
I0407 13:25:09.505311  6158 solver.cpp:337] Iteration 3200, Testing net (#0)
I0407 13:25:19.609495  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:25:20.477787  6158 solver.cpp:228] Iteration 3200, loss = -3.8147e-06
I0407 13:25:20.477854  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:25:20.477885  6158 sgd_solver.cpp:106] Iteration 3200, lr = 1e-08
I0407 13:26:12.455122  6158 solver.cpp:228] Iteration 3220, loss = -3.8147e-06
I0407 13:26:12.455346  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:26:12.455374  6158 sgd_solver.cpp:106] Iteration 3220, lr = 1e-08
I0407 13:27:04.420603  6158 solver.cpp:228] Iteration 3240, loss = -3.8147e-06
I0407 13:27:04.420868  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:27:04.420910  6158 sgd_solver.cpp:106] Iteration 3240, lr = 1e-08
I0407 13:27:56.302875  6158 solver.cpp:228] Iteration 3260, loss = -3.8147e-06
I0407 13:27:56.303470  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:27:56.303486  6158 sgd_solver.cpp:106] Iteration 3260, lr = 1e-08
I0407 13:28:48.122500  6158 solver.cpp:228] Iteration 3280, loss = -3.8147e-06
I0407 13:28:48.122679  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:28:48.122697  6158 sgd_solver.cpp:106] Iteration 3280, lr = 1e-08
I0407 13:29:37.444110  6158 solver.cpp:337] Iteration 3300, Testing net (#0)
I0407 13:29:48.598800  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:29:49.464052  6158 solver.cpp:228] Iteration 3300, loss = -3.8147e-06
I0407 13:29:49.464198  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:29:49.464253  6158 sgd_solver.cpp:106] Iteration 3300, lr = 1e-08
I0407 13:30:41.399988  6158 solver.cpp:228] Iteration 3320, loss = -3.8147e-06
I0407 13:30:41.400225  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:30:41.400265  6158 sgd_solver.cpp:106] Iteration 3320, lr = 1e-08
I0407 13:31:33.362582  6158 solver.cpp:228] Iteration 3340, loss = -3.8147e-06
I0407 13:31:33.362818  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:31:33.362845  6158 sgd_solver.cpp:106] Iteration 3340, lr = 1e-08
I0407 13:32:25.417227  6158 solver.cpp:228] Iteration 3360, loss = -3.8147e-06
I0407 13:32:25.417491  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:32:25.417526  6158 sgd_solver.cpp:106] Iteration 3360, lr = 1e-08
I0407 13:33:17.426239  6158 solver.cpp:228] Iteration 3380, loss = -3.8147e-06
I0407 13:33:17.427357  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:33:17.427390  6158 sgd_solver.cpp:106] Iteration 3380, lr = 1e-08
I0407 13:34:06.833680  6158 solver.cpp:337] Iteration 3400, Testing net (#0)
I0407 13:34:18.462519  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:34:19.329759  6158 solver.cpp:228] Iteration 3400, loss = -3.8147e-06
I0407 13:34:19.329846  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:34:19.329912  6158 sgd_solver.cpp:106] Iteration 3400, lr = 1e-08
I0407 13:35:11.338455  6158 solver.cpp:228] Iteration 3420, loss = -3.8147e-06
I0407 13:35:11.338732  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:35:11.338753  6158 sgd_solver.cpp:106] Iteration 3420, lr = 1e-08
I0407 13:36:03.381011  6158 solver.cpp:228] Iteration 3440, loss = -3.8147e-06
I0407 13:36:03.381275  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:36:03.381317  6158 sgd_solver.cpp:106] Iteration 3440, lr = 1e-08
I0407 13:36:55.467701  6158 solver.cpp:228] Iteration 3460, loss = -3.8147e-06
I0407 13:36:55.467969  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:36:55.468013  6158 sgd_solver.cpp:106] Iteration 3460, lr = 1e-08
I0407 13:37:47.521241  6158 solver.cpp:228] Iteration 3480, loss = -3.8147e-06
I0407 13:37:47.521404  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:37:47.521420  6158 sgd_solver.cpp:106] Iteration 3480, lr = 1e-08
I0407 13:38:36.863163  6158 solver.cpp:337] Iteration 3500, Testing net (#0)
I0407 13:38:40.387979  6158 blocking_queue.cpp:50] Data layer prefetch queue empty
I0407 13:38:47.286057  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:38:48.153555  6158 solver.cpp:228] Iteration 3500, loss = -3.8147e-06
I0407 13:38:48.153689  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:38:48.153712  6158 sgd_solver.cpp:106] Iteration 3500, lr = 1e-08
I0407 13:39:40.215551  6158 solver.cpp:228] Iteration 3520, loss = -3.8147e-06
I0407 13:39:40.217702  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:39:40.217720  6158 sgd_solver.cpp:106] Iteration 3520, lr = 1e-08
I0407 13:40:32.307166  6158 solver.cpp:228] Iteration 3540, loss = -3.8147e-06
I0407 13:40:32.307421  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:40:32.307452  6158 sgd_solver.cpp:106] Iteration 3540, lr = 1e-08
I0407 13:41:24.305821  6158 solver.cpp:228] Iteration 3560, loss = -3.8147e-06
I0407 13:41:24.306005  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:41:24.306021  6158 sgd_solver.cpp:106] Iteration 3560, lr = 1e-08
I0407 13:42:16.294672  6158 solver.cpp:228] Iteration 3580, loss = -3.8147e-06
I0407 13:42:16.294940  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:42:16.295001  6158 sgd_solver.cpp:106] Iteration 3580, lr = 1e-08
I0407 13:43:05.735607  6158 solver.cpp:337] Iteration 3600, Testing net (#0)
I0407 13:43:17.472560  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:43:18.340147  6158 solver.cpp:228] Iteration 3600, loss = -3.8147e-06
I0407 13:43:18.340207  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:43:18.340220  6158 sgd_solver.cpp:106] Iteration 3600, lr = 1e-08
I0407 13:44:10.344457  6158 solver.cpp:228] Iteration 3620, loss = -3.8147e-06
I0407 13:44:10.344617  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:44:10.344632  6158 sgd_solver.cpp:106] Iteration 3620, lr = 1e-08
I0407 13:45:02.400521  6158 solver.cpp:228] Iteration 3640, loss = -3.8147e-06
I0407 13:45:02.400679  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:45:02.400696  6158 sgd_solver.cpp:106] Iteration 3640, lr = 1e-08
I0407 13:45:54.588680  6158 solver.cpp:228] Iteration 3660, loss = -3.8147e-06
I0407 13:45:54.593952  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:45:54.593968  6158 sgd_solver.cpp:106] Iteration 3660, lr = 1e-08
I0407 13:46:46.769136  6158 solver.cpp:228] Iteration 3680, loss = -3.8147e-06
I0407 13:46:46.781630  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:46:46.781659  6158 sgd_solver.cpp:106] Iteration 3680, lr = 1e-08
I0407 13:47:36.213958  6158 solver.cpp:337] Iteration 3700, Testing net (#0)
I0407 13:47:48.538152  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:47:49.401563  6158 solver.cpp:228] Iteration 3700, loss = -3.8147e-06
I0407 13:47:49.401613  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:47:49.401629  6158 sgd_solver.cpp:106] Iteration 3700, lr = 1e-08
I0407 13:48:41.576380  6158 solver.cpp:228] Iteration 3720, loss = -3.8147e-06
I0407 13:48:41.576644  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:48:41.576678  6158 sgd_solver.cpp:106] Iteration 3720, lr = 1e-08
I0407 13:49:33.752215  6158 solver.cpp:228] Iteration 3740, loss = -3.8147e-06
I0407 13:49:33.752528  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:49:33.752578  6158 sgd_solver.cpp:106] Iteration 3740, lr = 1e-08
I0407 13:50:25.909574  6158 solver.cpp:228] Iteration 3760, loss = -3.8147e-06
I0407 13:50:25.917974  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:50:25.918174  6158 sgd_solver.cpp:106] Iteration 3760, lr = 1e-08
I0407 13:51:17.923492  6158 solver.cpp:228] Iteration 3780, loss = -3.8147e-06
I0407 13:51:17.923794  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:51:17.923856  6158 sgd_solver.cpp:106] Iteration 3780, lr = 1e-08
I0407 13:52:07.246361  6158 solver.cpp:337] Iteration 3800, Testing net (#0)
I0407 13:52:18.459420  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:52:19.325681  6158 solver.cpp:228] Iteration 3800, loss = -3.8147e-06
I0407 13:52:19.325724  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:52:19.325739  6158 sgd_solver.cpp:106] Iteration 3800, lr = 1e-08
I0407 13:53:11.381512  6158 solver.cpp:228] Iteration 3820, loss = -3.8147e-06
I0407 13:53:11.381882  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:53:11.381942  6158 sgd_solver.cpp:106] Iteration 3820, lr = 1e-08
I0407 13:54:03.416416  6158 solver.cpp:228] Iteration 3840, loss = -3.8147e-06
I0407 13:54:03.417750  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:54:03.417779  6158 sgd_solver.cpp:106] Iteration 3840, lr = 1e-08
I0407 13:54:55.315028  6158 solver.cpp:228] Iteration 3860, loss = -3.8147e-06
I0407 13:54:55.315292  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:54:55.315346  6158 sgd_solver.cpp:106] Iteration 3860, lr = 1e-08
I0407 13:55:47.221268  6158 solver.cpp:228] Iteration 3880, loss = -3.8147e-06
I0407 13:55:47.221488  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:55:47.221515  6158 sgd_solver.cpp:106] Iteration 3880, lr = 1e-08
I0407 13:56:36.631649  6158 solver.cpp:337] Iteration 3900, Testing net (#0)
I0407 13:56:47.764233  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:56:48.628568  6158 solver.cpp:228] Iteration 3900, loss = -3.8147e-06
I0407 13:56:48.628610  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:56:48.628623  6158 sgd_solver.cpp:106] Iteration 3900, lr = 1e-08
I0407 13:57:40.527004  6158 solver.cpp:228] Iteration 3920, loss = -3.8147e-06
I0407 13:57:40.527195  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:57:40.527210  6158 sgd_solver.cpp:106] Iteration 3920, lr = 1e-08
I0407 13:58:32.542560  6158 solver.cpp:228] Iteration 3940, loss = -3.8147e-06
I0407 13:58:32.542728  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:58:32.542742  6158 sgd_solver.cpp:106] Iteration 3940, lr = 1e-08
I0407 13:59:24.668104  6158 solver.cpp:228] Iteration 3960, loss = -3.8147e-06
I0407 13:59:24.668269  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 13:59:24.668284  6158 sgd_solver.cpp:106] Iteration 3960, lr = 1e-08
I0407 14:00:16.812693  6158 solver.cpp:228] Iteration 3980, loss = -3.8147e-06
I0407 14:00:16.813277  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:00:16.813293  6158 sgd_solver.cpp:106] Iteration 3980, lr = 1e-08
I0407 14:01:06.317986  6158 solver.cpp:454] Snapshotting to binary proto file c3d_ucf101_iter_4000.caffemodel
I0407 14:01:18.076705  6158 sgd_solver.cpp:273] Snapshotting solver state to binary proto file c3d_ucf101_iter_4000.solverstate
I0407 14:01:18.216387  6158 solver.cpp:337] Iteration 4000, Testing net (#0)
I0407 14:01:27.509081  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:01:28.371428  6158 solver.cpp:228] Iteration 4000, loss = -3.8147e-06
I0407 14:01:28.371475  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:01:28.371490  6158 sgd_solver.cpp:106] Iteration 4000, lr = 1e-08
I0407 14:02:20.507012  6158 solver.cpp:228] Iteration 4020, loss = -3.8147e-06
I0407 14:02:20.509122  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:02:20.509146  6158 sgd_solver.cpp:106] Iteration 4020, lr = 1e-08
I0407 14:03:13.324264  6158 solver.cpp:228] Iteration 4040, loss = -3.8147e-06
I0407 14:03:13.324430  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:03:13.324448  6158 sgd_solver.cpp:106] Iteration 4040, lr = 1e-08
I0407 14:04:05.587877  6158 solver.cpp:228] Iteration 4060, loss = -3.8147e-06
I0407 14:04:05.588176  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:04:05.588241  6158 sgd_solver.cpp:106] Iteration 4060, lr = 1e-08
I0407 14:04:57.594511  6158 solver.cpp:228] Iteration 4080, loss = -3.8147e-06
I0407 14:04:57.605888  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:04:57.605926  6158 sgd_solver.cpp:106] Iteration 4080, lr = 1e-08
I0407 14:05:47.025032  6158 solver.cpp:337] Iteration 4100, Testing net (#0)
I0407 14:05:58.861719  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:05:59.724957  6158 solver.cpp:228] Iteration 4100, loss = -3.8147e-06
I0407 14:05:59.725006  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:05:59.725033  6158 sgd_solver.cpp:106] Iteration 4100, lr = 1e-08
I0407 14:06:51.704159  6158 solver.cpp:228] Iteration 4120, loss = -3.8147e-06
I0407 14:06:51.704421  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:06:51.704434  6158 sgd_solver.cpp:106] Iteration 4120, lr = 1e-08
I0407 14:07:43.731951  6158 solver.cpp:228] Iteration 4140, loss = -3.8147e-06
I0407 14:07:43.732137  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:07:43.732152  6158 sgd_solver.cpp:106] Iteration 4140, lr = 1e-08
I0407 14:08:35.943248  6158 solver.cpp:228] Iteration 4160, loss = -3.8147e-06
I0407 14:08:35.943420  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:08:35.943435  6158 sgd_solver.cpp:106] Iteration 4160, lr = 1e-08
I0407 14:09:28.215164  6158 solver.cpp:228] Iteration 4180, loss = -3.8147e-06
I0407 14:09:28.215353  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:09:28.215368  6158 sgd_solver.cpp:106] Iteration 4180, lr = 1e-08
I0407 14:10:17.827597  6158 solver.cpp:337] Iteration 4200, Testing net (#0)
I0407 14:10:29.251794  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:10:30.115478  6158 solver.cpp:228] Iteration 4200, loss = -3.8147e-06
I0407 14:10:30.115530  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:10:30.115543  6158 sgd_solver.cpp:106] Iteration 4200, lr = 1e-08
I0407 14:11:22.129472  6158 solver.cpp:228] Iteration 4220, loss = -3.8147e-06
I0407 14:11:22.129734  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:11:22.129773  6158 sgd_solver.cpp:106] Iteration 4220, lr = 1e-08
I0407 14:12:14.172590  6158 solver.cpp:228] Iteration 4240, loss = -3.8147e-06
I0407 14:12:14.185055  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:12:14.185091  6158 sgd_solver.cpp:106] Iteration 4240, lr = 1e-08
I0407 14:13:06.276361  6158 solver.cpp:228] Iteration 4260, loss = -3.8147e-06
I0407 14:13:06.276556  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:13:06.276572  6158 sgd_solver.cpp:106] Iteration 4260, lr = 1e-08
I0407 14:13:58.435323  6158 solver.cpp:228] Iteration 4280, loss = -3.8147e-06
I0407 14:13:58.435883  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:13:58.435914  6158 sgd_solver.cpp:106] Iteration 4280, lr = 1e-08
I0407 14:14:47.896538  6158 solver.cpp:337] Iteration 4300, Testing net (#0)
I0407 14:14:56.884039  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:14:57.750319  6158 solver.cpp:228] Iteration 4300, loss = -3.8147e-06
I0407 14:14:57.750375  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:14:57.750386  6158 sgd_solver.cpp:106] Iteration 4300, lr = 1e-08
I0407 14:15:49.733537  6158 solver.cpp:228] Iteration 4320, loss = -3.8147e-06
I0407 14:15:49.733806  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:15:49.733850  6158 sgd_solver.cpp:106] Iteration 4320, lr = 1e-08
I0407 14:16:41.752125  6158 solver.cpp:228] Iteration 4340, loss = -3.8147e-06
I0407 14:16:41.752292  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:16:41.752318  6158 sgd_solver.cpp:106] Iteration 4340, lr = 1e-08
I0407 14:17:33.789710  6158 solver.cpp:228] Iteration 4360, loss = -3.8147e-06
I0407 14:17:33.789935  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:17:33.789952  6158 sgd_solver.cpp:106] Iteration 4360, lr = 1e-08
I0407 14:18:25.787034  6158 solver.cpp:228] Iteration 4380, loss = -3.8147e-06
I0407 14:18:25.787297  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:18:25.787336  6158 sgd_solver.cpp:106] Iteration 4380, lr = 1e-08
I0407 14:19:15.154992  6158 solver.cpp:337] Iteration 4400, Testing net (#0)
I0407 14:19:25.147619  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:19:26.016639  6158 solver.cpp:228] Iteration 4400, loss = -3.8147e-06
I0407 14:19:26.016693  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:19:26.016708  6158 sgd_solver.cpp:106] Iteration 4400, lr = 1e-08
I0407 14:20:18.134596  6158 solver.cpp:228] Iteration 4420, loss = -3.8147e-06
I0407 14:20:18.134850  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:20:18.134882  6158 sgd_solver.cpp:106] Iteration 4420, lr = 1e-08
I0407 14:21:10.305971  6158 solver.cpp:228] Iteration 4440, loss = -3.8147e-06
I0407 14:21:10.306264  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:21:10.306304  6158 sgd_solver.cpp:106] Iteration 4440, lr = 1e-08
I0407 14:22:02.394423  6158 solver.cpp:228] Iteration 4460, loss = -3.8147e-06
I0407 14:22:02.396911  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:22:02.396950  6158 sgd_solver.cpp:106] Iteration 4460, lr = 1e-08
I0407 14:22:54.358407  6158 solver.cpp:228] Iteration 4480, loss = -3.8147e-06
I0407 14:22:54.358645  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:22:54.358678  6158 sgd_solver.cpp:106] Iteration 4480, lr = 1e-08
I0407 14:23:43.752864  6158 solver.cpp:337] Iteration 4500, Testing net (#0)
I0407 14:23:53.767444  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:23:54.638253  6158 solver.cpp:228] Iteration 4500, loss = -3.8147e-06
I0407 14:23:54.638348  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:23:54.638368  6158 sgd_solver.cpp:106] Iteration 4500, lr = 1e-08
I0407 14:24:46.685511  6158 solver.cpp:228] Iteration 4520, loss = -3.8147e-06
I0407 14:24:46.685695  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:24:46.685724  6158 sgd_solver.cpp:106] Iteration 4520, lr = 1e-08
I0407 14:25:38.688236  6158 solver.cpp:228] Iteration 4540, loss = -3.8147e-06
I0407 14:25:38.701180  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:25:38.701205  6158 sgd_solver.cpp:106] Iteration 4540, lr = 1e-08
I0407 14:26:30.795527  6158 solver.cpp:228] Iteration 4560, loss = -3.8147e-06
I0407 14:26:30.806728  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:26:30.806757  6158 sgd_solver.cpp:106] Iteration 4560, lr = 1e-08
I0407 14:27:22.926193  6158 solver.cpp:228] Iteration 4580, loss = -3.8147e-06
I0407 14:27:22.926484  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:27:22.926528  6158 sgd_solver.cpp:106] Iteration 4580, lr = 1e-08
I0407 14:28:12.472043  6158 solver.cpp:337] Iteration 4600, Testing net (#0)
I0407 14:28:19.885273  6158 blocking_queue.cpp:50] Data layer prefetch queue empty
I0407 14:28:22.841532  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:28:23.710438  6158 solver.cpp:228] Iteration 4600, loss = -3.8147e-06
I0407 14:28:23.710481  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:28:23.710495  6158 sgd_solver.cpp:106] Iteration 4600, lr = 1e-08
I0407 14:29:15.706758  6158 solver.cpp:228] Iteration 4620, loss = -3.8147e-06
I0407 14:29:15.706998  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:29:15.707018  6158 sgd_solver.cpp:106] Iteration 4620, lr = 1e-08
I0407 14:30:07.721175  6158 solver.cpp:228] Iteration 4640, loss = -3.8147e-06
I0407 14:30:07.721376  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:30:07.721411  6158 sgd_solver.cpp:106] Iteration 4640, lr = 1e-08
I0407 14:30:59.751222  6158 solver.cpp:228] Iteration 4660, loss = -3.8147e-06
I0407 14:30:59.751706  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:30:59.751822  6158 sgd_solver.cpp:106] Iteration 4660, lr = 1e-08
I0407 14:31:51.832345  6158 solver.cpp:228] Iteration 4680, loss = -3.8147e-06
I0407 14:31:51.833171  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:31:51.833195  6158 sgd_solver.cpp:106] Iteration 4680, lr = 1e-08
I0407 14:32:41.333693  6158 solver.cpp:337] Iteration 4700, Testing net (#0)
I0407 14:32:51.244000  6158 solver.cpp:404]     Test net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:32:52.110178  6158 solver.cpp:228] Iteration 4700, loss = -3.8147e-06
I0407 14:32:52.110249  6158 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0407 14:32:52.110260  6158 sgd_solver.cpp:106] Iteration 4700, lr = 1e-08
