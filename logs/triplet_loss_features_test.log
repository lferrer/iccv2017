I0518 06:26:30.825507 31837 caffe.cpp:270] Use GPU with device ID 7
I0518 06:26:30.922464 31837 caffe.cpp:274] GPU device name: TITAN X (Pascal)
I0518 06:26:31.768023 31837 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams-Deploy"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  transform_param {
    mirror: true
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/Triplets/test"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn"
  type: "Python"
  bottom: "fc7"
  top: "fc7_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn_pos"
  type: "Python"
  bottom: "fc7_pos"
  top: "fc7_pos_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn_neg"
  type: "Python"
  bottom: "fc7_neg"
  top: "fc7_neg_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "save"
  type: "Python"
  bottom: "fc7_norm"
  bottom: "fc7_pos_norm"
  bottom: "fc7_neg_norm"
  python_param {
    module: "save_features"
    layer: "SaveFeaturesLayer"
    param_str: "{\"n_samples\":\"10000\", \"filename\":\"../../features/features_triplet_loss_mnv.npz\"}"
  }
}
I0518 06:26:31.769400 31837 layer_factory.hpp:77] Creating layer data
I0518 06:26:31.770004 31837 net.cpp:100] Creating Layer data
I0518 06:26:31.770020 31837 net.cpp:408] data -> triplet
I0518 06:26:31.773888 31849 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/Triplets/test
I0518 06:26:31.817551 31837 data_layer.cpp:41] output data size: 10,144,112,112
I0518 06:26:31.986723 31837 net.cpp:150] Setting up data
I0518 06:26:31.986785 31837 net.cpp:157] Top shape: 10 144 112 112 (18063360)
I0518 06:26:31.986793 31837 net.cpp:165] Memory required for data: 72253440
I0518 06:26:31.986812 31837 layer_factory.hpp:77] Creating layer slicer
I0518 06:26:31.986831 31837 net.cpp:100] Creating Layer slicer
I0518 06:26:31.986866 31837 net.cpp:434] slicer <- triplet
I0518 06:26:31.986878 31837 net.cpp:408] slicer -> anchor_stacked
I0518 06:26:31.986898 31837 net.cpp:408] slicer -> positive_stacked
I0518 06:26:31.986927 31837 net.cpp:408] slicer -> negative_stacked
I0518 06:26:31.987030 31837 net.cpp:150] Setting up slicer
I0518 06:26:31.987041 31837 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0518 06:26:31.987048 31837 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0518 06:26:31.987053 31837 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0518 06:26:31.987058 31837 net.cpp:165] Memory required for data: 144506880
I0518 06:26:31.987062 31837 layer_factory.hpp:77] Creating layer reshape_anchor
I0518 06:26:31.987087 31837 net.cpp:100] Creating Layer reshape_anchor
I0518 06:26:31.987102 31837 net.cpp:434] reshape_anchor <- anchor_stacked
I0518 06:26:31.987118 31837 net.cpp:408] reshape_anchor -> anchor
I0518 06:26:31.987180 31837 net.cpp:150] Setting up reshape_anchor
I0518 06:26:31.987191 31837 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0518 06:26:31.987221 31837 net.cpp:165] Memory required for data: 168591360
I0518 06:26:31.987241 31837 layer_factory.hpp:77] Creating layer reshape_positive
I0518 06:26:31.987253 31837 net.cpp:100] Creating Layer reshape_positive
I0518 06:26:31.987259 31837 net.cpp:434] reshape_positive <- positive_stacked
I0518 06:26:31.987269 31837 net.cpp:408] reshape_positive -> positive
I0518 06:26:31.987311 31837 net.cpp:150] Setting up reshape_positive
I0518 06:26:31.987321 31837 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0518 06:26:31.987325 31837 net.cpp:165] Memory required for data: 192675840
I0518 06:26:31.987367 31837 layer_factory.hpp:77] Creating layer reshape_negative
I0518 06:26:31.987378 31837 net.cpp:100] Creating Layer reshape_negative
I0518 06:26:31.987383 31837 net.cpp:434] reshape_negative <- negative_stacked
I0518 06:26:31.987391 31837 net.cpp:408] reshape_negative -> negative
I0518 06:26:31.987431 31837 net.cpp:150] Setting up reshape_negative
I0518 06:26:31.987440 31837 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0518 06:26:31.987444 31837 net.cpp:165] Memory required for data: 216760320
I0518 06:26:31.987448 31837 layer_factory.hpp:77] Creating layer conv1a
I0518 06:26:31.987474 31837 net.cpp:100] Creating Layer conv1a
I0518 06:26:31.987481 31837 net.cpp:434] conv1a <- anchor
I0518 06:26:31.987491 31837 net.cpp:408] conv1a -> conv1a
I0518 06:26:32.180480 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:26:32.963495 31837 net.cpp:150] Setting up conv1a
I0518 06:26:32.963538 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:32.963542 31837 net.cpp:165] Memory required for data: 730562560
I0518 06:26:32.963560 31837 layer_factory.hpp:77] Creating layer relu1a
I0518 06:26:32.963573 31837 net.cpp:100] Creating Layer relu1a
I0518 06:26:32.963578 31837 net.cpp:434] relu1a <- conv1a
I0518 06:26:32.963587 31837 net.cpp:395] relu1a -> conv1a (in-place)
I0518 06:26:32.963802 31837 net.cpp:150] Setting up relu1a
I0518 06:26:32.963821 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:32.963825 31837 net.cpp:165] Memory required for data: 1244364800
I0518 06:26:32.963829 31837 layer_factory.hpp:77] Creating layer pool1
I0518 06:26:32.963841 31837 net.cpp:100] Creating Layer pool1
I0518 06:26:32.963846 31837 net.cpp:434] pool1 <- conv1a
I0518 06:26:32.963853 31837 net.cpp:408] pool1 -> pool1
I0518 06:26:32.965032 31837 net.cpp:150] Setting up pool1
I0518 06:26:32.965049 31837 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0518 06:26:32.965052 31837 net.cpp:165] Memory required for data: 1372815360
I0518 06:26:32.965060 31837 layer_factory.hpp:77] Creating layer conv2a
I0518 06:26:32.965076 31837 net.cpp:100] Creating Layer conv2a
I0518 06:26:32.965080 31837 net.cpp:434] conv2a <- pool1
I0518 06:26:32.965090 31837 net.cpp:408] conv2a -> conv2a
I0518 06:26:32.976318 31837 net.cpp:150] Setting up conv2a
I0518 06:26:32.976336 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:32.976339 31837 net.cpp:165] Memory required for data: 1629716480
I0518 06:26:32.976349 31837 layer_factory.hpp:77] Creating layer relu2a
I0518 06:26:32.976356 31837 net.cpp:100] Creating Layer relu2a
I0518 06:26:32.976359 31837 net.cpp:434] relu2a <- conv2a
I0518 06:26:32.976366 31837 net.cpp:395] relu2a -> conv2a (in-place)
I0518 06:26:32.976577 31837 net.cpp:150] Setting up relu2a
I0518 06:26:32.976589 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:32.976593 31837 net.cpp:165] Memory required for data: 1886617600
I0518 06:26:32.976596 31837 layer_factory.hpp:77] Creating layer pool2
I0518 06:26:32.976605 31837 net.cpp:100] Creating Layer pool2
I0518 06:26:32.976611 31837 net.cpp:434] pool2 <- conv2a
I0518 06:26:32.976619 31837 net.cpp:408] pool2 -> pool2
I0518 06:26:32.976856 31837 net.cpp:150] Setting up pool2
I0518 06:26:32.976868 31837 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0518 06:26:32.976874 31837 net.cpp:165] Memory required for data: 1918730240
I0518 06:26:32.976878 31837 layer_factory.hpp:77] Creating layer conv3a
I0518 06:26:32.976889 31837 net.cpp:100] Creating Layer conv3a
I0518 06:26:32.976894 31837 net.cpp:434] conv3a <- pool2
I0518 06:26:32.976902 31837 net.cpp:408] conv3a -> conv3a
I0518 06:26:33.015353 31837 net.cpp:150] Setting up conv3a
I0518 06:26:33.015383 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:33.015388 31837 net.cpp:165] Memory required for data: 1982955520
I0518 06:26:33.015398 31837 layer_factory.hpp:77] Creating layer relu3a
I0518 06:26:33.015404 31837 net.cpp:100] Creating Layer relu3a
I0518 06:26:33.015408 31837 net.cpp:434] relu3a <- conv3a
I0518 06:26:33.015431 31837 net.cpp:395] relu3a -> conv3a (in-place)
I0518 06:26:33.015617 31837 net.cpp:150] Setting up relu3a
I0518 06:26:33.015628 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:33.015635 31837 net.cpp:165] Memory required for data: 2047180800
I0518 06:26:33.015637 31837 layer_factory.hpp:77] Creating layer pool3
I0518 06:26:33.015646 31837 net.cpp:100] Creating Layer pool3
I0518 06:26:33.015651 31837 net.cpp:434] pool3 <- conv3a
I0518 06:26:33.015656 31837 net.cpp:408] pool3 -> pool3
I0518 06:26:33.015892 31837 net.cpp:150] Setting up pool3
I0518 06:26:33.015905 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:33.015908 31837 net.cpp:165] Memory required for data: 2055208960
I0518 06:26:33.015913 31837 layer_factory.hpp:77] Creating layer conv4a
I0518 06:26:33.015923 31837 net.cpp:100] Creating Layer conv4a
I0518 06:26:33.015929 31837 net.cpp:434] conv4a <- pool3
I0518 06:26:33.015941 31837 net.cpp:408] conv4a -> conv4a
I0518 06:26:33.104127 31837 net.cpp:150] Setting up conv4a
I0518 06:26:33.104174 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:33.104181 31837 net.cpp:165] Memory required for data: 2063237120
I0518 06:26:33.104195 31837 layer_factory.hpp:77] Creating layer relu4a
I0518 06:26:33.104208 31837 net.cpp:100] Creating Layer relu4a
I0518 06:26:33.104221 31837 net.cpp:434] relu4a <- conv4a
I0518 06:26:33.104230 31837 net.cpp:395] relu4a -> conv4a (in-place)
I0518 06:26:33.105653 31837 net.cpp:150] Setting up relu4a
I0518 06:26:33.105686 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:33.105695 31837 net.cpp:165] Memory required for data: 2071265280
I0518 06:26:33.105702 31837 layer_factory.hpp:77] Creating layer pool4
I0518 06:26:33.105731 31837 net.cpp:100] Creating Layer pool4
I0518 06:26:33.105741 31837 net.cpp:434] pool4 <- conv4a
I0518 06:26:33.105754 31837 net.cpp:408] pool4 -> pool4
I0518 06:26:33.106148 31837 net.cpp:150] Setting up pool4
I0518 06:26:33.106171 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:33.106175 31837 net.cpp:165] Memory required for data: 2072268800
I0518 06:26:33.106180 31837 layer_factory.hpp:77] Creating layer conv5a
I0518 06:26:33.106206 31837 net.cpp:100] Creating Layer conv5a
I0518 06:26:33.106215 31837 net.cpp:434] conv5a <- pool4
I0518 06:26:33.106230 31837 net.cpp:408] conv5a -> conv5a
I0518 06:26:33.226876 31837 net.cpp:150] Setting up conv5a
I0518 06:26:33.226930 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:33.226943 31837 net.cpp:165] Memory required for data: 2073272320
I0518 06:26:33.226984 31837 layer_factory.hpp:77] Creating layer relu5a
I0518 06:26:33.226997 31837 net.cpp:100] Creating Layer relu5a
I0518 06:26:33.227004 31837 net.cpp:434] relu5a <- conv5a
I0518 06:26:33.227016 31837 net.cpp:395] relu5a -> conv5a (in-place)
I0518 06:26:33.227361 31837 net.cpp:150] Setting up relu5a
I0518 06:26:33.227387 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:33.227401 31837 net.cpp:165] Memory required for data: 2074275840
I0518 06:26:33.227406 31837 layer_factory.hpp:77] Creating layer pool5
I0518 06:26:33.227416 31837 net.cpp:100] Creating Layer pool5
I0518 06:26:33.227428 31837 net.cpp:434] pool5 <- conv5a
I0518 06:26:33.227450 31837 net.cpp:408] pool5 -> pool5
I0518 06:26:33.227834 31837 net.cpp:150] Setting up pool5
I0518 06:26:33.227854 31837 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0518 06:26:33.227857 31837 net.cpp:165] Memory required for data: 2074439680
I0518 06:26:33.227862 31837 layer_factory.hpp:77] Creating layer fc6
I0518 06:26:33.227896 31837 net.cpp:100] Creating Layer fc6
I0518 06:26:33.227901 31837 net.cpp:434] fc6 <- pool5
I0518 06:26:33.227916 31837 net.cpp:408] fc6 -> fc6
I0518 06:26:33.550750 31837 net.cpp:150] Setting up fc6
I0518 06:26:33.550796 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.550801 31837 net.cpp:165] Memory required for data: 2074521600
I0518 06:26:33.550814 31837 layer_factory.hpp:77] Creating layer relu6
I0518 06:26:33.550837 31837 net.cpp:100] Creating Layer relu6
I0518 06:26:33.550863 31837 net.cpp:434] relu6 <- fc6
I0518 06:26:33.550871 31837 net.cpp:395] relu6 -> fc6 (in-place)
I0518 06:26:33.552018 31837 net.cpp:150] Setting up relu6
I0518 06:26:33.552031 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.552047 31837 net.cpp:165] Memory required for data: 2074603520
I0518 06:26:33.552049 31837 layer_factory.hpp:77] Creating layer drop6
I0518 06:26:33.552058 31837 net.cpp:100] Creating Layer drop6
I0518 06:26:33.552062 31837 net.cpp:434] drop6 <- fc6
I0518 06:26:33.552067 31837 net.cpp:395] drop6 -> fc6 (in-place)
I0518 06:26:33.552139 31837 net.cpp:150] Setting up drop6
I0518 06:26:33.552146 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.552150 31837 net.cpp:165] Memory required for data: 2074685440
I0518 06:26:33.552152 31837 layer_factory.hpp:77] Creating layer fc7
I0518 06:26:33.552161 31837 net.cpp:100] Creating Layer fc7
I0518 06:26:33.552165 31837 net.cpp:434] fc7 <- fc6
I0518 06:26:33.552171 31837 net.cpp:408] fc7 -> fc7
I0518 06:26:33.684783 31837 net.cpp:150] Setting up fc7
I0518 06:26:33.684829 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.684834 31837 net.cpp:165] Memory required for data: 2074767360
I0518 06:26:33.684847 31837 layer_factory.hpp:77] Creating layer relu7
I0518 06:26:33.684857 31837 net.cpp:100] Creating Layer relu7
I0518 06:26:33.684861 31837 net.cpp:434] relu7 <- fc7
I0518 06:26:33.684869 31837 net.cpp:395] relu7 -> fc7 (in-place)
I0518 06:26:33.685147 31837 net.cpp:150] Setting up relu7
I0518 06:26:33.685156 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.685160 31837 net.cpp:165] Memory required for data: 2074849280
I0518 06:26:33.685163 31837 layer_factory.hpp:77] Creating layer drop7
I0518 06:26:33.685170 31837 net.cpp:100] Creating Layer drop7
I0518 06:26:33.685173 31837 net.cpp:434] drop7 <- fc7
I0518 06:26:33.685178 31837 net.cpp:395] drop7 -> fc7 (in-place)
I0518 06:26:33.685205 31837 net.cpp:150] Setting up drop7
I0518 06:26:33.685212 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:33.685214 31837 net.cpp:165] Memory required for data: 2074931200
I0518 06:26:33.685217 31837 layer_factory.hpp:77] Creating layer mvn
I0518 06:26:34.693488 31837 net.cpp:100] Creating Layer mvn
I0518 06:26:34.693544 31837 net.cpp:434] mvn <- fc7
I0518 06:26:34.693562 31837 net.cpp:408] mvn -> fc7_norm
I0518 06:26:35.871119 31837 net.cpp:150] Setting up mvn
I0518 06:26:35.871160 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:35.871165 31837 net.cpp:165] Memory required for data: 2075013120
I0518 06:26:35.871173 31837 layer_factory.hpp:77] Creating layer conv1a_pos
I0518 06:26:35.871191 31837 net.cpp:100] Creating Layer conv1a_pos
I0518 06:26:35.871197 31837 net.cpp:434] conv1a_pos <- positive
I0518 06:26:35.871209 31837 net.cpp:408] conv1a_pos -> conv1a_pos
I0518 06:26:35.876077 31837 net.cpp:150] Setting up conv1a_pos
I0518 06:26:35.876093 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:35.876104 31837 net.cpp:165] Memory required for data: 2588815360
I0518 06:26:35.876109 31837 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0518 06:26:35.876117 31837 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0518 06:26:35.876121 31837 layer_factory.hpp:77] Creating layer relu1a_pos
I0518 06:26:35.876135 31837 net.cpp:100] Creating Layer relu1a_pos
I0518 06:26:35.876142 31837 net.cpp:434] relu1a_pos <- conv1a_pos
I0518 06:26:35.876152 31837 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0518 06:26:35.876447 31837 net.cpp:150] Setting up relu1a_pos
I0518 06:26:35.876461 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:35.876464 31837 net.cpp:165] Memory required for data: 3102617600
I0518 06:26:35.876471 31837 layer_factory.hpp:77] Creating layer pool1_pos
I0518 06:26:35.876482 31837 net.cpp:100] Creating Layer pool1_pos
I0518 06:26:35.876490 31837 net.cpp:434] pool1_pos <- conv1a_pos
I0518 06:26:35.876507 31837 net.cpp:408] pool1_pos -> pool1_pos
I0518 06:26:35.877640 31837 net.cpp:150] Setting up pool1_pos
I0518 06:26:35.877655 31837 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0518 06:26:35.877660 31837 net.cpp:165] Memory required for data: 3231068160
I0518 06:26:35.877667 31837 layer_factory.hpp:77] Creating layer conv2a_pos
I0518 06:26:35.877686 31837 net.cpp:100] Creating Layer conv2a_pos
I0518 06:26:35.877694 31837 net.cpp:434] conv2a_pos <- pool1_pos
I0518 06:26:35.877708 31837 net.cpp:408] conv2a_pos -> conv2a_pos
I0518 06:26:35.885579 31837 net.cpp:150] Setting up conv2a_pos
I0518 06:26:35.885593 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:35.885597 31837 net.cpp:165] Memory required for data: 3487969280
I0518 06:26:35.885617 31837 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0518 06:26:35.885627 31837 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0518 06:26:35.885635 31837 layer_factory.hpp:77] Creating layer relu2a_pos
I0518 06:26:35.885644 31837 net.cpp:100] Creating Layer relu2a_pos
I0518 06:26:35.885653 31837 net.cpp:434] relu2a_pos <- conv2a_pos
I0518 06:26:35.885663 31837 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0518 06:26:35.886741 31837 net.cpp:150] Setting up relu2a_pos
I0518 06:26:35.886756 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:35.886760 31837 net.cpp:165] Memory required for data: 3744870400
I0518 06:26:35.886768 31837 layer_factory.hpp:77] Creating layer pool2_pos
I0518 06:26:35.886795 31837 net.cpp:100] Creating Layer pool2_pos
I0518 06:26:35.886804 31837 net.cpp:434] pool2_pos <- conv2a_pos
I0518 06:26:35.886816 31837 net.cpp:408] pool2_pos -> pool2_pos
I0518 06:26:35.887096 31837 net.cpp:150] Setting up pool2_pos
I0518 06:26:35.887109 31837 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0518 06:26:35.887112 31837 net.cpp:165] Memory required for data: 3776983040
I0518 06:26:35.887117 31837 layer_factory.hpp:77] Creating layer conv3a_pos
I0518 06:26:35.887135 31837 net.cpp:100] Creating Layer conv3a_pos
I0518 06:26:35.887142 31837 net.cpp:434] conv3a_pos <- pool2_pos
I0518 06:26:35.887159 31837 net.cpp:408] conv3a_pos -> conv3a_pos
I0518 06:26:35.919073 31837 net.cpp:150] Setting up conv3a_pos
I0518 06:26:35.919101 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:35.919112 31837 net.cpp:165] Memory required for data: 3841208320
I0518 06:26:35.919121 31837 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0518 06:26:35.919126 31837 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0518 06:26:35.919131 31837 layer_factory.hpp:77] Creating layer relu3a_pos
I0518 06:26:35.919147 31837 net.cpp:100] Creating Layer relu3a_pos
I0518 06:26:35.919157 31837 net.cpp:434] relu3a_pos <- conv3a_pos
I0518 06:26:35.919165 31837 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0518 06:26:35.919430 31837 net.cpp:150] Setting up relu3a_pos
I0518 06:26:35.919441 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:35.919445 31837 net.cpp:165] Memory required for data: 3905433600
I0518 06:26:35.919453 31837 layer_factory.hpp:77] Creating layer pool3_pos
I0518 06:26:35.919468 31837 net.cpp:100] Creating Layer pool3_pos
I0518 06:26:35.919476 31837 net.cpp:434] pool3_pos <- conv3a_pos
I0518 06:26:35.919489 31837 net.cpp:408] pool3_pos -> pool3_pos
I0518 06:26:35.919778 31837 net.cpp:150] Setting up pool3_pos
I0518 06:26:35.919790 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:35.919795 31837 net.cpp:165] Memory required for data: 3913461760
I0518 06:26:35.919800 31837 layer_factory.hpp:77] Creating layer conv4a_pos
I0518 06:26:35.919819 31837 net.cpp:100] Creating Layer conv4a_pos
I0518 06:26:35.919828 31837 net.cpp:434] conv4a_pos <- pool3_pos
I0518 06:26:35.919843 31837 net.cpp:408] conv4a_pos -> conv4a_pos
I0518 06:26:35.981371 31837 net.cpp:150] Setting up conv4a_pos
I0518 06:26:35.981407 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:35.981411 31837 net.cpp:165] Memory required for data: 3921489920
I0518 06:26:35.981448 31837 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0518 06:26:35.981457 31837 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0518 06:26:35.981463 31837 layer_factory.hpp:77] Creating layer relu4a_pos
I0518 06:26:35.981483 31837 net.cpp:100] Creating Layer relu4a_pos
I0518 06:26:35.981492 31837 net.cpp:434] relu4a_pos <- conv4a_pos
I0518 06:26:35.981501 31837 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0518 06:26:35.982591 31837 net.cpp:150] Setting up relu4a_pos
I0518 06:26:35.982605 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:35.982609 31837 net.cpp:165] Memory required for data: 3929518080
I0518 06:26:35.982619 31837 layer_factory.hpp:77] Creating layer pool4_pos
I0518 06:26:35.982630 31837 net.cpp:100] Creating Layer pool4_pos
I0518 06:26:35.982635 31837 net.cpp:434] pool4_pos <- conv4a_pos
I0518 06:26:35.982651 31837 net.cpp:408] pool4_pos -> pool4_pos
I0518 06:26:35.982949 31837 net.cpp:150] Setting up pool4_pos
I0518 06:26:35.982961 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:35.982964 31837 net.cpp:165] Memory required for data: 3930521600
I0518 06:26:35.982970 31837 layer_factory.hpp:77] Creating layer conv5a_pos
I0518 06:26:35.982987 31837 net.cpp:100] Creating Layer conv5a_pos
I0518 06:26:35.982996 31837 net.cpp:434] conv5a_pos <- pool4_pos
I0518 06:26:35.983011 31837 net.cpp:408] conv5a_pos -> conv5a_pos
I0518 06:26:36.053500 31837 net.cpp:150] Setting up conv5a_pos
I0518 06:26:36.053555 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:36.053560 31837 net.cpp:165] Memory required for data: 3931525120
I0518 06:26:36.053571 31837 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0518 06:26:36.053592 31837 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0518 06:26:36.053599 31837 layer_factory.hpp:77] Creating layer relu5a_pos
I0518 06:26:36.053647 31837 net.cpp:100] Creating Layer relu5a_pos
I0518 06:26:36.053660 31837 net.cpp:434] relu5a_pos <- conv5a_pos
I0518 06:26:36.053675 31837 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0518 06:26:36.054018 31837 net.cpp:150] Setting up relu5a_pos
I0518 06:26:36.054047 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:36.054054 31837 net.cpp:165] Memory required for data: 3932528640
I0518 06:26:36.054061 31837 layer_factory.hpp:77] Creating layer pool5_pos
I0518 06:26:36.054077 31837 net.cpp:100] Creating Layer pool5_pos
I0518 06:26:36.054087 31837 net.cpp:434] pool5_pos <- conv5a_pos
I0518 06:26:36.054100 31837 net.cpp:408] pool5_pos -> pool5_pos
I0518 06:26:36.054532 31837 net.cpp:150] Setting up pool5_pos
I0518 06:26:36.054548 31837 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0518 06:26:36.054567 31837 net.cpp:165] Memory required for data: 3932692480
I0518 06:26:36.054574 31837 layer_factory.hpp:77] Creating layer fc6_pos
I0518 06:26:36.054594 31837 net.cpp:100] Creating Layer fc6_pos
I0518 06:26:36.054603 31837 net.cpp:434] fc6_pos <- pool5_pos
I0518 06:26:36.054613 31837 net.cpp:408] fc6_pos -> fc6_pos
I0518 06:26:36.371585 31837 net.cpp:150] Setting up fc6_pos
I0518 06:26:36.371639 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.371644 31837 net.cpp:165] Memory required for data: 3932774400
I0518 06:26:36.371654 31837 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0518 06:26:36.371659 31837 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0518 06:26:36.371677 31837 layer_factory.hpp:77] Creating layer relu6_pos
I0518 06:26:36.371688 31837 net.cpp:100] Creating Layer relu6_pos
I0518 06:26:36.371693 31837 net.cpp:434] relu6_pos <- fc6_pos
I0518 06:26:36.371716 31837 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0518 06:26:36.372989 31837 net.cpp:150] Setting up relu6_pos
I0518 06:26:36.373004 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.373019 31837 net.cpp:165] Memory required for data: 3932856320
I0518 06:26:36.373023 31837 layer_factory.hpp:77] Creating layer drop6_pos
I0518 06:26:36.373064 31837 net.cpp:100] Creating Layer drop6_pos
I0518 06:26:36.373070 31837 net.cpp:434] drop6_pos <- fc6_pos
I0518 06:26:36.373077 31837 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0518 06:26:36.373117 31837 net.cpp:150] Setting up drop6_pos
I0518 06:26:36.373124 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.373127 31837 net.cpp:165] Memory required for data: 3932938240
I0518 06:26:36.373129 31837 layer_factory.hpp:77] Creating layer fc7_pos
I0518 06:26:36.373137 31837 net.cpp:100] Creating Layer fc7_pos
I0518 06:26:36.373142 31837 net.cpp:434] fc7_pos <- fc6_pos
I0518 06:26:36.373148 31837 net.cpp:408] fc7_pos -> fc7_pos
I0518 06:26:36.513159 31837 net.cpp:150] Setting up fc7_pos
I0518 06:26:36.513211 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.513216 31837 net.cpp:165] Memory required for data: 3933020160
I0518 06:26:36.513227 31837 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0518 06:26:36.513236 31837 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0518 06:26:36.513240 31837 layer_factory.hpp:77] Creating layer relu7_pos
I0518 06:26:36.513258 31837 net.cpp:100] Creating Layer relu7_pos
I0518 06:26:36.513278 31837 net.cpp:434] relu7_pos <- fc7_pos
I0518 06:26:36.513291 31837 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0518 06:26:36.513715 31837 net.cpp:150] Setting up relu7_pos
I0518 06:26:36.513731 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.513742 31837 net.cpp:165] Memory required for data: 3933102080
I0518 06:26:36.513748 31837 layer_factory.hpp:77] Creating layer drop7_pos
I0518 06:26:36.513761 31837 net.cpp:100] Creating Layer drop7_pos
I0518 06:26:36.513766 31837 net.cpp:434] drop7_pos <- fc7_pos
I0518 06:26:36.513772 31837 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0518 06:26:36.513831 31837 net.cpp:150] Setting up drop7_pos
I0518 06:26:36.513847 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.513869 31837 net.cpp:165] Memory required for data: 3933184000
I0518 06:26:36.513875 31837 layer_factory.hpp:77] Creating layer mvn_pos
I0518 06:26:36.513967 31837 net.cpp:100] Creating Layer mvn_pos
I0518 06:26:36.513980 31837 net.cpp:434] mvn_pos <- fc7_pos
I0518 06:26:36.513991 31837 net.cpp:408] mvn_pos -> fc7_pos_norm
I0518 06:26:36.514271 31837 net.cpp:150] Setting up mvn_pos
I0518 06:26:36.514294 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:36.514298 31837 net.cpp:165] Memory required for data: 3933265920
I0518 06:26:36.514302 31837 layer_factory.hpp:77] Creating layer conv1a_neg
I0518 06:26:36.514324 31837 net.cpp:100] Creating Layer conv1a_neg
I0518 06:26:36.514329 31837 net.cpp:434] conv1a_neg <- negative
I0518 06:26:36.514339 31837 net.cpp:408] conv1a_neg -> conv1a_neg
I0518 06:26:36.518352 31837 net.cpp:150] Setting up conv1a_neg
I0518 06:26:36.518374 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:36.518381 31837 net.cpp:165] Memory required for data: 4447068160
I0518 06:26:36.518388 31837 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0518 06:26:36.518395 31837 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0518 06:26:36.518401 31837 layer_factory.hpp:77] Creating layer relu1a_neg
I0518 06:26:36.518410 31837 net.cpp:100] Creating Layer relu1a_neg
I0518 06:26:36.518416 31837 net.cpp:434] relu1a_neg <- conv1a_neg
I0518 06:26:36.518429 31837 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0518 06:26:36.518784 31837 net.cpp:150] Setting up relu1a_neg
I0518 06:26:36.518800 31837 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0518 06:26:36.518808 31837 net.cpp:165] Memory required for data: 4960870400
I0518 06:26:36.518813 31837 layer_factory.hpp:77] Creating layer pool1_neg
I0518 06:26:36.518826 31837 net.cpp:100] Creating Layer pool1_neg
I0518 06:26:36.518829 31837 net.cpp:434] pool1_neg <- conv1a_neg
I0518 06:26:36.518838 31837 net.cpp:408] pool1_neg -> pool1_neg
I0518 06:26:36.519235 31837 net.cpp:150] Setting up pool1_neg
I0518 06:26:36.519281 31837 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0518 06:26:36.519285 31837 net.cpp:165] Memory required for data: 5089320960
I0518 06:26:36.519292 31837 layer_factory.hpp:77] Creating layer conv2a_neg
I0518 06:26:36.519312 31837 net.cpp:100] Creating Layer conv2a_neg
I0518 06:26:36.519317 31837 net.cpp:434] conv2a_neg <- pool1_neg
I0518 06:26:36.519327 31837 net.cpp:408] conv2a_neg -> conv2a_neg
I0518 06:26:36.529063 31837 net.cpp:150] Setting up conv2a_neg
I0518 06:26:36.529091 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:36.529094 31837 net.cpp:165] Memory required for data: 5346222080
I0518 06:26:36.529105 31837 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0518 06:26:36.529111 31837 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0518 06:26:36.529114 31837 layer_factory.hpp:77] Creating layer relu2a_neg
I0518 06:26:36.529122 31837 net.cpp:100] Creating Layer relu2a_neg
I0518 06:26:36.529126 31837 net.cpp:434] relu2a_neg <- conv2a_neg
I0518 06:26:36.529141 31837 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0518 06:26:36.529420 31837 net.cpp:150] Setting up relu2a_neg
I0518 06:26:36.529433 31837 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0518 06:26:36.529438 31837 net.cpp:165] Memory required for data: 5603123200
I0518 06:26:36.529443 31837 layer_factory.hpp:77] Creating layer pool2_neg
I0518 06:26:36.529456 31837 net.cpp:100] Creating Layer pool2_neg
I0518 06:26:36.529465 31837 net.cpp:434] pool2_neg <- conv2a_neg
I0518 06:26:36.529479 31837 net.cpp:408] pool2_neg -> pool2_neg
I0518 06:26:36.533929 31837 net.cpp:150] Setting up pool2_neg
I0518 06:26:36.533948 31837 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0518 06:26:36.533958 31837 net.cpp:165] Memory required for data: 5635235840
I0518 06:26:36.533962 31837 layer_factory.hpp:77] Creating layer conv3a_neg
I0518 06:26:36.533973 31837 net.cpp:100] Creating Layer conv3a_neg
I0518 06:26:36.533978 31837 net.cpp:434] conv3a_neg <- pool2_neg
I0518 06:26:36.533993 31837 net.cpp:408] conv3a_neg -> conv3a_neg
I0518 06:26:36.571983 31837 net.cpp:150] Setting up conv3a_neg
I0518 06:26:36.572041 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:36.572048 31837 net.cpp:165] Memory required for data: 5699461120
I0518 06:26:36.572089 31837 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0518 06:26:36.572109 31837 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0518 06:26:36.572121 31837 layer_factory.hpp:77] Creating layer relu3a_neg
I0518 06:26:36.572139 31837 net.cpp:100] Creating Layer relu3a_neg
I0518 06:26:36.572150 31837 net.cpp:434] relu3a_neg <- conv3a_neg
I0518 06:26:36.572168 31837 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0518 06:26:36.572870 31837 net.cpp:150] Setting up relu3a_neg
I0518 06:26:36.572916 31837 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0518 06:26:36.572923 31837 net.cpp:165] Memory required for data: 5763686400
I0518 06:26:36.572933 31837 layer_factory.hpp:77] Creating layer pool3_neg
I0518 06:26:36.572958 31837 net.cpp:100] Creating Layer pool3_neg
I0518 06:26:36.572966 31837 net.cpp:434] pool3_neg <- conv3a_neg
I0518 06:26:36.572983 31837 net.cpp:408] pool3_neg -> pool3_neg
I0518 06:26:36.573375 31837 net.cpp:150] Setting up pool3_neg
I0518 06:26:36.573390 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:36.573395 31837 net.cpp:165] Memory required for data: 5771714560
I0518 06:26:36.573401 31837 layer_factory.hpp:77] Creating layer conv4a_neg
I0518 06:26:36.573424 31837 net.cpp:100] Creating Layer conv4a_neg
I0518 06:26:36.573432 31837 net.cpp:434] conv4a_neg <- pool3_neg
I0518 06:26:36.573441 31837 net.cpp:408] conv4a_neg -> conv4a_neg
I0518 06:26:36.670136 31837 net.cpp:150] Setting up conv4a_neg
I0518 06:26:36.670176 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:36.670181 31837 net.cpp:165] Memory required for data: 5779742720
I0518 06:26:36.670228 31837 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0518 06:26:36.670234 31837 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0518 06:26:36.670238 31837 layer_factory.hpp:77] Creating layer relu4a_neg
I0518 06:26:36.670250 31837 net.cpp:100] Creating Layer relu4a_neg
I0518 06:26:36.670258 31837 net.cpp:434] relu4a_neg <- conv4a_neg
I0518 06:26:36.670267 31837 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0518 06:26:36.670478 31837 net.cpp:150] Setting up relu4a_neg
I0518 06:26:36.670490 31837 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0518 06:26:36.670493 31837 net.cpp:165] Memory required for data: 5787770880
I0518 06:26:36.670500 31837 layer_factory.hpp:77] Creating layer pool4_neg
I0518 06:26:36.670512 31837 net.cpp:100] Creating Layer pool4_neg
I0518 06:26:36.670517 31837 net.cpp:434] pool4_neg <- conv4a_neg
I0518 06:26:36.670524 31837 net.cpp:408] pool4_neg -> pool4_neg
I0518 06:26:36.671833 31837 net.cpp:150] Setting up pool4_neg
I0518 06:26:36.671854 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:36.671866 31837 net.cpp:165] Memory required for data: 5788774400
I0518 06:26:36.671870 31837 layer_factory.hpp:77] Creating layer conv5a_neg
I0518 06:26:36.671885 31837 net.cpp:100] Creating Layer conv5a_neg
I0518 06:26:36.671890 31837 net.cpp:434] conv5a_neg <- pool4_neg
I0518 06:26:36.671900 31837 net.cpp:408] conv5a_neg -> conv5a_neg
I0518 06:26:36.732586 31837 net.cpp:150] Setting up conv5a_neg
I0518 06:26:36.732620 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:36.732625 31837 net.cpp:165] Memory required for data: 5789777920
I0518 06:26:36.732636 31837 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0518 06:26:36.732642 31837 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0518 06:26:36.732646 31837 layer_factory.hpp:77] Creating layer relu5a_neg
I0518 06:26:36.732659 31837 net.cpp:100] Creating Layer relu5a_neg
I0518 06:26:36.732666 31837 net.cpp:434] relu5a_neg <- conv5a_neg
I0518 06:26:36.732671 31837 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0518 06:26:36.733889 31837 net.cpp:150] Setting up relu5a_neg
I0518 06:26:36.733906 31837 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0518 06:26:36.733909 31837 net.cpp:165] Memory required for data: 5790781440
I0518 06:26:36.733913 31837 layer_factory.hpp:77] Creating layer pool5_neg
I0518 06:26:36.733924 31837 net.cpp:100] Creating Layer pool5_neg
I0518 06:26:36.733930 31837 net.cpp:434] pool5_neg <- conv5a_neg
I0518 06:26:36.733939 31837 net.cpp:408] pool5_neg -> pool5_neg
I0518 06:26:36.734192 31837 net.cpp:150] Setting up pool5_neg
I0518 06:26:36.734203 31837 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0518 06:26:36.734206 31837 net.cpp:165] Memory required for data: 5790945280
I0518 06:26:36.734210 31837 layer_factory.hpp:77] Creating layer fc6_neg
I0518 06:26:36.734246 31837 net.cpp:100] Creating Layer fc6_neg
I0518 06:26:36.734251 31837 net.cpp:434] fc6_neg <- pool5_neg
I0518 06:26:36.734259 31837 net.cpp:408] fc6_neg -> fc6_neg
I0518 06:26:37.038450 31837 net.cpp:150] Setting up fc6_neg
I0518 06:26:37.038492 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.038496 31837 net.cpp:165] Memory required for data: 5791027200
I0518 06:26:37.038504 31837 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0518 06:26:37.038511 31837 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0518 06:26:37.038517 31837 layer_factory.hpp:77] Creating layer relu6_neg
I0518 06:26:37.038529 31837 net.cpp:100] Creating Layer relu6_neg
I0518 06:26:37.038535 31837 net.cpp:434] relu6_neg <- fc6_neg
I0518 06:26:37.038542 31837 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0518 06:26:37.038833 31837 net.cpp:150] Setting up relu6_neg
I0518 06:26:37.038844 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.038848 31837 net.cpp:165] Memory required for data: 5791109120
I0518 06:26:37.038852 31837 layer_factory.hpp:77] Creating layer drop6_neg
I0518 06:26:37.038890 31837 net.cpp:100] Creating Layer drop6_neg
I0518 06:26:37.038895 31837 net.cpp:434] drop6_neg <- fc6_neg
I0518 06:26:37.038902 31837 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0518 06:26:37.038967 31837 net.cpp:150] Setting up drop6_neg
I0518 06:26:37.038975 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.038978 31837 net.cpp:165] Memory required for data: 5791191040
I0518 06:26:37.038983 31837 layer_factory.hpp:77] Creating layer fc7_neg
I0518 06:26:37.038995 31837 net.cpp:100] Creating Layer fc7_neg
I0518 06:26:37.039005 31837 net.cpp:434] fc7_neg <- fc6_neg
I0518 06:26:37.039013 31837 net.cpp:408] fc7_neg -> fc7_neg
I0518 06:26:37.194789 31837 net.cpp:150] Setting up fc7_neg
I0518 06:26:37.194833 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.194836 31837 net.cpp:165] Memory required for data: 5791272960
I0518 06:26:37.194845 31837 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0518 06:26:37.194851 31837 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0518 06:26:37.194855 31837 layer_factory.hpp:77] Creating layer relu7_neg
I0518 06:26:37.194866 31837 net.cpp:100] Creating Layer relu7_neg
I0518 06:26:37.194874 31837 net.cpp:434] relu7_neg <- fc7_neg
I0518 06:26:37.194881 31837 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0518 06:26:37.195178 31837 net.cpp:150] Setting up relu7_neg
I0518 06:26:37.195188 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.195192 31837 net.cpp:165] Memory required for data: 5791354880
I0518 06:26:37.195195 31837 layer_factory.hpp:77] Creating layer drop7_neg
I0518 06:26:37.195206 31837 net.cpp:100] Creating Layer drop7_neg
I0518 06:26:37.195211 31837 net.cpp:434] drop7_neg <- fc7_neg
I0518 06:26:37.195217 31837 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0518 06:26:37.195260 31837 net.cpp:150] Setting up drop7_neg
I0518 06:26:37.195271 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.195276 31837 net.cpp:165] Memory required for data: 5791436800
I0518 06:26:37.195281 31837 layer_factory.hpp:77] Creating layer mvn_neg
I0518 06:26:37.195363 31837 net.cpp:100] Creating Layer mvn_neg
I0518 06:26:37.195374 31837 net.cpp:434] mvn_neg <- fc7_neg
I0518 06:26:37.195382 31837 net.cpp:408] mvn_neg -> fc7_neg_norm
I0518 06:26:37.195653 31837 net.cpp:150] Setting up mvn_neg
I0518 06:26:37.195668 31837 net.cpp:157] Top shape: 10 2048 (20480)
I0518 06:26:37.195673 31837 net.cpp:165] Memory required for data: 5791518720
I0518 06:26:37.195679 31837 layer_factory.hpp:77] Creating layer save
I0518 06:26:37.210438 31837 net.cpp:100] Creating Layer save
I0518 06:26:37.210455 31837 net.cpp:434] save <- fc7_norm
I0518 06:26:37.210466 31837 net.cpp:434] save <- fc7_pos_norm
I0518 06:26:37.210480 31837 net.cpp:434] save <- fc7_neg_norm
I0518 06:26:37.210633 31837 net.cpp:150] Setting up save
I0518 06:26:37.210644 31837 net.cpp:165] Memory required for data: 5791518720
I0518 06:26:37.210649 31837 net.cpp:228] save does not need backward computation.
I0518 06:26:37.210656 31837 net.cpp:228] mvn_neg does not need backward computation.
I0518 06:26:37.210693 31837 net.cpp:228] drop7_neg does not need backward computation.
I0518 06:26:37.210701 31837 net.cpp:228] relu7_neg does not need backward computation.
I0518 06:26:37.210706 31837 net.cpp:228] fc7_neg does not need backward computation.
I0518 06:26:37.210712 31837 net.cpp:228] drop6_neg does not need backward computation.
I0518 06:26:37.210721 31837 net.cpp:228] relu6_neg does not need backward computation.
I0518 06:26:37.210729 31837 net.cpp:228] fc6_neg does not need backward computation.
I0518 06:26:37.210736 31837 net.cpp:228] pool5_neg does not need backward computation.
I0518 06:26:37.210743 31837 net.cpp:228] relu5a_neg does not need backward computation.
I0518 06:26:37.210750 31837 net.cpp:228] conv5a_neg does not need backward computation.
I0518 06:26:37.210758 31837 net.cpp:228] pool4_neg does not need backward computation.
I0518 06:26:37.210767 31837 net.cpp:228] relu4a_neg does not need backward computation.
I0518 06:26:37.210794 31837 net.cpp:228] conv4a_neg does not need backward computation.
I0518 06:26:37.210801 31837 net.cpp:228] pool3_neg does not need backward computation.
I0518 06:26:37.210808 31837 net.cpp:228] relu3a_neg does not need backward computation.
I0518 06:26:37.210813 31837 net.cpp:228] conv3a_neg does not need backward computation.
I0518 06:26:37.210819 31837 net.cpp:228] pool2_neg does not need backward computation.
I0518 06:26:37.210825 31837 net.cpp:228] relu2a_neg does not need backward computation.
I0518 06:26:37.210830 31837 net.cpp:228] conv2a_neg does not need backward computation.
I0518 06:26:37.210837 31837 net.cpp:228] pool1_neg does not need backward computation.
I0518 06:26:37.210844 31837 net.cpp:228] relu1a_neg does not need backward computation.
I0518 06:26:37.210852 31837 net.cpp:228] conv1a_neg does not need backward computation.
I0518 06:26:37.210860 31837 net.cpp:228] mvn_pos does not need backward computation.
I0518 06:26:37.210868 31837 net.cpp:228] drop7_pos does not need backward computation.
I0518 06:26:37.210877 31837 net.cpp:228] relu7_pos does not need backward computation.
I0518 06:26:37.210886 31837 net.cpp:228] fc7_pos does not need backward computation.
I0518 06:26:37.210893 31837 net.cpp:228] drop6_pos does not need backward computation.
I0518 06:26:37.210901 31837 net.cpp:228] relu6_pos does not need backward computation.
I0518 06:26:37.210913 31837 net.cpp:228] fc6_pos does not need backward computation.
I0518 06:26:37.210921 31837 net.cpp:228] pool5_pos does not need backward computation.
I0518 06:26:37.210943 31837 net.cpp:228] relu5a_pos does not need backward computation.
I0518 06:26:37.210952 31837 net.cpp:228] conv5a_pos does not need backward computation.
I0518 06:26:37.210958 31837 net.cpp:228] pool4_pos does not need backward computation.
I0518 06:26:37.210963 31837 net.cpp:228] relu4a_pos does not need backward computation.
I0518 06:26:37.210986 31837 net.cpp:228] conv4a_pos does not need backward computation.
I0518 06:26:37.211010 31837 net.cpp:228] pool3_pos does not need backward computation.
I0518 06:26:37.211019 31837 net.cpp:228] relu3a_pos does not need backward computation.
I0518 06:26:37.211024 31837 net.cpp:228] conv3a_pos does not need backward computation.
I0518 06:26:37.211032 31837 net.cpp:228] pool2_pos does not need backward computation.
I0518 06:26:37.211053 31837 net.cpp:228] relu2a_pos does not need backward computation.
I0518 06:26:37.211061 31837 net.cpp:228] conv2a_pos does not need backward computation.
I0518 06:26:37.211066 31837 net.cpp:228] pool1_pos does not need backward computation.
I0518 06:26:37.211076 31837 net.cpp:228] relu1a_pos does not need backward computation.
I0518 06:26:37.211086 31837 net.cpp:228] conv1a_pos does not need backward computation.
I0518 06:26:37.211099 31837 net.cpp:228] mvn does not need backward computation.
I0518 06:26:37.211108 31837 net.cpp:228] drop7 does not need backward computation.
I0518 06:26:37.211127 31837 net.cpp:228] relu7 does not need backward computation.
I0518 06:26:37.211133 31837 net.cpp:228] fc7 does not need backward computation.
I0518 06:26:37.211140 31837 net.cpp:228] drop6 does not need backward computation.
I0518 06:26:37.211158 31837 net.cpp:228] relu6 does not need backward computation.
I0518 06:26:37.211164 31837 net.cpp:228] fc6 does not need backward computation.
I0518 06:26:37.211172 31837 net.cpp:228] pool5 does not need backward computation.
I0518 06:26:37.211181 31837 net.cpp:228] relu5a does not need backward computation.
I0518 06:26:37.211189 31837 net.cpp:228] conv5a does not need backward computation.
I0518 06:26:37.211207 31837 net.cpp:228] pool4 does not need backward computation.
I0518 06:26:37.211215 31837 net.cpp:228] relu4a does not need backward computation.
I0518 06:26:37.211221 31837 net.cpp:228] conv4a does not need backward computation.
I0518 06:26:37.211227 31837 net.cpp:228] pool3 does not need backward computation.
I0518 06:26:37.211236 31837 net.cpp:228] relu3a does not need backward computation.
I0518 06:26:37.211241 31837 net.cpp:228] conv3a does not need backward computation.
I0518 06:26:37.211259 31837 net.cpp:228] pool2 does not need backward computation.
I0518 06:26:37.211266 31837 net.cpp:228] relu2a does not need backward computation.
I0518 06:26:37.211274 31837 net.cpp:228] conv2a does not need backward computation.
I0518 06:26:37.211284 31837 net.cpp:228] pool1 does not need backward computation.
I0518 06:26:37.211293 31837 net.cpp:228] relu1a does not need backward computation.
I0518 06:26:37.211302 31837 net.cpp:228] conv1a does not need backward computation.
I0518 06:26:37.211313 31837 net.cpp:228] reshape_negative does not need backward computation.
I0518 06:26:37.211321 31837 net.cpp:228] reshape_positive does not need backward computation.
I0518 06:26:37.211328 31837 net.cpp:228] reshape_anchor does not need backward computation.
I0518 06:26:37.211334 31837 net.cpp:228] slicer does not need backward computation.
I0518 06:26:37.211340 31837 net.cpp:228] data does not need backward computation.
I0518 06:26:37.259789 31837 net.cpp:283] Network initialization done.
I0518 06:26:39.380633 31837 net.cpp:761] Ignoring source layer fc7_norm_mvn_0_split
I0518 06:26:39.416265 31837 net.cpp:761] Ignoring source layer fc7_pos_norm_mvn_pos_0_split
I0518 06:26:39.448124 31837 net.cpp:761] Ignoring source layer fc7_neg_norm_mvn_neg_0_split
I0518 06:26:39.448153 31837 net.cpp:761] Ignoring source layer loss
I0518 06:26:39.448158 31837 net.cpp:761] Ignoring source layer triplet_check
I0518 06:26:39.463248 31837 caffe.cpp:285] Running for 1000 iterations.
I0518 06:26:42.183107 31837 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:28:43.035392 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:30:34.410979 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:32:19.685204 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:34:09.004518 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:35:51.753895 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:37:26.204370 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:39:18.856115 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:41:30.798624 31853 blocking_queue.cpp:50] Waiting for data
I0518 06:44:15.102363 31837 caffe.cpp:313] Loss: 0
Features saved to: ../../features/features_triplet_loss_mnv.npz
