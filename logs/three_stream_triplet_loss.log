I0505 14:02:19.710739 26400 caffe.cpp:217] Using GPUs 1
I0505 14:02:19.935187 26400 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0505 14:02:20.912397 26400 solver.cpp:48] Initializing solver from parameters: 
test_iter: 500
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 60000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
stepsize: 20000
snapshot: 2000
snapshot_prefix: "three_stream_triplet_loss"
solver_mode: GPU
device_id: 1
net: "../../models/three_stream_triplet_loss.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-val"
}
I0505 14:02:20.923717 26400 solver.cpp:91] Creating training net from net file: ../../models/three_stream_triplet_loss.prototxt
I0505 14:02:20.926596 26400 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0505 14:02:20.927423 26400 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/Triplets/train"
    batch_size: 18
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "TripletLoss"
  bottom: "fc7"
  bottom: "fc7_pos"
  bottom: "fc7_neg"
  top: "loss"
  threshold_param {
    threshold: 1
  }
}
I0505 14:02:20.927716 26400 layer_factory.hpp:77] Creating layer data
I0505 14:02:20.928624 26400 net.cpp:100] Creating Layer data
I0505 14:02:20.928644 26400 net.cpp:408] data -> triplet
I0505 14:02:21.014539 26412 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/Triplets/train
I0505 14:02:21.207231 26400 data_layer.cpp:41] output data size: 18,144,112,112
I0505 14:02:21.459167 26400 net.cpp:150] Setting up data
I0505 14:02:21.459255 26400 net.cpp:157] Top shape: 18 144 112 112 (32514048)
I0505 14:02:21.459267 26400 net.cpp:165] Memory required for data: 130056192
I0505 14:02:21.459293 26400 layer_factory.hpp:77] Creating layer slicer
I0505 14:02:21.459341 26400 net.cpp:100] Creating Layer slicer
I0505 14:02:21.459353 26400 net.cpp:434] slicer <- triplet
I0505 14:02:21.459372 26400 net.cpp:408] slicer -> anchor_stacked
I0505 14:02:21.459391 26400 net.cpp:408] slicer -> positive_stacked
I0505 14:02:21.459405 26400 net.cpp:408] slicer -> negative_stacked
I0505 14:02:21.461225 26400 net.cpp:150] Setting up slicer
I0505 14:02:21.461266 26400 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0505 14:02:21.461279 26400 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0505 14:02:21.461290 26400 net.cpp:157] Top shape: 18 48 112 112 (10838016)
I0505 14:02:21.461299 26400 net.cpp:165] Memory required for data: 260112384
I0505 14:02:21.461318 26400 layer_factory.hpp:77] Creating layer reshape_anchor
I0505 14:02:21.461367 26400 net.cpp:100] Creating Layer reshape_anchor
I0505 14:02:21.461386 26400 net.cpp:434] reshape_anchor <- anchor_stacked
I0505 14:02:21.461428 26400 net.cpp:408] reshape_anchor -> anchor
I0505 14:02:21.461499 26400 net.cpp:150] Setting up reshape_anchor
I0505 14:02:21.461519 26400 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0505 14:02:21.461529 26400 net.cpp:165] Memory required for data: 303464448
I0505 14:02:21.461541 26400 layer_factory.hpp:77] Creating layer reshape_positive
I0505 14:02:21.461565 26400 net.cpp:100] Creating Layer reshape_positive
I0505 14:02:21.461577 26400 net.cpp:434] reshape_positive <- positive_stacked
I0505 14:02:21.461594 26400 net.cpp:408] reshape_positive -> positive
I0505 14:02:21.461681 26400 net.cpp:150] Setting up reshape_positive
I0505 14:02:21.461699 26400 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0505 14:02:21.461711 26400 net.cpp:165] Memory required for data: 346816512
I0505 14:02:21.461724 26400 layer_factory.hpp:77] Creating layer reshape_negative
I0505 14:02:21.461750 26400 net.cpp:100] Creating Layer reshape_negative
I0505 14:02:21.461760 26400 net.cpp:434] reshape_negative <- negative_stacked
I0505 14:02:21.461776 26400 net.cpp:408] reshape_negative -> negative
I0505 14:02:21.461829 26400 net.cpp:150] Setting up reshape_negative
I0505 14:02:21.461848 26400 net.cpp:157] Top shape: 18 3 16 112 112 (10838016)
I0505 14:02:21.461863 26400 net.cpp:165] Memory required for data: 390168576
I0505 14:02:21.461870 26400 layer_factory.hpp:77] Creating layer conv1a
I0505 14:02:21.461899 26400 net.cpp:100] Creating Layer conv1a
I0505 14:02:21.461911 26400 net.cpp:434] conv1a <- anchor
I0505 14:02:21.461931 26400 net.cpp:408] conv1a -> conv1a
I0505 14:02:21.538411 26416 blocking_queue.cpp:50] Waiting for data
I0505 14:02:22.167281 26400 net.cpp:150] Setting up conv1a
I0505 14:02:22.167373 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:22.167395 26400 net.cpp:165] Memory required for data: 1315012608
I0505 14:02:22.167430 26400 layer_factory.hpp:77] Creating layer relu1a
I0505 14:02:22.167485 26400 net.cpp:100] Creating Layer relu1a
I0505 14:02:22.167505 26400 net.cpp:434] relu1a <- conv1a
I0505 14:02:22.167533 26400 net.cpp:395] relu1a -> conv1a (in-place)
I0505 14:02:22.169823 26400 net.cpp:150] Setting up relu1a
I0505 14:02:22.169854 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:22.169860 26400 net.cpp:165] Memory required for data: 2239856640
I0505 14:02:22.169867 26400 layer_factory.hpp:77] Creating layer pool1
I0505 14:02:22.169891 26400 net.cpp:100] Creating Layer pool1
I0505 14:02:22.169898 26400 net.cpp:434] pool1 <- conv1a
I0505 14:02:22.169908 26400 net.cpp:408] pool1 -> pool1
I0505 14:02:22.170280 26400 net.cpp:150] Setting up pool1
I0505 14:02:22.170297 26400 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0505 14:02:22.170303 26400 net.cpp:165] Memory required for data: 2471067648
I0505 14:02:22.170310 26400 layer_factory.hpp:77] Creating layer conv2a
I0505 14:02:22.170327 26400 net.cpp:100] Creating Layer conv2a
I0505 14:02:22.170336 26400 net.cpp:434] conv2a <- pool1
I0505 14:02:22.170347 26400 net.cpp:408] conv2a -> conv2a
I0505 14:02:22.189543 26400 net.cpp:150] Setting up conv2a
I0505 14:02:22.189586 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:22.189590 26400 net.cpp:165] Memory required for data: 2933489664
I0505 14:02:22.189604 26400 layer_factory.hpp:77] Creating layer relu2a
I0505 14:02:22.189615 26400 net.cpp:100] Creating Layer relu2a
I0505 14:02:22.189620 26400 net.cpp:434] relu2a <- conv2a
I0505 14:02:22.189625 26400 net.cpp:395] relu2a -> conv2a (in-place)
I0505 14:02:22.190748 26400 net.cpp:150] Setting up relu2a
I0505 14:02:22.190762 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:22.190764 26400 net.cpp:165] Memory required for data: 3395911680
I0505 14:02:22.190768 26400 layer_factory.hpp:77] Creating layer pool2
I0505 14:02:22.190781 26400 net.cpp:100] Creating Layer pool2
I0505 14:02:22.190784 26400 net.cpp:434] pool2 <- conv2a
I0505 14:02:22.190791 26400 net.cpp:408] pool2 -> pool2
I0505 14:02:22.191017 26400 net.cpp:150] Setting up pool2
I0505 14:02:22.191030 26400 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0505 14:02:22.191033 26400 net.cpp:165] Memory required for data: 3453714432
I0505 14:02:22.191037 26400 layer_factory.hpp:77] Creating layer conv3a
I0505 14:02:22.191048 26400 net.cpp:100] Creating Layer conv3a
I0505 14:02:22.191052 26400 net.cpp:434] conv3a <- pool2
I0505 14:02:22.191058 26400 net.cpp:408] conv3a -> conv3a
I0505 14:02:22.232178 26400 net.cpp:150] Setting up conv3a
I0505 14:02:22.232216 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:22.232221 26400 net.cpp:165] Memory required for data: 3569319936
I0505 14:02:22.232267 26400 layer_factory.hpp:77] Creating layer relu3a
I0505 14:02:22.232280 26400 net.cpp:100] Creating Layer relu3a
I0505 14:02:22.232285 26400 net.cpp:434] relu3a <- conv3a
I0505 14:02:22.232291 26400 net.cpp:395] relu3a -> conv3a (in-place)
I0505 14:02:22.235085 26400 net.cpp:150] Setting up relu3a
I0505 14:02:22.235100 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:22.235105 26400 net.cpp:165] Memory required for data: 3684925440
I0505 14:02:22.235108 26400 layer_factory.hpp:77] Creating layer pool3
I0505 14:02:22.235118 26400 net.cpp:100] Creating Layer pool3
I0505 14:02:22.235121 26400 net.cpp:434] pool3 <- conv3a
I0505 14:02:22.235128 26400 net.cpp:408] pool3 -> pool3
I0505 14:02:22.235353 26400 net.cpp:150] Setting up pool3
I0505 14:02:22.235363 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:22.235366 26400 net.cpp:165] Memory required for data: 3699376128
I0505 14:02:22.235370 26400 layer_factory.hpp:77] Creating layer conv4a
I0505 14:02:22.235379 26400 net.cpp:100] Creating Layer conv4a
I0505 14:02:22.235383 26400 net.cpp:434] conv4a <- pool3
I0505 14:02:22.235389 26400 net.cpp:408] conv4a -> conv4a
I0505 14:02:22.297482 26400 net.cpp:150] Setting up conv4a
I0505 14:02:22.297510 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:22.297514 26400 net.cpp:165] Memory required for data: 3713826816
I0505 14:02:22.297528 26400 layer_factory.hpp:77] Creating layer relu4a
I0505 14:02:22.297538 26400 net.cpp:100] Creating Layer relu4a
I0505 14:02:22.297544 26400 net.cpp:434] relu4a <- conv4a
I0505 14:02:22.297551 26400 net.cpp:395] relu4a -> conv4a (in-place)
I0505 14:02:22.297744 26400 net.cpp:150] Setting up relu4a
I0505 14:02:22.297754 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:22.297756 26400 net.cpp:165] Memory required for data: 3728277504
I0505 14:02:22.297760 26400 layer_factory.hpp:77] Creating layer pool4
I0505 14:02:22.297772 26400 net.cpp:100] Creating Layer pool4
I0505 14:02:22.297776 26400 net.cpp:434] pool4 <- conv4a
I0505 14:02:22.297782 26400 net.cpp:408] pool4 -> pool4
I0505 14:02:22.298802 26400 net.cpp:150] Setting up pool4
I0505 14:02:22.298816 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:22.298820 26400 net.cpp:165] Memory required for data: 3730083840
I0505 14:02:22.298822 26400 layer_factory.hpp:77] Creating layer conv5a
I0505 14:02:22.298833 26400 net.cpp:100] Creating Layer conv5a
I0505 14:02:22.298836 26400 net.cpp:434] conv5a <- pool4
I0505 14:02:22.298846 26400 net.cpp:408] conv5a -> conv5a
I0505 14:02:22.378887 26400 net.cpp:150] Setting up conv5a
I0505 14:02:22.378945 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:22.378949 26400 net.cpp:165] Memory required for data: 3731890176
I0505 14:02:22.378968 26400 layer_factory.hpp:77] Creating layer relu5a
I0505 14:02:22.378980 26400 net.cpp:100] Creating Layer relu5a
I0505 14:02:22.378984 26400 net.cpp:434] relu5a <- conv5a
I0505 14:02:22.378993 26400 net.cpp:395] relu5a -> conv5a (in-place)
I0505 14:02:22.379190 26400 net.cpp:150] Setting up relu5a
I0505 14:02:22.379201 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:22.379204 26400 net.cpp:165] Memory required for data: 3733696512
I0505 14:02:22.379209 26400 layer_factory.hpp:77] Creating layer pool5
I0505 14:02:22.379217 26400 net.cpp:100] Creating Layer pool5
I0505 14:02:22.379222 26400 net.cpp:434] pool5 <- conv5a
I0505 14:02:22.379230 26400 net.cpp:408] pool5 -> pool5
I0505 14:02:22.380478 26400 net.cpp:150] Setting up pool5
I0505 14:02:22.380492 26400 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0505 14:02:22.380496 26400 net.cpp:165] Memory required for data: 3733991424
I0505 14:02:22.380499 26400 layer_factory.hpp:77] Creating layer fc6
I0505 14:02:22.380533 26400 net.cpp:100] Creating Layer fc6
I0505 14:02:22.380538 26400 net.cpp:434] fc6 <- pool5
I0505 14:02:22.380547 26400 net.cpp:408] fc6 -> fc6
I0505 14:02:22.666035 26400 net.cpp:150] Setting up fc6
I0505 14:02:22.666079 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.666106 26400 net.cpp:165] Memory required for data: 3734138880
I0505 14:02:22.666119 26400 layer_factory.hpp:77] Creating layer relu6
I0505 14:02:22.666132 26400 net.cpp:100] Creating Layer relu6
I0505 14:02:22.666138 26400 net.cpp:434] relu6 <- fc6
I0505 14:02:22.666144 26400 net.cpp:395] relu6 -> fc6 (in-place)
I0505 14:02:22.666421 26400 net.cpp:150] Setting up relu6
I0505 14:02:22.666434 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.666436 26400 net.cpp:165] Memory required for data: 3734286336
I0505 14:02:22.666453 26400 layer_factory.hpp:77] Creating layer drop6
I0505 14:02:22.666468 26400 net.cpp:100] Creating Layer drop6
I0505 14:02:22.666484 26400 net.cpp:434] drop6 <- fc6
I0505 14:02:22.666489 26400 net.cpp:395] drop6 -> fc6 (in-place)
I0505 14:02:22.666535 26400 net.cpp:150] Setting up drop6
I0505 14:02:22.666544 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.666548 26400 net.cpp:165] Memory required for data: 3734433792
I0505 14:02:22.666553 26400 layer_factory.hpp:77] Creating layer fc7
I0505 14:02:22.666574 26400 net.cpp:100] Creating Layer fc7
I0505 14:02:22.666607 26400 net.cpp:434] fc7 <- fc6
I0505 14:02:22.666617 26400 net.cpp:408] fc7 -> fc7
I0505 14:02:22.872300 26400 net.cpp:150] Setting up fc7
I0505 14:02:22.872344 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.872351 26400 net.cpp:165] Memory required for data: 3734581248
I0505 14:02:22.872370 26400 layer_factory.hpp:77] Creating layer relu7
I0505 14:02:22.872385 26400 net.cpp:100] Creating Layer relu7
I0505 14:02:22.872391 26400 net.cpp:434] relu7 <- fc7
I0505 14:02:22.872404 26400 net.cpp:395] relu7 -> fc7 (in-place)
I0505 14:02:22.876298 26400 net.cpp:150] Setting up relu7
I0505 14:02:22.876324 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.876333 26400 net.cpp:165] Memory required for data: 3734728704
I0505 14:02:22.876340 26400 layer_factory.hpp:77] Creating layer drop7
I0505 14:02:22.876353 26400 net.cpp:100] Creating Layer drop7
I0505 14:02:22.876359 26400 net.cpp:434] drop7 <- fc7
I0505 14:02:22.876389 26400 net.cpp:395] drop7 -> fc7 (in-place)
I0505 14:02:22.876441 26400 net.cpp:150] Setting up drop7
I0505 14:02:22.876451 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:22.876456 26400 net.cpp:165] Memory required for data: 3734876160
I0505 14:02:22.876466 26400 layer_factory.hpp:77] Creating layer conv1a_pos
I0505 14:02:22.876484 26400 net.cpp:100] Creating Layer conv1a_pos
I0505 14:02:22.876492 26400 net.cpp:434] conv1a_pos <- positive
I0505 14:02:22.876502 26400 net.cpp:408] conv1a_pos -> conv1a_pos
I0505 14:02:22.880934 26400 net.cpp:150] Setting up conv1a_pos
I0505 14:02:22.880970 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:22.880976 26400 net.cpp:165] Memory required for data: 4659720192
I0505 14:02:22.880985 26400 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0505 14:02:22.880995 26400 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0505 14:02:22.881000 26400 layer_factory.hpp:77] Creating layer relu1a_pos
I0505 14:02:22.881016 26400 net.cpp:100] Creating Layer relu1a_pos
I0505 14:02:22.881024 26400 net.cpp:434] relu1a_pos <- conv1a_pos
I0505 14:02:22.881034 26400 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0505 14:02:22.881362 26400 net.cpp:150] Setting up relu1a_pos
I0505 14:02:22.881378 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:22.881384 26400 net.cpp:165] Memory required for data: 5584564224
I0505 14:02:22.881391 26400 layer_factory.hpp:77] Creating layer pool1_pos
I0505 14:02:22.881407 26400 net.cpp:100] Creating Layer pool1_pos
I0505 14:02:22.881414 26400 net.cpp:434] pool1_pos <- conv1a_pos
I0505 14:02:22.881424 26400 net.cpp:408] pool1_pos -> pool1_pos
I0505 14:02:22.882587 26400 net.cpp:150] Setting up pool1_pos
I0505 14:02:22.882604 26400 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0505 14:02:22.882611 26400 net.cpp:165] Memory required for data: 5815775232
I0505 14:02:22.882618 26400 layer_factory.hpp:77] Creating layer conv2a_pos
I0505 14:02:22.882664 26400 net.cpp:100] Creating Layer conv2a_pos
I0505 14:02:22.882673 26400 net.cpp:434] conv2a_pos <- pool1_pos
I0505 14:02:22.882684 26400 net.cpp:408] conv2a_pos -> conv2a_pos
I0505 14:02:22.902297 26400 net.cpp:150] Setting up conv2a_pos
I0505 14:02:22.902333 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:22.902339 26400 net.cpp:165] Memory required for data: 6278197248
I0505 14:02:22.902357 26400 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0505 14:02:22.902367 26400 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0505 14:02:22.902374 26400 layer_factory.hpp:77] Creating layer relu2a_pos
I0505 14:02:22.902387 26400 net.cpp:100] Creating Layer relu2a_pos
I0505 14:02:22.902398 26400 net.cpp:434] relu2a_pos <- conv2a_pos
I0505 14:02:22.902408 26400 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0505 14:02:22.902705 26400 net.cpp:150] Setting up relu2a_pos
I0505 14:02:22.902721 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:22.902727 26400 net.cpp:165] Memory required for data: 6740619264
I0505 14:02:22.902734 26400 layer_factory.hpp:77] Creating layer pool2_pos
I0505 14:02:22.902748 26400 net.cpp:100] Creating Layer pool2_pos
I0505 14:02:22.902755 26400 net.cpp:434] pool2_pos <- conv2a_pos
I0505 14:02:22.902765 26400 net.cpp:408] pool2_pos -> pool2_pos
I0505 14:02:22.904453 26400 net.cpp:150] Setting up pool2_pos
I0505 14:02:22.904472 26400 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0505 14:02:22.904479 26400 net.cpp:165] Memory required for data: 6798422016
I0505 14:02:22.904485 26400 layer_factory.hpp:77] Creating layer conv3a_pos
I0505 14:02:22.904532 26400 net.cpp:100] Creating Layer conv3a_pos
I0505 14:02:22.904541 26400 net.cpp:434] conv3a_pos <- pool2_pos
I0505 14:02:22.904557 26400 net.cpp:408] conv3a_pos -> conv3a_pos
I0505 14:02:22.948072 26400 net.cpp:150] Setting up conv3a_pos
I0505 14:02:22.948103 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:22.948109 26400 net.cpp:165] Memory required for data: 6914027520
I0505 14:02:22.948120 26400 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0505 14:02:22.948128 26400 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0505 14:02:22.948135 26400 layer_factory.hpp:77] Creating layer relu3a_pos
I0505 14:02:22.948150 26400 net.cpp:100] Creating Layer relu3a_pos
I0505 14:02:22.948158 26400 net.cpp:434] relu3a_pos <- conv3a_pos
I0505 14:02:22.948168 26400 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0505 14:02:22.949334 26400 net.cpp:150] Setting up relu3a_pos
I0505 14:02:22.949352 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:22.949357 26400 net.cpp:165] Memory required for data: 7029633024
I0505 14:02:22.949363 26400 layer_factory.hpp:77] Creating layer pool3_pos
I0505 14:02:22.949380 26400 net.cpp:100] Creating Layer pool3_pos
I0505 14:02:22.949388 26400 net.cpp:434] pool3_pos <- conv3a_pos
I0505 14:02:22.949398 26400 net.cpp:408] pool3_pos -> pool3_pos
I0505 14:02:22.952219 26400 net.cpp:150] Setting up pool3_pos
I0505 14:02:22.952253 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:22.952260 26400 net.cpp:165] Memory required for data: 7044083712
I0505 14:02:22.952266 26400 layer_factory.hpp:77] Creating layer conv4a_pos
I0505 14:02:22.952301 26400 net.cpp:100] Creating Layer conv4a_pos
I0505 14:02:22.952311 26400 net.cpp:434] conv4a_pos <- pool3_pos
I0505 14:02:22.952322 26400 net.cpp:408] conv4a_pos -> conv4a_pos
I0505 14:02:23.017271 26400 net.cpp:150] Setting up conv4a_pos
I0505 14:02:23.017300 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:23.017305 26400 net.cpp:165] Memory required for data: 7058534400
I0505 14:02:23.017313 26400 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0505 14:02:23.017319 26400 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0505 14:02:23.017323 26400 layer_factory.hpp:77] Creating layer relu4a_pos
I0505 14:02:23.017359 26400 net.cpp:100] Creating Layer relu4a_pos
I0505 14:02:23.017364 26400 net.cpp:434] relu4a_pos <- conv4a_pos
I0505 14:02:23.017370 26400 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0505 14:02:23.018635 26400 net.cpp:150] Setting up relu4a_pos
I0505 14:02:23.018649 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:23.018653 26400 net.cpp:165] Memory required for data: 7072985088
I0505 14:02:23.018657 26400 layer_factory.hpp:77] Creating layer pool4_pos
I0505 14:02:23.018667 26400 net.cpp:100] Creating Layer pool4_pos
I0505 14:02:23.018673 26400 net.cpp:434] pool4_pos <- conv4a_pos
I0505 14:02:23.018678 26400 net.cpp:408] pool4_pos -> pool4_pos
I0505 14:02:23.018921 26400 net.cpp:150] Setting up pool4_pos
I0505 14:02:23.018931 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.018934 26400 net.cpp:165] Memory required for data: 7074791424
I0505 14:02:23.018937 26400 layer_factory.hpp:77] Creating layer conv5a_pos
I0505 14:02:23.018949 26400 net.cpp:100] Creating Layer conv5a_pos
I0505 14:02:23.018954 26400 net.cpp:434] conv5a_pos <- pool4_pos
I0505 14:02:23.018960 26400 net.cpp:408] conv5a_pos -> conv5a_pos
I0505 14:02:23.087405 26400 net.cpp:150] Setting up conv5a_pos
I0505 14:02:23.087448 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.087455 26400 net.cpp:165] Memory required for data: 7076597760
I0505 14:02:23.087466 26400 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0505 14:02:23.087474 26400 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0505 14:02:23.087481 26400 layer_factory.hpp:77] Creating layer relu5a_pos
I0505 14:02:23.087494 26400 net.cpp:100] Creating Layer relu5a_pos
I0505 14:02:23.087502 26400 net.cpp:434] relu5a_pos <- conv5a_pos
I0505 14:02:23.087512 26400 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0505 14:02:23.088893 26400 net.cpp:150] Setting up relu5a_pos
I0505 14:02:23.088912 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.088917 26400 net.cpp:165] Memory required for data: 7078404096
I0505 14:02:23.088922 26400 layer_factory.hpp:77] Creating layer pool5_pos
I0505 14:02:23.088938 26400 net.cpp:100] Creating Layer pool5_pos
I0505 14:02:23.088943 26400 net.cpp:434] pool5_pos <- conv5a_pos
I0505 14:02:23.088954 26400 net.cpp:408] pool5_pos -> pool5_pos
I0505 14:02:23.089280 26400 net.cpp:150] Setting up pool5_pos
I0505 14:02:23.089295 26400 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0505 14:02:23.089301 26400 net.cpp:165] Memory required for data: 7078699008
I0505 14:02:23.089306 26400 layer_factory.hpp:77] Creating layer fc6_pos
I0505 14:02:23.089324 26400 net.cpp:100] Creating Layer fc6_pos
I0505 14:02:23.089330 26400 net.cpp:434] fc6_pos <- pool5_pos
I0505 14:02:23.089339 26400 net.cpp:408] fc6_pos -> fc6_pos
I0505 14:02:23.385787 26400 net.cpp:150] Setting up fc6_pos
I0505 14:02:23.385819 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.385823 26400 net.cpp:165] Memory required for data: 7078846464
I0505 14:02:23.385831 26400 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0505 14:02:23.385848 26400 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0505 14:02:23.385854 26400 layer_factory.hpp:77] Creating layer relu6_pos
I0505 14:02:23.385864 26400 net.cpp:100] Creating Layer relu6_pos
I0505 14:02:23.385869 26400 net.cpp:434] relu6_pos <- fc6_pos
I0505 14:02:23.385877 26400 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0505 14:02:23.392220 26400 net.cpp:150] Setting up relu6_pos
I0505 14:02:23.392268 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.392277 26400 net.cpp:165] Memory required for data: 7078993920
I0505 14:02:23.392294 26400 layer_factory.hpp:77] Creating layer drop6_pos
I0505 14:02:23.392313 26400 net.cpp:100] Creating Layer drop6_pos
I0505 14:02:23.392323 26400 net.cpp:434] drop6_pos <- fc6_pos
I0505 14:02:23.392335 26400 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0505 14:02:23.392442 26400 net.cpp:150] Setting up drop6_pos
I0505 14:02:23.392455 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.392462 26400 net.cpp:165] Memory required for data: 7079141376
I0505 14:02:23.392468 26400 layer_factory.hpp:77] Creating layer fc7_pos
I0505 14:02:23.392488 26400 net.cpp:100] Creating Layer fc7_pos
I0505 14:02:23.392495 26400 net.cpp:434] fc7_pos <- fc6_pos
I0505 14:02:23.392508 26400 net.cpp:408] fc7_pos -> fc7_pos
I0505 14:02:23.555563 26400 net.cpp:150] Setting up fc7_pos
I0505 14:02:23.555606 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.555610 26400 net.cpp:165] Memory required for data: 7079288832
I0505 14:02:23.555619 26400 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0505 14:02:23.555626 26400 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0505 14:02:23.555630 26400 layer_factory.hpp:77] Creating layer relu7_pos
I0505 14:02:23.555640 26400 net.cpp:100] Creating Layer relu7_pos
I0505 14:02:23.555645 26400 net.cpp:434] relu7_pos <- fc7_pos
I0505 14:02:23.555658 26400 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0505 14:02:23.555954 26400 net.cpp:150] Setting up relu7_pos
I0505 14:02:23.555966 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.555974 26400 net.cpp:165] Memory required for data: 7079436288
I0505 14:02:23.555994 26400 layer_factory.hpp:77] Creating layer drop7_pos
I0505 14:02:23.556008 26400 net.cpp:100] Creating Layer drop7_pos
I0505 14:02:23.556015 26400 net.cpp:434] drop7_pos <- fc7_pos
I0505 14:02:23.556023 26400 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0505 14:02:23.556063 26400 net.cpp:150] Setting up drop7_pos
I0505 14:02:23.556071 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:23.556078 26400 net.cpp:165] Memory required for data: 7079583744
I0505 14:02:23.556087 26400 layer_factory.hpp:77] Creating layer conv1a_neg
I0505 14:02:23.556102 26400 net.cpp:100] Creating Layer conv1a_neg
I0505 14:02:23.556112 26400 net.cpp:434] conv1a_neg <- negative
I0505 14:02:23.556125 26400 net.cpp:408] conv1a_neg -> conv1a_neg
I0505 14:02:23.559483 26400 net.cpp:150] Setting up conv1a_neg
I0505 14:02:23.559500 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:23.559510 26400 net.cpp:165] Memory required for data: 8004427776
I0505 14:02:23.559515 26400 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0505 14:02:23.559521 26400 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0505 14:02:23.559525 26400 layer_factory.hpp:77] Creating layer relu1a_neg
I0505 14:02:23.559540 26400 net.cpp:100] Creating Layer relu1a_neg
I0505 14:02:23.559546 26400 net.cpp:434] relu1a_neg <- conv1a_neg
I0505 14:02:23.559556 26400 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0505 14:02:23.564595 26400 net.cpp:150] Setting up relu1a_neg
I0505 14:02:23.564635 26400 net.cpp:157] Top shape: 18 64 16 112 112 (231211008)
I0505 14:02:23.564643 26400 net.cpp:165] Memory required for data: 8929271808
I0505 14:02:23.564654 26400 layer_factory.hpp:77] Creating layer pool1_neg
I0505 14:02:23.564676 26400 net.cpp:100] Creating Layer pool1_neg
I0505 14:02:23.564685 26400 net.cpp:434] pool1_neg <- conv1a_neg
I0505 14:02:23.564697 26400 net.cpp:408] pool1_neg -> pool1_neg
I0505 14:02:23.565151 26400 net.cpp:150] Setting up pool1_neg
I0505 14:02:23.565171 26400 net.cpp:157] Top shape: 18 64 16 56 56 (57802752)
I0505 14:02:23.565178 26400 net.cpp:165] Memory required for data: 9160482816
I0505 14:02:23.565184 26400 layer_factory.hpp:77] Creating layer conv2a_neg
I0505 14:02:23.565201 26400 net.cpp:100] Creating Layer conv2a_neg
I0505 14:02:23.565209 26400 net.cpp:434] conv2a_neg <- pool1_neg
I0505 14:02:23.565230 26400 net.cpp:408] conv2a_neg -> conv2a_neg
I0505 14:02:23.579275 26400 net.cpp:150] Setting up conv2a_neg
I0505 14:02:23.579303 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:23.579311 26400 net.cpp:165] Memory required for data: 9622904832
I0505 14:02:23.579321 26400 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0505 14:02:23.579365 26400 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0505 14:02:23.579373 26400 layer_factory.hpp:77] Creating layer relu2a_neg
I0505 14:02:23.579388 26400 net.cpp:100] Creating Layer relu2a_neg
I0505 14:02:23.579397 26400 net.cpp:434] relu2a_neg <- conv2a_neg
I0505 14:02:23.579411 26400 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0505 14:02:23.581070 26400 net.cpp:150] Setting up relu2a_neg
I0505 14:02:23.581094 26400 net.cpp:157] Top shape: 18 128 16 56 56 (115605504)
I0505 14:02:23.581104 26400 net.cpp:165] Memory required for data: 10085326848
I0505 14:02:23.581112 26400 layer_factory.hpp:77] Creating layer pool2_neg
I0505 14:02:23.581130 26400 net.cpp:100] Creating Layer pool2_neg
I0505 14:02:23.581140 26400 net.cpp:434] pool2_neg <- conv2a_neg
I0505 14:02:23.581151 26400 net.cpp:408] pool2_neg -> pool2_neg
I0505 14:02:23.581621 26400 net.cpp:150] Setting up pool2_neg
I0505 14:02:23.581641 26400 net.cpp:157] Top shape: 18 128 8 28 28 (14450688)
I0505 14:02:23.581650 26400 net.cpp:165] Memory required for data: 10143129600
I0505 14:02:23.581656 26400 layer_factory.hpp:77] Creating layer conv3a_neg
I0505 14:02:23.581676 26400 net.cpp:100] Creating Layer conv3a_neg
I0505 14:02:23.581686 26400 net.cpp:434] conv3a_neg <- pool2_neg
I0505 14:02:23.581697 26400 net.cpp:408] conv3a_neg -> conv3a_neg
I0505 14:02:23.636121 26400 net.cpp:150] Setting up conv3a_neg
I0505 14:02:23.636148 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:23.636154 26400 net.cpp:165] Memory required for data: 10258735104
I0505 14:02:23.636168 26400 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0505 14:02:23.636181 26400 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0505 14:02:23.636188 26400 layer_factory.hpp:77] Creating layer relu3a_neg
I0505 14:02:23.636198 26400 net.cpp:100] Creating Layer relu3a_neg
I0505 14:02:23.636204 26400 net.cpp:434] relu3a_neg <- conv3a_neg
I0505 14:02:23.636212 26400 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0505 14:02:23.636504 26400 net.cpp:150] Setting up relu3a_neg
I0505 14:02:23.636521 26400 net.cpp:157] Top shape: 18 256 8 28 28 (28901376)
I0505 14:02:23.636526 26400 net.cpp:165] Memory required for data: 10374340608
I0505 14:02:23.636531 26400 layer_factory.hpp:77] Creating layer pool3_neg
I0505 14:02:23.636543 26400 net.cpp:100] Creating Layer pool3_neg
I0505 14:02:23.636549 26400 net.cpp:434] pool3_neg <- conv3a_neg
I0505 14:02:23.636559 26400 net.cpp:408] pool3_neg -> pool3_neg
I0505 14:02:23.640774 26400 net.cpp:150] Setting up pool3_neg
I0505 14:02:23.640790 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:23.640794 26400 net.cpp:165] Memory required for data: 10388791296
I0505 14:02:23.640803 26400 layer_factory.hpp:77] Creating layer conv4a_neg
I0505 14:02:23.640815 26400 net.cpp:100] Creating Layer conv4a_neg
I0505 14:02:23.640818 26400 net.cpp:434] conv4a_neg <- pool3_neg
I0505 14:02:23.640826 26400 net.cpp:408] conv4a_neg -> conv4a_neg
I0505 14:02:23.704025 26400 net.cpp:150] Setting up conv4a_neg
I0505 14:02:23.704053 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:23.704057 26400 net.cpp:165] Memory required for data: 10403241984
I0505 14:02:23.704066 26400 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0505 14:02:23.704071 26400 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0505 14:02:23.704075 26400 layer_factory.hpp:77] Creating layer relu4a_neg
I0505 14:02:23.704087 26400 net.cpp:100] Creating Layer relu4a_neg
I0505 14:02:23.704092 26400 net.cpp:434] relu4a_neg <- conv4a_neg
I0505 14:02:23.704107 26400 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0505 14:02:23.704298 26400 net.cpp:150] Setting up relu4a_neg
I0505 14:02:23.704308 26400 net.cpp:157] Top shape: 18 256 4 14 14 (3612672)
I0505 14:02:23.704311 26400 net.cpp:165] Memory required for data: 10417692672
I0505 14:02:23.704347 26400 layer_factory.hpp:77] Creating layer pool4_neg
I0505 14:02:23.704365 26400 net.cpp:100] Creating Layer pool4_neg
I0505 14:02:23.704383 26400 net.cpp:434] pool4_neg <- conv4a_neg
I0505 14:02:23.704391 26400 net.cpp:408] pool4_neg -> pool4_neg
I0505 14:02:23.705579 26400 net.cpp:150] Setting up pool4_neg
I0505 14:02:23.705592 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.705595 26400 net.cpp:165] Memory required for data: 10419499008
I0505 14:02:23.705600 26400 layer_factory.hpp:77] Creating layer conv5a_neg
I0505 14:02:23.705611 26400 net.cpp:100] Creating Layer conv5a_neg
I0505 14:02:23.705617 26400 net.cpp:434] conv5a_neg <- pool4_neg
I0505 14:02:23.705623 26400 net.cpp:408] conv5a_neg -> conv5a_neg
I0505 14:02:23.818276 26400 net.cpp:150] Setting up conv5a_neg
I0505 14:02:23.818318 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.818326 26400 net.cpp:165] Memory required for data: 10421305344
I0505 14:02:23.818341 26400 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0505 14:02:23.818351 26400 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0505 14:02:23.818358 26400 layer_factory.hpp:77] Creating layer relu5a_neg
I0505 14:02:23.818374 26400 net.cpp:100] Creating Layer relu5a_neg
I0505 14:02:23.818387 26400 net.cpp:434] relu5a_neg <- conv5a_neg
I0505 14:02:23.818400 26400 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0505 14:02:23.818825 26400 net.cpp:150] Setting up relu5a_neg
I0505 14:02:23.818842 26400 net.cpp:157] Top shape: 18 256 2 7 7 (451584)
I0505 14:02:23.818848 26400 net.cpp:165] Memory required for data: 10423111680
I0505 14:02:23.818855 26400 layer_factory.hpp:77] Creating layer pool5_neg
I0505 14:02:23.818871 26400 net.cpp:100] Creating Layer pool5_neg
I0505 14:02:23.818881 26400 net.cpp:434] pool5_neg <- conv5a_neg
I0505 14:02:23.818892 26400 net.cpp:408] pool5_neg -> pool5_neg
I0505 14:02:23.820359 26400 net.cpp:150] Setting up pool5_neg
I0505 14:02:23.820386 26400 net.cpp:157] Top shape: 18 256 1 4 4 (73728)
I0505 14:02:23.820397 26400 net.cpp:165] Memory required for data: 10423406592
I0505 14:02:23.820410 26400 layer_factory.hpp:77] Creating layer fc6_neg
I0505 14:02:23.820437 26400 net.cpp:100] Creating Layer fc6_neg
I0505 14:02:23.820448 26400 net.cpp:434] fc6_neg <- pool5_neg
I0505 14:02:23.820463 26400 net.cpp:408] fc6_neg -> fc6_neg
I0505 14:02:24.151684 26400 net.cpp:150] Setting up fc6_neg
I0505 14:02:24.151733 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.151738 26400 net.cpp:165] Memory required for data: 10423554048
I0505 14:02:24.151752 26400 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0505 14:02:24.151760 26400 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0505 14:02:24.151765 26400 layer_factory.hpp:77] Creating layer relu6_neg
I0505 14:02:24.151778 26400 net.cpp:100] Creating Layer relu6_neg
I0505 14:02:24.151787 26400 net.cpp:434] relu6_neg <- fc6_neg
I0505 14:02:24.151794 26400 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0505 14:02:24.161353 26400 net.cpp:150] Setting up relu6_neg
I0505 14:02:24.161367 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.161383 26400 net.cpp:165] Memory required for data: 10423701504
I0505 14:02:24.161387 26400 layer_factory.hpp:77] Creating layer drop6_neg
I0505 14:02:24.161418 26400 net.cpp:100] Creating Layer drop6_neg
I0505 14:02:24.161427 26400 net.cpp:434] drop6_neg <- fc6_neg
I0505 14:02:24.161433 26400 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0505 14:02:24.161475 26400 net.cpp:150] Setting up drop6_neg
I0505 14:02:24.161485 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.161489 26400 net.cpp:165] Memory required for data: 10423848960
I0505 14:02:24.161495 26400 layer_factory.hpp:77] Creating layer fc7_neg
I0505 14:02:24.161514 26400 net.cpp:100] Creating Layer fc7_neg
I0505 14:02:24.161521 26400 net.cpp:434] fc7_neg <- fc6_neg
I0505 14:02:24.161533 26400 net.cpp:408] fc7_neg -> fc7_neg
I0505 14:02:24.367846 26400 net.cpp:150] Setting up fc7_neg
I0505 14:02:24.367913 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.367919 26400 net.cpp:165] Memory required for data: 10423996416
I0505 14:02:24.367929 26400 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0505 14:02:24.367938 26400 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0505 14:02:24.367943 26400 layer_factory.hpp:77] Creating layer relu7_neg
I0505 14:02:24.367954 26400 net.cpp:100] Creating Layer relu7_neg
I0505 14:02:24.367959 26400 net.cpp:434] relu7_neg <- fc7_neg
I0505 14:02:24.367967 26400 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0505 14:02:24.374588 26400 net.cpp:150] Setting up relu7_neg
I0505 14:02:24.374608 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.374617 26400 net.cpp:165] Memory required for data: 10424143872
I0505 14:02:24.374622 26400 layer_factory.hpp:77] Creating layer drop7_neg
I0505 14:02:24.374636 26400 net.cpp:100] Creating Layer drop7_neg
I0505 14:02:24.374641 26400 net.cpp:434] drop7_neg <- fc7_neg
I0505 14:02:24.374650 26400 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0505 14:02:24.374712 26400 net.cpp:150] Setting up drop7_neg
I0505 14:02:24.374722 26400 net.cpp:157] Top shape: 18 2048 (36864)
I0505 14:02:24.374727 26400 net.cpp:165] Memory required for data: 10424291328
I0505 14:02:24.374730 26400 layer_factory.hpp:77] Creating layer loss
I0505 14:02:24.375314 26400 net.cpp:100] Creating Layer loss
I0505 14:02:24.375331 26400 net.cpp:434] loss <- fc7
I0505 14:02:24.375339 26400 net.cpp:434] loss <- fc7_pos
I0505 14:02:24.375344 26400 net.cpp:434] loss <- fc7_neg
I0505 14:02:24.375358 26400 net.cpp:408] loss -> loss
I0505 14:02:24.375488 26400 net.cpp:150] Setting up loss
I0505 14:02:24.375502 26400 net.cpp:157] Top shape: (1)
I0505 14:02:24.375506 26400 net.cpp:160]     with loss weight 1
I0505 14:02:24.375540 26400 net.cpp:165] Memory required for data: 10424291332
I0505 14:02:24.375547 26400 net.cpp:226] loss needs backward computation.
I0505 14:02:24.375558 26400 net.cpp:226] drop7_neg needs backward computation.
I0505 14:02:24.375567 26400 net.cpp:226] relu7_neg needs backward computation.
I0505 14:02:24.375573 26400 net.cpp:226] fc7_neg needs backward computation.
I0505 14:02:24.375582 26400 net.cpp:226] drop6_neg needs backward computation.
I0505 14:02:24.375589 26400 net.cpp:226] relu6_neg needs backward computation.
I0505 14:02:24.375597 26400 net.cpp:226] fc6_neg needs backward computation.
I0505 14:02:24.375604 26400 net.cpp:226] pool5_neg needs backward computation.
I0505 14:02:24.375613 26400 net.cpp:226] relu5a_neg needs backward computation.
I0505 14:02:24.375623 26400 net.cpp:226] conv5a_neg needs backward computation.
I0505 14:02:24.375633 26400 net.cpp:226] pool4_neg needs backward computation.
I0505 14:02:24.375640 26400 net.cpp:226] relu4a_neg needs backward computation.
I0505 14:02:24.375645 26400 net.cpp:226] conv4a_neg needs backward computation.
I0505 14:02:24.375649 26400 net.cpp:226] pool3_neg needs backward computation.
I0505 14:02:24.375653 26400 net.cpp:226] relu3a_neg needs backward computation.
I0505 14:02:24.375656 26400 net.cpp:226] conv3a_neg needs backward computation.
I0505 14:02:24.375660 26400 net.cpp:226] pool2_neg needs backward computation.
I0505 14:02:24.375664 26400 net.cpp:226] relu2a_neg needs backward computation.
I0505 14:02:24.375669 26400 net.cpp:226] conv2a_neg needs backward computation.
I0505 14:02:24.375672 26400 net.cpp:226] pool1_neg needs backward computation.
I0505 14:02:24.375676 26400 net.cpp:226] relu1a_neg needs backward computation.
I0505 14:02:24.375680 26400 net.cpp:226] conv1a_neg needs backward computation.
I0505 14:02:24.375684 26400 net.cpp:226] drop7_pos needs backward computation.
I0505 14:02:24.375691 26400 net.cpp:226] relu7_pos needs backward computation.
I0505 14:02:24.375696 26400 net.cpp:226] fc7_pos needs backward computation.
I0505 14:02:24.375704 26400 net.cpp:226] drop6_pos needs backward computation.
I0505 14:02:24.375710 26400 net.cpp:226] relu6_pos needs backward computation.
I0505 14:02:24.375738 26400 net.cpp:226] fc6_pos needs backward computation.
I0505 14:02:24.375747 26400 net.cpp:226] pool5_pos needs backward computation.
I0505 14:02:24.375756 26400 net.cpp:226] relu5a_pos needs backward computation.
I0505 14:02:24.375762 26400 net.cpp:226] conv5a_pos needs backward computation.
I0505 14:02:24.375767 26400 net.cpp:226] pool4_pos needs backward computation.
I0505 14:02:24.375771 26400 net.cpp:226] relu4a_pos needs backward computation.
I0505 14:02:24.375775 26400 net.cpp:226] conv4a_pos needs backward computation.
I0505 14:02:24.375779 26400 net.cpp:226] pool3_pos needs backward computation.
I0505 14:02:24.375783 26400 net.cpp:226] relu3a_pos needs backward computation.
I0505 14:02:24.375787 26400 net.cpp:226] conv3a_pos needs backward computation.
I0505 14:02:24.375792 26400 net.cpp:226] pool2_pos needs backward computation.
I0505 14:02:24.375795 26400 net.cpp:226] relu2a_pos needs backward computation.
I0505 14:02:24.375799 26400 net.cpp:226] conv2a_pos needs backward computation.
I0505 14:02:24.375803 26400 net.cpp:226] pool1_pos needs backward computation.
I0505 14:02:24.375808 26400 net.cpp:226] relu1a_pos needs backward computation.
I0505 14:02:24.375811 26400 net.cpp:226] conv1a_pos needs backward computation.
I0505 14:02:24.375816 26400 net.cpp:226] drop7 needs backward computation.
I0505 14:02:24.375820 26400 net.cpp:226] relu7 needs backward computation.
I0505 14:02:24.375824 26400 net.cpp:226] fc7 needs backward computation.
I0505 14:02:24.375828 26400 net.cpp:226] drop6 needs backward computation.
I0505 14:02:24.375833 26400 net.cpp:226] relu6 needs backward computation.
I0505 14:02:24.375835 26400 net.cpp:226] fc6 needs backward computation.
I0505 14:02:24.375840 26400 net.cpp:226] pool5 needs backward computation.
I0505 14:02:24.375844 26400 net.cpp:226] relu5a needs backward computation.
I0505 14:02:24.375849 26400 net.cpp:226] conv5a needs backward computation.
I0505 14:02:24.375852 26400 net.cpp:226] pool4 needs backward computation.
I0505 14:02:24.375857 26400 net.cpp:226] relu4a needs backward computation.
I0505 14:02:24.375861 26400 net.cpp:226] conv4a needs backward computation.
I0505 14:02:24.375865 26400 net.cpp:226] pool3 needs backward computation.
I0505 14:02:24.375869 26400 net.cpp:226] relu3a needs backward computation.
I0505 14:02:24.375872 26400 net.cpp:226] conv3a needs backward computation.
I0505 14:02:24.375877 26400 net.cpp:226] pool2 needs backward computation.
I0505 14:02:24.375881 26400 net.cpp:226] relu2a needs backward computation.
I0505 14:02:24.375885 26400 net.cpp:226] conv2a needs backward computation.
I0505 14:02:24.375890 26400 net.cpp:226] pool1 needs backward computation.
I0505 14:02:24.375895 26400 net.cpp:226] relu1a needs backward computation.
I0505 14:02:24.375898 26400 net.cpp:226] conv1a needs backward computation.
I0505 14:02:24.375908 26400 net.cpp:228] reshape_negative does not need backward computation.
I0505 14:02:24.375916 26400 net.cpp:228] reshape_positive does not need backward computation.
I0505 14:02:24.375921 26400 net.cpp:228] reshape_anchor does not need backward computation.
I0505 14:02:24.375926 26400 net.cpp:228] slicer does not need backward computation.
I0505 14:02:24.375931 26400 net.cpp:228] data does not need backward computation.
I0505 14:02:24.375934 26400 net.cpp:270] This network produces output loss
I0505 14:02:24.497913 26400 net.cpp:283] Network initialization done.
I0505 14:02:24.501677 26400 solver.cpp:181] Creating test net (#0) specified by net file: ../../models/three_stream_triplet_loss.prototxt
I0505 14:02:24.501893 26400 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0505 14:02:24.502794 26400 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams"
state {
  phase: TEST
  stage: "test-on-val"
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  include {
    phase: TEST
    stage: "test-on-val"
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/Triplets/val"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "TripletLoss"
  bottom: "fc7"
  bottom: "fc7_pos"
  bottom: "fc7_neg"
  top: "loss"
  threshold_param {
    threshold: 1
  }
}
I0505 14:02:24.503258 26400 layer_factory.hpp:77] Creating layer data
I0505 14:02:24.503373 26400 net.cpp:100] Creating Layer data
I0505 14:02:24.503391 26400 net.cpp:408] data -> triplet
I0505 14:02:24.548789 26429 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/Triplets/val
I0505 14:02:24.683316 26400 data_layer.cpp:41] output data size: 1,144,112,112
I0505 14:02:24.716296 26400 net.cpp:150] Setting up data
I0505 14:02:24.716358 26400 net.cpp:157] Top shape: 1 144 112 112 (1806336)
I0505 14:02:24.716365 26400 net.cpp:165] Memory required for data: 7225344
I0505 14:02:24.716378 26400 layer_factory.hpp:77] Creating layer slicer
I0505 14:02:24.716405 26400 net.cpp:100] Creating Layer slicer
I0505 14:02:24.716415 26400 net.cpp:434] slicer <- triplet
I0505 14:02:24.716428 26400 net.cpp:408] slicer -> anchor_stacked
I0505 14:02:24.716444 26400 net.cpp:408] slicer -> positive_stacked
I0505 14:02:24.716454 26400 net.cpp:408] slicer -> negative_stacked
I0505 14:02:24.716675 26400 net.cpp:150] Setting up slicer
I0505 14:02:24.716689 26400 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0505 14:02:24.716697 26400 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0505 14:02:24.716707 26400 net.cpp:157] Top shape: 1 48 112 112 (602112)
I0505 14:02:24.716717 26400 net.cpp:165] Memory required for data: 14450688
I0505 14:02:24.716723 26400 layer_factory.hpp:77] Creating layer reshape_anchor
I0505 14:02:24.716738 26400 net.cpp:100] Creating Layer reshape_anchor
I0505 14:02:24.716747 26400 net.cpp:434] reshape_anchor <- anchor_stacked
I0505 14:02:24.716763 26400 net.cpp:408] reshape_anchor -> anchor
I0505 14:02:24.716830 26400 net.cpp:150] Setting up reshape_anchor
I0505 14:02:24.716843 26400 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0505 14:02:24.716852 26400 net.cpp:165] Memory required for data: 16859136
I0505 14:02:24.716858 26400 layer_factory.hpp:77] Creating layer reshape_positive
I0505 14:02:24.716868 26400 net.cpp:100] Creating Layer reshape_positive
I0505 14:02:24.716874 26400 net.cpp:434] reshape_positive <- positive_stacked
I0505 14:02:24.716883 26400 net.cpp:408] reshape_positive -> positive
I0505 14:02:24.716948 26400 net.cpp:150] Setting up reshape_positive
I0505 14:02:24.716960 26400 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0505 14:02:24.716967 26400 net.cpp:165] Memory required for data: 19267584
I0505 14:02:24.716974 26400 layer_factory.hpp:77] Creating layer reshape_negative
I0505 14:02:24.716987 26400 net.cpp:100] Creating Layer reshape_negative
I0505 14:02:24.716995 26400 net.cpp:434] reshape_negative <- negative_stacked
I0505 14:02:24.717005 26400 net.cpp:408] reshape_negative -> negative
I0505 14:02:24.717061 26400 net.cpp:150] Setting up reshape_negative
I0505 14:02:24.717073 26400 net.cpp:157] Top shape: 1 3 16 112 112 (602112)
I0505 14:02:24.717080 26400 net.cpp:165] Memory required for data: 21676032
I0505 14:02:24.717087 26400 layer_factory.hpp:77] Creating layer conv1a
I0505 14:02:24.717108 26400 net.cpp:100] Creating Layer conv1a
I0505 14:02:24.717114 26400 net.cpp:434] conv1a <- anchor
I0505 14:02:24.717126 26400 net.cpp:408] conv1a -> conv1a
I0505 14:02:24.723239 26400 net.cpp:150] Setting up conv1a
I0505 14:02:24.723266 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:24.723273 26400 net.cpp:165] Memory required for data: 73056256
I0505 14:02:24.723323 26400 layer_factory.hpp:77] Creating layer relu1a
I0505 14:02:24.723340 26400 net.cpp:100] Creating Layer relu1a
I0505 14:02:24.723350 26400 net.cpp:434] relu1a <- conv1a
I0505 14:02:24.723357 26400 net.cpp:395] relu1a -> conv1a (in-place)
I0505 14:02:24.724334 26400 net.cpp:150] Setting up relu1a
I0505 14:02:24.724354 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:24.724359 26400 net.cpp:165] Memory required for data: 124436480
I0505 14:02:24.724365 26400 layer_factory.hpp:77] Creating layer pool1
I0505 14:02:24.724381 26400 net.cpp:100] Creating Layer pool1
I0505 14:02:24.724388 26400 net.cpp:434] pool1 <- conv1a
I0505 14:02:24.724398 26400 net.cpp:408] pool1 -> pool1
I0505 14:02:24.725455 26400 net.cpp:150] Setting up pool1
I0505 14:02:24.725473 26400 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0505 14:02:24.725479 26400 net.cpp:165] Memory required for data: 137281536
I0505 14:02:24.725486 26400 layer_factory.hpp:77] Creating layer conv2a
I0505 14:02:24.725504 26400 net.cpp:100] Creating Layer conv2a
I0505 14:02:24.725512 26400 net.cpp:434] conv2a <- pool1
I0505 14:02:24.725533 26400 net.cpp:408] conv2a -> conv2a
I0505 14:02:24.746168 26400 net.cpp:150] Setting up conv2a
I0505 14:02:24.746209 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:24.746217 26400 net.cpp:165] Memory required for data: 162971648
I0505 14:02:24.746238 26400 layer_factory.hpp:77] Creating layer relu2a
I0505 14:02:24.746258 26400 net.cpp:100] Creating Layer relu2a
I0505 14:02:24.746265 26400 net.cpp:434] relu2a <- conv2a
I0505 14:02:24.746276 26400 net.cpp:395] relu2a -> conv2a (in-place)
I0505 14:02:24.747388 26400 net.cpp:150] Setting up relu2a
I0505 14:02:24.747406 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:24.747412 26400 net.cpp:165] Memory required for data: 188661760
I0505 14:02:24.747419 26400 layer_factory.hpp:77] Creating layer pool2
I0505 14:02:24.747437 26400 net.cpp:100] Creating Layer pool2
I0505 14:02:24.747443 26400 net.cpp:434] pool2 <- conv2a
I0505 14:02:24.747453 26400 net.cpp:408] pool2 -> pool2
I0505 14:02:24.748450 26400 net.cpp:150] Setting up pool2
I0505 14:02:24.748466 26400 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0505 14:02:24.748472 26400 net.cpp:165] Memory required for data: 191873024
I0505 14:02:24.748479 26400 layer_factory.hpp:77] Creating layer conv3a
I0505 14:02:24.748500 26400 net.cpp:100] Creating Layer conv3a
I0505 14:02:24.748507 26400 net.cpp:434] conv3a <- pool2
I0505 14:02:24.748520 26400 net.cpp:408] conv3a -> conv3a
I0505 14:02:24.818163 26400 net.cpp:150] Setting up conv3a
I0505 14:02:24.818264 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:24.818286 26400 net.cpp:165] Memory required for data: 198295552
I0505 14:02:24.818325 26400 layer_factory.hpp:77] Creating layer relu3a
I0505 14:02:24.818356 26400 net.cpp:100] Creating Layer relu3a
I0505 14:02:24.818374 26400 net.cpp:434] relu3a <- conv3a
I0505 14:02:24.818394 26400 net.cpp:395] relu3a -> conv3a (in-place)
I0505 14:02:24.819692 26400 net.cpp:150] Setting up relu3a
I0505 14:02:24.819716 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:24.819723 26400 net.cpp:165] Memory required for data: 204718080
I0505 14:02:24.819730 26400 layer_factory.hpp:77] Creating layer pool3
I0505 14:02:24.819748 26400 net.cpp:100] Creating Layer pool3
I0505 14:02:24.819756 26400 net.cpp:434] pool3 <- conv3a
I0505 14:02:24.819769 26400 net.cpp:408] pool3 -> pool3
I0505 14:02:24.820143 26400 net.cpp:150] Setting up pool3
I0505 14:02:24.820160 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:24.820166 26400 net.cpp:165] Memory required for data: 205520896
I0505 14:02:24.820171 26400 layer_factory.hpp:77] Creating layer conv4a
I0505 14:02:24.820188 26400 net.cpp:100] Creating Layer conv4a
I0505 14:02:24.820214 26400 net.cpp:434] conv4a <- pool3
I0505 14:02:24.820240 26400 net.cpp:408] conv4a -> conv4a
I0505 14:02:24.892137 26400 net.cpp:150] Setting up conv4a
I0505 14:02:24.892225 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:24.892235 26400 net.cpp:165] Memory required for data: 206323712
I0505 14:02:24.892252 26400 layer_factory.hpp:77] Creating layer relu4a
I0505 14:02:24.892282 26400 net.cpp:100] Creating Layer relu4a
I0505 14:02:24.892292 26400 net.cpp:434] relu4a <- conv4a
I0505 14:02:24.892307 26400 net.cpp:395] relu4a -> conv4a (in-place)
I0505 14:02:24.893982 26400 net.cpp:150] Setting up relu4a
I0505 14:02:24.894008 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:24.894021 26400 net.cpp:165] Memory required for data: 207126528
I0505 14:02:24.894028 26400 layer_factory.hpp:77] Creating layer pool4
I0505 14:02:24.894057 26400 net.cpp:100] Creating Layer pool4
I0505 14:02:24.894067 26400 net.cpp:434] pool4 <- conv4a
I0505 14:02:24.894078 26400 net.cpp:408] pool4 -> pool4
I0505 14:02:24.894553 26400 net.cpp:150] Setting up pool4
I0505 14:02:24.894573 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:24.894582 26400 net.cpp:165] Memory required for data: 207226880
I0505 14:02:24.894588 26400 layer_factory.hpp:77] Creating layer conv5a
I0505 14:02:24.894608 26400 net.cpp:100] Creating Layer conv5a
I0505 14:02:24.894615 26400 net.cpp:434] conv5a <- pool4
I0505 14:02:24.894629 26400 net.cpp:408] conv5a -> conv5a
I0505 14:02:25.003520 26400 net.cpp:150] Setting up conv5a
I0505 14:02:25.003558 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:25.003564 26400 net.cpp:165] Memory required for data: 207327232
I0505 14:02:25.003592 26400 layer_factory.hpp:77] Creating layer relu5a
I0505 14:02:25.003609 26400 net.cpp:100] Creating Layer relu5a
I0505 14:02:25.003623 26400 net.cpp:434] relu5a <- conv5a
I0505 14:02:25.003638 26400 net.cpp:395] relu5a -> conv5a (in-place)
I0505 14:02:25.004715 26400 net.cpp:150] Setting up relu5a
I0505 14:02:25.004731 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:25.004736 26400 net.cpp:165] Memory required for data: 207427584
I0505 14:02:25.004740 26400 layer_factory.hpp:77] Creating layer pool5
I0505 14:02:25.004751 26400 net.cpp:100] Creating Layer pool5
I0505 14:02:25.004760 26400 net.cpp:434] pool5 <- conv5a
I0505 14:02:25.004767 26400 net.cpp:408] pool5 -> pool5
I0505 14:02:25.005074 26400 net.cpp:150] Setting up pool5
I0505 14:02:25.005089 26400 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0505 14:02:25.005095 26400 net.cpp:165] Memory required for data: 207443968
I0505 14:02:25.005098 26400 layer_factory.hpp:77] Creating layer fc6
I0505 14:02:25.005110 26400 net.cpp:100] Creating Layer fc6
I0505 14:02:25.005116 26400 net.cpp:434] fc6 <- pool5
I0505 14:02:25.005131 26400 net.cpp:408] fc6 -> fc6
I0505 14:02:25.318255 26400 net.cpp:150] Setting up fc6
I0505 14:02:25.318296 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.318301 26400 net.cpp:165] Memory required for data: 207452160
I0505 14:02:25.318315 26400 layer_factory.hpp:77] Creating layer relu6
I0505 14:02:25.318326 26400 net.cpp:100] Creating Layer relu6
I0505 14:02:25.318331 26400 net.cpp:434] relu6 <- fc6
I0505 14:02:25.318337 26400 net.cpp:395] relu6 -> fc6 (in-place)
I0505 14:02:25.320199 26400 net.cpp:150] Setting up relu6
I0505 14:02:25.320215 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.320220 26400 net.cpp:165] Memory required for data: 207460352
I0505 14:02:25.320225 26400 layer_factory.hpp:77] Creating layer drop6
I0505 14:02:25.320232 26400 net.cpp:100] Creating Layer drop6
I0505 14:02:25.320236 26400 net.cpp:434] drop6 <- fc6
I0505 14:02:25.320243 26400 net.cpp:395] drop6 -> fc6 (in-place)
I0505 14:02:25.320281 26400 net.cpp:150] Setting up drop6
I0505 14:02:25.320288 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.320297 26400 net.cpp:165] Memory required for data: 207468544
I0505 14:02:25.320302 26400 layer_factory.hpp:77] Creating layer fc7
I0505 14:02:25.320319 26400 net.cpp:100] Creating Layer fc7
I0505 14:02:25.320323 26400 net.cpp:434] fc7 <- fc6
I0505 14:02:25.320332 26400 net.cpp:408] fc7 -> fc7
I0505 14:02:25.471735 26400 net.cpp:150] Setting up fc7
I0505 14:02:25.471781 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.471815 26400 net.cpp:165] Memory required for data: 207476736
I0505 14:02:25.471828 26400 layer_factory.hpp:77] Creating layer relu7
I0505 14:02:25.471838 26400 net.cpp:100] Creating Layer relu7
I0505 14:02:25.471843 26400 net.cpp:434] relu7 <- fc7
I0505 14:02:25.471853 26400 net.cpp:395] relu7 -> fc7 (in-place)
I0505 14:02:25.472131 26400 net.cpp:150] Setting up relu7
I0505 14:02:25.472144 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.472148 26400 net.cpp:165] Memory required for data: 207484928
I0505 14:02:25.472151 26400 layer_factory.hpp:77] Creating layer drop7
I0505 14:02:25.472172 26400 net.cpp:100] Creating Layer drop7
I0505 14:02:25.472179 26400 net.cpp:434] drop7 <- fc7
I0505 14:02:25.472187 26400 net.cpp:395] drop7 -> fc7 (in-place)
I0505 14:02:25.472236 26400 net.cpp:150] Setting up drop7
I0505 14:02:25.472247 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:25.472254 26400 net.cpp:165] Memory required for data: 207493120
I0505 14:02:25.472259 26400 layer_factory.hpp:77] Creating layer conv1a_pos
I0505 14:02:25.472285 26400 net.cpp:100] Creating Layer conv1a_pos
I0505 14:02:25.472295 26400 net.cpp:434] conv1a_pos <- positive
I0505 14:02:25.472312 26400 net.cpp:408] conv1a_pos -> conv1a_pos
I0505 14:02:25.476955 26400 net.cpp:150] Setting up conv1a_pos
I0505 14:02:25.476975 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:25.476982 26400 net.cpp:165] Memory required for data: 258873344
I0505 14:02:25.476991 26400 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0505 14:02:25.477004 26400 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0505 14:02:25.477011 26400 layer_factory.hpp:77] Creating layer relu1a_pos
I0505 14:02:25.477023 26400 net.cpp:100] Creating Layer relu1a_pos
I0505 14:02:25.477032 26400 net.cpp:434] relu1a_pos <- conv1a_pos
I0505 14:02:25.477042 26400 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0505 14:02:25.477952 26400 net.cpp:150] Setting up relu1a_pos
I0505 14:02:25.477967 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:25.477974 26400 net.cpp:165] Memory required for data: 310253568
I0505 14:02:25.477980 26400 layer_factory.hpp:77] Creating layer pool1_pos
I0505 14:02:25.477995 26400 net.cpp:100] Creating Layer pool1_pos
I0505 14:02:25.478003 26400 net.cpp:434] pool1_pos <- conv1a_pos
I0505 14:02:25.478013 26400 net.cpp:408] pool1_pos -> pool1_pos
I0505 14:02:25.478276 26400 net.cpp:150] Setting up pool1_pos
I0505 14:02:25.478291 26400 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0505 14:02:25.478296 26400 net.cpp:165] Memory required for data: 323098624
I0505 14:02:25.478302 26400 layer_factory.hpp:77] Creating layer conv2a_pos
I0505 14:02:25.478317 26400 net.cpp:100] Creating Layer conv2a_pos
I0505 14:02:25.478328 26400 net.cpp:434] conv2a_pos <- pool1_pos
I0505 14:02:25.478343 26400 net.cpp:408] conv2a_pos -> conv2a_pos
I0505 14:02:25.488029 26400 net.cpp:150] Setting up conv2a_pos
I0505 14:02:25.488066 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:25.488072 26400 net.cpp:165] Memory required for data: 348788736
I0505 14:02:25.488101 26400 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0505 14:02:25.488111 26400 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0505 14:02:25.488121 26400 layer_factory.hpp:77] Creating layer relu2a_pos
I0505 14:02:25.488142 26400 net.cpp:100] Creating Layer relu2a_pos
I0505 14:02:25.488150 26400 net.cpp:434] relu2a_pos <- conv2a_pos
I0505 14:02:25.488162 26400 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0505 14:02:25.488376 26400 net.cpp:150] Setting up relu2a_pos
I0505 14:02:25.488391 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:25.488397 26400 net.cpp:165] Memory required for data: 374478848
I0505 14:02:25.488404 26400 layer_factory.hpp:77] Creating layer pool2_pos
I0505 14:02:25.488420 26400 net.cpp:100] Creating Layer pool2_pos
I0505 14:02:25.488446 26400 net.cpp:434] pool2_pos <- conv2a_pos
I0505 14:02:25.488459 26400 net.cpp:408] pool2_pos -> pool2_pos
I0505 14:02:25.489440 26400 net.cpp:150] Setting up pool2_pos
I0505 14:02:25.489457 26400 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0505 14:02:25.489464 26400 net.cpp:165] Memory required for data: 377690112
I0505 14:02:25.489470 26400 layer_factory.hpp:77] Creating layer conv3a_pos
I0505 14:02:25.489516 26400 net.cpp:100] Creating Layer conv3a_pos
I0505 14:02:25.489524 26400 net.cpp:434] conv3a_pos <- pool2_pos
I0505 14:02:25.490036 26400 net.cpp:408] conv3a_pos -> conv3a_pos
I0505 14:02:25.519507 26400 net.cpp:150] Setting up conv3a_pos
I0505 14:02:25.519547 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:25.519553 26400 net.cpp:165] Memory required for data: 384112640
I0505 14:02:25.519564 26400 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0505 14:02:25.519585 26400 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0505 14:02:25.519592 26400 layer_factory.hpp:77] Creating layer relu3a_pos
I0505 14:02:25.519611 26400 net.cpp:100] Creating Layer relu3a_pos
I0505 14:02:25.519620 26400 net.cpp:434] relu3a_pos <- conv3a_pos
I0505 14:02:25.519634 26400 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0505 14:02:25.519850 26400 net.cpp:150] Setting up relu3a_pos
I0505 14:02:25.519865 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:25.519870 26400 net.cpp:165] Memory required for data: 390535168
I0505 14:02:25.519877 26400 layer_factory.hpp:77] Creating layer pool3_pos
I0505 14:02:25.519892 26400 net.cpp:100] Creating Layer pool3_pos
I0505 14:02:25.519901 26400 net.cpp:434] pool3_pos <- conv3a_pos
I0505 14:02:25.519911 26400 net.cpp:408] pool3_pos -> pool3_pos
I0505 14:02:25.520889 26400 net.cpp:150] Setting up pool3_pos
I0505 14:02:25.520905 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:25.520911 26400 net.cpp:165] Memory required for data: 391337984
I0505 14:02:25.520917 26400 layer_factory.hpp:77] Creating layer conv4a_pos
I0505 14:02:25.520949 26400 net.cpp:100] Creating Layer conv4a_pos
I0505 14:02:25.520957 26400 net.cpp:434] conv4a_pos <- pool3_pos
I0505 14:02:25.520972 26400 net.cpp:408] conv4a_pos -> conv4a_pos
I0505 14:02:25.583343 26400 net.cpp:150] Setting up conv4a_pos
I0505 14:02:25.583380 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:25.583390 26400 net.cpp:165] Memory required for data: 392140800
I0505 14:02:25.583401 26400 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0505 14:02:25.583422 26400 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0505 14:02:25.583429 26400 layer_factory.hpp:77] Creating layer relu4a_pos
I0505 14:02:25.583444 26400 net.cpp:100] Creating Layer relu4a_pos
I0505 14:02:25.583456 26400 net.cpp:434] relu4a_pos <- conv4a_pos
I0505 14:02:25.583468 26400 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0505 14:02:25.583681 26400 net.cpp:150] Setting up relu4a_pos
I0505 14:02:25.583695 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:25.583701 26400 net.cpp:165] Memory required for data: 392943616
I0505 14:02:25.583709 26400 layer_factory.hpp:77] Creating layer pool4_pos
I0505 14:02:25.583721 26400 net.cpp:100] Creating Layer pool4_pos
I0505 14:02:25.583729 26400 net.cpp:434] pool4_pos <- conv4a_pos
I0505 14:02:25.583741 26400 net.cpp:408] pool4_pos -> pool4_pos
I0505 14:02:25.584723 26400 net.cpp:150] Setting up pool4_pos
I0505 14:02:25.584740 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:25.584746 26400 net.cpp:165] Memory required for data: 393043968
I0505 14:02:25.584753 26400 layer_factory.hpp:77] Creating layer conv5a_pos
I0505 14:02:25.584776 26400 net.cpp:100] Creating Layer conv5a_pos
I0505 14:02:25.584784 26400 net.cpp:434] conv5a_pos <- pool4_pos
I0505 14:02:25.584797 26400 net.cpp:408] conv5a_pos -> conv5a_pos
I0505 14:02:25.655325 26400 net.cpp:150] Setting up conv5a_pos
I0505 14:02:25.655375 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:25.655467 26400 net.cpp:165] Memory required for data: 393144320
I0505 14:02:25.655485 26400 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0505 14:02:25.655511 26400 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0505 14:02:25.655520 26400 layer_factory.hpp:77] Creating layer relu5a_pos
I0505 14:02:25.655542 26400 net.cpp:100] Creating Layer relu5a_pos
I0505 14:02:25.655551 26400 net.cpp:434] relu5a_pos <- conv5a_pos
I0505 14:02:25.655566 26400 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0505 14:02:25.656759 26400 net.cpp:150] Setting up relu5a_pos
I0505 14:02:25.656793 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:25.656800 26400 net.cpp:165] Memory required for data: 393244672
I0505 14:02:25.656807 26400 layer_factory.hpp:77] Creating layer pool5_pos
I0505 14:02:25.656826 26400 net.cpp:100] Creating Layer pool5_pos
I0505 14:02:25.656849 26400 net.cpp:434] pool5_pos <- conv5a_pos
I0505 14:02:25.656867 26400 net.cpp:408] pool5_pos -> pool5_pos
I0505 14:02:25.657992 26400 net.cpp:150] Setting up pool5_pos
I0505 14:02:25.658012 26400 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0505 14:02:25.658017 26400 net.cpp:165] Memory required for data: 393261056
I0505 14:02:25.658025 26400 layer_factory.hpp:77] Creating layer fc6_pos
I0505 14:02:25.658043 26400 net.cpp:100] Creating Layer fc6_pos
I0505 14:02:25.658051 26400 net.cpp:434] fc6_pos <- pool5_pos
I0505 14:02:25.658066 26400 net.cpp:408] fc6_pos -> fc6_pos
I0505 14:02:26.086742 26400 net.cpp:150] Setting up fc6_pos
I0505 14:02:26.086781 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.086786 26400 net.cpp:165] Memory required for data: 393269248
I0505 14:02:26.086794 26400 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0505 14:02:26.086800 26400 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0505 14:02:26.086805 26400 layer_factory.hpp:77] Creating layer relu6_pos
I0505 14:02:26.086825 26400 net.cpp:100] Creating Layer relu6_pos
I0505 14:02:26.086832 26400 net.cpp:434] relu6_pos <- fc6_pos
I0505 14:02:26.086839 26400 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0505 14:02:26.087122 26400 net.cpp:150] Setting up relu6_pos
I0505 14:02:26.087136 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.087138 26400 net.cpp:165] Memory required for data: 393277440
I0505 14:02:26.087142 26400 layer_factory.hpp:77] Creating layer drop6_pos
I0505 14:02:26.087152 26400 net.cpp:100] Creating Layer drop6_pos
I0505 14:02:26.087157 26400 net.cpp:434] drop6_pos <- fc6_pos
I0505 14:02:26.087160 26400 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0505 14:02:26.087198 26400 net.cpp:150] Setting up drop6_pos
I0505 14:02:26.087203 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.087206 26400 net.cpp:165] Memory required for data: 393285632
I0505 14:02:26.087209 26400 layer_factory.hpp:77] Creating layer fc7_pos
I0505 14:02:26.087218 26400 net.cpp:100] Creating Layer fc7_pos
I0505 14:02:26.087221 26400 net.cpp:434] fc7_pos <- fc6_pos
I0505 14:02:26.087230 26400 net.cpp:408] fc7_pos -> fc7_pos
I0505 14:02:26.264341 26400 net.cpp:150] Setting up fc7_pos
I0505 14:02:26.264379 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.264381 26400 net.cpp:165] Memory required for data: 393293824
I0505 14:02:26.264391 26400 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0505 14:02:26.264397 26400 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0505 14:02:26.264401 26400 layer_factory.hpp:77] Creating layer relu7_pos
I0505 14:02:26.264412 26400 net.cpp:100] Creating Layer relu7_pos
I0505 14:02:26.264417 26400 net.cpp:434] relu7_pos <- fc7_pos
I0505 14:02:26.264425 26400 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0505 14:02:26.265547 26400 net.cpp:150] Setting up relu7_pos
I0505 14:02:26.265560 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.265565 26400 net.cpp:165] Memory required for data: 393302016
I0505 14:02:26.265599 26400 layer_factory.hpp:77] Creating layer drop7_pos
I0505 14:02:26.265609 26400 net.cpp:100] Creating Layer drop7_pos
I0505 14:02:26.265614 26400 net.cpp:434] drop7_pos <- fc7_pos
I0505 14:02:26.265617 26400 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0505 14:02:26.265656 26400 net.cpp:150] Setting up drop7_pos
I0505 14:02:26.265663 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.265666 26400 net.cpp:165] Memory required for data: 393310208
I0505 14:02:26.265668 26400 layer_factory.hpp:77] Creating layer conv1a_neg
I0505 14:02:26.265681 26400 net.cpp:100] Creating Layer conv1a_neg
I0505 14:02:26.265686 26400 net.cpp:434] conv1a_neg <- negative
I0505 14:02:26.265694 26400 net.cpp:408] conv1a_neg -> conv1a_neg
I0505 14:02:26.268232 26400 net.cpp:150] Setting up conv1a_neg
I0505 14:02:26.268247 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:26.268251 26400 net.cpp:165] Memory required for data: 444690432
I0505 14:02:26.268257 26400 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0505 14:02:26.268262 26400 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0505 14:02:26.268266 26400 layer_factory.hpp:77] Creating layer relu1a_neg
I0505 14:02:26.268273 26400 net.cpp:100] Creating Layer relu1a_neg
I0505 14:02:26.268277 26400 net.cpp:434] relu1a_neg <- conv1a_neg
I0505 14:02:26.268282 26400 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0505 14:02:26.269132 26400 net.cpp:150] Setting up relu1a_neg
I0505 14:02:26.269145 26400 net.cpp:157] Top shape: 1 64 16 112 112 (12845056)
I0505 14:02:26.269148 26400 net.cpp:165] Memory required for data: 496070656
I0505 14:02:26.269152 26400 layer_factory.hpp:77] Creating layer pool1_neg
I0505 14:02:26.269166 26400 net.cpp:100] Creating Layer pool1_neg
I0505 14:02:26.269171 26400 net.cpp:434] pool1_neg <- conv1a_neg
I0505 14:02:26.269178 26400 net.cpp:408] pool1_neg -> pool1_neg
I0505 14:02:26.269418 26400 net.cpp:150] Setting up pool1_neg
I0505 14:02:26.269429 26400 net.cpp:157] Top shape: 1 64 16 56 56 (3211264)
I0505 14:02:26.269433 26400 net.cpp:165] Memory required for data: 508915712
I0505 14:02:26.269435 26400 layer_factory.hpp:77] Creating layer conv2a_neg
I0505 14:02:26.269446 26400 net.cpp:100] Creating Layer conv2a_neg
I0505 14:02:26.269451 26400 net.cpp:434] conv2a_neg <- pool1_neg
I0505 14:02:26.269459 26400 net.cpp:408] conv2a_neg -> conv2a_neg
I0505 14:02:26.290894 26400 net.cpp:150] Setting up conv2a_neg
I0505 14:02:26.290956 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:26.290963 26400 net.cpp:165] Memory required for data: 534605824
I0505 14:02:26.290973 26400 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0505 14:02:26.290982 26400 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0505 14:02:26.290989 26400 layer_factory.hpp:77] Creating layer relu2a_neg
I0505 14:02:26.291003 26400 net.cpp:100] Creating Layer relu2a_neg
I0505 14:02:26.291012 26400 net.cpp:434] relu2a_neg <- conv2a_neg
I0505 14:02:26.291028 26400 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0505 14:02:26.292537 26400 net.cpp:150] Setting up relu2a_neg
I0505 14:02:26.292554 26400 net.cpp:157] Top shape: 1 128 16 56 56 (6422528)
I0505 14:02:26.292560 26400 net.cpp:165] Memory required for data: 560295936
I0505 14:02:26.292578 26400 layer_factory.hpp:77] Creating layer pool2_neg
I0505 14:02:26.292590 26400 net.cpp:100] Creating Layer pool2_neg
I0505 14:02:26.292600 26400 net.cpp:434] pool2_neg <- conv2a_neg
I0505 14:02:26.292609 26400 net.cpp:408] pool2_neg -> pool2_neg
I0505 14:02:26.292935 26400 net.cpp:150] Setting up pool2_neg
I0505 14:02:26.292949 26400 net.cpp:157] Top shape: 1 128 8 28 28 (802816)
I0505 14:02:26.292954 26400 net.cpp:165] Memory required for data: 563507200
I0505 14:02:26.292960 26400 layer_factory.hpp:77] Creating layer conv3a_neg
I0505 14:02:26.292976 26400 net.cpp:100] Creating Layer conv3a_neg
I0505 14:02:26.292984 26400 net.cpp:434] conv3a_neg <- pool2_neg
I0505 14:02:26.293021 26400 net.cpp:408] conv3a_neg -> conv3a_neg
I0505 14:02:26.325767 26400 net.cpp:150] Setting up conv3a_neg
I0505 14:02:26.325801 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:26.325806 26400 net.cpp:165] Memory required for data: 569929728
I0505 14:02:26.325821 26400 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0505 14:02:26.325829 26400 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0505 14:02:26.325834 26400 layer_factory.hpp:77] Creating layer relu3a_neg
I0505 14:02:26.325845 26400 net.cpp:100] Creating Layer relu3a_neg
I0505 14:02:26.325850 26400 net.cpp:434] relu3a_neg <- conv3a_neg
I0505 14:02:26.325865 26400 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0505 14:02:26.327116 26400 net.cpp:150] Setting up relu3a_neg
I0505 14:02:26.327131 26400 net.cpp:157] Top shape: 1 256 8 28 28 (1605632)
I0505 14:02:26.327136 26400 net.cpp:165] Memory required for data: 576352256
I0505 14:02:26.327139 26400 layer_factory.hpp:77] Creating layer pool3_neg
I0505 14:02:26.327152 26400 net.cpp:100] Creating Layer pool3_neg
I0505 14:02:26.327157 26400 net.cpp:434] pool3_neg <- conv3a_neg
I0505 14:02:26.327162 26400 net.cpp:408] pool3_neg -> pool3_neg
I0505 14:02:26.327556 26400 net.cpp:150] Setting up pool3_neg
I0505 14:02:26.327577 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:26.327585 26400 net.cpp:165] Memory required for data: 577155072
I0505 14:02:26.327592 26400 layer_factory.hpp:77] Creating layer conv4a_neg
I0505 14:02:26.327616 26400 net.cpp:100] Creating Layer conv4a_neg
I0505 14:02:26.327626 26400 net.cpp:434] conv4a_neg <- pool3_neg
I0505 14:02:26.327642 26400 net.cpp:408] conv4a_neg -> conv4a_neg
I0505 14:02:26.419881 26400 net.cpp:150] Setting up conv4a_neg
I0505 14:02:26.419931 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:26.419939 26400 net.cpp:165] Memory required for data: 577957888
I0505 14:02:26.419950 26400 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0505 14:02:26.419958 26400 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0505 14:02:26.419965 26400 layer_factory.hpp:77] Creating layer relu4a_neg
I0505 14:02:26.419989 26400 net.cpp:100] Creating Layer relu4a_neg
I0505 14:02:26.419997 26400 net.cpp:434] relu4a_neg <- conv4a_neg
I0505 14:02:26.420030 26400 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0505 14:02:26.421447 26400 net.cpp:150] Setting up relu4a_neg
I0505 14:02:26.421470 26400 net.cpp:157] Top shape: 1 256 4 14 14 (200704)
I0505 14:02:26.421476 26400 net.cpp:165] Memory required for data: 578760704
I0505 14:02:26.421489 26400 layer_factory.hpp:77] Creating layer pool4_neg
I0505 14:02:26.421502 26400 net.cpp:100] Creating Layer pool4_neg
I0505 14:02:26.421509 26400 net.cpp:434] pool4_neg <- conv4a_neg
I0505 14:02:26.421528 26400 net.cpp:408] pool4_neg -> pool4_neg
I0505 14:02:26.421924 26400 net.cpp:150] Setting up pool4_neg
I0505 14:02:26.421952 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:26.421957 26400 net.cpp:165] Memory required for data: 578861056
I0505 14:02:26.421973 26400 layer_factory.hpp:77] Creating layer conv5a_neg
I0505 14:02:26.421998 26400 net.cpp:100] Creating Layer conv5a_neg
I0505 14:02:26.422013 26400 net.cpp:434] conv5a_neg <- pool4_neg
I0505 14:02:26.422040 26400 net.cpp:408] conv5a_neg -> conv5a_neg
I0505 14:02:26.513140 26400 net.cpp:150] Setting up conv5a_neg
I0505 14:02:26.513196 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:26.513203 26400 net.cpp:165] Memory required for data: 578961408
I0505 14:02:26.513219 26400 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0505 14:02:26.513228 26400 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0505 14:02:26.513238 26400 layer_factory.hpp:77] Creating layer relu5a_neg
I0505 14:02:26.513258 26400 net.cpp:100] Creating Layer relu5a_neg
I0505 14:02:26.513270 26400 net.cpp:434] relu5a_neg <- conv5a_neg
I0505 14:02:26.513319 26400 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0505 14:02:26.513653 26400 net.cpp:150] Setting up relu5a_neg
I0505 14:02:26.513671 26400 net.cpp:157] Top shape: 1 256 2 7 7 (25088)
I0505 14:02:26.513680 26400 net.cpp:165] Memory required for data: 579061760
I0505 14:02:26.513687 26400 layer_factory.hpp:77] Creating layer pool5_neg
I0505 14:02:26.513705 26400 net.cpp:100] Creating Layer pool5_neg
I0505 14:02:26.513713 26400 net.cpp:434] pool5_neg <- conv5a_neg
I0505 14:02:26.513725 26400 net.cpp:408] pool5_neg -> pool5_neg
I0505 14:02:26.517961 26400 net.cpp:150] Setting up pool5_neg
I0505 14:02:26.517992 26400 net.cpp:157] Top shape: 1 256 1 4 4 (4096)
I0505 14:02:26.518003 26400 net.cpp:165] Memory required for data: 579078144
I0505 14:02:26.518009 26400 layer_factory.hpp:77] Creating layer fc6_neg
I0505 14:02:26.518025 26400 net.cpp:100] Creating Layer fc6_neg
I0505 14:02:26.518031 26400 net.cpp:434] fc6_neg <- pool5_neg
I0505 14:02:26.518038 26400 net.cpp:408] fc6_neg -> fc6_neg
I0505 14:02:26.872123 26400 net.cpp:150] Setting up fc6_neg
I0505 14:02:26.872164 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.872169 26400 net.cpp:165] Memory required for data: 579086336
I0505 14:02:26.872175 26400 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0505 14:02:26.872184 26400 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0505 14:02:26.872187 26400 layer_factory.hpp:77] Creating layer relu6_neg
I0505 14:02:26.872197 26400 net.cpp:100] Creating Layer relu6_neg
I0505 14:02:26.872202 26400 net.cpp:434] relu6_neg <- fc6_neg
I0505 14:02:26.872208 26400 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0505 14:02:26.872505 26400 net.cpp:150] Setting up relu6_neg
I0505 14:02:26.872515 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.872519 26400 net.cpp:165] Memory required for data: 579094528
I0505 14:02:26.872522 26400 layer_factory.hpp:77] Creating layer drop6_neg
I0505 14:02:26.872544 26400 net.cpp:100] Creating Layer drop6_neg
I0505 14:02:26.872548 26400 net.cpp:434] drop6_neg <- fc6_neg
I0505 14:02:26.872555 26400 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0505 14:02:26.872593 26400 net.cpp:150] Setting up drop6_neg
I0505 14:02:26.872601 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:26.872603 26400 net.cpp:165] Memory required for data: 579102720
I0505 14:02:26.872607 26400 layer_factory.hpp:77] Creating layer fc7_neg
I0505 14:02:26.872617 26400 net.cpp:100] Creating Layer fc7_neg
I0505 14:02:26.872620 26400 net.cpp:434] fc7_neg <- fc6_neg
I0505 14:02:26.872627 26400 net.cpp:408] fc7_neg -> fc7_neg
I0505 14:02:27.043823 26400 net.cpp:150] Setting up fc7_neg
I0505 14:02:27.043907 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:27.043911 26400 net.cpp:165] Memory required for data: 579110912
I0505 14:02:27.043925 26400 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0505 14:02:27.043936 26400 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0505 14:02:27.043942 26400 layer_factory.hpp:77] Creating layer relu7_neg
I0505 14:02:27.043970 26400 net.cpp:100] Creating Layer relu7_neg
I0505 14:02:27.043985 26400 net.cpp:434] relu7_neg <- fc7_neg
I0505 14:02:27.043999 26400 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0505 14:02:27.057792 26400 net.cpp:150] Setting up relu7_neg
I0505 14:02:27.057819 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:27.057823 26400 net.cpp:165] Memory required for data: 579119104
I0505 14:02:27.057828 26400 layer_factory.hpp:77] Creating layer drop7_neg
I0505 14:02:27.057840 26400 net.cpp:100] Creating Layer drop7_neg
I0505 14:02:27.057845 26400 net.cpp:434] drop7_neg <- fc7_neg
I0505 14:02:27.057850 26400 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0505 14:02:27.057904 26400 net.cpp:150] Setting up drop7_neg
I0505 14:02:27.057911 26400 net.cpp:157] Top shape: 1 2048 (2048)
I0505 14:02:27.057914 26400 net.cpp:165] Memory required for data: 579127296
I0505 14:02:27.057917 26400 layer_factory.hpp:77] Creating layer loss
I0505 14:02:27.057947 26400 net.cpp:100] Creating Layer loss
I0505 14:02:27.057951 26400 net.cpp:434] loss <- fc7
I0505 14:02:27.057955 26400 net.cpp:434] loss <- fc7_pos
I0505 14:02:27.057960 26400 net.cpp:434] loss <- fc7_neg
I0505 14:02:27.057965 26400 net.cpp:408] loss -> loss
I0505 14:02:27.058038 26400 net.cpp:150] Setting up loss
I0505 14:02:27.058045 26400 net.cpp:157] Top shape: (1)
I0505 14:02:27.058048 26400 net.cpp:160]     with loss weight 1
I0505 14:02:27.058121 26400 net.cpp:165] Memory required for data: 579127300
I0505 14:02:27.058147 26400 net.cpp:226] loss needs backward computation.
I0505 14:02:27.058158 26400 net.cpp:226] drop7_neg needs backward computation.
I0505 14:02:27.058166 26400 net.cpp:226] relu7_neg needs backward computation.
I0505 14:02:27.058172 26400 net.cpp:226] fc7_neg needs backward computation.
I0505 14:02:27.058181 26400 net.cpp:226] drop6_neg needs backward computation.
I0505 14:02:27.058187 26400 net.cpp:226] relu6_neg needs backward computation.
I0505 14:02:27.058193 26400 net.cpp:226] fc6_neg needs backward computation.
I0505 14:02:27.058202 26400 net.cpp:226] pool5_neg needs backward computation.
I0505 14:02:27.058209 26400 net.cpp:226] relu5a_neg needs backward computation.
I0505 14:02:27.058215 26400 net.cpp:226] conv5a_neg needs backward computation.
I0505 14:02:27.058223 26400 net.cpp:226] pool4_neg needs backward computation.
I0505 14:02:27.058230 26400 net.cpp:226] relu4a_neg needs backward computation.
I0505 14:02:27.058238 26400 net.cpp:226] conv4a_neg needs backward computation.
I0505 14:02:27.058245 26400 net.cpp:226] pool3_neg needs backward computation.
I0505 14:02:27.058253 26400 net.cpp:226] relu3a_neg needs backward computation.
I0505 14:02:27.058267 26400 net.cpp:226] conv3a_neg needs backward computation.
I0505 14:02:27.058275 26400 net.cpp:226] pool2_neg needs backward computation.
I0505 14:02:27.058282 26400 net.cpp:226] relu2a_neg needs backward computation.
I0505 14:02:27.058290 26400 net.cpp:226] conv2a_neg needs backward computation.
I0505 14:02:27.058296 26400 net.cpp:226] pool1_neg needs backward computation.
I0505 14:02:27.058303 26400 net.cpp:226] relu1a_neg needs backward computation.
I0505 14:02:27.058311 26400 net.cpp:226] conv1a_neg needs backward computation.
I0505 14:02:27.058320 26400 net.cpp:226] drop7_pos needs backward computation.
I0505 14:02:27.058326 26400 net.cpp:226] relu7_pos needs backward computation.
I0505 14:02:27.058346 26400 net.cpp:226] fc7_pos needs backward computation.
I0505 14:02:27.058353 26400 net.cpp:226] drop6_pos needs backward computation.
I0505 14:02:27.058362 26400 net.cpp:226] relu6_pos needs backward computation.
I0505 14:02:27.058367 26400 net.cpp:226] fc6_pos needs backward computation.
I0505 14:02:27.058375 26400 net.cpp:226] pool5_pos needs backward computation.
I0505 14:02:27.058382 26400 net.cpp:226] relu5a_pos needs backward computation.
I0505 14:02:27.058389 26400 net.cpp:226] conv5a_pos needs backward computation.
I0505 14:02:27.058396 26400 net.cpp:226] pool4_pos needs backward computation.
I0505 14:02:27.058403 26400 net.cpp:226] relu4a_pos needs backward computation.
I0505 14:02:27.058410 26400 net.cpp:226] conv4a_pos needs backward computation.
I0505 14:02:27.058416 26400 net.cpp:226] pool3_pos needs backward computation.
I0505 14:02:27.058424 26400 net.cpp:226] relu3a_pos needs backward computation.
I0505 14:02:27.058430 26400 net.cpp:226] conv3a_pos needs backward computation.
I0505 14:02:27.058439 26400 net.cpp:226] pool2_pos needs backward computation.
I0505 14:02:27.058445 26400 net.cpp:226] relu2a_pos needs backward computation.
I0505 14:02:27.058452 26400 net.cpp:226] conv2a_pos needs backward computation.
I0505 14:02:27.058459 26400 net.cpp:226] pool1_pos needs backward computation.
I0505 14:02:27.058466 26400 net.cpp:226] relu1a_pos needs backward computation.
I0505 14:02:27.058473 26400 net.cpp:226] conv1a_pos needs backward computation.
I0505 14:02:27.058481 26400 net.cpp:226] drop7 needs backward computation.
I0505 14:02:27.058488 26400 net.cpp:226] relu7 needs backward computation.
I0505 14:02:27.058516 26400 net.cpp:226] fc7 needs backward computation.
I0505 14:02:27.058522 26400 net.cpp:226] drop6 needs backward computation.
I0505 14:02:27.058527 26400 net.cpp:226] relu6 needs backward computation.
I0505 14:02:27.058534 26400 net.cpp:226] fc6 needs backward computation.
I0505 14:02:27.058542 26400 net.cpp:226] pool5 needs backward computation.
I0505 14:02:27.058548 26400 net.cpp:226] relu5a needs backward computation.
I0505 14:02:27.058555 26400 net.cpp:226] conv5a needs backward computation.
I0505 14:02:27.058564 26400 net.cpp:226] pool4 needs backward computation.
I0505 14:02:27.058571 26400 net.cpp:226] relu4a needs backward computation.
I0505 14:02:27.058578 26400 net.cpp:226] conv4a needs backward computation.
I0505 14:02:27.058585 26400 net.cpp:226] pool3 needs backward computation.
I0505 14:02:27.058593 26400 net.cpp:226] relu3a needs backward computation.
I0505 14:02:27.058599 26400 net.cpp:226] conv3a needs backward computation.
I0505 14:02:27.058604 26400 net.cpp:226] pool2 needs backward computation.
I0505 14:02:27.058612 26400 net.cpp:226] relu2a needs backward computation.
I0505 14:02:27.058619 26400 net.cpp:226] conv2a needs backward computation.
I0505 14:02:27.058637 26400 net.cpp:226] pool1 needs backward computation.
I0505 14:02:27.058645 26400 net.cpp:226] relu1a needs backward computation.
I0505 14:02:27.058652 26400 net.cpp:226] conv1a needs backward computation.
I0505 14:02:27.058660 26400 net.cpp:228] reshape_negative does not need backward computation.
I0505 14:02:27.058668 26400 net.cpp:228] reshape_positive does not need backward computation.
I0505 14:02:27.058676 26400 net.cpp:228] reshape_anchor does not need backward computation.
I0505 14:02:27.058686 26400 net.cpp:228] slicer does not need backward computation.
I0505 14:02:27.058692 26400 net.cpp:228] data does not need backward computation.
I0505 14:02:27.058699 26400 net.cpp:270] This network produces output loss
I0505 14:02:27.109556 26400 net.cpp:283] Network initialization done.
I0505 14:02:27.110203 26400 solver.cpp:60] Solver scaffolding done.
I0505 14:02:27.111667 26400 caffe.cpp:155] Finetuning from ../../../c3d_ucf101_iter_38000.caffemodel
I0505 14:02:28.002805 26400 net.cpp:761] Ignoring source layer fc8
I0505 14:02:28.470993 26400 net.cpp:761] Ignoring source layer fc8
I0505 14:02:28.474926 26400 caffe.cpp:251] Starting Optimization
I0505 14:02:28.474978 26400 solver.cpp:279] Solving C3D-Three-Streams
I0505 14:02:28.474993 26400 solver.cpp:280] Learning Rate Policy: step
I0505 14:02:28.489248 26400 solver.cpp:337] Iteration 0, Testing net (#0)
I0505 14:02:29.343868 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 14:02:58.844271 26400 solver.cpp:404]     Test net output #0: loss = 35.3498 (* 1 = 35.3498 loss)
I0505 14:02:59.806480 26400 solver.cpp:228] Iteration 0, loss = 367.607
I0505 14:02:59.806543 26400 solver.cpp:244]     Train net output #0: loss = 367.607 (* 1 = 367.607 loss)
I0505 14:02:59.806571 26400 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0505 14:05:11.446315 26400 solver.cpp:228] Iteration 50, loss = 0.553912
I0505 14:05:11.449064 26400 solver.cpp:244]     Train net output #0: loss = 0.553913 (* 1 = 0.553913 loss)
I0505 14:05:11.449087 26400 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0505 14:07:21.243357 26400 solver.cpp:228] Iteration 100, loss = 0.398459
I0505 14:07:21.243537 26400 solver.cpp:244]     Train net output #0: loss = 0.39846 (* 1 = 0.39846 loss)
I0505 14:07:21.243552 26400 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0505 14:09:31.133535 26400 solver.cpp:228] Iteration 150, loss = 0.868767
I0505 14:09:31.133675 26400 solver.cpp:244]     Train net output #0: loss = 0.868768 (* 1 = 0.868768 loss)
I0505 14:09:31.133687 26400 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0505 14:11:38.885654 26400 solver.cpp:337] Iteration 200, Testing net (#0)
I0505 14:12:15.290333 26400 solver.cpp:404]     Test net output #0: loss = 0.478053 (* 1 = 0.478053 loss)
I0505 14:12:16.167306 26400 solver.cpp:228] Iteration 200, loss = 0.415763
I0505 14:12:16.167356 26400 solver.cpp:244]     Train net output #0: loss = 0.415764 (* 1 = 0.415764 loss)
I0505 14:12:16.167369 26400 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0505 14:14:26.599449 26400 solver.cpp:228] Iteration 250, loss = 0.306227
I0505 14:14:26.599620 26400 solver.cpp:244]     Train net output #0: loss = 0.306228 (* 1 = 0.306228 loss)
I0505 14:14:26.599640 26400 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0505 14:16:35.932797 26400 solver.cpp:228] Iteration 300, loss = 0.286201
I0505 14:16:35.933028 26400 solver.cpp:244]     Train net output #0: loss = 0.286202 (* 1 = 0.286202 loss)
I0505 14:16:35.933066 26400 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0505 14:18:46.269286 26400 solver.cpp:228] Iteration 350, loss = 0.293279
I0505 14:18:46.269515 26400 solver.cpp:244]     Train net output #0: loss = 0.29328 (* 1 = 0.29328 loss)
I0505 14:18:46.269564 26400 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0505 14:20:53.907692 26400 solver.cpp:337] Iteration 400, Testing net (#0)
I0505 14:20:58.863255 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 14:21:25.687835 26400 solver.cpp:404]     Test net output #0: loss = 0.446848 (* 1 = 0.446848 loss)
I0505 14:21:26.551110 26400 solver.cpp:228] Iteration 400, loss = 0.428421
I0505 14:21:26.551169 26400 solver.cpp:244]     Train net output #0: loss = 0.428422 (* 1 = 0.428422 loss)
I0505 14:21:26.551183 26400 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0505 14:23:36.772132 26400 solver.cpp:228] Iteration 450, loss = 1.31114
I0505 14:23:36.773895 26400 solver.cpp:244]     Train net output #0: loss = 1.31114 (* 1 = 1.31114 loss)
I0505 14:23:36.773973 26400 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0505 14:25:47.221535 26400 solver.cpp:228] Iteration 500, loss = 0.275947
I0505 14:25:47.221784 26400 solver.cpp:244]     Train net output #0: loss = 0.275948 (* 1 = 0.275948 loss)
I0505 14:25:47.221824 26400 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0505 14:27:57.074455 26400 solver.cpp:228] Iteration 550, loss = 0.299967
I0505 14:27:57.074609 26400 solver.cpp:244]     Train net output #0: loss = 0.299968 (* 1 = 0.299968 loss)
I0505 14:27:57.074623 26400 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0505 14:30:04.659935 26400 solver.cpp:337] Iteration 600, Testing net (#0)
I0505 14:30:37.161764 26400 solver.cpp:404]     Test net output #0: loss = 0.382902 (* 1 = 0.382902 loss)
I0505 14:30:38.026671 26400 solver.cpp:228] Iteration 600, loss = 0.252222
I0505 14:30:38.026708 26400 solver.cpp:244]     Train net output #0: loss = 0.252223 (* 1 = 0.252223 loss)
I0505 14:30:38.026733 26400 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0505 14:32:47.895076 26400 solver.cpp:228] Iteration 650, loss = 0.125877
I0505 14:32:47.895311 26400 solver.cpp:244]     Train net output #0: loss = 0.125878 (* 1 = 0.125878 loss)
I0505 14:32:47.895344 26400 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0505 14:34:58.139487 26400 solver.cpp:228] Iteration 700, loss = 0.289048
I0505 14:34:58.140095 26400 solver.cpp:244]     Train net output #0: loss = 0.289049 (* 1 = 0.289049 loss)
I0505 14:34:58.140249 26400 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0505 14:37:08.144929 26400 solver.cpp:228] Iteration 750, loss = 0.143048
I0505 14:37:08.145133 26400 solver.cpp:244]     Train net output #0: loss = 0.143048 (* 1 = 0.143048 loss)
I0505 14:37:08.145162 26400 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0505 14:39:15.259202 26400 solver.cpp:337] Iteration 800, Testing net (#0)
I0505 14:39:28.129731 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 14:39:46.454080 26400 solver.cpp:404]     Test net output #0: loss = 0.379266 (* 1 = 0.379266 loss)
I0505 14:39:47.337311 26400 solver.cpp:228] Iteration 800, loss = 0.428902
I0505 14:39:47.337365 26400 solver.cpp:244]     Train net output #0: loss = 0.428903 (* 1 = 0.428903 loss)
I0505 14:39:47.337380 26400 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0505 14:41:57.692642 26400 solver.cpp:228] Iteration 850, loss = 0.103864
I0505 14:41:57.705983 26400 solver.cpp:244]     Train net output #0: loss = 0.103865 (* 1 = 0.103865 loss)
I0505 14:41:57.706025 26400 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0505 14:44:07.553125 26400 solver.cpp:228] Iteration 900, loss = 0.165112
I0505 14:44:07.555379 26400 solver.cpp:244]     Train net output #0: loss = 0.165113 (* 1 = 0.165113 loss)
I0505 14:44:07.555394 26400 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0505 14:46:17.790504 26400 solver.cpp:228] Iteration 950, loss = 0.254378
I0505 14:46:17.790673 26400 solver.cpp:244]     Train net output #0: loss = 0.254379 (* 1 = 0.254379 loss)
I0505 14:46:17.790698 26400 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0505 14:48:25.677860 26400 solver.cpp:337] Iteration 1000, Testing net (#0)
I0505 14:49:01.480788 26400 solver.cpp:404]     Test net output #0: loss = 0.303555 (* 1 = 0.303555 loss)
I0505 14:49:02.346705 26400 solver.cpp:228] Iteration 1000, loss = 0.199819
I0505 14:49:02.346750 26400 solver.cpp:244]     Train net output #0: loss = 0.19982 (* 1 = 0.19982 loss)
I0505 14:49:02.346770 26400 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0505 14:51:12.449915 26400 solver.cpp:228] Iteration 1050, loss = 0.203474
I0505 14:51:12.450096 26400 solver.cpp:244]     Train net output #0: loss = 0.203475 (* 1 = 0.203475 loss)
I0505 14:51:12.450117 26400 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0505 14:53:22.625638 26400 solver.cpp:228] Iteration 1100, loss = 0.295886
I0505 14:53:22.625797 26400 solver.cpp:244]     Train net output #0: loss = 0.295886 (* 1 = 0.295886 loss)
I0505 14:53:22.625818 26400 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0505 14:55:33.013089 26400 solver.cpp:228] Iteration 1150, loss = 0.554079
I0505 14:55:33.013324 26400 solver.cpp:244]     Train net output #0: loss = 0.55408 (* 1 = 0.55408 loss)
I0505 14:55:33.013339 26400 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0505 14:57:40.451445 26400 solver.cpp:337] Iteration 1200, Testing net (#0)
I0505 14:58:00.810401 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 14:58:14.904345 26400 solver.cpp:404]     Test net output #0: loss = 0.310049 (* 1 = 0.310049 loss)
I0505 14:58:15.776688 26400 solver.cpp:228] Iteration 1200, loss = 0.107361
I0505 14:58:15.776830 26400 solver.cpp:244]     Train net output #0: loss = 0.107362 (* 1 = 0.107362 loss)
I0505 14:58:15.776880 26400 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0505 15:00:25.686576 26400 solver.cpp:228] Iteration 1250, loss = 0.308168
I0505 15:00:25.687753 26400 solver.cpp:244]     Train net output #0: loss = 0.308169 (* 1 = 0.308169 loss)
I0505 15:00:25.687778 26400 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0505 15:02:35.695857 26400 solver.cpp:228] Iteration 1300, loss = 0.168714
I0505 15:02:35.695992 26400 solver.cpp:244]     Train net output #0: loss = 0.168715 (* 1 = 0.168715 loss)
I0505 15:02:35.696009 26400 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0505 15:04:46.029412 26400 solver.cpp:228] Iteration 1350, loss = 0.0422204
I0505 15:04:46.029659 26400 solver.cpp:244]     Train net output #0: loss = 0.0422214 (* 1 = 0.0422214 loss)
I0505 15:04:46.029700 26400 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0505 15:06:53.544427 26400 solver.cpp:337] Iteration 1400, Testing net (#0)
I0505 15:07:24.413827 26400 solver.cpp:404]     Test net output #0: loss = 0.336108 (* 1 = 0.336108 loss)
I0505 15:07:25.290681 26400 solver.cpp:228] Iteration 1400, loss = 0.50712
I0505 15:07:25.290731 26400 solver.cpp:244]     Train net output #0: loss = 0.507121 (* 1 = 0.507121 loss)
I0505 15:07:25.290762 26400 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0505 15:09:35.611502 26400 solver.cpp:228] Iteration 1450, loss = 0.372025
I0505 15:09:35.613637 26400 solver.cpp:244]     Train net output #0: loss = 0.372026 (* 1 = 0.372026 loss)
I0505 15:09:35.613652 26400 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0505 15:11:45.682548 26400 solver.cpp:228] Iteration 1500, loss = 0.325797
I0505 15:11:45.682729 26400 solver.cpp:244]     Train net output #0: loss = 0.325798 (* 1 = 0.325798 loss)
I0505 15:11:45.682744 26400 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0505 15:13:55.695538 26400 solver.cpp:228] Iteration 1550, loss = 0.242786
I0505 15:13:55.707988 26400 solver.cpp:244]     Train net output #0: loss = 0.242787 (* 1 = 0.242787 loss)
I0505 15:13:55.708003 26400 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0505 15:16:03.332792 26400 solver.cpp:337] Iteration 1600, Testing net (#0)
I0505 15:16:26.614138 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 15:16:38.877451 26400 solver.cpp:404]     Test net output #0: loss = 0.41454 (* 1 = 0.41454 loss)
I0505 15:16:39.753218 26400 solver.cpp:228] Iteration 1600, loss = 0.241559
I0505 15:16:39.753326 26400 solver.cpp:244]     Train net output #0: loss = 0.24156 (* 1 = 0.24156 loss)
I0505 15:16:39.753383 26400 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0505 15:18:49.964341 26400 solver.cpp:228] Iteration 1650, loss = 0.099265
I0505 15:18:49.964557 26400 solver.cpp:244]     Train net output #0: loss = 0.099266 (* 1 = 0.099266 loss)
I0505 15:18:49.964586 26400 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0505 15:21:00.029469 26400 solver.cpp:228] Iteration 1700, loss = 0.146908
I0505 15:21:00.029633 26400 solver.cpp:244]     Train net output #0: loss = 0.146909 (* 1 = 0.146909 loss)
I0505 15:21:00.029647 26400 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0505 15:23:10.313796 26400 solver.cpp:228] Iteration 1750, loss = 0.174301
I0505 15:23:10.314719 26400 solver.cpp:244]     Train net output #0: loss = 0.174302 (* 1 = 0.174302 loss)
I0505 15:23:10.314749 26400 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0505 15:25:17.861870 26400 solver.cpp:337] Iteration 1800, Testing net (#0)
I0505 15:25:52.471508 26400 solver.cpp:404]     Test net output #0: loss = 0.270143 (* 1 = 0.270143 loss)
I0505 15:25:53.338485 26400 solver.cpp:228] Iteration 1800, loss = 0.0928375
I0505 15:25:53.338531 26400 solver.cpp:244]     Train net output #0: loss = 0.0928385 (* 1 = 0.0928385 loss)
I0505 15:25:53.338543 26400 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0505 15:28:03.505758 26400 solver.cpp:228] Iteration 1850, loss = 0.118891
I0505 15:28:03.505930 26400 solver.cpp:244]     Train net output #0: loss = 0.118892 (* 1 = 0.118892 loss)
I0505 15:28:03.505951 26400 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0505 15:30:13.262966 26400 solver.cpp:228] Iteration 1900, loss = 0.21652
I0505 15:30:13.263136 26400 solver.cpp:244]     Train net output #0: loss = 0.21652 (* 1 = 0.21652 loss)
I0505 15:30:13.263182 26400 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0505 15:32:23.228689 26400 solver.cpp:228] Iteration 1950, loss = 0.104016
I0505 15:32:23.229559 26400 solver.cpp:244]     Train net output #0: loss = 0.104017 (* 1 = 0.104017 loss)
I0505 15:32:23.229585 26400 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0505 15:34:30.766757 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_2000.caffemodel
I0505 15:34:35.523105 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_2000.solverstate
I0505 15:34:35.667029 26400 solver.cpp:337] Iteration 2000, Testing net (#0)
I0505 15:34:58.049892 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 15:35:04.967784 26400 solver.cpp:404]     Test net output #0: loss = 0.302473 (* 1 = 0.302473 loss)
I0505 15:35:05.833245 26400 solver.cpp:228] Iteration 2000, loss = 0.194804
I0505 15:35:05.833303 26400 solver.cpp:244]     Train net output #0: loss = 0.194805 (* 1 = 0.194805 loss)
I0505 15:35:05.833317 26400 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0505 15:37:16.009081 26400 solver.cpp:228] Iteration 2050, loss = 0.462149
I0505 15:37:16.009925 26400 solver.cpp:244]     Train net output #0: loss = 0.46215 (* 1 = 0.46215 loss)
I0505 15:37:16.009941 26400 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0505 15:39:26.205888 26400 solver.cpp:228] Iteration 2100, loss = 0.18934
I0505 15:39:26.206033 26400 solver.cpp:244]     Train net output #0: loss = 0.189341 (* 1 = 0.189341 loss)
I0505 15:39:26.206050 26400 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0505 15:41:36.059660 26400 solver.cpp:228] Iteration 2150, loss = 0.189213
I0505 15:41:36.072031 26400 solver.cpp:244]     Train net output #0: loss = 0.189214 (* 1 = 0.189214 loss)
I0505 15:41:36.072049 26400 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0505 15:43:43.680305 26400 solver.cpp:337] Iteration 2200, Testing net (#0)
I0505 15:44:15.164961 26400 solver.cpp:404]     Test net output #0: loss = 0.295443 (* 1 = 0.295443 loss)
I0505 15:44:16.036592 26400 solver.cpp:228] Iteration 2200, loss = 0.158915
I0505 15:44:16.036640 26400 solver.cpp:244]     Train net output #0: loss = 0.158916 (* 1 = 0.158916 loss)
I0505 15:44:16.036659 26400 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0505 15:46:25.951457 26400 solver.cpp:228] Iteration 2250, loss = 0.245574
I0505 15:46:25.951670 26400 solver.cpp:244]     Train net output #0: loss = 0.245575 (* 1 = 0.245575 loss)
I0505 15:46:25.951706 26400 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0505 15:48:35.989166 26400 solver.cpp:228] Iteration 2300, loss = 0.221386
I0505 15:48:35.989380 26400 solver.cpp:244]     Train net output #0: loss = 0.221386 (* 1 = 0.221386 loss)
I0505 15:48:35.989408 26400 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0505 15:50:46.169683 26400 solver.cpp:228] Iteration 2350, loss = 0.107089
I0505 15:50:46.169845 26400 solver.cpp:244]     Train net output #0: loss = 0.107089 (* 1 = 0.107089 loss)
I0505 15:50:46.169860 26400 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0505 15:52:53.267197 26400 solver.cpp:337] Iteration 2400, Testing net (#0)
I0505 15:53:24.893064 26400 solver.cpp:404]     Test net output #0: loss = 0.305704 (* 1 = 0.305704 loss)
I0505 15:53:25.762019 26400 solver.cpp:228] Iteration 2400, loss = 0.219574
I0505 15:53:25.762065 26400 solver.cpp:244]     Train net output #0: loss = 0.219575 (* 1 = 0.219575 loss)
I0505 15:53:25.762080 26400 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0505 15:55:36.066365 26400 solver.cpp:228] Iteration 2450, loss = 0.166852
I0505 15:55:36.066599 26400 solver.cpp:244]     Train net output #0: loss = 0.166853 (* 1 = 0.166853 loss)
I0505 15:55:36.066643 26400 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0505 15:57:46.167074 26400 solver.cpp:228] Iteration 2500, loss = 0.11492
I0505 15:57:46.167217 26400 solver.cpp:244]     Train net output #0: loss = 0.114921 (* 1 = 0.114921 loss)
I0505 15:57:46.167232 26400 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0505 15:59:56.268937 26400 solver.cpp:228] Iteration 2550, loss = 0.030252
I0505 15:59:56.269822 26400 solver.cpp:244]     Train net output #0: loss = 0.0302529 (* 1 = 0.0302529 loss)
I0505 15:59:56.269858 26400 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0505 16:02:03.816336 26400 solver.cpp:337] Iteration 2600, Testing net (#0)
I0505 16:02:07.458087 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 16:02:35.400226 26400 solver.cpp:404]     Test net output #0: loss = 0.218581 (* 1 = 0.218581 loss)
I0505 16:02:36.271400 26400 solver.cpp:228] Iteration 2600, loss = 0.190206
I0505 16:02:36.271456 26400 solver.cpp:244]     Train net output #0: loss = 0.190207 (* 1 = 0.190207 loss)
I0505 16:02:36.271469 26400 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0505 16:04:46.248772 26400 solver.cpp:228] Iteration 2650, loss = 0.124884
I0505 16:04:46.249130 26400 solver.cpp:244]     Train net output #0: loss = 0.124885 (* 1 = 0.124885 loss)
I0505 16:04:46.249145 26400 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0505 16:06:56.278934 26400 solver.cpp:228] Iteration 2700, loss = 0.175378
I0505 16:06:56.279067 26400 solver.cpp:244]     Train net output #0: loss = 0.175379 (* 1 = 0.175379 loss)
I0505 16:06:56.279081 26400 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0505 16:09:05.905941 26400 solver.cpp:228] Iteration 2750, loss = 0.298301
I0505 16:09:05.906112 26400 solver.cpp:244]     Train net output #0: loss = 0.298302 (* 1 = 0.298302 loss)
I0505 16:09:05.906134 26400 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0505 16:11:13.439368 26400 solver.cpp:337] Iteration 2800, Testing net (#0)
I0505 16:11:46.730593 26400 solver.cpp:404]     Test net output #0: loss = 0.275678 (* 1 = 0.275678 loss)
I0505 16:11:47.601783 26400 solver.cpp:228] Iteration 2800, loss = 0.101619
I0505 16:11:47.601871 26400 solver.cpp:244]     Train net output #0: loss = 0.10162 (* 1 = 0.10162 loss)
I0505 16:11:47.601920 26400 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0505 16:13:57.558214 26400 solver.cpp:228] Iteration 2850, loss = 0.131515
I0505 16:13:57.558404 26400 solver.cpp:244]     Train net output #0: loss = 0.131516 (* 1 = 0.131516 loss)
I0505 16:13:57.558421 26400 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0505 16:16:07.674334 26400 solver.cpp:228] Iteration 2900, loss = 0.240352
I0505 16:16:07.677346 26400 solver.cpp:244]     Train net output #0: loss = 0.240353 (* 1 = 0.240353 loss)
I0505 16:16:07.677377 26400 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0505 16:18:17.896215 26400 solver.cpp:228] Iteration 2950, loss = 0.290194
I0505 16:18:17.896405 26400 solver.cpp:244]     Train net output #0: loss = 0.290195 (* 1 = 0.290195 loss)
I0505 16:18:17.896425 26400 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0505 16:20:25.137856 26400 solver.cpp:337] Iteration 3000, Testing net (#0)
I0505 16:20:33.428139 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 16:20:57.458688 26400 solver.cpp:404]     Test net output #0: loss = 0.288434 (* 1 = 0.288434 loss)
I0505 16:20:58.326658 26400 solver.cpp:228] Iteration 3000, loss = 0.188155
I0505 16:20:58.326720 26400 solver.cpp:244]     Train net output #0: loss = 0.188156 (* 1 = 0.188156 loss)
I0505 16:20:58.326736 26400 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0505 16:23:08.362820 26400 solver.cpp:228] Iteration 3050, loss = 0.034974
I0505 16:23:08.362989 26400 solver.cpp:244]     Train net output #0: loss = 0.034975 (* 1 = 0.034975 loss)
I0505 16:23:08.363010 26400 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0505 16:25:18.090209 26400 solver.cpp:228] Iteration 3100, loss = 0.089299
I0505 16:25:18.090363 26400 solver.cpp:244]     Train net output #0: loss = 0.0893001 (* 1 = 0.0893001 loss)
I0505 16:25:18.090389 26400 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0505 16:27:28.324913 26400 solver.cpp:228] Iteration 3150, loss = 0.0982193
I0505 16:27:28.325104 26400 solver.cpp:244]     Train net output #0: loss = 0.0982204 (* 1 = 0.0982204 loss)
I0505 16:27:28.325125 26400 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0505 16:29:35.856510 26400 solver.cpp:337] Iteration 3200, Testing net (#0)
I0505 16:30:06.562223 26400 solver.cpp:404]     Test net output #0: loss = 0.181928 (* 1 = 0.181928 loss)
I0505 16:30:07.432837 26400 solver.cpp:228] Iteration 3200, loss = 0.11491
I0505 16:30:07.432901 26400 solver.cpp:244]     Train net output #0: loss = 0.114911 (* 1 = 0.114911 loss)
I0505 16:30:07.432916 26400 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0505 16:32:17.408262 26400 solver.cpp:228] Iteration 3250, loss = 0.209239
I0505 16:32:17.408493 26400 solver.cpp:244]     Train net output #0: loss = 0.20924 (* 1 = 0.20924 loss)
I0505 16:32:17.408537 26400 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0505 16:34:27.461582 26400 solver.cpp:228] Iteration 3300, loss = 0.0556773
I0505 16:34:27.462466 26400 solver.cpp:244]     Train net output #0: loss = 0.0556782 (* 1 = 0.0556782 loss)
I0505 16:34:27.462537 26400 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0505 16:36:37.228166 26400 solver.cpp:228] Iteration 3350, loss = 0.0825646
I0505 16:36:37.228305 26400 solver.cpp:244]     Train net output #0: loss = 0.0825656 (* 1 = 0.0825656 loss)
I0505 16:36:37.228323 26400 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0505 16:38:44.604599 26400 solver.cpp:337] Iteration 3400, Testing net (#0)
I0505 16:38:58.153277 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 16:39:25.733717 26400 solver.cpp:404]     Test net output #0: loss = 0.242813 (* 1 = 0.242813 loss)
I0505 16:39:26.598438 26400 solver.cpp:228] Iteration 3400, loss = 0.107762
I0505 16:39:26.598486 26400 solver.cpp:244]     Train net output #0: loss = 0.107763 (* 1 = 0.107763 loss)
I0505 16:39:26.598516 26400 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0505 16:41:36.620867 26400 solver.cpp:228] Iteration 3450, loss = 0.0449715
I0505 16:41:36.633314 26400 solver.cpp:244]     Train net output #0: loss = 0.0449724 (* 1 = 0.0449724 loss)
I0505 16:41:36.633364 26400 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0505 16:43:46.619575 26400 solver.cpp:228] Iteration 3500, loss = 0.0765382
I0505 16:43:46.625336 26400 solver.cpp:244]     Train net output #0: loss = 0.076539 (* 1 = 0.076539 loss)
I0505 16:43:46.625355 26400 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0505 16:45:56.710569 26400 solver.cpp:228] Iteration 3550, loss = 0.0274695
I0505 16:45:56.710785 26400 solver.cpp:244]     Train net output #0: loss = 0.0274704 (* 1 = 0.0274704 loss)
I0505 16:45:56.710813 26400 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0505 16:48:04.006021 26400 solver.cpp:337] Iteration 3600, Testing net (#0)
I0505 16:48:55.489434 26400 solver.cpp:404]     Test net output #0: loss = 0.336351 (* 1 = 0.336351 loss)
I0505 16:48:56.352496 26400 solver.cpp:228] Iteration 3600, loss = 0.148823
I0505 16:48:56.352552 26400 solver.cpp:244]     Train net output #0: loss = 0.148824 (* 1 = 0.148824 loss)
I0505 16:48:56.352568 26400 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0505 16:51:06.479367 26400 solver.cpp:228] Iteration 3650, loss = 0.0157202
I0505 16:51:06.479519 26400 solver.cpp:244]     Train net output #0: loss = 0.015721 (* 1 = 0.015721 loss)
I0505 16:51:06.479533 26400 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0505 16:53:16.586278 26400 solver.cpp:228] Iteration 3700, loss = 0.22047
I0505 16:53:16.586454 26400 solver.cpp:244]     Train net output #0: loss = 0.220471 (* 1 = 0.220471 loss)
I0505 16:53:16.586469 26400 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0505 16:55:26.585959 26400 solver.cpp:228] Iteration 3750, loss = 0.142538
I0505 16:55:26.586165 26400 solver.cpp:244]     Train net output #0: loss = 0.142539 (* 1 = 0.142539 loss)
I0505 16:55:26.586194 26400 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0505 16:57:33.752727 26400 solver.cpp:337] Iteration 3800, Testing net (#0)
I0505 16:57:49.391155 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 16:58:16.858947 26400 solver.cpp:404]     Test net output #0: loss = 0.174249 (* 1 = 0.174249 loss)
I0505 16:58:17.726331 26400 solver.cpp:228] Iteration 3800, loss = 0.152655
I0505 16:58:17.726377 26400 solver.cpp:244]     Train net output #0: loss = 0.152656 (* 1 = 0.152656 loss)
I0505 16:58:17.726393 26400 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0505 17:00:27.845026 26400 solver.cpp:228] Iteration 3850, loss = 0.141704
I0505 17:00:27.845173 26400 solver.cpp:244]     Train net output #0: loss = 0.141705 (* 1 = 0.141705 loss)
I0505 17:00:27.845190 26400 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0505 17:02:37.763093 26400 solver.cpp:228] Iteration 3900, loss = 0.0798799
I0505 17:02:37.763274 26400 solver.cpp:244]     Train net output #0: loss = 0.0798808 (* 1 = 0.0798808 loss)
I0505 17:02:37.763308 26400 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0505 17:04:47.729290 26400 solver.cpp:228] Iteration 3950, loss = 0.0215347
I0505 17:04:47.729496 26400 solver.cpp:244]     Train net output #0: loss = 0.0215356 (* 1 = 0.0215356 loss)
I0505 17:04:47.729542 26400 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0505 17:06:54.816666 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_4000.caffemodel
I0505 17:06:58.773162 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_4000.solverstate
I0505 17:06:58.837515 26400 solver.cpp:337] Iteration 4000, Testing net (#0)
I0505 17:07:41.551434 26400 solver.cpp:404]     Test net output #0: loss = 0.316702 (* 1 = 0.316702 loss)
I0505 17:07:42.415633 26400 solver.cpp:228] Iteration 4000, loss = 0.0552318
I0505 17:07:42.415680 26400 solver.cpp:244]     Train net output #0: loss = 0.0552327 (* 1 = 0.0552327 loss)
I0505 17:07:42.415696 26400 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I0505 17:09:52.919261 26400 solver.cpp:228] Iteration 4050, loss = 0.0483182
I0505 17:09:52.933359 26400 solver.cpp:244]     Train net output #0: loss = 0.0483191 (* 1 = 0.0483191 loss)
I0505 17:09:52.933384 26400 sgd_solver.cpp:106] Iteration 4050, lr = 1e-05
I0505 17:12:02.669044 26400 solver.cpp:228] Iteration 4100, loss = 0.0568914
I0505 17:12:04.061247 26400 solver.cpp:244]     Train net output #0: loss = 0.0568924 (* 1 = 0.0568924 loss)
I0505 17:12:04.061326 26400 sgd_solver.cpp:106] Iteration 4100, lr = 1e-05
I0505 17:14:12.634651 26400 solver.cpp:228] Iteration 4150, loss = 0.123647
I0505 17:14:12.634863 26400 solver.cpp:244]     Train net output #0: loss = 0.123648 (* 1 = 0.123648 loss)
I0505 17:14:12.634894 26400 sgd_solver.cpp:106] Iteration 4150, lr = 1e-05
I0505 17:16:19.946413 26400 solver.cpp:337] Iteration 4200, Testing net (#0)
I0505 17:16:38.686794 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 17:17:00.596071 26400 solver.cpp:404]     Test net output #0: loss = 0.240713 (* 1 = 0.240713 loss)
I0505 17:17:01.461076 26400 solver.cpp:228] Iteration 4200, loss = 0.15241
I0505 17:17:01.461122 26400 solver.cpp:244]     Train net output #0: loss = 0.152411 (* 1 = 0.152411 loss)
I0505 17:17:01.461135 26400 sgd_solver.cpp:106] Iteration 4200, lr = 1e-05
I0505 17:19:11.338277 26400 solver.cpp:228] Iteration 4250, loss = 0.0776985
I0505 17:19:11.338436 26400 solver.cpp:244]     Train net output #0: loss = 0.0776994 (* 1 = 0.0776994 loss)
I0505 17:19:11.338455 26400 sgd_solver.cpp:106] Iteration 4250, lr = 1e-05
I0505 17:21:21.157868 26400 solver.cpp:228] Iteration 4300, loss = 0.087951
I0505 17:21:21.158352 26400 solver.cpp:244]     Train net output #0: loss = 0.0879519 (* 1 = 0.0879519 loss)
I0505 17:21:21.158375 26400 sgd_solver.cpp:106] Iteration 4300, lr = 1e-05
I0505 17:23:30.806282 26400 solver.cpp:228] Iteration 4350, loss = 0.00781313
I0505 17:23:30.806530 26400 solver.cpp:244]     Train net output #0: loss = 0.007814 (* 1 = 0.007814 loss)
I0505 17:23:30.806566 26400 sgd_solver.cpp:106] Iteration 4350, lr = 1e-05
I0505 17:25:38.309608 26400 solver.cpp:337] Iteration 4400, Testing net (#0)
I0505 17:26:34.517781 26400 solver.cpp:404]     Test net output #0: loss = 0.287852 (* 1 = 0.287852 loss)
I0505 17:26:35.379359 26400 solver.cpp:228] Iteration 4400, loss = 0.250686
I0505 17:26:35.379396 26400 solver.cpp:244]     Train net output #0: loss = 0.250687 (* 1 = 0.250687 loss)
I0505 17:26:35.379410 26400 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0505 17:28:45.450970 26400 solver.cpp:228] Iteration 4450, loss = 0.0288675
I0505 17:28:45.451102 26400 solver.cpp:244]     Train net output #0: loss = 0.0288683 (* 1 = 0.0288683 loss)
I0505 17:28:45.451117 26400 sgd_solver.cpp:106] Iteration 4450, lr = 1e-05
I0505 17:30:55.706768 26400 solver.cpp:228] Iteration 4500, loss = 0.189249
I0505 17:30:55.710065 26400 solver.cpp:244]     Train net output #0: loss = 0.18925 (* 1 = 0.18925 loss)
I0505 17:30:55.710091 26400 sgd_solver.cpp:106] Iteration 4500, lr = 1e-05
I0505 17:33:06.085454 26400 solver.cpp:228] Iteration 4550, loss = 0.296584
I0505 17:33:06.085597 26400 solver.cpp:244]     Train net output #0: loss = 0.296585 (* 1 = 0.296585 loss)
I0505 17:33:06.085613 26400 sgd_solver.cpp:106] Iteration 4550, lr = 1e-05
I0505 17:35:13.340291 26400 solver.cpp:337] Iteration 4600, Testing net (#0)
I0505 17:35:41.760501 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 17:36:08.769582 26400 solver.cpp:404]     Test net output #0: loss = 0.274584 (* 1 = 0.274584 loss)
I0505 17:36:09.629222 26400 solver.cpp:228] Iteration 4600, loss = 0.134228
I0505 17:36:09.629268 26400 solver.cpp:244]     Train net output #0: loss = 0.134228 (* 1 = 0.134228 loss)
I0505 17:36:09.629287 26400 sgd_solver.cpp:106] Iteration 4600, lr = 1e-05
I0505 17:38:20.285776 26400 solver.cpp:228] Iteration 4650, loss = 0.167977
I0505 17:38:20.286043 26400 solver.cpp:244]     Train net output #0: loss = 0.167978 (* 1 = 0.167978 loss)
I0505 17:38:20.286120 26400 sgd_solver.cpp:106] Iteration 4650, lr = 1e-05
I0505 17:40:30.314815 26400 solver.cpp:228] Iteration 4700, loss = 0.159539
I0505 17:40:30.327404 26400 solver.cpp:244]     Train net output #0: loss = 0.15954 (* 1 = 0.15954 loss)
I0505 17:40:30.327440 26400 sgd_solver.cpp:106] Iteration 4700, lr = 1e-05
I0505 17:42:40.140266 26400 solver.cpp:228] Iteration 4750, loss = 0.153304
I0505 17:42:40.140393 26400 solver.cpp:244]     Train net output #0: loss = 0.153305 (* 1 = 0.153305 loss)
I0505 17:42:40.140409 26400 sgd_solver.cpp:106] Iteration 4750, lr = 1e-05
I0505 17:44:47.751423 26400 solver.cpp:337] Iteration 4800, Testing net (#0)
I0505 17:45:47.176427 26400 solver.cpp:404]     Test net output #0: loss = 0.227282 (* 1 = 0.227282 loss)
I0505 17:45:48.035562 26400 solver.cpp:228] Iteration 4800, loss = 0.123011
I0505 17:45:48.035619 26400 solver.cpp:244]     Train net output #0: loss = 0.123011 (* 1 = 0.123011 loss)
I0505 17:45:48.035656 26400 sgd_solver.cpp:106] Iteration 4800, lr = 1e-05
I0505 17:47:58.434413 26400 solver.cpp:228] Iteration 4850, loss = 0.0968685
I0505 17:47:58.434693 26400 solver.cpp:244]     Train net output #0: loss = 0.0968693 (* 1 = 0.0968693 loss)
I0505 17:47:58.434728 26400 sgd_solver.cpp:106] Iteration 4850, lr = 1e-05
I0505 17:50:08.208945 26400 solver.cpp:228] Iteration 4900, loss = 0.0316307
I0505 17:50:08.209182 26400 solver.cpp:244]     Train net output #0: loss = 0.0316316 (* 1 = 0.0316316 loss)
I0505 17:50:08.209237 26400 sgd_solver.cpp:106] Iteration 4900, lr = 1e-05
I0505 17:52:18.290500 26400 solver.cpp:228] Iteration 4950, loss = 0.163685
I0505 17:52:18.290670 26400 solver.cpp:244]     Train net output #0: loss = 0.163686 (* 1 = 0.163686 loss)
I0505 17:52:18.290686 26400 sgd_solver.cpp:106] Iteration 4950, lr = 1e-05
I0505 17:54:25.948691 26400 solver.cpp:337] Iteration 5000, Testing net (#0)
I0505 17:54:59.664094 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 17:55:24.737033 26400 solver.cpp:404]     Test net output #0: loss = 0.24753 (* 1 = 0.24753 loss)
I0505 17:55:25.595067 26400 solver.cpp:228] Iteration 5000, loss = 0.0716549
I0505 17:55:25.595108 26400 solver.cpp:244]     Train net output #0: loss = 0.0716557 (* 1 = 0.0716557 loss)
I0505 17:55:25.595135 26400 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0505 17:57:35.786000 26400 solver.cpp:228] Iteration 5050, loss = 0.16518
I0505 17:57:35.786201 26400 solver.cpp:244]     Train net output #0: loss = 0.165181 (* 1 = 0.165181 loss)
I0505 17:57:35.786227 26400 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0505 17:59:45.772236 26400 solver.cpp:228] Iteration 5100, loss = 0.130126
I0505 17:59:45.772395 26400 solver.cpp:244]     Train net output #0: loss = 0.130127 (* 1 = 0.130127 loss)
I0505 17:59:45.772410 26400 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0505 18:01:55.898851 26400 solver.cpp:228] Iteration 5150, loss = 0.285041
I0505 18:01:55.899147 26400 solver.cpp:244]     Train net output #0: loss = 0.285042 (* 1 = 0.285042 loss)
I0505 18:01:55.899176 26400 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0505 18:04:03.154832 26400 solver.cpp:337] Iteration 5200, Testing net (#0)
I0505 18:05:03.159018 26400 solver.cpp:404]     Test net output #0: loss = 0.2887 (* 1 = 0.2887 loss)
I0505 18:05:04.015812 26400 solver.cpp:228] Iteration 5200, loss = 0.00251135
I0505 18:05:04.015859 26400 solver.cpp:244]     Train net output #0: loss = 0.00251209 (* 1 = 0.00251209 loss)
I0505 18:05:04.015874 26400 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0505 18:07:13.991106 26400 solver.cpp:228] Iteration 5250, loss = 0.138507
I0505 18:07:13.992312 26400 solver.cpp:244]     Train net output #0: loss = 0.138508 (* 1 = 0.138508 loss)
I0505 18:07:13.992331 26400 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0505 18:09:24.184368 26400 solver.cpp:228] Iteration 5300, loss = 1.25262
I0505 18:09:24.184509 26400 solver.cpp:244]     Train net output #0: loss = 1.25262 (* 1 = 1.25262 loss)
I0505 18:09:24.184525 26400 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0505 18:11:34.127427 26400 solver.cpp:228] Iteration 5350, loss = 0.136384
I0505 18:11:34.143025 26400 solver.cpp:244]     Train net output #0: loss = 0.136385 (* 1 = 0.136385 loss)
I0505 18:11:34.143062 26400 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0505 18:13:41.486235 26400 solver.cpp:337] Iteration 5400, Testing net (#0)
I0505 18:14:01.984567 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 18:14:11.668740 26400 solver.cpp:404]     Test net output #0: loss = 0.305262 (* 1 = 0.305262 loss)
I0505 18:14:12.534927 26400 solver.cpp:228] Iteration 5400, loss = 0.106238
I0505 18:14:12.534970 26400 solver.cpp:244]     Train net output #0: loss = 0.106239 (* 1 = 0.106239 loss)
I0505 18:14:12.534982 26400 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0505 18:16:22.634169 26400 solver.cpp:228] Iteration 5450, loss = 0.20961
I0505 18:16:22.637466 26400 solver.cpp:244]     Train net output #0: loss = 0.209611 (* 1 = 0.209611 loss)
I0505 18:16:22.637481 26400 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0505 18:18:32.448984 26400 solver.cpp:228] Iteration 5500, loss = 0.089905
I0505 18:18:32.449363 26400 solver.cpp:244]     Train net output #0: loss = 0.0899058 (* 1 = 0.0899058 loss)
I0505 18:18:32.449409 26400 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0505 18:20:42.404247 26400 solver.cpp:228] Iteration 5550, loss = 0.135226
I0505 18:20:42.405607 26400 solver.cpp:244]     Train net output #0: loss = 0.135226 (* 1 = 0.135226 loss)
I0505 18:20:42.405634 26400 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0505 18:22:49.661186 26400 solver.cpp:337] Iteration 5600, Testing net (#0)
I0505 18:23:19.909379 26400 solver.cpp:404]     Test net output #0: loss = 0.313247 (* 1 = 0.313247 loss)
I0505 18:23:20.781482 26400 solver.cpp:228] Iteration 5600, loss = 0.0784885
I0505 18:23:20.781535 26400 solver.cpp:244]     Train net output #0: loss = 0.0784893 (* 1 = 0.0784893 loss)
I0505 18:23:20.781566 26400 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0505 18:25:30.361408 26400 solver.cpp:228] Iteration 5650, loss = 0.0841357
I0505 18:25:30.361613 26400 solver.cpp:244]     Train net output #0: loss = 0.0841366 (* 1 = 0.0841366 loss)
I0505 18:25:30.361631 26400 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0505 18:27:40.295243 26400 solver.cpp:228] Iteration 5700, loss = 0.0572972
I0505 18:27:40.295459 26400 solver.cpp:244]     Train net output #0: loss = 0.0572981 (* 1 = 0.0572981 loss)
I0505 18:27:40.295480 26400 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0505 18:29:50.160926 26400 solver.cpp:228] Iteration 5750, loss = 0.0812804
I0505 18:29:50.161221 26400 solver.cpp:244]     Train net output #0: loss = 0.0812813 (* 1 = 0.0812813 loss)
I0505 18:29:50.161237 26400 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0505 18:31:57.487607 26400 solver.cpp:337] Iteration 5800, Testing net (#0)
I0505 18:32:27.659739 26400 solver.cpp:404]     Test net output #0: loss = 0.221396 (* 1 = 0.221396 loss)
I0505 18:32:28.528872 26400 solver.cpp:228] Iteration 5800, loss = 0.0488389
I0505 18:32:28.528921 26400 solver.cpp:244]     Train net output #0: loss = 0.0488398 (* 1 = 0.0488398 loss)
I0505 18:32:28.528934 26400 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0505 18:34:38.594205 26400 solver.cpp:228] Iteration 5850, loss = 0.089429
I0505 18:34:38.594359 26400 solver.cpp:244]     Train net output #0: loss = 0.0894298 (* 1 = 0.0894298 loss)
I0505 18:34:38.594373 26400 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0505 18:36:48.526657 26400 solver.cpp:228] Iteration 5900, loss = 0.116188
I0505 18:36:48.526824 26400 solver.cpp:244]     Train net output #0: loss = 0.116189 (* 1 = 0.116189 loss)
I0505 18:36:48.526847 26400 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0505 18:38:58.428318 26400 solver.cpp:228] Iteration 5950, loss = 0.191274
I0505 18:38:58.428467 26400 solver.cpp:244]     Train net output #0: loss = 0.191275 (* 1 = 0.191275 loss)
I0505 18:38:58.428486 26400 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0505 18:41:05.578263 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_6000.caffemodel
I0505 18:41:08.322945 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_6000.solverstate
I0505 18:41:08.378190 26400 solver.cpp:337] Iteration 6000, Testing net (#0)
I0505 18:41:10.344879 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 18:41:36.866819 26400 solver.cpp:404]     Test net output #0: loss = 0.270222 (* 1 = 0.270222 loss)
I0505 18:41:37.733247 26400 solver.cpp:228] Iteration 6000, loss = 0.13077
I0505 18:41:37.733297 26400 solver.cpp:244]     Train net output #0: loss = 0.13077 (* 1 = 0.13077 loss)
I0505 18:41:37.733327 26400 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0505 18:43:47.514854 26400 solver.cpp:228] Iteration 6050, loss = 0.069576
I0505 18:43:47.515669 26400 solver.cpp:244]     Train net output #0: loss = 0.0695769 (* 1 = 0.0695769 loss)
I0505 18:43:47.515708 26400 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I0505 18:45:57.436115 26400 solver.cpp:228] Iteration 6100, loss = 0.203358
I0505 18:45:57.436940 26400 solver.cpp:244]     Train net output #0: loss = 0.203359 (* 1 = 0.203359 loss)
I0505 18:45:57.436959 26400 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0505 18:48:07.299427 26400 solver.cpp:228] Iteration 6150, loss = 0.0505506
I0505 18:48:07.299659 26400 solver.cpp:244]     Train net output #0: loss = 0.0505515 (* 1 = 0.0505515 loss)
I0505 18:48:07.299718 26400 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I0505 18:50:14.581995 26400 solver.cpp:337] Iteration 6200, Testing net (#0)
I0505 18:50:48.437952 26400 solver.cpp:404]     Test net output #0: loss = 0.152815 (* 1 = 0.152815 loss)
I0505 18:50:49.305182 26400 solver.cpp:228] Iteration 6200, loss = 0.159994
I0505 18:50:49.305258 26400 solver.cpp:244]     Train net output #0: loss = 0.159995 (* 1 = 0.159995 loss)
I0505 18:50:49.305271 26400 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0505 18:52:59.099428 26400 solver.cpp:228] Iteration 6250, loss = 0.428771
I0505 18:52:59.099586 26400 solver.cpp:244]     Train net output #0: loss = 0.428772 (* 1 = 0.428772 loss)
I0505 18:52:59.099601 26400 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I0505 18:55:08.976065 26400 solver.cpp:228] Iteration 6300, loss = 0.130004
I0505 18:55:08.976974 26400 solver.cpp:244]     Train net output #0: loss = 0.130005 (* 1 = 0.130005 loss)
I0505 18:55:08.977020 26400 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0505 18:57:18.997169 26400 solver.cpp:228] Iteration 6350, loss = 0.158937
I0505 18:57:18.997333 26400 solver.cpp:244]     Train net output #0: loss = 0.158938 (* 1 = 0.158938 loss)
I0505 18:57:18.997347 26400 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I0505 18:59:26.272639 26400 solver.cpp:337] Iteration 6400, Testing net (#0)
I0505 18:59:34.638633 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 19:00:21.265389 26400 solver.cpp:404]     Test net output #0: loss = 0.140489 (* 1 = 0.140489 loss)
I0505 19:00:22.124550 26400 solver.cpp:228] Iteration 6400, loss = -9.38773e-07
I0505 19:00:22.124616 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 19:00:22.124634 26400 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0505 19:02:32.195984 26400 solver.cpp:228] Iteration 6450, loss = 0.153456
I0505 19:02:32.199450 26400 solver.cpp:244]     Train net output #0: loss = 0.153457 (* 1 = 0.153457 loss)
I0505 19:02:32.199467 26400 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I0505 19:04:42.106549 26400 solver.cpp:228] Iteration 6500, loss = 0.113821
I0505 19:04:42.107081 26400 solver.cpp:244]     Train net output #0: loss = 0.113822 (* 1 = 0.113822 loss)
I0505 19:04:42.107102 26400 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0505 19:06:52.189770 26400 solver.cpp:228] Iteration 6550, loss = 0.0909997
I0505 19:06:52.189935 26400 solver.cpp:244]     Train net output #0: loss = 0.0910007 (* 1 = 0.0910007 loss)
I0505 19:06:52.189951 26400 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I0505 19:08:59.383054 26400 solver.cpp:337] Iteration 6600, Testing net (#0)
I0505 19:09:50.725059 26400 solver.cpp:404]     Test net output #0: loss = 0.287079 (* 1 = 0.287079 loss)
I0505 19:09:53.399977 26400 solver.cpp:228] Iteration 6600, loss = -9.23872e-07
I0505 19:09:53.400046 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 19:09:53.400061 26400 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0505 19:12:03.785198 26400 solver.cpp:228] Iteration 6650, loss = -9.09378e-07
I0505 19:12:03.785935 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 19:12:03.785953 26400 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I0505 19:14:13.747015 26400 solver.cpp:228] Iteration 6700, loss = 0.0272719
I0505 19:14:13.747221 26400 solver.cpp:244]     Train net output #0: loss = 0.0272728 (* 1 = 0.0272728 loss)
I0505 19:14:13.747247 26400 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0505 19:16:23.667160 26400 solver.cpp:228] Iteration 6750, loss = 0.255353
I0505 19:16:23.667330 26400 solver.cpp:244]     Train net output #0: loss = 0.255354 (* 1 = 0.255354 loss)
I0505 19:16:23.667347 26400 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I0505 19:18:31.243202 26400 solver.cpp:337] Iteration 6800, Testing net (#0)
I0505 19:18:41.026909 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 19:19:20.563933 26400 solver.cpp:404]     Test net output #0: loss = 0.183414 (* 1 = 0.183414 loss)
I0505 19:19:21.427207 26400 solver.cpp:228] Iteration 6800, loss = 0.11847
I0505 19:19:21.427319 26400 solver.cpp:244]     Train net output #0: loss = 0.118471 (* 1 = 0.118471 loss)
I0505 19:19:21.427337 26400 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0505 19:21:31.653291 26400 solver.cpp:228] Iteration 6850, loss = 0.0576077
I0505 19:21:31.659065 26400 solver.cpp:244]     Train net output #0: loss = 0.0576086 (* 1 = 0.0576086 loss)
I0505 19:21:31.659080 26400 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I0505 19:23:41.644235 26400 solver.cpp:228] Iteration 6900, loss = 0.0138747
I0505 19:23:41.644475 26400 solver.cpp:244]     Train net output #0: loss = 0.0138756 (* 1 = 0.0138756 loss)
I0505 19:23:41.644531 26400 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0505 19:25:51.571671 26400 solver.cpp:228] Iteration 6950, loss = 0.00593441
I0505 19:25:51.571837 26400 solver.cpp:244]     Train net output #0: loss = 0.00593532 (* 1 = 0.00593532 loss)
I0505 19:25:51.571854 26400 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I0505 19:27:58.570247 26400 solver.cpp:337] Iteration 7000, Testing net (#0)
I0505 19:28:44.901017 26400 solver.cpp:404]     Test net output #0: loss = 0.185774 (* 1 = 0.185774 loss)
I0505 19:28:45.770691 26400 solver.cpp:228] Iteration 7000, loss = 0.0113233
I0505 19:28:45.770793 26400 solver.cpp:244]     Train net output #0: loss = 0.0113242 (* 1 = 0.0113242 loss)
I0505 19:28:45.770823 26400 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0505 19:30:55.796574 26400 solver.cpp:228] Iteration 7050, loss = 0.349667
I0505 19:30:55.796779 26400 solver.cpp:244]     Train net output #0: loss = 0.349668 (* 1 = 0.349668 loss)
I0505 19:30:55.796815 26400 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I0505 19:33:05.470114 26400 solver.cpp:228] Iteration 7100, loss = 0.0569429
I0505 19:33:05.470273 26400 solver.cpp:244]     Train net output #0: loss = 0.0569437 (* 1 = 0.0569437 loss)
I0505 19:33:05.470286 26400 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0505 19:35:15.400981 26400 solver.cpp:228] Iteration 7150, loss = -9.23872e-07
I0505 19:35:15.402539 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 19:35:15.402555 26400 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I0505 19:37:22.719864 26400 solver.cpp:337] Iteration 7200, Testing net (#0)
I0505 19:37:40.196286 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 19:38:13.485692 26400 solver.cpp:404]     Test net output #0: loss = 0.153033 (* 1 = 0.153033 loss)
I0505 19:38:14.350467 26400 solver.cpp:228] Iteration 7200, loss = 0.150335
I0505 19:38:14.350530 26400 solver.cpp:244]     Train net output #0: loss = 0.150336 (* 1 = 0.150336 loss)
I0505 19:38:14.350550 26400 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0505 19:40:24.827432 26400 solver.cpp:228] Iteration 7250, loss = 0.201839
I0505 19:40:24.840056 26400 solver.cpp:244]     Train net output #0: loss = 0.20184 (* 1 = 0.20184 loss)
I0505 19:40:24.840085 26400 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I0505 19:42:34.900482 26400 solver.cpp:228] Iteration 7300, loss = 0.0206751
I0505 19:42:34.900651 26400 solver.cpp:244]     Train net output #0: loss = 0.0206761 (* 1 = 0.0206761 loss)
I0505 19:42:34.900667 26400 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0505 19:44:44.874333 26400 solver.cpp:228] Iteration 7350, loss = 0.0328166
I0505 19:44:44.874694 26400 solver.cpp:244]     Train net output #0: loss = 0.0328176 (* 1 = 0.0328176 loss)
I0505 19:44:44.874789 26400 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I0505 19:46:52.367976 26400 solver.cpp:337] Iteration 7400, Testing net (#0)
I0505 19:47:38.873883 26400 solver.cpp:404]     Test net output #0: loss = 0.143772 (* 1 = 0.143772 loss)
I0505 19:47:39.742660 26400 solver.cpp:228] Iteration 7400, loss = 0.0493332
I0505 19:47:39.742724 26400 solver.cpp:244]     Train net output #0: loss = 0.0493342 (* 1 = 0.0493342 loss)
I0505 19:47:39.742738 26400 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0505 19:49:50.251883 26400 solver.cpp:228] Iteration 7450, loss = 0.13615
I0505 19:49:50.254976 26400 solver.cpp:244]     Train net output #0: loss = 0.136151 (* 1 = 0.136151 loss)
I0505 19:49:50.255004 26400 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I0505 19:52:00.277555 26400 solver.cpp:228] Iteration 7500, loss = 0.12768
I0505 19:52:00.279103 26400 solver.cpp:244]     Train net output #0: loss = 0.127681 (* 1 = 0.127681 loss)
I0505 19:52:00.279132 26400 sgd_solver.cpp:106] Iteration 7500, lr = 1e-05
I0505 19:54:09.987989 26400 solver.cpp:228] Iteration 7550, loss = 0.0186889
I0505 19:54:09.988239 26400 solver.cpp:244]     Train net output #0: loss = 0.0186899 (* 1 = 0.0186899 loss)
I0505 19:54:09.988301 26400 sgd_solver.cpp:106] Iteration 7550, lr = 1e-05
I0505 19:56:17.340312 26400 solver.cpp:337] Iteration 7600, Testing net (#0)
I0505 19:56:28.348659 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 19:56:48.105715 26400 solver.cpp:404]     Test net output #0: loss = 0.130891 (* 1 = 0.130891 loss)
I0505 19:56:48.975528 26400 solver.cpp:228] Iteration 7600, loss = 0.0119272
I0505 19:56:48.975610 26400 solver.cpp:244]     Train net output #0: loss = 0.0119283 (* 1 = 0.0119283 loss)
I0505 19:56:48.975646 26400 sgd_solver.cpp:106] Iteration 7600, lr = 1e-05
I0505 19:58:59.031747 26400 solver.cpp:228] Iteration 7650, loss = 0.00701305
I0505 19:58:59.031874 26400 solver.cpp:244]     Train net output #0: loss = 0.00701405 (* 1 = 0.00701405 loss)
I0505 19:58:59.031889 26400 sgd_solver.cpp:106] Iteration 7650, lr = 1e-05
I0505 20:01:08.856978 26400 solver.cpp:228] Iteration 7700, loss = -1.01328e-06
I0505 20:01:08.857177 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 20:01:08.857197 26400 sgd_solver.cpp:106] Iteration 7700, lr = 1e-05
I0505 20:03:19.016926 26400 solver.cpp:228] Iteration 7750, loss = 0.0459466
I0505 20:03:19.017092 26400 solver.cpp:244]     Train net output #0: loss = 0.0459476 (* 1 = 0.0459476 loss)
I0505 20:03:19.017112 26400 sgd_solver.cpp:106] Iteration 7750, lr = 1e-05
I0505 20:05:26.415952 26400 solver.cpp:337] Iteration 7800, Testing net (#0)
I0505 20:06:11.466068 26400 solver.cpp:404]     Test net output #0: loss = 0.170765 (* 1 = 0.170765 loss)
I0505 20:06:12.332412 26400 solver.cpp:228] Iteration 7800, loss = 0.00837737
I0505 20:06:12.332479 26400 solver.cpp:244]     Train net output #0: loss = 0.00837845 (* 1 = 0.00837845 loss)
I0505 20:06:12.332509 26400 sgd_solver.cpp:106] Iteration 7800, lr = 1e-05
I0505 20:08:22.706512 26400 solver.cpp:228] Iteration 7850, loss = 0.163426
I0505 20:08:22.706807 26400 solver.cpp:244]     Train net output #0: loss = 0.163427 (* 1 = 0.163427 loss)
I0505 20:08:22.706842 26400 sgd_solver.cpp:106] Iteration 7850, lr = 1e-05
I0505 20:10:32.567977 26400 solver.cpp:228] Iteration 7900, loss = 0.0773961
I0505 20:10:32.580379 26400 solver.cpp:244]     Train net output #0: loss = 0.0773972 (* 1 = 0.0773972 loss)
I0505 20:10:32.580401 26400 sgd_solver.cpp:106] Iteration 7900, lr = 1e-05
I0505 20:12:42.425207 26400 solver.cpp:228] Iteration 7950, loss = 0.0497707
I0505 20:12:42.425492 26400 solver.cpp:244]     Train net output #0: loss = 0.0497719 (* 1 = 0.0497719 loss)
I0505 20:12:42.425537 26400 sgd_solver.cpp:106] Iteration 7950, lr = 1e-05
I0505 20:14:49.896070 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_8000.caffemodel
I0505 20:14:53.840886 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_8000.solverstate
I0505 20:14:53.901391 26400 solver.cpp:337] Iteration 8000, Testing net (#0)
I0505 20:15:13.777422 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 20:15:44.301906 26400 solver.cpp:404]     Test net output #0: loss = 0.179348 (* 1 = 0.179348 loss)
I0505 20:15:45.159449 26400 solver.cpp:228] Iteration 8000, loss = 0.121468
I0505 20:15:45.159508 26400 solver.cpp:244]     Train net output #0: loss = 0.121469 (* 1 = 0.121469 loss)
I0505 20:15:45.159523 26400 sgd_solver.cpp:106] Iteration 8000, lr = 1e-05
I0505 20:17:55.536097 26400 solver.cpp:228] Iteration 8050, loss = 0.120907
I0505 20:17:55.536239 26400 solver.cpp:244]     Train net output #0: loss = 0.120908 (* 1 = 0.120908 loss)
I0505 20:17:55.536267 26400 sgd_solver.cpp:106] Iteration 8050, lr = 1e-05
I0505 20:20:05.459800 26400 solver.cpp:228] Iteration 8100, loss = 0.161962
I0505 20:20:05.460043 26400 solver.cpp:244]     Train net output #0: loss = 0.161963 (* 1 = 0.161963 loss)
I0505 20:20:05.460085 26400 sgd_solver.cpp:106] Iteration 8100, lr = 1e-05
I0505 20:22:15.357395 26400 solver.cpp:228] Iteration 8150, loss = 0.0753155
I0505 20:22:15.357558 26400 solver.cpp:244]     Train net output #0: loss = 0.0753166 (* 1 = 0.0753166 loss)
I0505 20:22:15.357586 26400 sgd_solver.cpp:106] Iteration 8150, lr = 1e-05
I0505 20:24:22.836894 26400 solver.cpp:337] Iteration 8200, Testing net (#0)
I0505 20:25:07.630615 26400 solver.cpp:404]     Test net output #0: loss = 0.172612 (* 1 = 0.172612 loss)
I0505 20:25:08.496583 26400 solver.cpp:228] Iteration 8200, loss = 0.0968867
I0505 20:25:08.496628 26400 solver.cpp:244]     Train net output #0: loss = 0.0968879 (* 1 = 0.0968879 loss)
I0505 20:25:08.496641 26400 sgd_solver.cpp:106] Iteration 8200, lr = 1e-05
I0505 20:27:19.115707 26400 solver.cpp:228] Iteration 8250, loss = 0.191542
I0505 20:27:19.115957 26400 solver.cpp:244]     Train net output #0: loss = 0.191543 (* 1 = 0.191543 loss)
I0505 20:27:19.115979 26400 sgd_solver.cpp:106] Iteration 8250, lr = 1e-05
I0505 20:29:29.020965 26400 solver.cpp:228] Iteration 8300, loss = 0.184345
I0505 20:29:29.021191 26400 solver.cpp:244]     Train net output #0: loss = 0.184346 (* 1 = 0.184346 loss)
I0505 20:29:29.021227 26400 sgd_solver.cpp:106] Iteration 8300, lr = 1e-05
I0505 20:31:38.782526 26400 solver.cpp:228] Iteration 8350, loss = 0.0406283
I0505 20:31:38.782712 26400 solver.cpp:244]     Train net output #0: loss = 0.0406296 (* 1 = 0.0406296 loss)
I0505 20:31:38.782733 26400 sgd_solver.cpp:106] Iteration 8350, lr = 1e-05
I0505 20:33:46.255146 26400 solver.cpp:337] Iteration 8400, Testing net (#0)
I0505 20:34:02.354364 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 20:34:16.443040 26400 solver.cpp:404]     Test net output #0: loss = 0.152088 (* 1 = 0.152088 loss)
I0505 20:34:17.310977 26400 solver.cpp:228] Iteration 8400, loss = 0.0534193
I0505 20:34:17.311022 26400 solver.cpp:244]     Train net output #0: loss = 0.0534205 (* 1 = 0.0534205 loss)
I0505 20:34:17.311036 26400 sgd_solver.cpp:106] Iteration 8400, lr = 1e-05
I0505 20:36:27.250684 26400 solver.cpp:228] Iteration 8450, loss = 0.114099
I0505 20:36:27.250824 26400 solver.cpp:244]     Train net output #0: loss = 0.114101 (* 1 = 0.114101 loss)
I0505 20:36:27.250844 26400 sgd_solver.cpp:106] Iteration 8450, lr = 1e-05
I0505 20:38:37.165189 26400 solver.cpp:228] Iteration 8500, loss = 0.0908717
I0505 20:38:37.177661 26400 solver.cpp:244]     Train net output #0: loss = 0.090873 (* 1 = 0.090873 loss)
I0505 20:38:37.177703 26400 sgd_solver.cpp:106] Iteration 8500, lr = 1e-05
I0505 20:40:47.215679 26400 solver.cpp:228] Iteration 8550, loss = 0.00878148
I0505 20:40:47.215849 26400 solver.cpp:244]     Train net output #0: loss = 0.0087829 (* 1 = 0.0087829 loss)
I0505 20:40:47.215865 26400 sgd_solver.cpp:106] Iteration 8550, lr = 1e-05
I0505 20:42:54.582327 26400 solver.cpp:337] Iteration 8600, Testing net (#0)
I0505 20:43:24.713091 26400 solver.cpp:404]     Test net output #0: loss = 0.137005 (* 1 = 0.137005 loss)
I0505 20:43:25.582640 26400 solver.cpp:228] Iteration 8600, loss = 0.0572574
I0505 20:43:25.582705 26400 solver.cpp:244]     Train net output #0: loss = 0.0572588 (* 1 = 0.0572588 loss)
I0505 20:43:25.582720 26400 sgd_solver.cpp:106] Iteration 8600, lr = 1e-05
I0505 20:45:35.315788 26400 solver.cpp:228] Iteration 8650, loss = 0.00344735
I0505 20:45:35.322965 26400 solver.cpp:244]     Train net output #0: loss = 0.00344879 (* 1 = 0.00344879 loss)
I0505 20:45:35.322985 26400 sgd_solver.cpp:106] Iteration 8650, lr = 1e-05
I0505 20:47:45.220366 26400 solver.cpp:228] Iteration 8700, loss = 0.0408639
I0505 20:47:45.220579 26400 solver.cpp:244]     Train net output #0: loss = 0.0408653 (* 1 = 0.0408653 loss)
I0505 20:47:45.220608 26400 sgd_solver.cpp:106] Iteration 8700, lr = 1e-05
I0505 20:49:55.029947 26400 solver.cpp:228] Iteration 8750, loss = 0.00339977
I0505 20:49:55.030184 26400 solver.cpp:244]     Train net output #0: loss = 0.0034012 (* 1 = 0.0034012 loss)
I0505 20:49:55.030220 26400 sgd_solver.cpp:106] Iteration 8750, lr = 1e-05
I0505 20:52:02.112756 26400 solver.cpp:337] Iteration 8800, Testing net (#0)
I0505 20:52:27.862537 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 20:52:32.591202 26400 solver.cpp:404]     Test net output #0: loss = 0.151523 (* 1 = 0.151523 loss)
I0505 20:52:33.460109 26400 solver.cpp:228] Iteration 8800, loss = 0.0428393
I0505 20:52:33.460162 26400 solver.cpp:244]     Train net output #0: loss = 0.0428407 (* 1 = 0.0428407 loss)
I0505 20:52:33.460181 26400 sgd_solver.cpp:106] Iteration 8800, lr = 1e-05
I0505 20:54:43.461853 26400 solver.cpp:228] Iteration 8850, loss = 0.124567
I0505 20:54:43.462064 26400 solver.cpp:244]     Train net output #0: loss = 0.124568 (* 1 = 0.124568 loss)
I0505 20:54:43.462092 26400 sgd_solver.cpp:106] Iteration 8850, lr = 1e-05
I0505 20:56:53.384893 26400 solver.cpp:228] Iteration 8900, loss = 0.0528253
I0505 20:56:53.386500 26400 solver.cpp:244]     Train net output #0: loss = 0.0528268 (* 1 = 0.0528268 loss)
I0505 20:56:53.386519 26400 sgd_solver.cpp:106] Iteration 8900, lr = 1e-05
I0505 20:59:03.307852 26400 solver.cpp:228] Iteration 8950, loss = 0.164084
I0505 20:59:03.308006 26400 solver.cpp:244]     Train net output #0: loss = 0.164085 (* 1 = 0.164085 loss)
I0505 20:59:03.308030 26400 sgd_solver.cpp:106] Iteration 8950, lr = 1e-05
I0505 21:01:10.677006 26400 solver.cpp:337] Iteration 9000, Testing net (#0)
I0505 21:01:40.826220 26400 solver.cpp:404]     Test net output #0: loss = 0.143194 (* 1 = 0.143194 loss)
I0505 21:01:41.691500 26400 solver.cpp:228] Iteration 9000, loss = -1.43051e-06
I0505 21:01:41.691562 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 21:01:41.691587 26400 sgd_solver.cpp:106] Iteration 9000, lr = 1e-05
I0505 21:03:51.811007 26400 solver.cpp:228] Iteration 9050, loss = 0.187863
I0505 21:03:51.811209 26400 solver.cpp:244]     Train net output #0: loss = 0.187864 (* 1 = 0.187864 loss)
I0505 21:03:51.811240 26400 sgd_solver.cpp:106] Iteration 9050, lr = 1e-05
I0505 21:06:01.833339 26400 solver.cpp:228] Iteration 9100, loss = 0.139128
I0505 21:06:01.833523 26400 solver.cpp:244]     Train net output #0: loss = 0.139129 (* 1 = 0.139129 loss)
I0505 21:06:01.833555 26400 sgd_solver.cpp:106] Iteration 9100, lr = 1e-05
I0505 21:08:11.813760 26400 solver.cpp:228] Iteration 9150, loss = 0.232347
I0505 21:08:11.814079 26400 solver.cpp:244]     Train net output #0: loss = 0.232349 (* 1 = 0.232349 loss)
I0505 21:08:11.814115 26400 sgd_solver.cpp:106] Iteration 9150, lr = 1e-05
I0505 21:10:19.282608 26400 solver.cpp:337] Iteration 9200, Testing net (#0)
I0505 21:10:51.755167 26400 solver.cpp:404]     Test net output #0: loss = 0.217112 (* 1 = 0.217112 loss)
I0505 21:10:52.621762 26400 solver.cpp:228] Iteration 9200, loss = 0.0672223
I0505 21:10:52.621822 26400 solver.cpp:244]     Train net output #0: loss = 0.0672236 (* 1 = 0.0672236 loss)
I0505 21:10:52.621837 26400 sgd_solver.cpp:106] Iteration 9200, lr = 1e-05
I0505 21:13:02.599973 26400 solver.cpp:228] Iteration 9250, loss = 0.168468
I0505 21:13:02.600244 26400 solver.cpp:244]     Train net output #0: loss = 0.168469 (* 1 = 0.168469 loss)
I0505 21:13:02.600284 26400 sgd_solver.cpp:106] Iteration 9250, lr = 1e-05
I0505 21:15:12.389027 26400 solver.cpp:228] Iteration 9300, loss = 0.0895952
I0505 21:15:12.390594 26400 solver.cpp:244]     Train net output #0: loss = 0.0895965 (* 1 = 0.0895965 loss)
I0505 21:15:12.390628 26400 sgd_solver.cpp:106] Iteration 9300, lr = 1e-05
I0505 21:17:22.407912 26400 solver.cpp:228] Iteration 9350, loss = 0.0450223
I0505 21:17:22.410295 26400 solver.cpp:244]     Train net output #0: loss = 0.0450236 (* 1 = 0.0450236 loss)
I0505 21:17:22.410327 26400 sgd_solver.cpp:106] Iteration 9350, lr = 1e-05
I0505 21:19:29.795225 26400 solver.cpp:337] Iteration 9400, Testing net (#0)
I0505 21:19:37.660562 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 21:20:04.208981 26400 solver.cpp:404]     Test net output #0: loss = 0.340742 (* 1 = 0.340742 loss)
I0505 21:20:05.073822 26400 solver.cpp:228] Iteration 9400, loss = 0.074362
I0505 21:20:05.073899 26400 solver.cpp:244]     Train net output #0: loss = 0.0743633 (* 1 = 0.0743633 loss)
I0505 21:20:05.073914 26400 sgd_solver.cpp:106] Iteration 9400, lr = 1e-05
I0505 21:22:15.184449 26400 solver.cpp:228] Iteration 9450, loss = 0.0602381
I0505 21:22:15.184696 26400 solver.cpp:244]     Train net output #0: loss = 0.0602394 (* 1 = 0.0602394 loss)
I0505 21:22:15.184754 26400 sgd_solver.cpp:106] Iteration 9450, lr = 1e-05
I0505 21:24:25.073140 26400 solver.cpp:228] Iteration 9500, loss = 0.0312929
I0505 21:24:25.073303 26400 solver.cpp:244]     Train net output #0: loss = 0.0312943 (* 1 = 0.0312943 loss)
I0505 21:24:25.073318 26400 sgd_solver.cpp:106] Iteration 9500, lr = 1e-05
I0505 21:26:34.975790 26400 solver.cpp:228] Iteration 9550, loss = 0.0379834
I0505 21:26:34.976039 26400 solver.cpp:244]     Train net output #0: loss = 0.0379848 (* 1 = 0.0379848 loss)
I0505 21:26:34.976088 26400 sgd_solver.cpp:106] Iteration 9550, lr = 1e-05
I0505 21:28:42.545732 26400 solver.cpp:337] Iteration 9600, Testing net (#0)
I0505 21:29:33.097930 26400 solver.cpp:404]     Test net output #0: loss = 0.180022 (* 1 = 0.180022 loss)
I0505 21:29:33.963009 26400 solver.cpp:228] Iteration 9600, loss = 0.0903167
I0505 21:29:33.963073 26400 solver.cpp:244]     Train net output #0: loss = 0.090318 (* 1 = 0.090318 loss)
I0505 21:29:33.963095 26400 sgd_solver.cpp:106] Iteration 9600, lr = 1e-05
I0505 21:31:44.371175 26400 solver.cpp:228] Iteration 9650, loss = 0.0844588
I0505 21:31:44.371855 26400 solver.cpp:244]     Train net output #0: loss = 0.0844602 (* 1 = 0.0844602 loss)
I0505 21:31:44.371914 26400 sgd_solver.cpp:106] Iteration 9650, lr = 1e-05
I0505 21:33:54.040091 26400 solver.cpp:228] Iteration 9700, loss = -1.37091e-06
I0505 21:33:54.040354 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 21:33:54.040390 26400 sgd_solver.cpp:106] Iteration 9700, lr = 1e-05
I0505 21:36:03.993796 26400 solver.cpp:228] Iteration 9750, loss = 0.0128356
I0505 21:36:03.994014 26400 solver.cpp:244]     Train net output #0: loss = 0.012837 (* 1 = 0.012837 loss)
I0505 21:36:03.994048 26400 sgd_solver.cpp:106] Iteration 9750, lr = 1e-05
I0505 21:38:11.535821 26400 solver.cpp:337] Iteration 9800, Testing net (#0)
I0505 21:38:24.993547 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 21:38:51.389446 26400 solver.cpp:404]     Test net output #0: loss = 0.204192 (* 1 = 0.204192 loss)
I0505 21:38:52.257340 26400 solver.cpp:228] Iteration 9800, loss = 0.0933621
I0505 21:38:52.257395 26400 solver.cpp:244]     Train net output #0: loss = 0.0933635 (* 1 = 0.0933635 loss)
I0505 21:38:52.257407 26400 sgd_solver.cpp:106] Iteration 9800, lr = 1e-05
I0505 21:41:02.169268 26400 solver.cpp:228] Iteration 9850, loss = -1.35787e-06
I0505 21:41:02.171514 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 21:41:02.171542 26400 sgd_solver.cpp:106] Iteration 9850, lr = 1e-05
I0505 21:43:12.215384 26400 solver.cpp:228] Iteration 9900, loss = 0.102626
I0505 21:43:12.215643 26400 solver.cpp:244]     Train net output #0: loss = 0.102627 (* 1 = 0.102627 loss)
I0505 21:43:12.215692 26400 sgd_solver.cpp:106] Iteration 9900, lr = 1e-05
I0505 21:45:21.905979 26400 solver.cpp:228] Iteration 9950, loss = 0.025239
I0505 21:45:21.908231 26400 solver.cpp:244]     Train net output #0: loss = 0.0252404 (* 1 = 0.0252404 loss)
I0505 21:45:21.908275 26400 sgd_solver.cpp:106] Iteration 9950, lr = 1e-05
I0505 21:47:29.154428 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_10000.caffemodel
I0505 21:47:36.453311 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_10000.solverstate
I0505 21:47:36.510378 26400 solver.cpp:337] Iteration 10000, Testing net (#0)
I0505 21:48:21.461218 26400 solver.cpp:404]     Test net output #0: loss = 0.110498 (* 1 = 0.110498 loss)
I0505 21:48:22.320273 26400 solver.cpp:228] Iteration 10000, loss = -1.34483e-06
I0505 21:48:22.320322 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 21:48:22.320348 26400 sgd_solver.cpp:106] Iteration 10000, lr = 1e-05
I0505 21:50:32.796535 26400 solver.cpp:228] Iteration 10050, loss = 0.0728562
I0505 21:50:32.797670 26400 solver.cpp:244]     Train net output #0: loss = 0.0728576 (* 1 = 0.0728576 loss)
I0505 21:50:32.797731 26400 sgd_solver.cpp:106] Iteration 10050, lr = 1e-05
I0505 21:52:42.902741 26400 solver.cpp:228] Iteration 10100, loss = 0.265671
I0505 21:52:42.902932 26400 solver.cpp:244]     Train net output #0: loss = 0.265672 (* 1 = 0.265672 loss)
I0505 21:52:42.902950 26400 sgd_solver.cpp:106] Iteration 10100, lr = 1e-05
I0505 21:54:52.988685 26400 solver.cpp:228] Iteration 10150, loss = 0.104124
I0505 21:54:52.989912 26400 solver.cpp:244]     Train net output #0: loss = 0.104125 (* 1 = 0.104125 loss)
I0505 21:54:52.989941 26400 sgd_solver.cpp:106] Iteration 10150, lr = 1e-05
I0505 21:57:00.272079 26400 solver.cpp:337] Iteration 10200, Testing net (#0)
I0505 21:57:13.769203 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 21:57:42.666750 26400 solver.cpp:404]     Test net output #0: loss = 0.145382 (* 1 = 0.145382 loss)
I0505 21:57:43.533305 26400 solver.cpp:228] Iteration 10200, loss = 0.0144033
I0505 21:57:43.533354 26400 solver.cpp:244]     Train net output #0: loss = 0.0144046 (* 1 = 0.0144046 loss)
I0505 21:57:43.533367 26400 sgd_solver.cpp:106] Iteration 10200, lr = 1e-05
I0505 21:59:53.803684 26400 solver.cpp:228] Iteration 10250, loss = 0.0466879
I0505 21:59:53.804939 26400 solver.cpp:244]     Train net output #0: loss = 0.0466891 (* 1 = 0.0466891 loss)
I0505 21:59:53.804986 26400 sgd_solver.cpp:106] Iteration 10250, lr = 1e-05
I0505 22:02:04.069100 26400 solver.cpp:228] Iteration 10300, loss = 0.145126
I0505 22:02:04.069272 26400 solver.cpp:244]     Train net output #0: loss = 0.145128 (* 1 = 0.145128 loss)
I0505 22:02:04.069295 26400 sgd_solver.cpp:106] Iteration 10300, lr = 1e-05
I0505 22:04:14.154319 26400 solver.cpp:228] Iteration 10350, loss = 0.0330198
I0505 22:04:14.154546 26400 solver.cpp:244]     Train net output #0: loss = 0.0330211 (* 1 = 0.0330211 loss)
I0505 22:04:14.154594 26400 sgd_solver.cpp:106] Iteration 10350, lr = 1e-05
I0505 22:06:21.700865 26400 solver.cpp:337] Iteration 10400, Testing net (#0)
I0505 22:06:55.549768 26400 solver.cpp:404]     Test net output #0: loss = 0.112611 (* 1 = 0.112611 loss)
I0505 22:06:56.416265 26400 solver.cpp:228] Iteration 10400, loss = 0.0894996
I0505 22:06:56.416345 26400 solver.cpp:244]     Train net output #0: loss = 0.0895009 (* 1 = 0.0895009 loss)
I0505 22:06:56.416362 26400 sgd_solver.cpp:106] Iteration 10400, lr = 1e-05
I0505 22:09:06.344621 26400 solver.cpp:228] Iteration 10450, loss = 0.0162911
I0505 22:09:06.346442 26400 solver.cpp:244]     Train net output #0: loss = 0.0162925 (* 1 = 0.0162925 loss)
I0505 22:09:06.346473 26400 sgd_solver.cpp:106] Iteration 10450, lr = 1e-05
I0505 22:11:16.399948 26400 solver.cpp:228] Iteration 10500, loss = -1.3113e-06
I0505 22:11:16.400179 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 22:11:16.400223 26400 sgd_solver.cpp:106] Iteration 10500, lr = 1e-05
I0505 22:13:26.525113 26400 solver.cpp:228] Iteration 10550, loss = 0.0738902
I0505 22:13:26.525274 26400 solver.cpp:244]     Train net output #0: loss = 0.0738915 (* 1 = 0.0738915 loss)
I0505 22:13:26.525290 26400 sgd_solver.cpp:106] Iteration 10550, lr = 1e-05
I0505 22:15:33.914888 26400 solver.cpp:337] Iteration 10600, Testing net (#0)
I0505 22:15:55.564180 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 22:16:21.476830 26400 solver.cpp:404]     Test net output #0: loss = 0.168228 (* 1 = 0.168228 loss)
I0505 22:16:22.337177 26400 solver.cpp:228] Iteration 10600, loss = 0.0955108
I0505 22:16:22.337245 26400 solver.cpp:244]     Train net output #0: loss = 0.0955122 (* 1 = 0.0955122 loss)
I0505 22:16:22.337260 26400 sgd_solver.cpp:106] Iteration 10600, lr = 1e-05
I0505 22:18:32.397585 26400 solver.cpp:228] Iteration 10650, loss = 0.0484336
I0505 22:18:32.397774 26400 solver.cpp:244]     Train net output #0: loss = 0.0484349 (* 1 = 0.0484349 loss)
I0505 22:18:32.397789 26400 sgd_solver.cpp:106] Iteration 10650, lr = 1e-05
I0505 22:20:42.538573 26400 solver.cpp:228] Iteration 10700, loss = 0.0568966
I0505 22:20:42.538744 26400 solver.cpp:244]     Train net output #0: loss = 0.0568979 (* 1 = 0.0568979 loss)
I0505 22:20:42.538759 26400 sgd_solver.cpp:106] Iteration 10700, lr = 1e-05
I0505 22:22:52.695788 26400 solver.cpp:228] Iteration 10750, loss = 0.0188763
I0505 22:22:52.696020 26400 solver.cpp:244]     Train net output #0: loss = 0.0188776 (* 1 = 0.0188776 loss)
I0505 22:22:52.696065 26400 sgd_solver.cpp:106] Iteration 10750, lr = 1e-05
I0505 22:25:00.194351 26400 solver.cpp:337] Iteration 10800, Testing net (#0)
I0505 22:25:50.044494 26400 solver.cpp:404]     Test net output #0: loss = 0.16047 (* 1 = 0.16047 loss)
I0505 22:25:50.910142 26400 solver.cpp:228] Iteration 10800, loss = 0.0683613
I0505 22:25:50.910205 26400 solver.cpp:244]     Train net output #0: loss = 0.0683626 (* 1 = 0.0683626 loss)
I0505 22:25:50.910223 26400 sgd_solver.cpp:106] Iteration 10800, lr = 1e-05
I0505 22:28:01.739152 26400 solver.cpp:228] Iteration 10850, loss = 0.0287285
I0505 22:28:01.739323 26400 solver.cpp:244]     Train net output #0: loss = 0.0287298 (* 1 = 0.0287298 loss)
I0505 22:28:01.739338 26400 sgd_solver.cpp:106] Iteration 10850, lr = 1e-05
I0505 22:30:11.828449 26400 solver.cpp:228] Iteration 10900, loss = 0.159015
I0505 22:30:11.829299 26400 solver.cpp:244]     Train net output #0: loss = 0.159016 (* 1 = 0.159016 loss)
I0505 22:30:11.829314 26400 sgd_solver.cpp:106] Iteration 10900, lr = 1e-05
I0505 22:32:21.516204 26400 solver.cpp:228] Iteration 10950, loss = 0.152751
I0505 22:32:21.518226 26400 solver.cpp:244]     Train net output #0: loss = 0.152752 (* 1 = 0.152752 loss)
I0505 22:32:21.518254 26400 sgd_solver.cpp:106] Iteration 10950, lr = 1e-05
I0505 22:34:29.070446 26400 solver.cpp:337] Iteration 11000, Testing net (#0)
I0505 22:34:50.133859 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 22:34:59.263242 26400 solver.cpp:404]     Test net output #0: loss = 0.134495 (* 1 = 0.134495 loss)
I0505 22:35:00.135812 26400 solver.cpp:228] Iteration 11000, loss = 0.101772
I0505 22:35:00.135870 26400 solver.cpp:244]     Train net output #0: loss = 0.101774 (* 1 = 0.101774 loss)
I0505 22:35:00.135895 26400 sgd_solver.cpp:106] Iteration 11000, lr = 1e-05
I0505 22:37:10.131158 26400 solver.cpp:228] Iteration 11050, loss = 0.0859926
I0505 22:37:10.133591 26400 solver.cpp:244]     Train net output #0: loss = 0.0859939 (* 1 = 0.0859939 loss)
I0505 22:37:10.133656 26400 sgd_solver.cpp:106] Iteration 11050, lr = 1e-05
I0505 22:39:20.246999 26400 solver.cpp:228] Iteration 11100, loss = 0.028515
I0505 22:39:20.247172 26400 solver.cpp:244]     Train net output #0: loss = 0.0285163 (* 1 = 0.0285163 loss)
I0505 22:39:20.247195 26400 sgd_solver.cpp:106] Iteration 11100, lr = 1e-05
I0505 22:41:30.350329 26400 solver.cpp:228] Iteration 11150, loss = 0.040666
I0505 22:41:30.351789 26400 solver.cpp:244]     Train net output #0: loss = 0.0406674 (* 1 = 0.0406674 loss)
I0505 22:41:30.351805 26400 sgd_solver.cpp:106] Iteration 11150, lr = 1e-05
I0505 22:43:37.854297 26400 solver.cpp:337] Iteration 11200, Testing net (#0)
I0505 22:44:08.390961 26400 solver.cpp:404]     Test net output #0: loss = 0.154877 (* 1 = 0.154877 loss)
I0505 22:44:09.260061 26400 solver.cpp:228] Iteration 11200, loss = 0.123354
I0505 22:44:09.260125 26400 solver.cpp:244]     Train net output #0: loss = 0.123355 (* 1 = 0.123355 loss)
I0505 22:44:09.260143 26400 sgd_solver.cpp:106] Iteration 11200, lr = 1e-05
I0505 22:46:19.674780 26400 solver.cpp:228] Iteration 11250, loss = 0.0673441
I0505 22:46:19.677882 26400 solver.cpp:244]     Train net output #0: loss = 0.0673454 (* 1 = 0.0673454 loss)
I0505 22:46:19.677913 26400 sgd_solver.cpp:106] Iteration 11250, lr = 1e-05
I0505 22:48:29.801453 26400 solver.cpp:228] Iteration 11300, loss = 0.0662037
I0505 22:48:29.801692 26400 solver.cpp:244]     Train net output #0: loss = 0.0662051 (* 1 = 0.0662051 loss)
I0505 22:48:29.801729 26400 sgd_solver.cpp:106] Iteration 11300, lr = 1e-05
I0505 22:50:39.670575 26400 solver.cpp:228] Iteration 11350, loss = 0.190604
I0505 22:50:39.670790 26400 solver.cpp:244]     Train net output #0: loss = 0.190606 (* 1 = 0.190606 loss)
I0505 22:50:39.670825 26400 sgd_solver.cpp:106] Iteration 11350, lr = 1e-05
I0505 22:52:47.315660 26400 solver.cpp:337] Iteration 11400, Testing net (#0)
I0505 22:53:18.034889 26400 solver.cpp:404]     Test net output #0: loss = 0.11665 (* 1 = 0.11665 loss)
I0505 22:53:18.899796 26400 solver.cpp:228] Iteration 11400, loss = -1.37091e-06
I0505 22:53:18.899852 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 22:53:18.899866 26400 sgd_solver.cpp:106] Iteration 11400, lr = 1e-05
I0505 22:55:28.824609 26400 solver.cpp:228] Iteration 11450, loss = 0.0804904
I0505 22:55:28.824847 26400 solver.cpp:244]     Train net output #0: loss = 0.0804918 (* 1 = 0.0804918 loss)
I0505 22:55:28.824887 26400 sgd_solver.cpp:106] Iteration 11450, lr = 1e-05
I0505 22:57:38.892377 26400 solver.cpp:228] Iteration 11500, loss = 0.14125
I0505 22:57:38.892606 26400 solver.cpp:244]     Train net output #0: loss = 0.141252 (* 1 = 0.141252 loss)
I0505 22:57:38.892637 26400 sgd_solver.cpp:106] Iteration 11500, lr = 1e-05
I0505 22:59:49.141084 26400 solver.cpp:228] Iteration 11550, loss = 0.00192241
I0505 22:59:49.141369 26400 solver.cpp:244]     Train net output #0: loss = 0.00192386 (* 1 = 0.00192386 loss)
I0505 22:59:49.141428 26400 sgd_solver.cpp:106] Iteration 11550, lr = 1e-05
I0505 23:01:56.557657 26400 solver.cpp:337] Iteration 11600, Testing net (#0)
I0505 23:02:02.080214 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 23:02:28.561674 26400 solver.cpp:404]     Test net output #0: loss = 0.22807 (* 1 = 0.22807 loss)
I0505 23:02:29.432054 26400 solver.cpp:228] Iteration 11600, loss = 0.0678697
I0505 23:02:29.432107 26400 solver.cpp:244]     Train net output #0: loss = 0.0678712 (* 1 = 0.0678712 loss)
I0505 23:02:29.432121 26400 sgd_solver.cpp:106] Iteration 11600, lr = 1e-05
I0505 23:04:39.656190 26400 solver.cpp:228] Iteration 11650, loss = 0.141974
I0505 23:04:39.656361 26400 solver.cpp:244]     Train net output #0: loss = 0.141976 (* 1 = 0.141976 loss)
I0505 23:04:39.656390 26400 sgd_solver.cpp:106] Iteration 11650, lr = 1e-05
I0505 23:06:49.615428 26400 solver.cpp:228] Iteration 11700, loss = 0.314537
I0505 23:06:49.616170 26400 solver.cpp:244]     Train net output #0: loss = 0.314538 (* 1 = 0.314538 loss)
I0505 23:06:49.616209 26400 sgd_solver.cpp:106] Iteration 11700, lr = 1e-05
I0505 23:08:59.510648 26400 solver.cpp:228] Iteration 11750, loss = 0.0255424
I0505 23:08:59.523324 26400 solver.cpp:244]     Train net output #0: loss = 0.0255439 (* 1 = 0.0255439 loss)
I0505 23:08:59.523345 26400 sgd_solver.cpp:106] Iteration 11750, lr = 1e-05
I0505 23:11:06.946638 26400 solver.cpp:337] Iteration 11800, Testing net (#0)
I0505 23:11:37.374259 26400 solver.cpp:404]     Test net output #0: loss = 0.201343 (* 1 = 0.201343 loss)
I0505 23:11:38.238611 26400 solver.cpp:228] Iteration 11800, loss = 0.00856769
I0505 23:11:38.238667 26400 solver.cpp:244]     Train net output #0: loss = 0.00856916 (* 1 = 0.00856916 loss)
I0505 23:11:38.238680 26400 sgd_solver.cpp:106] Iteration 11800, lr = 1e-05
I0505 23:13:48.197892 26400 solver.cpp:228] Iteration 11850, loss = 0.13078
I0505 23:13:48.198143 26400 solver.cpp:244]     Train net output #0: loss = 0.130782 (* 1 = 0.130782 loss)
I0505 23:13:48.198189 26400 sgd_solver.cpp:106] Iteration 11850, lr = 1e-05
I0505 23:15:58.306579 26400 solver.cpp:228] Iteration 11900, loss = -1.43796e-06
I0505 23:15:58.306857 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 23:15:58.306891 26400 sgd_solver.cpp:106] Iteration 11900, lr = 1e-05
I0505 23:18:08.342329 26400 solver.cpp:228] Iteration 11950, loss = -1.46031e-06
I0505 23:18:08.342522 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0505 23:18:08.342540 26400 sgd_solver.cpp:106] Iteration 11950, lr = 1e-05
I0505 23:20:15.662516 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_12000.caffemodel
I0505 23:20:19.133975 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_12000.solverstate
I0505 23:20:19.189589 26400 solver.cpp:337] Iteration 12000, Testing net (#0)
I0505 23:20:25.686005 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 23:20:49.927731 26400 solver.cpp:404]     Test net output #0: loss = 0.233574 (* 1 = 0.233574 loss)
I0505 23:20:50.794931 26400 solver.cpp:228] Iteration 12000, loss = 0.0601589
I0505 23:20:50.794980 26400 solver.cpp:244]     Train net output #0: loss = 0.0601603 (* 1 = 0.0601603 loss)
I0505 23:20:50.794993 26400 sgd_solver.cpp:106] Iteration 12000, lr = 1e-05
I0505 23:23:00.869814 26400 solver.cpp:228] Iteration 12050, loss = 0.00581071
I0505 23:23:00.870056 26400 solver.cpp:244]     Train net output #0: loss = 0.00581214 (* 1 = 0.00581214 loss)
I0505 23:23:00.870105 26400 sgd_solver.cpp:106] Iteration 12050, lr = 1e-05
I0505 23:25:10.855598 26400 solver.cpp:228] Iteration 12100, loss = 0.0671651
I0505 23:25:10.855852 26400 solver.cpp:244]     Train net output #0: loss = 0.0671665 (* 1 = 0.0671665 loss)
I0505 23:25:10.855909 26400 sgd_solver.cpp:106] Iteration 12100, lr = 1e-05
I0505 23:27:20.776031 26400 solver.cpp:228] Iteration 12150, loss = 0.0121348
I0505 23:27:20.776592 26400 solver.cpp:244]     Train net output #0: loss = 0.0121362 (* 1 = 0.0121362 loss)
I0505 23:27:20.776607 26400 sgd_solver.cpp:106] Iteration 12150, lr = 1e-05
I0505 23:29:28.164844 26400 solver.cpp:337] Iteration 12200, Testing net (#0)
I0505 23:29:59.846958 26400 solver.cpp:404]     Test net output #0: loss = 0.251485 (* 1 = 0.251485 loss)
I0505 23:30:00.718255 26400 solver.cpp:228] Iteration 12200, loss = 0.270853
I0505 23:30:00.718317 26400 solver.cpp:244]     Train net output #0: loss = 0.270854 (* 1 = 0.270854 loss)
I0505 23:30:00.718335 26400 sgd_solver.cpp:106] Iteration 12200, lr = 1e-05
I0505 23:32:10.981773 26400 solver.cpp:228] Iteration 12250, loss = 0.0672981
I0505 23:32:10.982209 26400 solver.cpp:244]     Train net output #0: loss = 0.0672996 (* 1 = 0.0672996 loss)
I0505 23:32:10.982249 26400 sgd_solver.cpp:106] Iteration 12250, lr = 1e-05
I0505 23:34:21.051692 26400 solver.cpp:228] Iteration 12300, loss = 0.206661
I0505 23:34:21.051868 26400 solver.cpp:244]     Train net output #0: loss = 0.206663 (* 1 = 0.206663 loss)
I0505 23:34:21.051888 26400 sgd_solver.cpp:106] Iteration 12300, lr = 1e-05
I0505 23:36:31.044548 26400 solver.cpp:228] Iteration 12350, loss = 0.0265248
I0505 23:36:31.056946 26400 solver.cpp:244]     Train net output #0: loss = 0.0265263 (* 1 = 0.0265263 loss)
I0505 23:36:31.056967 26400 sgd_solver.cpp:106] Iteration 12350, lr = 1e-05
I0505 23:38:38.755785 26400 solver.cpp:337] Iteration 12400, Testing net (#0)
I0505 23:38:52.303704 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 23:39:12.397610 26400 solver.cpp:404]     Test net output #0: loss = 0.147607 (* 1 = 0.147607 loss)
I0505 23:39:13.271260 26400 solver.cpp:228] Iteration 12400, loss = 0.0322694
I0505 23:39:13.271323 26400 solver.cpp:244]     Train net output #0: loss = 0.0322708 (* 1 = 0.0322708 loss)
I0505 23:39:13.271337 26400 sgd_solver.cpp:106] Iteration 12400, lr = 1e-05
I0505 23:41:23.271785 26400 solver.cpp:228] Iteration 12450, loss = 0.174043
I0505 23:41:23.271960 26400 solver.cpp:244]     Train net output #0: loss = 0.174045 (* 1 = 0.174045 loss)
I0505 23:41:23.271976 26400 sgd_solver.cpp:106] Iteration 12450, lr = 1e-05
I0505 23:43:33.445413 26400 solver.cpp:228] Iteration 12500, loss = 0.0249309
I0505 23:43:33.445572 26400 solver.cpp:244]     Train net output #0: loss = 0.0249324 (* 1 = 0.0249324 loss)
I0505 23:43:33.445588 26400 sgd_solver.cpp:106] Iteration 12500, lr = 1e-05
I0505 23:45:43.254227 26400 solver.cpp:228] Iteration 12550, loss = 0.0319213
I0505 23:45:43.254467 26400 solver.cpp:244]     Train net output #0: loss = 0.0319228 (* 1 = 0.0319228 loss)
I0505 23:45:43.254513 26400 sgd_solver.cpp:106] Iteration 12550, lr = 1e-05
I0505 23:47:50.631659 26400 solver.cpp:337] Iteration 12600, Testing net (#0)
I0505 23:48:34.762198 26400 solver.cpp:404]     Test net output #0: loss = 0.117564 (* 1 = 0.117564 loss)
I0505 23:48:35.638471 26400 solver.cpp:228] Iteration 12600, loss = 0.344448
I0505 23:48:35.638535 26400 solver.cpp:244]     Train net output #0: loss = 0.344449 (* 1 = 0.344449 loss)
I0505 23:48:35.638550 26400 sgd_solver.cpp:106] Iteration 12600, lr = 1e-05
I0505 23:50:46.280258 26400 solver.cpp:228] Iteration 12650, loss = 0.04901
I0505 23:50:46.280441 26400 solver.cpp:244]     Train net output #0: loss = 0.0490115 (* 1 = 0.0490115 loss)
I0505 23:50:46.280457 26400 sgd_solver.cpp:106] Iteration 12650, lr = 1e-05
I0505 23:52:56.511072 26400 solver.cpp:228] Iteration 12700, loss = 0.0876036
I0505 23:52:56.511265 26400 solver.cpp:244]     Train net output #0: loss = 0.0876052 (* 1 = 0.0876052 loss)
I0505 23:52:56.511286 26400 sgd_solver.cpp:106] Iteration 12700, lr = 1e-05
I0505 23:55:06.375409 26400 solver.cpp:228] Iteration 12750, loss = 0.263359
I0505 23:55:06.375589 26400 solver.cpp:244]     Train net output #0: loss = 0.26336 (* 1 = 0.26336 loss)
I0505 23:55:06.375607 26400 sgd_solver.cpp:106] Iteration 12750, lr = 1e-05
I0505 23:57:13.550580 26400 solver.cpp:337] Iteration 12800, Testing net (#0)
I0505 23:57:32.524914 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0505 23:57:55.395133 26400 solver.cpp:404]     Test net output #0: loss = 0.12426 (* 1 = 0.12426 loss)
I0505 23:57:56.259636 26400 solver.cpp:228] Iteration 12800, loss = 0.0124515
I0505 23:57:56.259712 26400 solver.cpp:244]     Train net output #0: loss = 0.0124531 (* 1 = 0.0124531 loss)
I0505 23:57:56.259729 26400 sgd_solver.cpp:106] Iteration 12800, lr = 1e-05
I0506 00:00:06.804579 26400 solver.cpp:228] Iteration 12850, loss = -1.54972e-06
I0506 00:00:06.807082 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 00:00:06.807132 26400 sgd_solver.cpp:106] Iteration 12850, lr = 1e-05
I0506 00:02:16.841569 26400 solver.cpp:228] Iteration 12900, loss = 0.0212161
I0506 00:02:16.841826 26400 solver.cpp:244]     Train net output #0: loss = 0.0212177 (* 1 = 0.0212177 loss)
I0506 00:02:16.841874 26400 sgd_solver.cpp:106] Iteration 12900, lr = 1e-05
I0506 00:04:26.833909 26400 solver.cpp:228] Iteration 12950, loss = 0.0286799
I0506 00:04:26.834095 26400 solver.cpp:244]     Train net output #0: loss = 0.0286815 (* 1 = 0.0286815 loss)
I0506 00:04:26.834110 26400 sgd_solver.cpp:106] Iteration 12950, lr = 1e-05
I0506 00:06:34.376325 26400 solver.cpp:337] Iteration 13000, Testing net (#0)
I0506 00:07:10.773500 26400 solver.cpp:404]     Test net output #0: loss = 0.117408 (* 1 = 0.117408 loss)
I0506 00:07:11.640283 26400 solver.cpp:228] Iteration 13000, loss = -1.58697e-06
I0506 00:07:11.640357 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 00:07:11.640390 26400 sgd_solver.cpp:106] Iteration 13000, lr = 1e-05
I0506 00:09:21.746287 26400 solver.cpp:228] Iteration 13050, loss = 0.0980988
I0506 00:09:21.746807 26400 solver.cpp:244]     Train net output #0: loss = 0.0981004 (* 1 = 0.0981004 loss)
I0506 00:09:21.746835 26400 sgd_solver.cpp:106] Iteration 13050, lr = 1e-05
I0506 00:11:31.799345 26400 solver.cpp:228] Iteration 13100, loss = 0.0223239
I0506 00:11:31.799568 26400 solver.cpp:244]     Train net output #0: loss = 0.0223255 (* 1 = 0.0223255 loss)
I0506 00:11:31.799610 26400 sgd_solver.cpp:106] Iteration 13100, lr = 1e-05
I0506 00:13:41.961894 26400 solver.cpp:228] Iteration 13150, loss = 0.00445016
I0506 00:13:41.962049 26400 solver.cpp:244]     Train net output #0: loss = 0.00445174 (* 1 = 0.00445174 loss)
I0506 00:13:41.962067 26400 sgd_solver.cpp:106] Iteration 13150, lr = 1e-05
I0506 00:15:49.317682 26400 solver.cpp:337] Iteration 13200, Testing net (#0)
I0506 00:16:08.336426 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 00:16:19.559837 26400 solver.cpp:404]     Test net output #0: loss = 0.156023 (* 1 = 0.156023 loss)
I0506 00:16:20.428077 26400 solver.cpp:228] Iteration 13200, loss = -1.57952e-06
I0506 00:16:20.428162 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 00:16:20.428190 26400 sgd_solver.cpp:106] Iteration 13200, lr = 1e-05
I0506 00:18:30.511996 26400 solver.cpp:228] Iteration 13250, loss = 0.0301333
I0506 00:18:30.512233 26400 solver.cpp:244]     Train net output #0: loss = 0.0301349 (* 1 = 0.0301349 loss)
I0506 00:18:30.512287 26400 sgd_solver.cpp:106] Iteration 13250, lr = 1e-05
I0506 00:20:40.814348 26400 solver.cpp:228] Iteration 13300, loss = 0.0720042
I0506 00:20:40.815861 26400 solver.cpp:244]     Train net output #0: loss = 0.0720057 (* 1 = 0.0720057 loss)
I0506 00:20:40.815876 26400 sgd_solver.cpp:106] Iteration 13300, lr = 1e-05
I0506 00:22:50.774897 26400 solver.cpp:228] Iteration 13350, loss = 0.119932
I0506 00:22:50.775167 26400 solver.cpp:244]     Train net output #0: loss = 0.119934 (* 1 = 0.119934 loss)
I0506 00:22:50.775233 26400 sgd_solver.cpp:106] Iteration 13350, lr = 1e-05
I0506 00:24:58.121038 26400 solver.cpp:337] Iteration 13400, Testing net (#0)
I0506 00:25:28.342223 26400 solver.cpp:404]     Test net output #0: loss = 0.111012 (* 1 = 0.111012 loss)
I0506 00:25:29.216338 26400 solver.cpp:228] Iteration 13400, loss = 0.0890227
I0506 00:25:29.216390 26400 solver.cpp:244]     Train net output #0: loss = 0.0890242 (* 1 = 0.0890242 loss)
I0506 00:25:29.216403 26400 sgd_solver.cpp:106] Iteration 13400, lr = 1e-05
I0506 00:27:39.278466 26400 solver.cpp:228] Iteration 13450, loss = 0.00576637
I0506 00:27:39.278725 26400 solver.cpp:244]     Train net output #0: loss = 0.00576789 (* 1 = 0.00576789 loss)
I0506 00:27:39.278758 26400 sgd_solver.cpp:106] Iteration 13450, lr = 1e-05
I0506 00:29:49.009702 26400 solver.cpp:228] Iteration 13500, loss = 0.0596973
I0506 00:29:49.009948 26400 solver.cpp:244]     Train net output #0: loss = 0.0596988 (* 1 = 0.0596988 loss)
I0506 00:29:49.010004 26400 sgd_solver.cpp:106] Iteration 13500, lr = 1e-05
I0506 00:31:58.883723 26400 solver.cpp:228] Iteration 13550, loss = 0.397801
I0506 00:31:58.884312 26400 solver.cpp:244]     Train net output #0: loss = 0.397803 (* 1 = 0.397803 loss)
I0506 00:31:58.884330 26400 sgd_solver.cpp:106] Iteration 13550, lr = 1e-05
I0506 00:34:06.452664 26400 solver.cpp:337] Iteration 13600, Testing net (#0)
I0506 00:34:29.557265 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 00:34:36.682106 26400 solver.cpp:404]     Test net output #0: loss = 0.0915074 (* 1 = 0.0915074 loss)
I0506 00:34:37.564832 26400 solver.cpp:228] Iteration 13600, loss = 0.330982
I0506 00:34:37.564883 26400 solver.cpp:244]     Train net output #0: loss = 0.330983 (* 1 = 0.330983 loss)
I0506 00:34:37.564913 26400 sgd_solver.cpp:106] Iteration 13600, lr = 1e-05
I0506 00:36:47.558050 26400 solver.cpp:228] Iteration 13650, loss = -1.47149e-06
I0506 00:36:47.558286 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 00:36:47.558328 26400 sgd_solver.cpp:106] Iteration 13650, lr = 1e-05
I0506 00:38:57.823918 26400 solver.cpp:228] Iteration 13700, loss = -1.49012e-06
I0506 00:38:57.824169 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 00:38:57.824220 26400 sgd_solver.cpp:106] Iteration 13700, lr = 1e-05
I0506 00:41:07.986593 26400 solver.cpp:228] Iteration 13750, loss = 0.00291628
I0506 00:41:07.987002 26400 solver.cpp:244]     Train net output #0: loss = 0.00291777 (* 1 = 0.00291777 loss)
I0506 00:41:07.987047 26400 sgd_solver.cpp:106] Iteration 13750, lr = 1e-05
I0506 00:43:15.304620 26400 solver.cpp:337] Iteration 13800, Testing net (#0)
I0506 00:43:45.918331 26400 solver.cpp:404]     Test net output #0: loss = 0.1961 (* 1 = 0.1961 loss)
I0506 00:43:46.792853 26400 solver.cpp:228] Iteration 13800, loss = 0.0772441
I0506 00:43:46.792923 26400 solver.cpp:244]     Train net output #0: loss = 0.0772455 (* 1 = 0.0772455 loss)
I0506 00:43:46.792937 26400 sgd_solver.cpp:106] Iteration 13800, lr = 1e-05
I0506 00:45:56.849236 26400 solver.cpp:228] Iteration 13850, loss = 0.0507455
I0506 00:45:56.849455 26400 solver.cpp:244]     Train net output #0: loss = 0.050747 (* 1 = 0.050747 loss)
I0506 00:45:56.849474 26400 sgd_solver.cpp:106] Iteration 13850, lr = 1e-05
I0506 00:48:06.825542 26400 solver.cpp:228] Iteration 13900, loss = 0.0930161
I0506 00:48:06.825732 26400 solver.cpp:244]     Train net output #0: loss = 0.0930175 (* 1 = 0.0930175 loss)
I0506 00:48:06.825758 26400 sgd_solver.cpp:106] Iteration 13900, lr = 1e-05
I0506 00:50:16.794206 26400 solver.cpp:228] Iteration 13950, loss = 0.0304917
I0506 00:50:16.796677 26400 solver.cpp:244]     Train net output #0: loss = 0.0304932 (* 1 = 0.0304932 loss)
I0506 00:50:16.796728 26400 sgd_solver.cpp:106] Iteration 13950, lr = 1e-05
I0506 00:52:24.337788 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_14000.caffemodel
I0506 00:52:28.300904 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_14000.solverstate
I0506 00:52:28.358005 26400 solver.cpp:337] Iteration 14000, Testing net (#0)
I0506 00:52:57.142952 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 00:52:59.467833 26400 solver.cpp:404]     Test net output #0: loss = 0.145981 (* 1 = 0.145981 loss)
I0506 00:53:00.331760 26400 solver.cpp:228] Iteration 14000, loss = 0.011809
I0506 00:53:00.331801 26400 solver.cpp:244]     Train net output #0: loss = 0.0118105 (* 1 = 0.0118105 loss)
I0506 00:53:00.331816 26400 sgd_solver.cpp:106] Iteration 14000, lr = 1e-05
I0506 00:55:10.528586 26400 solver.cpp:228] Iteration 14050, loss = 0.0355277
I0506 00:55:10.528940 26400 solver.cpp:244]     Train net output #0: loss = 0.0355291 (* 1 = 0.0355291 loss)
I0506 00:55:10.529044 26400 sgd_solver.cpp:106] Iteration 14050, lr = 1e-05
I0506 00:57:20.618703 26400 solver.cpp:228] Iteration 14100, loss = 0.30864
I0506 00:57:20.618921 26400 solver.cpp:244]     Train net output #0: loss = 0.308641 (* 1 = 0.308641 loss)
I0506 00:57:20.618945 26400 sgd_solver.cpp:106] Iteration 14100, lr = 1e-05
I0506 00:59:30.599566 26400 solver.cpp:228] Iteration 14150, loss = 0.0269304
I0506 00:59:30.599728 26400 solver.cpp:244]     Train net output #0: loss = 0.0269319 (* 1 = 0.0269319 loss)
I0506 00:59:30.599755 26400 sgd_solver.cpp:106] Iteration 14150, lr = 1e-05
I0506 01:01:38.159832 26400 solver.cpp:337] Iteration 14200, Testing net (#0)
I0506 01:02:16.378173 26400 solver.cpp:404]     Test net output #0: loss = 0.167003 (* 1 = 0.167003 loss)
I0506 01:02:17.242851 26400 solver.cpp:228] Iteration 14200, loss = 0.0847175
I0506 01:02:17.242936 26400 solver.cpp:244]     Train net output #0: loss = 0.084719 (* 1 = 0.084719 loss)
I0506 01:02:17.242985 26400 sgd_solver.cpp:106] Iteration 14200, lr = 1e-05
I0506 01:04:27.320050 26400 solver.cpp:228] Iteration 14250, loss = 0.201913
I0506 01:04:27.333638 26400 solver.cpp:244]     Train net output #0: loss = 0.201914 (* 1 = 0.201914 loss)
I0506 01:04:27.333657 26400 sgd_solver.cpp:106] Iteration 14250, lr = 1e-05
I0506 01:06:37.284344 26400 solver.cpp:228] Iteration 14300, loss = -1.51992e-06
I0506 01:06:37.284499 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:06:37.284515 26400 sgd_solver.cpp:106] Iteration 14300, lr = 1e-05
I0506 01:08:47.354208 26400 solver.cpp:228] Iteration 14350, loss = -1.54972e-06
I0506 01:08:47.367033 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:08:47.367058 26400 sgd_solver.cpp:106] Iteration 14350, lr = 1e-05
I0506 01:10:54.719635 26400 solver.cpp:337] Iteration 14400, Testing net (#0)
I0506 01:11:36.947269 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 01:11:37.279878 26400 solver.cpp:404]     Test net output #0: loss = 0.0963229 (* 1 = 0.0963229 loss)
I0506 01:11:38.142379 26400 solver.cpp:228] Iteration 14400, loss = 0.171245
I0506 01:11:38.142444 26400 solver.cpp:244]     Train net output #0: loss = 0.171246 (* 1 = 0.171246 loss)
I0506 01:11:38.142475 26400 sgd_solver.cpp:106] Iteration 14400, lr = 1e-05
I0506 01:13:48.632866 26400 solver.cpp:228] Iteration 14450, loss = 0.101514
I0506 01:13:48.633041 26400 solver.cpp:244]     Train net output #0: loss = 0.101516 (* 1 = 0.101516 loss)
I0506 01:13:48.633069 26400 sgd_solver.cpp:106] Iteration 14450, lr = 1e-05
I0506 01:15:58.935730 26400 solver.cpp:228] Iteration 14500, loss = 0.0601959
I0506 01:15:58.938161 26400 solver.cpp:244]     Train net output #0: loss = 0.0601974 (* 1 = 0.0601974 loss)
I0506 01:15:58.938194 26400 sgd_solver.cpp:106] Iteration 14500, lr = 1e-05
I0506 01:18:09.111523 26400 solver.cpp:228] Iteration 14550, loss = 0.0288947
I0506 01:18:09.111773 26400 solver.cpp:244]     Train net output #0: loss = 0.0288961 (* 1 = 0.0288961 loss)
I0506 01:18:09.111816 26400 sgd_solver.cpp:106] Iteration 14550, lr = 1e-05
I0506 01:20:16.508288 26400 solver.cpp:337] Iteration 14600, Testing net (#0)
I0506 01:20:46.836282 26400 solver.cpp:404]     Test net output #0: loss = 0.178431 (* 1 = 0.178431 loss)
I0506 01:20:47.706024 26400 solver.cpp:228] Iteration 14600, loss = 0.0512289
I0506 01:20:47.706084 26400 solver.cpp:244]     Train net output #0: loss = 0.0512303 (* 1 = 0.0512303 loss)
I0506 01:20:47.706097 26400 sgd_solver.cpp:106] Iteration 14600, lr = 1e-05
I0506 01:22:57.517805 26400 solver.cpp:228] Iteration 14650, loss = 0.0130091
I0506 01:22:57.518069 26400 solver.cpp:244]     Train net output #0: loss = 0.0130106 (* 1 = 0.0130106 loss)
I0506 01:22:57.518112 26400 sgd_solver.cpp:106] Iteration 14650, lr = 1e-05
I0506 01:25:07.484318 26400 solver.cpp:228] Iteration 14700, loss = 0.0548609
I0506 01:25:07.485491 26400 solver.cpp:244]     Train net output #0: loss = 0.0548623 (* 1 = 0.0548623 loss)
I0506 01:25:07.485510 26400 sgd_solver.cpp:106] Iteration 14700, lr = 1e-05
I0506 01:27:17.610183 26400 solver.cpp:228] Iteration 14750, loss = -1.40071e-06
I0506 01:27:17.610425 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:27:17.610476 26400 sgd_solver.cpp:106] Iteration 14750, lr = 1e-05
I0506 01:29:24.977947 26400 solver.cpp:337] Iteration 14800, Testing net (#0)
I0506 01:30:09.002563 26400 solver.cpp:404]     Test net output #0: loss = 0.130476 (* 1 = 0.130476 loss)
I0506 01:30:09.871517 26400 solver.cpp:228] Iteration 14800, loss = 0.0327484
I0506 01:30:09.871574 26400 solver.cpp:244]     Train net output #0: loss = 0.0327498 (* 1 = 0.0327498 loss)
I0506 01:30:09.871589 26400 sgd_solver.cpp:106] Iteration 14800, lr = 1e-05
I0506 01:32:20.372926 26400 solver.cpp:228] Iteration 14850, loss = -1.3411e-06
I0506 01:32:20.373139 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:32:20.373174 26400 sgd_solver.cpp:106] Iteration 14850, lr = 1e-05
I0506 01:34:30.350096 26400 solver.cpp:228] Iteration 14900, loss = 0.0792242
I0506 01:34:30.352391 26400 solver.cpp:244]     Train net output #0: loss = 0.0792255 (* 1 = 0.0792255 loss)
I0506 01:34:30.352407 26400 sgd_solver.cpp:106] Iteration 14900, lr = 1e-05
I0506 01:36:40.270982 26400 solver.cpp:228] Iteration 14950, loss = -1.30944e-06
I0506 01:36:40.271143 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:36:40.271160 26400 sgd_solver.cpp:106] Iteration 14950, lr = 1e-05
I0506 01:38:47.630566 26400 solver.cpp:337] Iteration 15000, Testing net (#0)
I0506 01:39:01.211119 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 01:39:28.748965 26400 solver.cpp:404]     Test net output #0: loss = 0.151577 (* 1 = 0.151577 loss)
I0506 01:39:29.617946 26400 solver.cpp:228] Iteration 15000, loss = 0.0378824
I0506 01:39:29.618002 26400 solver.cpp:244]     Train net output #0: loss = 0.0378838 (* 1 = 0.0378838 loss)
I0506 01:39:29.618016 26400 sgd_solver.cpp:106] Iteration 15000, lr = 1e-05
I0506 01:41:40.025516 26400 solver.cpp:228] Iteration 15050, loss = -1.35601e-06
I0506 01:41:40.025707 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:41:40.025740 26400 sgd_solver.cpp:106] Iteration 15050, lr = 1e-05
I0506 01:43:50.358475 26400 solver.cpp:228] Iteration 15100, loss = -1.40071e-06
I0506 01:43:50.358702 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:43:50.358750 26400 sgd_solver.cpp:106] Iteration 15100, lr = 1e-05
I0506 01:46:00.365136 26400 solver.cpp:228] Iteration 15150, loss = -1.37091e-06
I0506 01:46:00.365387 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:46:00.365432 26400 sgd_solver.cpp:106] Iteration 15150, lr = 1e-05
I0506 01:48:07.851364 26400 solver.cpp:337] Iteration 15200, Testing net (#0)
I0506 01:48:56.899907 26400 solver.cpp:404]     Test net output #0: loss = 0.172359 (* 1 = 0.172359 loss)
I0506 01:48:57.762477 26400 solver.cpp:228] Iteration 15200, loss = 0.0826785
I0506 01:48:57.762537 26400 solver.cpp:244]     Train net output #0: loss = 0.0826798 (* 1 = 0.0826798 loss)
I0506 01:48:57.762552 26400 sgd_solver.cpp:106] Iteration 15200, lr = 1e-05
I0506 01:51:08.748128 26400 solver.cpp:228] Iteration 15250, loss = -1.3113e-06
I0506 01:51:08.748406 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 01:51:08.748452 26400 sgd_solver.cpp:106] Iteration 15250, lr = 1e-05
I0506 01:53:18.911087 26400 solver.cpp:228] Iteration 15300, loss = 0.0566586
I0506 01:53:18.911336 26400 solver.cpp:244]     Train net output #0: loss = 0.05666 (* 1 = 0.05666 loss)
I0506 01:53:18.911386 26400 sgd_solver.cpp:106] Iteration 15300, lr = 1e-05
I0506 01:55:28.599987 26400 solver.cpp:228] Iteration 15350, loss = 0.135592
I0506 01:55:28.600265 26400 solver.cpp:244]     Train net output #0: loss = 0.135593 (* 1 = 0.135593 loss)
I0506 01:55:28.600286 26400 sgd_solver.cpp:106] Iteration 15350, lr = 1e-05
I0506 01:57:36.122663 26400 solver.cpp:337] Iteration 15400, Testing net (#0)
I0506 01:57:57.076949 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 01:58:25.994930 26400 solver.cpp:404]     Test net output #0: loss = 0.116922 (* 1 = 0.116922 loss)
I0506 01:58:26.860546 26400 solver.cpp:228] Iteration 15400, loss = 0.0447382
I0506 01:58:26.860599 26400 solver.cpp:244]     Train net output #0: loss = 0.0447394 (* 1 = 0.0447394 loss)
I0506 01:58:26.860635 26400 sgd_solver.cpp:106] Iteration 15400, lr = 1e-05
I0506 02:00:37.754266 26400 solver.cpp:228] Iteration 15450, loss = 0.0969015
I0506 02:00:37.754719 26400 solver.cpp:244]     Train net output #0: loss = 0.0969027 (* 1 = 0.0969027 loss)
I0506 02:00:37.754758 26400 sgd_solver.cpp:106] Iteration 15450, lr = 1e-05
I0506 02:02:48.085041 26400 solver.cpp:228] Iteration 15500, loss = 0.0193467
I0506 02:02:48.088610 26400 solver.cpp:244]     Train net output #0: loss = 0.0193478 (* 1 = 0.0193478 loss)
I0506 02:02:48.088634 26400 sgd_solver.cpp:106] Iteration 15500, lr = 1e-05
I0506 02:04:58.305984 26400 solver.cpp:228] Iteration 15550, loss = 0.142527
I0506 02:04:58.319258 26400 solver.cpp:244]     Train net output #0: loss = 0.142528 (* 1 = 0.142528 loss)
I0506 02:04:58.319278 26400 sgd_solver.cpp:106] Iteration 15550, lr = 1e-05
I0506 02:07:05.533898 26400 solver.cpp:337] Iteration 15600, Testing net (#0)
I0506 02:07:59.032757 26400 solver.cpp:404]     Test net output #0: loss = 0.104928 (* 1 = 0.104928 loss)
I0506 02:07:59.893257 26400 solver.cpp:228] Iteration 15600, loss = 0.283854
I0506 02:07:59.893314 26400 solver.cpp:244]     Train net output #0: loss = 0.283855 (* 1 = 0.283855 loss)
I0506 02:07:59.893329 26400 sgd_solver.cpp:106] Iteration 15600, lr = 1e-05
I0506 02:10:10.896055 26400 solver.cpp:228] Iteration 15650, loss = 0.0966937
I0506 02:10:10.896308 26400 solver.cpp:244]     Train net output #0: loss = 0.0966948 (* 1 = 0.0966948 loss)
I0506 02:10:10.896363 26400 sgd_solver.cpp:106] Iteration 15650, lr = 1e-05
I0506 02:12:21.210789 26400 solver.cpp:228] Iteration 15700, loss = -1.07288e-06
I0506 02:12:21.211727 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 02:12:21.211791 26400 sgd_solver.cpp:106] Iteration 15700, lr = 1e-05
I0506 02:14:31.246845 26400 solver.cpp:228] Iteration 15750, loss = 0.0719446
I0506 02:14:31.247031 26400 solver.cpp:244]     Train net output #0: loss = 0.0719457 (* 1 = 0.0719457 loss)
I0506 02:14:31.247053 26400 sgd_solver.cpp:106] Iteration 15750, lr = 1e-05
I0506 02:16:38.337837 26400 solver.cpp:337] Iteration 15800, Testing net (#0)
I0506 02:16:51.899051 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 02:17:08.546928 26400 solver.cpp:404]     Test net output #0: loss = 0.220271 (* 1 = 0.220271 loss)
I0506 02:17:09.415223 26400 solver.cpp:228] Iteration 15800, loss = 0.0855484
I0506 02:17:09.415311 26400 solver.cpp:244]     Train net output #0: loss = 0.0855495 (* 1 = 0.0855495 loss)
I0506 02:17:09.415350 26400 sgd_solver.cpp:106] Iteration 15800, lr = 1e-05
I0506 02:19:19.465064 26400 solver.cpp:228] Iteration 15850, loss = 0.00750192
I0506 02:19:19.466470 26400 solver.cpp:244]     Train net output #0: loss = 0.00750305 (* 1 = 0.00750305 loss)
I0506 02:19:19.466486 26400 sgd_solver.cpp:106] Iteration 15850, lr = 1e-05
I0506 02:21:29.467942 26400 solver.cpp:228] Iteration 15900, loss = 0.0437774
I0506 02:21:29.469007 26400 solver.cpp:244]     Train net output #0: loss = 0.0437786 (* 1 = 0.0437786 loss)
I0506 02:21:29.469038 26400 sgd_solver.cpp:106] Iteration 15900, lr = 1e-05
I0506 02:23:39.463801 26400 solver.cpp:228] Iteration 15950, loss = 0.0706124
I0506 02:23:39.463985 26400 solver.cpp:244]     Train net output #0: loss = 0.0706136 (* 1 = 0.0706136 loss)
I0506 02:23:39.464001 26400 sgd_solver.cpp:106] Iteration 15950, lr = 1e-05
I0506 02:25:47.139681 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_16000.caffemodel
I0506 02:25:50.884029 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_16000.solverstate
I0506 02:25:50.945917 26400 solver.cpp:337] Iteration 16000, Testing net (#0)
I0506 02:26:19.365022 26400 solver.cpp:404]     Test net output #0: loss = 0.122793 (* 1 = 0.122793 loss)
I0506 02:26:20.231966 26400 solver.cpp:228] Iteration 16000, loss = 0.141486
I0506 02:26:20.232031 26400 solver.cpp:244]     Train net output #0: loss = 0.141487 (* 1 = 0.141487 loss)
I0506 02:26:20.232045 26400 sgd_solver.cpp:106] Iteration 16000, lr = 1e-05
I0506 02:28:30.230968 26400 solver.cpp:228] Iteration 16050, loss = 0.133896
I0506 02:28:30.231151 26400 solver.cpp:244]     Train net output #0: loss = 0.133897 (* 1 = 0.133897 loss)
I0506 02:28:30.231190 26400 sgd_solver.cpp:106] Iteration 16050, lr = 1e-05
I0506 02:30:40.335736 26400 solver.cpp:228] Iteration 16100, loss = 0.105047
I0506 02:30:40.335970 26400 solver.cpp:244]     Train net output #0: loss = 0.105048 (* 1 = 0.105048 loss)
I0506 02:30:40.336017 26400 sgd_solver.cpp:106] Iteration 16100, lr = 1e-05
I0506 02:32:50.301806 26400 solver.cpp:228] Iteration 16150, loss = 0.0539193
I0506 02:32:50.314312 26400 solver.cpp:244]     Train net output #0: loss = 0.0539204 (* 1 = 0.0539204 loss)
I0506 02:32:50.314347 26400 sgd_solver.cpp:106] Iteration 16150, lr = 1e-05
I0506 02:34:57.401705 26400 solver.cpp:337] Iteration 16200, Testing net (#0)
I0506 02:35:22.764833 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 02:35:27.610900 26400 solver.cpp:404]     Test net output #0: loss = 0.127961 (* 1 = 0.127961 loss)
I0506 02:35:28.490993 26400 solver.cpp:228] Iteration 16200, loss = -1.13249e-06
I0506 02:35:28.491044 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 02:35:28.491061 26400 sgd_solver.cpp:106] Iteration 16200, lr = 1e-05
I0506 02:37:38.600816 26400 solver.cpp:228] Iteration 16250, loss = -1.12504e-06
I0506 02:37:38.601009 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 02:37:38.601050 26400 sgd_solver.cpp:106] Iteration 16250, lr = 1e-05
I0506 02:39:48.523200 26400 solver.cpp:228] Iteration 16300, loss = 0.0157371
I0506 02:39:48.523433 26400 solver.cpp:244]     Train net output #0: loss = 0.0157382 (* 1 = 0.0157382 loss)
I0506 02:39:48.523478 26400 sgd_solver.cpp:106] Iteration 16300, lr = 1e-05
I0506 02:41:58.582048 26400 solver.cpp:228] Iteration 16350, loss = 0.038229
I0506 02:41:58.582226 26400 solver.cpp:244]     Train net output #0: loss = 0.0382301 (* 1 = 0.0382301 loss)
I0506 02:41:58.582240 26400 sgd_solver.cpp:106] Iteration 16350, lr = 1e-05
I0506 02:44:06.304908 26400 solver.cpp:337] Iteration 16400, Testing net (#0)
I0506 02:44:37.838469 26400 solver.cpp:404]     Test net output #0: loss = 0.170357 (* 1 = 0.170357 loss)
I0506 02:44:38.709488 26400 solver.cpp:228] Iteration 16400, loss = 0.0805707
I0506 02:44:38.709548 26400 solver.cpp:244]     Train net output #0: loss = 0.0805718 (* 1 = 0.0805718 loss)
I0506 02:44:38.709565 26400 sgd_solver.cpp:106] Iteration 16400, lr = 1e-05
I0506 02:46:48.755295 26400 solver.cpp:228] Iteration 16450, loss = 0.0798919
I0506 02:46:48.755481 26400 solver.cpp:244]     Train net output #0: loss = 0.079893 (* 1 = 0.079893 loss)
I0506 02:46:48.755497 26400 sgd_solver.cpp:106] Iteration 16450, lr = 1e-05
I0506 02:48:58.831135 26400 solver.cpp:228] Iteration 16500, loss = 0.0348429
I0506 02:48:58.831387 26400 solver.cpp:244]     Train net output #0: loss = 0.034844 (* 1 = 0.034844 loss)
I0506 02:48:58.831436 26400 sgd_solver.cpp:106] Iteration 16500, lr = 1e-05
I0506 02:51:08.828434 26400 solver.cpp:228] Iteration 16550, loss = -1.07288e-06
I0506 02:51:08.828688 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 02:51:08.828729 26400 sgd_solver.cpp:106] Iteration 16550, lr = 1e-05
I0506 02:53:15.966259 26400 solver.cpp:337] Iteration 16600, Testing net (#0)
I0506 02:53:48.061456 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 02:53:49.486338 26400 solver.cpp:404]     Test net output #0: loss = 0.105305 (* 1 = 0.105305 loss)
I0506 02:53:50.354375 26400 solver.cpp:228] Iteration 16600, loss = 0.0333413
I0506 02:53:50.354423 26400 solver.cpp:244]     Train net output #0: loss = 0.0333424 (* 1 = 0.0333424 loss)
I0506 02:53:50.354450 26400 sgd_solver.cpp:106] Iteration 16600, lr = 1e-05
I0506 02:56:00.395740 26400 solver.cpp:228] Iteration 16650, loss = 0.00719162
I0506 02:56:00.395952 26400 solver.cpp:244]     Train net output #0: loss = 0.00719272 (* 1 = 0.00719272 loss)
I0506 02:56:00.395967 26400 sgd_solver.cpp:106] Iteration 16650, lr = 1e-05
I0506 02:58:10.436003 26400 solver.cpp:228] Iteration 16700, loss = 0.0413284
I0506 02:58:10.436178 26400 solver.cpp:244]     Train net output #0: loss = 0.0413295 (* 1 = 0.0413295 loss)
I0506 02:58:10.436221 26400 sgd_solver.cpp:106] Iteration 16700, lr = 1e-05
I0506 03:00:20.764506 26400 solver.cpp:228] Iteration 16750, loss = 0.0173482
I0506 03:00:20.764916 26400 solver.cpp:244]     Train net output #0: loss = 0.0173493 (* 1 = 0.0173493 loss)
I0506 03:00:20.764951 26400 sgd_solver.cpp:106] Iteration 16750, lr = 1e-05
I0506 03:02:28.230736 26400 solver.cpp:337] Iteration 16800, Testing net (#0)
I0506 03:03:25.999765 26400 solver.cpp:404]     Test net output #0: loss = 0.105228 (* 1 = 0.105228 loss)
I0506 03:03:26.861773 26400 solver.cpp:228] Iteration 16800, loss = 0.0347021
I0506 03:03:26.861822 26400 solver.cpp:244]     Train net output #0: loss = 0.0347032 (* 1 = 0.0347032 loss)
I0506 03:03:26.861836 26400 sgd_solver.cpp:106] Iteration 16800, lr = 1e-05
I0506 03:05:37.341261 26400 solver.cpp:228] Iteration 16850, loss = 0.0313615
I0506 03:05:37.341434 26400 solver.cpp:244]     Train net output #0: loss = 0.0313627 (* 1 = 0.0313627 loss)
I0506 03:05:37.341449 26400 sgd_solver.cpp:106] Iteration 16850, lr = 1e-05
I0506 03:07:47.446040 26400 solver.cpp:228] Iteration 16900, loss = 0.105233
I0506 03:07:47.446321 26400 solver.cpp:244]     Train net output #0: loss = 0.105234 (* 1 = 0.105234 loss)
I0506 03:07:47.446385 26400 sgd_solver.cpp:106] Iteration 16900, lr = 1e-05
I0506 03:09:57.466491 26400 solver.cpp:228] Iteration 16950, loss = 0.207316
I0506 03:09:57.466671 26400 solver.cpp:244]     Train net output #0: loss = 0.207318 (* 1 = 0.207318 loss)
I0506 03:09:57.466687 26400 sgd_solver.cpp:106] Iteration 16950, lr = 1e-05
I0506 03:12:04.496356 26400 solver.cpp:337] Iteration 17000, Testing net (#0)
I0506 03:12:54.134960 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 03:12:54.322190 26400 solver.cpp:404]     Test net output #0: loss = 0.217558 (* 1 = 0.217558 loss)
I0506 03:12:55.181397 26400 solver.cpp:228] Iteration 17000, loss = 0.0326076
I0506 03:12:55.181439 26400 solver.cpp:244]     Train net output #0: loss = 0.0326088 (* 1 = 0.0326088 loss)
I0506 03:12:55.181452 26400 sgd_solver.cpp:106] Iteration 17000, lr = 1e-05
I0506 03:15:05.794749 26400 solver.cpp:228] Iteration 17050, loss = -1.19209e-06
I0506 03:15:05.795858 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:15:05.795887 26400 sgd_solver.cpp:106] Iteration 17050, lr = 1e-05
I0506 03:17:15.885996 26400 solver.cpp:228] Iteration 17100, loss = 0.0428677
I0506 03:17:15.886215 26400 solver.cpp:244]     Train net output #0: loss = 0.0428688 (* 1 = 0.0428688 loss)
I0506 03:17:15.886256 26400 sgd_solver.cpp:106] Iteration 17100, lr = 1e-05
I0506 03:19:25.978134 26400 solver.cpp:228] Iteration 17150, loss = 0.059911
I0506 03:19:25.978485 26400 solver.cpp:244]     Train net output #0: loss = 0.0599122 (* 1 = 0.0599122 loss)
I0506 03:19:25.978538 26400 sgd_solver.cpp:106] Iteration 17150, lr = 1e-05
I0506 03:21:33.444192 26400 solver.cpp:337] Iteration 17200, Testing net (#0)
I0506 03:22:18.304124 26400 solver.cpp:404]     Test net output #0: loss = 0.123523 (* 1 = 0.123523 loss)
I0506 03:22:19.168596 26400 solver.cpp:228] Iteration 17200, loss = -1.19023e-06
I0506 03:22:19.168660 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:22:19.168674 26400 sgd_solver.cpp:106] Iteration 17200, lr = 1e-05
I0506 03:24:29.864975 26400 solver.cpp:228] Iteration 17250, loss = 0.0431197
I0506 03:24:29.865164 26400 solver.cpp:244]     Train net output #0: loss = 0.0431209 (* 1 = 0.0431209 loss)
I0506 03:24:29.865181 26400 sgd_solver.cpp:106] Iteration 17250, lr = 1e-05
I0506 03:26:40.014271 26400 solver.cpp:228] Iteration 17300, loss = -1.24052e-06
I0506 03:26:40.015306 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:26:40.015336 26400 sgd_solver.cpp:106] Iteration 17300, lr = 1e-05
I0506 03:28:49.920812 26400 solver.cpp:228] Iteration 17350, loss = 0.0273577
I0506 03:28:49.925021 26400 solver.cpp:244]     Train net output #0: loss = 0.027359 (* 1 = 0.027359 loss)
I0506 03:28:49.925060 26400 sgd_solver.cpp:106] Iteration 17350, lr = 1e-05
I0506 03:30:57.311520 26400 solver.cpp:337] Iteration 17400, Testing net (#0)
I0506 03:31:36.101505 26400 solver.cpp:404]     Test net output #0: loss = 0.185845 (* 1 = 0.185845 loss)
I0506 03:31:36.968647 26400 solver.cpp:228] Iteration 17400, loss = 0.0594479
I0506 03:31:36.968706 26400 solver.cpp:244]     Train net output #0: loss = 0.0594491 (* 1 = 0.0594491 loss)
I0506 03:31:36.968724 26400 sgd_solver.cpp:106] Iteration 17400, lr = 1e-05
I0506 03:33:47.389276 26400 solver.cpp:228] Iteration 17450, loss = 0.0293467
I0506 03:33:47.401724 26400 solver.cpp:244]     Train net output #0: loss = 0.0293479 (* 1 = 0.0293479 loss)
I0506 03:33:47.401767 26400 sgd_solver.cpp:106] Iteration 17450, lr = 1e-05
I0506 03:35:57.197209 26400 solver.cpp:228] Iteration 17500, loss = 0.0666864
I0506 03:35:57.197489 26400 solver.cpp:244]     Train net output #0: loss = 0.0666876 (* 1 = 0.0666876 loss)
I0506 03:35:57.197552 26400 sgd_solver.cpp:106] Iteration 17500, lr = 1e-05
I0506 03:38:07.220413 26400 solver.cpp:228] Iteration 17550, loss = -1.2219e-06
I0506 03:38:07.220635 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:38:07.220661 26400 sgd_solver.cpp:106] Iteration 17550, lr = 1e-05
I0506 03:40:14.812533 26400 solver.cpp:337] Iteration 17600, Testing net (#0)
I0506 03:40:20.906446 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 03:40:46.984359 26400 solver.cpp:404]     Test net output #0: loss = 0.112509 (* 1 = 0.112509 loss)
I0506 03:40:47.854288 26400 solver.cpp:228] Iteration 17600, loss = 0.00505576
I0506 03:40:47.854360 26400 solver.cpp:244]     Train net output #0: loss = 0.00505702 (* 1 = 0.00505702 loss)
I0506 03:40:47.854377 26400 sgd_solver.cpp:106] Iteration 17600, lr = 1e-05
I0506 03:42:57.923110 26400 solver.cpp:228] Iteration 17650, loss = 0.149287
I0506 03:42:57.923261 26400 solver.cpp:244]     Train net output #0: loss = 0.149288 (* 1 = 0.149288 loss)
I0506 03:42:57.923277 26400 sgd_solver.cpp:106] Iteration 17650, lr = 1e-05
I0506 03:45:08.090375 26400 solver.cpp:228] Iteration 17700, loss = 0.196372
I0506 03:45:08.092416 26400 solver.cpp:244]     Train net output #0: loss = 0.196373 (* 1 = 0.196373 loss)
I0506 03:45:08.092456 26400 sgd_solver.cpp:106] Iteration 17700, lr = 1e-05
I0506 03:47:17.650002 26400 solver.cpp:228] Iteration 17750, loss = 0.0644111
I0506 03:47:17.650266 26400 solver.cpp:244]     Train net output #0: loss = 0.0644124 (* 1 = 0.0644124 loss)
I0506 03:47:17.650318 26400 sgd_solver.cpp:106] Iteration 17750, lr = 1e-05
I0506 03:49:24.857971 26400 solver.cpp:337] Iteration 17800, Testing net (#0)
I0506 03:49:58.023617 26400 solver.cpp:404]     Test net output #0: loss = 0.151198 (* 1 = 0.151198 loss)
I0506 03:49:58.888883 26400 solver.cpp:228] Iteration 17800, loss = 0.0479053
I0506 03:49:58.888939 26400 solver.cpp:244]     Train net output #0: loss = 0.0479066 (* 1 = 0.0479066 loss)
I0506 03:49:58.888969 26400 sgd_solver.cpp:106] Iteration 17800, lr = 1e-05
I0506 03:52:08.876631 26400 solver.cpp:228] Iteration 17850, loss = -1.30385e-06
I0506 03:52:08.876806 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:52:08.876839 26400 sgd_solver.cpp:106] Iteration 17850, lr = 1e-05
I0506 03:54:19.134243 26400 solver.cpp:228] Iteration 17900, loss = 0.0113736
I0506 03:54:19.134409 26400 solver.cpp:244]     Train net output #0: loss = 0.0113749 (* 1 = 0.0113749 loss)
I0506 03:54:19.134425 26400 sgd_solver.cpp:106] Iteration 17900, lr = 1e-05
I0506 03:56:29.228762 26400 solver.cpp:228] Iteration 17950, loss = -1.34856e-06
I0506 03:56:29.228966 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 03:56:29.228998 26400 sgd_solver.cpp:106] Iteration 17950, lr = 1e-05
I0506 03:58:36.596846 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_18000.caffemodel
I0506 03:58:40.071718 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_18000.solverstate
I0506 03:58:40.124819 26400 solver.cpp:337] Iteration 18000, Testing net (#0)
I0506 03:59:11.753682 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 03:59:33.341187 26400 solver.cpp:404]     Test net output #0: loss = 0.164787 (* 1 = 0.164787 loss)
I0506 03:59:34.201208 26400 solver.cpp:228] Iteration 18000, loss = 0.0783819
I0506 03:59:34.201261 26400 solver.cpp:244]     Train net output #0: loss = 0.0783832 (* 1 = 0.0783832 loss)
I0506 03:59:34.201274 26400 sgd_solver.cpp:106] Iteration 18000, lr = 1e-05
I0506 04:01:44.743793 26400 solver.cpp:228] Iteration 18050, loss = -1.35601e-06
I0506 04:01:44.756328 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:01:44.756367 26400 sgd_solver.cpp:106] Iteration 18050, lr = 1e-05
I0506 04:03:54.811357 26400 solver.cpp:228] Iteration 18100, loss = -1.36718e-06
I0506 04:03:54.811795 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:03:54.811826 26400 sgd_solver.cpp:106] Iteration 18100, lr = 1e-05
I0506 04:06:04.396257 26400 solver.cpp:228] Iteration 18150, loss = 0.126382
I0506 04:06:04.396463 26400 solver.cpp:244]     Train net output #0: loss = 0.126383 (* 1 = 0.126383 loss)
I0506 04:06:04.396513 26400 sgd_solver.cpp:106] Iteration 18150, lr = 1e-05
I0506 04:08:11.730274 26400 solver.cpp:337] Iteration 18200, Testing net (#0)
I0506 04:09:11.151064 26400 solver.cpp:404]     Test net output #0: loss = 0.0988098 (* 1 = 0.0988098 loss)
I0506 04:09:12.011101 26400 solver.cpp:228] Iteration 18200, loss = 0.144186
I0506 04:09:12.011147 26400 solver.cpp:244]     Train net output #0: loss = 0.144187 (* 1 = 0.144187 loss)
I0506 04:09:12.011163 26400 sgd_solver.cpp:106] Iteration 18200, lr = 1e-05
I0506 04:11:22.245151 26400 solver.cpp:228] Iteration 18250, loss = -1.37091e-06
I0506 04:11:22.245313 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:11:22.245329 26400 sgd_solver.cpp:106] Iteration 18250, lr = 1e-05
I0506 04:13:32.311028 26400 solver.cpp:228] Iteration 18300, loss = 0.200931
I0506 04:13:32.311229 26400 solver.cpp:244]     Train net output #0: loss = 0.200933 (* 1 = 0.200933 loss)
I0506 04:13:32.311259 26400 sgd_solver.cpp:106] Iteration 18300, lr = 1e-05
I0506 04:15:42.410033 26400 solver.cpp:228] Iteration 18350, loss = 0.0544137
I0506 04:15:42.410260 26400 solver.cpp:244]     Train net output #0: loss = 0.0544151 (* 1 = 0.0544151 loss)
I0506 04:15:42.410303 26400 sgd_solver.cpp:106] Iteration 18350, lr = 1e-05
I0506 04:17:49.727761 26400 solver.cpp:337] Iteration 18400, Testing net (#0)
I0506 04:18:28.008396 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 04:18:49.744560 26400 solver.cpp:404]     Test net output #0: loss = 0.0989592 (* 1 = 0.0989592 loss)
I0506 04:18:50.602015 26400 solver.cpp:228] Iteration 18400, loss = -1.35601e-06
I0506 04:18:50.602071 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:18:50.602085 26400 sgd_solver.cpp:106] Iteration 18400, lr = 1e-05
I0506 04:21:01.194221 26400 solver.cpp:228] Iteration 18450, loss = 0.11558
I0506 04:21:01.194582 26400 solver.cpp:244]     Train net output #0: loss = 0.115581 (* 1 = 0.115581 loss)
I0506 04:21:01.194607 26400 sgd_solver.cpp:106] Iteration 18450, lr = 1e-05
I0506 04:23:11.385809 26400 solver.cpp:228] Iteration 18500, loss = 0.0176897
I0506 04:23:11.388260 26400 solver.cpp:244]     Train net output #0: loss = 0.0176911 (* 1 = 0.0176911 loss)
I0506 04:23:11.388330 26400 sgd_solver.cpp:106] Iteration 18500, lr = 1e-05
I0506 04:25:21.191205 26400 solver.cpp:228] Iteration 18550, loss = 0.0517872
I0506 04:25:21.191478 26400 solver.cpp:244]     Train net output #0: loss = 0.0517886 (* 1 = 0.0517886 loss)
I0506 04:25:21.191529 26400 sgd_solver.cpp:106] Iteration 18550, lr = 1e-05
I0506 04:27:28.368618 26400 solver.cpp:337] Iteration 18600, Testing net (#0)
I0506 04:28:26.547958 26400 solver.cpp:404]     Test net output #0: loss = 0.119511 (* 1 = 0.119511 loss)
I0506 04:28:27.408818 26400 solver.cpp:228] Iteration 18600, loss = 0.0189657
I0506 04:28:27.408884 26400 solver.cpp:244]     Train net output #0: loss = 0.018967 (* 1 = 0.018967 loss)
I0506 04:28:27.408898 26400 sgd_solver.cpp:106] Iteration 18600, lr = 1e-05
I0506 04:30:38.041086 26400 solver.cpp:228] Iteration 18650, loss = 0.0104054
I0506 04:30:38.042695 26400 solver.cpp:244]     Train net output #0: loss = 0.0104068 (* 1 = 0.0104068 loss)
I0506 04:30:38.042711 26400 sgd_solver.cpp:106] Iteration 18650, lr = 1e-05
I0506 04:32:48.248190 26400 solver.cpp:228] Iteration 18700, loss = 0.0157077
I0506 04:32:48.260710 26400 solver.cpp:244]     Train net output #0: loss = 0.015709 (* 1 = 0.015709 loss)
I0506 04:32:48.260748 26400 sgd_solver.cpp:106] Iteration 18700, lr = 1e-05
I0506 04:34:58.419700 26400 solver.cpp:228] Iteration 18750, loss = 0.0223502
I0506 04:34:58.419922 26400 solver.cpp:244]     Train net output #0: loss = 0.0223516 (* 1 = 0.0223516 loss)
I0506 04:34:58.419961 26400 sgd_solver.cpp:106] Iteration 18750, lr = 1e-05
I0506 04:37:05.832273 26400 solver.cpp:337] Iteration 18800, Testing net (#0)
I0506 04:37:29.666134 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 04:37:36.061096 26400 solver.cpp:404]     Test net output #0: loss = 0.17334 (* 1 = 0.17334 loss)
I0506 04:37:36.927469 26400 solver.cpp:228] Iteration 18800, loss = 0.0270741
I0506 04:37:36.927511 26400 solver.cpp:244]     Train net output #0: loss = 0.0270754 (* 1 = 0.0270754 loss)
I0506 04:37:36.927542 26400 sgd_solver.cpp:106] Iteration 18800, lr = 1e-05
I0506 04:39:47.124555 26400 solver.cpp:228] Iteration 18850, loss = -1.35414e-06
I0506 04:39:47.124814 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:39:47.124837 26400 sgd_solver.cpp:106] Iteration 18850, lr = 1e-05
I0506 04:41:57.081624 26400 solver.cpp:228] Iteration 18900, loss = 0.0251646
I0506 04:41:57.081868 26400 solver.cpp:244]     Train net output #0: loss = 0.025166 (* 1 = 0.025166 loss)
I0506 04:41:57.081920 26400 sgd_solver.cpp:106] Iteration 18900, lr = 1e-05
I0506 04:44:07.004863 26400 solver.cpp:228] Iteration 18950, loss = 0.043865
I0506 04:44:07.005040 26400 solver.cpp:244]     Train net output #0: loss = 0.0438664 (* 1 = 0.0438664 loss)
I0506 04:44:07.005064 26400 sgd_solver.cpp:106] Iteration 18950, lr = 1e-05
I0506 04:46:14.473626 26400 solver.cpp:337] Iteration 19000, Testing net (#0)
I0506 04:46:44.693225 26400 solver.cpp:404]     Test net output #0: loss = 0.167312 (* 1 = 0.167312 loss)
I0506 04:46:45.561784 26400 solver.cpp:228] Iteration 19000, loss = 0.095671
I0506 04:46:45.561849 26400 solver.cpp:244]     Train net output #0: loss = 0.0956724 (* 1 = 0.0956724 loss)
I0506 04:46:45.561864 26400 sgd_solver.cpp:106] Iteration 19000, lr = 1e-05
I0506 04:48:55.565094 26400 solver.cpp:228] Iteration 19050, loss = 0.12532
I0506 04:48:55.566223 26400 solver.cpp:244]     Train net output #0: loss = 0.125321 (* 1 = 0.125321 loss)
I0506 04:48:55.566243 26400 sgd_solver.cpp:106] Iteration 19050, lr = 1e-05
I0506 04:51:05.550431 26400 solver.cpp:228] Iteration 19100, loss = 0.401562
I0506 04:51:05.552820 26400 solver.cpp:244]     Train net output #0: loss = 0.401563 (* 1 = 0.401563 loss)
I0506 04:51:05.552844 26400 sgd_solver.cpp:106] Iteration 19100, lr = 1e-05
I0506 04:53:15.593632 26400 solver.cpp:228] Iteration 19150, loss = -1.3411e-06
I0506 04:53:15.593889 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 04:53:15.593921 26400 sgd_solver.cpp:106] Iteration 19150, lr = 1e-05
I0506 04:55:22.834008 26400 solver.cpp:337] Iteration 19200, Testing net (#0)
I0506 04:55:52.999883 26400 solver.cpp:404]     Test net output #0: loss = 0.128535 (* 1 = 0.128535 loss)
I0506 04:55:53.866441 26400 solver.cpp:228] Iteration 19200, loss = 0.0745569
I0506 04:55:53.866492 26400 solver.cpp:244]     Train net output #0: loss = 0.0745583 (* 1 = 0.0745583 loss)
I0506 04:55:53.866518 26400 sgd_solver.cpp:106] Iteration 19200, lr = 1e-05
I0506 04:58:03.848038 26400 solver.cpp:228] Iteration 19250, loss = 0.0396677
I0506 04:58:03.848253 26400 solver.cpp:244]     Train net output #0: loss = 0.039669 (* 1 = 0.039669 loss)
I0506 04:58:03.848290 26400 sgd_solver.cpp:106] Iteration 19250, lr = 1e-05
I0506 05:00:13.631973 26400 solver.cpp:228] Iteration 19300, loss = -1.3262e-06
I0506 05:00:13.632155 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:00:13.632192 26400 sgd_solver.cpp:106] Iteration 19300, lr = 1e-05
I0506 05:02:23.653118 26400 solver.cpp:228] Iteration 19350, loss = 0.00709334
I0506 05:02:23.653347 26400 solver.cpp:244]     Train net output #0: loss = 0.00709465 (* 1 = 0.00709465 loss)
I0506 05:02:23.653386 26400 sgd_solver.cpp:106] Iteration 19350, lr = 1e-05
I0506 05:04:31.243156 26400 solver.cpp:337] Iteration 19400, Testing net (#0)
I0506 05:04:34.891598 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 05:05:04.106119 26400 solver.cpp:404]     Test net output #0: loss = 0.144709 (* 1 = 0.144709 loss)
I0506 05:05:04.976876 26400 solver.cpp:228] Iteration 19400, loss = 0.0514224
I0506 05:05:04.976929 26400 solver.cpp:244]     Train net output #0: loss = 0.0514237 (* 1 = 0.0514237 loss)
I0506 05:05:04.976945 26400 sgd_solver.cpp:106] Iteration 19400, lr = 1e-05
I0506 05:07:14.919620 26400 solver.cpp:228] Iteration 19450, loss = 0.0258977
I0506 05:07:14.919833 26400 solver.cpp:244]     Train net output #0: loss = 0.025899 (* 1 = 0.025899 loss)
I0506 05:07:14.919878 26400 sgd_solver.cpp:106] Iteration 19450, lr = 1e-05
I0506 05:09:25.024281 26400 solver.cpp:228] Iteration 19500, loss = -1.31456e-06
I0506 05:09:25.026096 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:09:25.026149 26400 sgd_solver.cpp:106] Iteration 19500, lr = 1e-05
I0506 05:11:34.724462 26400 solver.cpp:228] Iteration 19550, loss = 0.0692405
I0506 05:11:34.724640 26400 solver.cpp:244]     Train net output #0: loss = 0.0692418 (* 1 = 0.0692418 loss)
I0506 05:11:34.724658 26400 sgd_solver.cpp:106] Iteration 19550, lr = 1e-05
I0506 05:13:41.710155 26400 solver.cpp:337] Iteration 19600, Testing net (#0)
I0506 05:14:37.417681 26400 solver.cpp:404]     Test net output #0: loss = 0.119116 (* 1 = 0.119116 loss)
I0506 05:14:38.280371 26400 solver.cpp:228] Iteration 19600, loss = 0.0645104
I0506 05:14:38.280427 26400 solver.cpp:244]     Train net output #0: loss = 0.0645117 (* 1 = 0.0645117 loss)
I0506 05:14:38.280444 26400 sgd_solver.cpp:106] Iteration 19600, lr = 1e-05
I0506 05:16:48.703343 26400 solver.cpp:228] Iteration 19650, loss = 0.00759038
I0506 05:16:48.704947 26400 solver.cpp:244]     Train net output #0: loss = 0.00759171 (* 1 = 0.00759171 loss)
I0506 05:16:48.704996 26400 sgd_solver.cpp:106] Iteration 19650, lr = 1e-05
I0506 05:18:58.706167 26400 solver.cpp:228] Iteration 19700, loss = 0.0577647
I0506 05:18:58.706408 26400 solver.cpp:244]     Train net output #0: loss = 0.0577659 (* 1 = 0.0577659 loss)
I0506 05:18:58.706451 26400 sgd_solver.cpp:106] Iteration 19700, lr = 1e-05
I0506 05:21:08.591599 26400 solver.cpp:228] Iteration 19750, loss = -1.25542e-06
I0506 05:21:08.596786 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:21:08.596819 26400 sgd_solver.cpp:106] Iteration 19750, lr = 1e-05
I0506 05:23:15.702672 26400 solver.cpp:337] Iteration 19800, Testing net (#0)
I0506 05:23:21.742516 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 05:24:02.888110 26400 solver.cpp:404]     Test net output #0: loss = 0.108092 (* 1 = 0.108092 loss)
I0506 05:24:03.753249 26400 solver.cpp:228] Iteration 19800, loss = -1.2517e-06
I0506 05:24:03.753325 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:24:03.753350 26400 sgd_solver.cpp:106] Iteration 19800, lr = 1e-05
I0506 05:26:14.292002 26400 solver.cpp:228] Iteration 19850, loss = -1.25915e-06
I0506 05:26:14.292227 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:26:14.292255 26400 sgd_solver.cpp:106] Iteration 19850, lr = 1e-05
I0506 05:28:24.289579 26400 solver.cpp:228] Iteration 19900, loss = -1.24797e-06
I0506 05:28:24.289865 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:28:24.289913 26400 sgd_solver.cpp:106] Iteration 19900, lr = 1e-05
I0506 05:30:33.727655 26400 solver.cpp:228] Iteration 19950, loss = 0.10437
I0506 05:30:33.728242 26400 solver.cpp:244]     Train net output #0: loss = 0.104371 (* 1 = 0.104371 loss)
I0506 05:30:33.728266 26400 sgd_solver.cpp:106] Iteration 19950, lr = 1e-05
I0506 05:32:41.130733 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_20000.caffemodel
I0506 05:32:46.490200 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_20000.solverstate
I0506 05:32:46.548638 26400 solver.cpp:337] Iteration 20000, Testing net (#0)
I0506 05:33:27.276283 26400 solver.cpp:404]     Test net output #0: loss = 0.0834807 (* 1 = 0.0834807 loss)
I0506 05:33:28.142757 26400 solver.cpp:228] Iteration 20000, loss = 0.219463
I0506 05:33:28.142807 26400 solver.cpp:244]     Train net output #0: loss = 0.219464 (* 1 = 0.219464 loss)
I0506 05:33:28.142827 26400 sgd_solver.cpp:106] Iteration 20000, lr = 1e-06
I0506 05:35:38.876180 26400 solver.cpp:228] Iteration 20050, loss = 0.0263684
I0506 05:35:38.876375 26400 solver.cpp:244]     Train net output #0: loss = 0.0263697 (* 1 = 0.0263697 loss)
I0506 05:35:38.876412 26400 sgd_solver.cpp:106] Iteration 20050, lr = 1e-06
I0506 05:37:48.748337 26400 solver.cpp:228] Iteration 20100, loss = 0.230949
I0506 05:37:48.748479 26400 solver.cpp:244]     Train net output #0: loss = 0.23095 (* 1 = 0.23095 loss)
I0506 05:37:48.748495 26400 sgd_solver.cpp:106] Iteration 20100, lr = 1e-06
I0506 05:39:58.517385 26400 solver.cpp:228] Iteration 20150, loss = 0.0967033
I0506 05:39:58.517913 26400 solver.cpp:244]     Train net output #0: loss = 0.0967046 (* 1 = 0.0967046 loss)
I0506 05:39:58.517941 26400 sgd_solver.cpp:106] Iteration 20150, lr = 1e-06
I0506 05:42:05.988603 26400 solver.cpp:337] Iteration 20200, Testing net (#0)
I0506 05:42:14.743445 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 05:42:54.249034 26400 solver.cpp:404]     Test net output #0: loss = 0.117179 (* 1 = 0.117179 loss)
I0506 05:42:55.114297 26400 solver.cpp:228] Iteration 20200, loss = 0.042979
I0506 05:42:55.114351 26400 solver.cpp:244]     Train net output #0: loss = 0.0429803 (* 1 = 0.0429803 loss)
I0506 05:42:55.114364 26400 sgd_solver.cpp:106] Iteration 20200, lr = 1e-06
I0506 05:45:05.998406 26400 solver.cpp:228] Iteration 20250, loss = 0.200413
I0506 05:45:05.998651 26400 solver.cpp:244]     Train net output #0: loss = 0.200414 (* 1 = 0.200414 loss)
I0506 05:45:05.998667 26400 sgd_solver.cpp:106] Iteration 20250, lr = 1e-06
I0506 05:47:15.815356 26400 solver.cpp:228] Iteration 20300, loss = 1.64509e-05
I0506 05:47:15.816651 26400 solver.cpp:244]     Train net output #0: loss = 1.7792e-05 (* 1 = 1.7792e-05 loss)
I0506 05:47:15.816679 26400 sgd_solver.cpp:106] Iteration 20300, lr = 1e-06
I0506 05:49:25.507856 26400 solver.cpp:228] Iteration 20350, loss = -1.3411e-06
I0506 05:49:25.508029 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:49:25.508050 26400 sgd_solver.cpp:106] Iteration 20350, lr = 1e-06
I0506 05:51:32.821519 26400 solver.cpp:337] Iteration 20400, Testing net (#0)
I0506 05:52:14.057531 26400 solver.cpp:404]     Test net output #0: loss = 0.11485 (* 1 = 0.11485 loss)
I0506 05:52:14.921063 26400 solver.cpp:228] Iteration 20400, loss = 0.389986
I0506 05:52:14.921128 26400 solver.cpp:244]     Train net output #0: loss = 0.389987 (* 1 = 0.389987 loss)
I0506 05:52:14.921142 26400 sgd_solver.cpp:106] Iteration 20400, lr = 1e-06
I0506 05:54:25.002640 26400 solver.cpp:228] Iteration 20450, loss = -1.35601e-06
I0506 05:54:25.002841 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:54:25.002867 26400 sgd_solver.cpp:106] Iteration 20450, lr = 1e-06
I0506 05:56:35.089082 26400 solver.cpp:228] Iteration 20500, loss = 0.0491317
I0506 05:56:35.089239 26400 solver.cpp:244]     Train net output #0: loss = 0.0491331 (* 1 = 0.0491331 loss)
I0506 05:56:35.089256 26400 sgd_solver.cpp:106] Iteration 20500, lr = 1e-06
I0506 05:58:45.027360 26400 solver.cpp:228] Iteration 20550, loss = -1.37091e-06
I0506 05:58:45.027503 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 05:58:45.027530 26400 sgd_solver.cpp:106] Iteration 20550, lr = 1e-06
I0506 06:00:52.230167 26400 solver.cpp:337] Iteration 20600, Testing net (#0)
I0506 06:01:07.539050 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 06:01:22.952976 26400 solver.cpp:404]     Test net output #0: loss = 0.106599 (* 1 = 0.106599 loss)
I0506 06:01:23.821593 26400 solver.cpp:228] Iteration 20600, loss = 0.0221313
I0506 06:01:23.821652 26400 solver.cpp:244]     Train net output #0: loss = 0.0221326 (* 1 = 0.0221326 loss)
I0506 06:01:23.821666 26400 sgd_solver.cpp:106] Iteration 20600, lr = 1e-06
I0506 06:03:33.469437 26400 solver.cpp:228] Iteration 20650, loss = 0.00255356
I0506 06:03:33.469909 26400 solver.cpp:244]     Train net output #0: loss = 0.00255492 (* 1 = 0.00255492 loss)
I0506 06:03:33.469925 26400 sgd_solver.cpp:106] Iteration 20650, lr = 1e-06
I0506 06:05:43.369968 26400 solver.cpp:228] Iteration 20700, loss = -1.3113e-06
I0506 06:05:43.370184 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:05:43.370225 26400 sgd_solver.cpp:106] Iteration 20700, lr = 1e-06
I0506 06:07:53.428174 26400 solver.cpp:228] Iteration 20750, loss = 0.0691996
I0506 06:07:53.428345 26400 solver.cpp:244]     Train net output #0: loss = 0.0692009 (* 1 = 0.0692009 loss)
I0506 06:07:53.428372 26400 sgd_solver.cpp:106] Iteration 20750, lr = 1e-06
I0506 06:10:00.774405 26400 solver.cpp:337] Iteration 20800, Testing net (#0)
I0506 06:10:47.934231 26400 solver.cpp:404]     Test net output #0: loss = 0.111813 (* 1 = 0.111813 loss)
I0506 06:10:48.796557 26400 solver.cpp:228] Iteration 20800, loss = 0.123214
I0506 06:10:48.796622 26400 solver.cpp:244]     Train net output #0: loss = 0.123216 (* 1 = 0.123216 loss)
I0506 06:10:48.796634 26400 sgd_solver.cpp:106] Iteration 20800, lr = 1e-06
I0506 06:12:59.384691 26400 solver.cpp:228] Iteration 20850, loss = 0.0283778
I0506 06:12:59.384827 26400 solver.cpp:244]     Train net output #0: loss = 0.0283791 (* 1 = 0.0283791 loss)
I0506 06:12:59.384842 26400 sgd_solver.cpp:106] Iteration 20850, lr = 1e-06
I0506 06:15:09.452157 26400 solver.cpp:228] Iteration 20900, loss = 0.00335888
I0506 06:15:09.452407 26400 solver.cpp:244]     Train net output #0: loss = 0.00336019 (* 1 = 0.00336019 loss)
I0506 06:15:09.452442 26400 sgd_solver.cpp:106] Iteration 20900, lr = 1e-06
I0506 06:17:19.222030 26400 solver.cpp:228] Iteration 20950, loss = -1.3113e-06
I0506 06:17:19.222259 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:17:19.222301 26400 sgd_solver.cpp:106] Iteration 20950, lr = 1e-06
I0506 06:19:26.297727 26400 solver.cpp:337] Iteration 21000, Testing net (#0)
I0506 06:19:53.909885 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 06:20:14.586642 26400 solver.cpp:404]     Test net output #0: loss = 0.115707 (* 1 = 0.115707 loss)
I0506 06:20:15.448451 26400 solver.cpp:228] Iteration 21000, loss = 0.0769346
I0506 06:20:15.448506 26400 solver.cpp:244]     Train net output #0: loss = 0.0769359 (* 1 = 0.0769359 loss)
I0506 06:20:15.448539 26400 sgd_solver.cpp:106] Iteration 21000, lr = 1e-06
I0506 06:22:25.889652 26400 solver.cpp:228] Iteration 21050, loss = 0.0462888
I0506 06:22:25.889886 26400 solver.cpp:244]     Train net output #0: loss = 0.0462901 (* 1 = 0.0462901 loss)
I0506 06:22:25.889943 26400 sgd_solver.cpp:106] Iteration 21050, lr = 1e-06
I0506 06:24:36.120203 26400 solver.cpp:228] Iteration 21100, loss = 0.0381342
I0506 06:24:36.121296 26400 solver.cpp:244]     Train net output #0: loss = 0.0381354 (* 1 = 0.0381354 loss)
I0506 06:24:36.121343 26400 sgd_solver.cpp:106] Iteration 21100, lr = 1e-06
I0506 06:26:46.188302 26400 solver.cpp:228] Iteration 21150, loss = 0.0533363
I0506 06:26:46.188881 26400 solver.cpp:244]     Train net output #0: loss = 0.0533376 (* 1 = 0.0533376 loss)
I0506 06:26:46.188904 26400 sgd_solver.cpp:106] Iteration 21150, lr = 1e-06
I0506 06:28:53.389392 26400 solver.cpp:337] Iteration 21200, Testing net (#0)
I0506 06:29:48.904261 26400 solver.cpp:404]     Test net output #0: loss = 0.11913 (* 1 = 0.11913 loss)
I0506 06:29:49.766988 26400 solver.cpp:228] Iteration 21200, loss = 0.0332539
I0506 06:29:49.767051 26400 solver.cpp:244]     Train net output #0: loss = 0.0332552 (* 1 = 0.0332552 loss)
I0506 06:29:49.767077 26400 sgd_solver.cpp:106] Iteration 21200, lr = 1e-06
I0506 06:32:00.451443 26400 solver.cpp:228] Iteration 21250, loss = 0.0257991
I0506 06:32:00.463992 26400 solver.cpp:244]     Train net output #0: loss = 0.0258003 (* 1 = 0.0258003 loss)
I0506 06:32:00.464017 26400 sgd_solver.cpp:106] Iteration 21250, lr = 1e-06
I0506 06:34:10.554565 26400 solver.cpp:228] Iteration 21300, loss = -1.2219e-06
I0506 06:34:10.559012 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:34:10.559037 26400 sgd_solver.cpp:106] Iteration 21300, lr = 1e-06
I0506 06:36:20.247390 26400 solver.cpp:228] Iteration 21350, loss = 0.0174387
I0506 06:36:20.247586 26400 solver.cpp:244]     Train net output #0: loss = 0.01744 (* 1 = 0.01744 loss)
I0506 06:36:20.247601 26400 sgd_solver.cpp:106] Iteration 21350, lr = 1e-06
I0506 06:38:27.482303 26400 solver.cpp:337] Iteration 21400, Testing net (#0)
I0506 06:38:48.689957 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 06:38:57.701906 26400 solver.cpp:404]     Test net output #0: loss = 0.109347 (* 1 = 0.109347 loss)
I0506 06:38:58.578372 26400 solver.cpp:228] Iteration 21400, loss = -1.2815e-06
I0506 06:38:58.578430 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:38:58.578444 26400 sgd_solver.cpp:106] Iteration 21400, lr = 1e-06
I0506 06:41:08.483206 26400 solver.cpp:228] Iteration 21450, loss = -1.2815e-06
I0506 06:41:08.483371 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:41:08.483386 26400 sgd_solver.cpp:106] Iteration 21450, lr = 1e-06
I0506 06:43:18.473920 26400 solver.cpp:228] Iteration 21500, loss = 0.0210886
I0506 06:43:18.474156 26400 solver.cpp:244]     Train net output #0: loss = 0.0210899 (* 1 = 0.0210899 loss)
I0506 06:43:18.474191 26400 sgd_solver.cpp:106] Iteration 21500, lr = 1e-06
I0506 06:45:28.657872 26400 solver.cpp:228] Iteration 21550, loss = 0.0411871
I0506 06:45:28.658010 26400 solver.cpp:244]     Train net output #0: loss = 0.0411883 (* 1 = 0.0411883 loss)
I0506 06:45:28.658025 26400 sgd_solver.cpp:106] Iteration 21550, lr = 1e-06
I0506 06:47:36.253393 26400 solver.cpp:337] Iteration 21600, Testing net (#0)
I0506 06:48:06.263820 26400 solver.cpp:404]     Test net output #0: loss = 0.112304 (* 1 = 0.112304 loss)
I0506 06:48:07.133096 26400 solver.cpp:228] Iteration 21600, loss = -1.2517e-06
I0506 06:48:07.133141 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:48:07.133167 26400 sgd_solver.cpp:106] Iteration 21600, lr = 1e-06
I0506 06:50:17.042253 26400 solver.cpp:228] Iteration 21650, loss = 0.0496097
I0506 06:50:17.043452 26400 solver.cpp:244]     Train net output #0: loss = 0.0496109 (* 1 = 0.0496109 loss)
I0506 06:50:17.043488 26400 sgd_solver.cpp:106] Iteration 21650, lr = 1e-06
I0506 06:52:27.018913 26400 solver.cpp:228] Iteration 21700, loss = 0.0755899
I0506 06:52:27.019091 26400 solver.cpp:244]     Train net output #0: loss = 0.0755911 (* 1 = 0.0755911 loss)
I0506 06:52:27.019106 26400 sgd_solver.cpp:106] Iteration 21700, lr = 1e-06
I0506 06:54:36.800432 26400 solver.cpp:228] Iteration 21750, loss = -1.23307e-06
I0506 06:54:36.800899 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 06:54:36.801025 26400 sgd_solver.cpp:106] Iteration 21750, lr = 1e-06
I0506 06:56:44.123019 26400 solver.cpp:337] Iteration 21800, Testing net (#0)
I0506 06:57:14.283438 26400 solver.cpp:404]     Test net output #0: loss = 0.0862611 (* 1 = 0.0862611 loss)
I0506 06:57:15.151751 26400 solver.cpp:228] Iteration 21800, loss = 0.098901
I0506 06:57:15.151813 26400 solver.cpp:244]     Train net output #0: loss = 0.0989022 (* 1 = 0.0989022 loss)
I0506 06:57:15.151828 26400 sgd_solver.cpp:106] Iteration 21800, lr = 1e-06
I0506 06:59:25.277614 26400 solver.cpp:228] Iteration 21850, loss = 0.0438667
I0506 06:59:25.277853 26400 solver.cpp:244]     Train net output #0: loss = 0.0438679 (* 1 = 0.0438679 loss)
I0506 06:59:25.277889 26400 sgd_solver.cpp:106] Iteration 21850, lr = 1e-06
I0506 07:01:35.032292 26400 solver.cpp:228] Iteration 21900, loss = 0.0603859
I0506 07:01:35.035595 26400 solver.cpp:244]     Train net output #0: loss = 0.0603871 (* 1 = 0.0603871 loss)
I0506 07:01:35.035624 26400 sgd_solver.cpp:106] Iteration 21900, lr = 1e-06
I0506 07:03:44.924159 26400 solver.cpp:228] Iteration 21950, loss = 0.00959905
I0506 07:03:44.936671 26400 solver.cpp:244]     Train net output #0: loss = 0.00960028 (* 1 = 0.00960028 loss)
I0506 07:03:44.936717 26400 sgd_solver.cpp:106] Iteration 21950, lr = 1e-06
I0506 07:05:52.378069 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_22000.caffemodel
I0506 07:06:01.448623 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_22000.solverstate
I0506 07:06:01.504067 26400 solver.cpp:337] Iteration 22000, Testing net (#0)
I0506 07:06:19.121104 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 07:06:29.901546 26400 solver.cpp:404]     Test net output #0: loss = 0.104067 (* 1 = 0.104067 loss)
I0506 07:06:30.767979 26400 solver.cpp:228] Iteration 22000, loss = 0.057287
I0506 07:06:30.768034 26400 solver.cpp:244]     Train net output #0: loss = 0.0572882 (* 1 = 0.0572882 loss)
I0506 07:06:30.768050 26400 sgd_solver.cpp:106] Iteration 22000, lr = 1e-06
I0506 07:08:40.839615 26400 solver.cpp:228] Iteration 22050, loss = 0.00108925
I0506 07:08:40.841987 26400 solver.cpp:244]     Train net output #0: loss = 0.00109046 (* 1 = 0.00109046 loss)
I0506 07:08:40.842028 26400 sgd_solver.cpp:106] Iteration 22050, lr = 1e-06
I0506 07:10:50.756376 26400 solver.cpp:228] Iteration 22100, loss = 0.0933478
I0506 07:10:50.756628 26400 solver.cpp:244]     Train net output #0: loss = 0.0933491 (* 1 = 0.0933491 loss)
I0506 07:10:50.756676 26400 sgd_solver.cpp:106] Iteration 22100, lr = 1e-06
I0506 07:13:00.676398 26400 solver.cpp:228] Iteration 22150, loss = -1.2368e-06
I0506 07:13:00.676592 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 07:13:00.676609 26400 sgd_solver.cpp:106] Iteration 22150, lr = 1e-06
I0506 07:15:08.029340 26400 solver.cpp:337] Iteration 22200, Testing net (#0)
I0506 07:15:38.284806 26400 solver.cpp:404]     Test net output #0: loss = 0.118733 (* 1 = 0.118733 loss)
I0506 07:15:39.161442 26400 solver.cpp:228] Iteration 22200, loss = 0.038655
I0506 07:15:39.161507 26400 solver.cpp:244]     Train net output #0: loss = 0.0386562 (* 1 = 0.0386562 loss)
I0506 07:15:39.161525 26400 sgd_solver.cpp:106] Iteration 22200, lr = 1e-06
I0506 07:17:49.156862 26400 solver.cpp:228] Iteration 22250, loss = 0.0858184
I0506 07:17:49.157068 26400 solver.cpp:244]     Train net output #0: loss = 0.0858196 (* 1 = 0.0858196 loss)
I0506 07:17:49.157095 26400 sgd_solver.cpp:106] Iteration 22250, lr = 1e-06
I0506 07:19:58.956936 26400 solver.cpp:228] Iteration 22300, loss = -1.24425e-06
I0506 07:19:58.957160 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 07:19:58.957211 26400 sgd_solver.cpp:106] Iteration 22300, lr = 1e-06
I0506 07:22:09.021772 26400 solver.cpp:228] Iteration 22350, loss = 0.00580044
I0506 07:22:09.021966 26400 solver.cpp:244]     Train net output #0: loss = 0.00580169 (* 1 = 0.00580169 loss)
I0506 07:22:09.022014 26400 sgd_solver.cpp:106] Iteration 22350, lr = 1e-06
I0506 07:24:16.341234 26400 solver.cpp:337] Iteration 22400, Testing net (#0)
I0506 07:24:57.709487 26400 solver.cpp:404]     Test net output #0: loss = 0.129859 (* 1 = 0.129859 loss)
I0506 07:24:58.571846 26400 solver.cpp:228] Iteration 22400, loss = -1.2219e-06
I0506 07:24:58.571892 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 07:24:58.571918 26400 sgd_solver.cpp:106] Iteration 22400, lr = 1e-06
I0506 07:27:08.797966 26400 solver.cpp:228] Iteration 22450, loss = 0.0312075
I0506 07:27:08.798192 26400 solver.cpp:244]     Train net output #0: loss = 0.0312087 (* 1 = 0.0312087 loss)
I0506 07:27:08.798218 26400 sgd_solver.cpp:106] Iteration 22450, lr = 1e-06
I0506 07:29:18.745023 26400 solver.cpp:228] Iteration 22500, loss = 0.0522183
I0506 07:29:18.746729 26400 solver.cpp:244]     Train net output #0: loss = 0.0522195 (* 1 = 0.0522195 loss)
I0506 07:29:18.746749 26400 sgd_solver.cpp:106] Iteration 22500, lr = 1e-06
I0506 07:31:28.506445 26400 solver.cpp:228] Iteration 22550, loss = 0.0194114
I0506 07:31:28.508004 26400 solver.cpp:244]     Train net output #0: loss = 0.0194126 (* 1 = 0.0194126 loss)
I0506 07:31:28.508023 26400 sgd_solver.cpp:106] Iteration 22550, lr = 1e-06
I0506 07:33:36.090073 26400 solver.cpp:337] Iteration 22600, Testing net (#0)
I0506 07:33:45.470336 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 07:34:27.842819 26400 solver.cpp:404]     Test net output #0: loss = 0.121575 (* 1 = 0.121575 loss)
I0506 07:34:28.702726 26400 solver.cpp:228] Iteration 22600, loss = 0.012742
I0506 07:34:28.702785 26400 solver.cpp:244]     Train net output #0: loss = 0.0127432 (* 1 = 0.0127432 loss)
I0506 07:34:28.702798 26400 sgd_solver.cpp:106] Iteration 22600, lr = 1e-06
I0506 07:36:39.216447 26400 solver.cpp:228] Iteration 22650, loss = 0.0385082
I0506 07:36:39.216821 26400 solver.cpp:244]     Train net output #0: loss = 0.0385095 (* 1 = 0.0385095 loss)
I0506 07:36:39.216936 26400 sgd_solver.cpp:106] Iteration 22650, lr = 1e-06
I0506 07:38:49.379058 26400 solver.cpp:228] Iteration 22700, loss = 0.0242826
I0506 07:38:49.379292 26400 solver.cpp:244]     Train net output #0: loss = 0.0242839 (* 1 = 0.0242839 loss)
I0506 07:38:49.379338 26400 sgd_solver.cpp:106] Iteration 22700, lr = 1e-06
I0506 07:40:59.366446 26400 solver.cpp:228] Iteration 22750, loss = 0.0502465
I0506 07:40:59.367440 26400 solver.cpp:244]     Train net output #0: loss = 0.0502479 (* 1 = 0.0502479 loss)
I0506 07:40:59.367462 26400 sgd_solver.cpp:106] Iteration 22750, lr = 1e-06
I0506 07:43:06.392803 26400 solver.cpp:337] Iteration 22800, Testing net (#0)
I0506 07:43:49.494524 26400 solver.cpp:404]     Test net output #0: loss = 0.13361 (* 1 = 0.13361 loss)
I0506 07:43:50.357638 26400 solver.cpp:228] Iteration 22800, loss = 0.316239
I0506 07:43:50.357688 26400 solver.cpp:244]     Train net output #0: loss = 0.316241 (* 1 = 0.316241 loss)
I0506 07:43:50.357728 26400 sgd_solver.cpp:106] Iteration 22800, lr = 1e-06
I0506 07:46:00.517737 26400 solver.cpp:228] Iteration 22850, loss = -1.30385e-06
I0506 07:46:00.518396 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 07:46:00.518425 26400 sgd_solver.cpp:106] Iteration 22850, lr = 1e-06
I0506 07:48:10.395784 26400 solver.cpp:228] Iteration 22900, loss = 0.0188579
I0506 07:48:10.395946 26400 solver.cpp:244]     Train net output #0: loss = 0.0188591 (* 1 = 0.0188591 loss)
I0506 07:48:10.395961 26400 sgd_solver.cpp:106] Iteration 22900, lr = 1e-06
I0506 07:50:20.234988 26400 solver.cpp:228] Iteration 22950, loss = 0.0772876
I0506 07:50:20.241425 26400 solver.cpp:244]     Train net output #0: loss = 0.0772888 (* 1 = 0.0772888 loss)
I0506 07:50:20.241477 26400 sgd_solver.cpp:106] Iteration 22950, lr = 1e-06
I0506 07:52:27.536643 26400 solver.cpp:337] Iteration 23000, Testing net (#0)
I0506 07:52:39.970017 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 07:53:16.561040 26400 solver.cpp:404]     Test net output #0: loss = 0.122949 (* 1 = 0.122949 loss)
I0506 07:53:17.425918 26400 solver.cpp:228] Iteration 23000, loss = 0.105248
I0506 07:53:17.425961 26400 solver.cpp:244]     Train net output #0: loss = 0.105249 (* 1 = 0.105249 loss)
I0506 07:53:17.425974 26400 sgd_solver.cpp:106] Iteration 23000, lr = 1e-06
I0506 07:55:27.960984 26400 solver.cpp:228] Iteration 23050, loss = 0.0129675
I0506 07:55:27.961160 26400 solver.cpp:244]     Train net output #0: loss = 0.0129688 (* 1 = 0.0129688 loss)
I0506 07:55:27.961181 26400 sgd_solver.cpp:106] Iteration 23050, lr = 1e-06
I0506 07:57:37.870769 26400 solver.cpp:228] Iteration 23100, loss = 0.0366015
I0506 07:57:37.870997 26400 solver.cpp:244]     Train net output #0: loss = 0.0366027 (* 1 = 0.0366027 loss)
I0506 07:57:37.871019 26400 sgd_solver.cpp:106] Iteration 23100, lr = 1e-06
I0506 07:59:47.754837 26400 solver.cpp:228] Iteration 23150, loss = -1.25915e-06
I0506 07:59:47.755682 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 07:59:47.755700 26400 sgd_solver.cpp:106] Iteration 23150, lr = 1e-06
I0506 08:01:54.943143 26400 solver.cpp:337] Iteration 23200, Testing net (#0)
I0506 08:02:37.830466 26400 solver.cpp:404]     Test net output #0: loss = 0.129304 (* 1 = 0.129304 loss)
I0506 08:02:38.694526 26400 solver.cpp:228] Iteration 23200, loss = -1.2517e-06
I0506 08:02:38.694581 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:02:38.694602 26400 sgd_solver.cpp:106] Iteration 23200, lr = 1e-06
I0506 08:04:48.788731 26400 solver.cpp:228] Iteration 23250, loss = 0.054772
I0506 08:04:48.791528 26400 solver.cpp:244]     Train net output #0: loss = 0.0547733 (* 1 = 0.0547733 loss)
I0506 08:04:48.791563 26400 sgd_solver.cpp:106] Iteration 23250, lr = 1e-06
I0506 08:06:58.486671 26400 solver.cpp:228] Iteration 23300, loss = -1.2815e-06
I0506 08:06:58.488939 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:06:58.488986 26400 sgd_solver.cpp:106] Iteration 23300, lr = 1e-06
I0506 08:09:08.197139 26400 solver.cpp:228] Iteration 23350, loss = 0.025419
I0506 08:09:08.197918 26400 solver.cpp:244]     Train net output #0: loss = 0.0254203 (* 1 = 0.0254203 loss)
I0506 08:09:08.197950 26400 sgd_solver.cpp:106] Iteration 23350, lr = 1e-06
I0506 08:11:15.364022 26400 solver.cpp:337] Iteration 23400, Testing net (#0)
I0506 08:11:27.973302 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 08:11:48.015416 26400 solver.cpp:404]     Test net output #0: loss = 0.102361 (* 1 = 0.102361 loss)
I0506 08:11:48.881786 26400 solver.cpp:228] Iteration 23400, loss = -1.27405e-06
I0506 08:11:48.881845 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:11:48.881875 26400 sgd_solver.cpp:106] Iteration 23400, lr = 1e-06
I0506 08:13:58.691495 26400 solver.cpp:228] Iteration 23450, loss = 0.108316
I0506 08:13:58.691944 26400 solver.cpp:244]     Train net output #0: loss = 0.108318 (* 1 = 0.108318 loss)
I0506 08:13:58.691994 26400 sgd_solver.cpp:106] Iteration 23450, lr = 1e-06
I0506 08:16:08.474485 26400 solver.cpp:228] Iteration 23500, loss = 0.0267541
I0506 08:16:08.474673 26400 solver.cpp:244]     Train net output #0: loss = 0.0267553 (* 1 = 0.0267553 loss)
I0506 08:16:08.474695 26400 sgd_solver.cpp:106] Iteration 23500, lr = 1e-06
I0506 08:18:18.200664 26400 solver.cpp:228] Iteration 23550, loss = -1.20699e-06
I0506 08:18:18.200830 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:18:18.200846 26400 sgd_solver.cpp:106] Iteration 23550, lr = 1e-06
I0506 08:20:25.256273 26400 solver.cpp:337] Iteration 23600, Testing net (#0)
I0506 08:21:08.183408 26400 solver.cpp:404]     Test net output #0: loss = 0.116345 (* 1 = 0.116345 loss)
I0506 08:21:09.054175 26400 solver.cpp:228] Iteration 23600, loss = 0.0255063
I0506 08:21:09.054226 26400 solver.cpp:244]     Train net output #0: loss = 0.0255075 (* 1 = 0.0255075 loss)
I0506 08:21:09.054242 26400 sgd_solver.cpp:106] Iteration 23600, lr = 1e-06
I0506 08:23:19.277269 26400 solver.cpp:228] Iteration 23650, loss = 0.0216482
I0506 08:23:19.277472 26400 solver.cpp:244]     Train net output #0: loss = 0.0216494 (* 1 = 0.0216494 loss)
I0506 08:23:19.277519 26400 sgd_solver.cpp:106] Iteration 23650, lr = 1e-06
I0506 08:25:29.286273 26400 solver.cpp:228] Iteration 23700, loss = 0.233871
I0506 08:25:29.287174 26400 solver.cpp:244]     Train net output #0: loss = 0.233873 (* 1 = 0.233873 loss)
I0506 08:25:29.287212 26400 sgd_solver.cpp:106] Iteration 23700, lr = 1e-06
I0506 08:27:39.146224 26400 solver.cpp:228] Iteration 23750, loss = 0.11039
I0506 08:27:39.148108 26400 solver.cpp:244]     Train net output #0: loss = 0.110391 (* 1 = 0.110391 loss)
I0506 08:27:39.148134 26400 sgd_solver.cpp:106] Iteration 23750, lr = 1e-06
I0506 08:29:46.326547 26400 solver.cpp:337] Iteration 23800, Testing net (#0)
I0506 08:30:12.694377 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 08:30:37.777582 26400 solver.cpp:404]     Test net output #0: loss = 0.142831 (* 1 = 0.142831 loss)
I0506 08:30:38.635984 26400 solver.cpp:228] Iteration 23800, loss = -1.18406e-06
I0506 08:30:38.636039 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:30:38.636062 26400 sgd_solver.cpp:106] Iteration 23800, lr = 1e-06
I0506 08:32:49.413321 26400 solver.cpp:228] Iteration 23850, loss = 0.0517289
I0506 08:32:49.428366 26400 solver.cpp:244]     Train net output #0: loss = 0.05173 (* 1 = 0.05173 loss)
I0506 08:32:49.428395 26400 sgd_solver.cpp:106] Iteration 23850, lr = 1e-06
I0506 08:34:59.504354 26400 solver.cpp:228] Iteration 23900, loss = -1.19954e-06
I0506 08:34:59.504523 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:34:59.504539 26400 sgd_solver.cpp:106] Iteration 23900, lr = 1e-06
I0506 08:37:09.421026 26400 solver.cpp:228] Iteration 23950, loss = -1.16974e-06
I0506 08:37:09.421181 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:37:09.421203 26400 sgd_solver.cpp:106] Iteration 23950, lr = 1e-06
I0506 08:39:16.772908 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_24000.caffemodel
I0506 08:39:23.803575 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_24000.solverstate
I0506 08:39:23.865362 26400 solver.cpp:337] Iteration 24000, Testing net (#0)
I0506 08:39:52.353600 26400 solver.cpp:404]     Test net output #0: loss = 0.104846 (* 1 = 0.104846 loss)
I0506 08:39:53.225955 26400 solver.cpp:228] Iteration 24000, loss = -1.16229e-06
I0506 08:39:53.226012 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:39:53.226027 26400 sgd_solver.cpp:106] Iteration 24000, lr = 1e-06
I0506 08:42:03.230496 26400 solver.cpp:228] Iteration 24050, loss = 0.0309424
I0506 08:42:03.231106 26400 solver.cpp:244]     Train net output #0: loss = 0.0309436 (* 1 = 0.0309436 loss)
I0506 08:42:03.231127 26400 sgd_solver.cpp:106] Iteration 24050, lr = 1e-06
I0506 08:44:13.142734 26400 solver.cpp:228] Iteration 24100, loss = -1.16229e-06
I0506 08:44:13.142937 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:44:13.142979 26400 sgd_solver.cpp:106] Iteration 24100, lr = 1e-06
I0506 08:46:23.295222 26400 solver.cpp:228] Iteration 24150, loss = -1.18464e-06
I0506 08:46:23.295934 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:46:23.295979 26400 sgd_solver.cpp:106] Iteration 24150, lr = 1e-06
I0506 08:48:30.855357 26400 solver.cpp:337] Iteration 24200, Testing net (#0)
I0506 08:48:51.215311 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 08:49:01.091655 26400 solver.cpp:404]     Test net output #0: loss = 0.125457 (* 1 = 0.125457 loss)
I0506 08:49:01.958364 26400 solver.cpp:228] Iteration 24200, loss = -1.16229e-06
I0506 08:49:01.958425 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:49:01.958439 26400 sgd_solver.cpp:106] Iteration 24200, lr = 1e-06
I0506 08:51:12.239457 26400 solver.cpp:228] Iteration 24250, loss = -1.19209e-06
I0506 08:51:12.239603 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 08:51:12.239619 26400 sgd_solver.cpp:106] Iteration 24250, lr = 1e-06
I0506 08:53:22.414646 26400 solver.cpp:228] Iteration 24300, loss = 0.0654087
I0506 08:53:22.414888 26400 solver.cpp:244]     Train net output #0: loss = 0.0654099 (* 1 = 0.0654099 loss)
I0506 08:53:22.414959 26400 sgd_solver.cpp:106] Iteration 24300, lr = 1e-06
I0506 08:55:32.093255 26400 solver.cpp:228] Iteration 24350, loss = 0.049191
I0506 08:55:32.093461 26400 solver.cpp:244]     Train net output #0: loss = 0.0491922 (* 1 = 0.0491922 loss)
I0506 08:55:32.093477 26400 sgd_solver.cpp:106] Iteration 24350, lr = 1e-06
I0506 08:57:39.613903 26400 solver.cpp:337] Iteration 24400, Testing net (#0)
I0506 08:58:10.480196 26400 solver.cpp:404]     Test net output #0: loss = 0.109389 (* 1 = 0.109389 loss)
I0506 08:58:11.349961 26400 solver.cpp:228] Iteration 24400, loss = 0.481605
I0506 08:58:11.350018 26400 solver.cpp:244]     Train net output #0: loss = 0.481606 (* 1 = 0.481606 loss)
I0506 08:58:11.350033 26400 sgd_solver.cpp:106] Iteration 24400, lr = 1e-06
I0506 09:00:21.077414 26400 solver.cpp:228] Iteration 24450, loss = -1.2219e-06
I0506 09:00:21.090004 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:00:21.090030 26400 sgd_solver.cpp:106] Iteration 24450, lr = 1e-06
I0506 09:02:30.749832 26400 solver.cpp:228] Iteration 24500, loss = 0.0316685
I0506 09:02:30.750092 26400 solver.cpp:244]     Train net output #0: loss = 0.0316697 (* 1 = 0.0316697 loss)
I0506 09:02:30.750133 26400 sgd_solver.cpp:106] Iteration 24500, lr = 1e-06
I0506 09:04:40.913013 26400 solver.cpp:228] Iteration 24550, loss = 0.0174263
I0506 09:04:40.913132 26400 solver.cpp:244]     Train net output #0: loss = 0.0174275 (* 1 = 0.0174275 loss)
I0506 09:04:40.913147 26400 sgd_solver.cpp:106] Iteration 24550, lr = 1e-06
I0506 09:06:48.195632 26400 solver.cpp:337] Iteration 24600, Testing net (#0)
I0506 09:07:19.670610 26400 solver.cpp:404]     Test net output #0: loss = 0.147692 (* 1 = 0.147692 loss)
I0506 09:07:20.550603 26400 solver.cpp:228] Iteration 24600, loss = 0.0246079
I0506 09:07:20.550653 26400 solver.cpp:244]     Train net output #0: loss = 0.0246091 (* 1 = 0.0246091 loss)
I0506 09:07:20.550667 26400 sgd_solver.cpp:106] Iteration 24600, lr = 1e-06
I0506 09:09:30.830051 26400 solver.cpp:228] Iteration 24650, loss = -1.13249e-06
I0506 09:09:30.830216 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:09:30.830237 26400 sgd_solver.cpp:106] Iteration 24650, lr = 1e-06
I0506 09:11:40.559926 26400 solver.cpp:228] Iteration 24700, loss = 0.00568813
I0506 09:11:40.561455 26400 solver.cpp:244]     Train net output #0: loss = 0.00568925 (* 1 = 0.00568925 loss)
I0506 09:11:40.561477 26400 sgd_solver.cpp:106] Iteration 24700, lr = 1e-06
I0506 09:13:50.462796 26400 solver.cpp:228] Iteration 24750, loss = 0.135915
I0506 09:13:50.463826 26400 solver.cpp:244]     Train net output #0: loss = 0.135917 (* 1 = 0.135917 loss)
I0506 09:13:50.463845 26400 sgd_solver.cpp:106] Iteration 24750, lr = 1e-06
I0506 09:15:58.057030 26400 solver.cpp:337] Iteration 24800, Testing net (#0)
I0506 09:16:04.620667 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 09:16:29.103996 26400 solver.cpp:404]     Test net output #0: loss = 0.110258 (* 1 = 0.110258 loss)
I0506 09:16:29.970121 26400 solver.cpp:228] Iteration 24800, loss = -1.06543e-06
I0506 09:16:29.970176 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:16:29.970191 26400 sgd_solver.cpp:106] Iteration 24800, lr = 1e-06
I0506 09:18:39.404695 26400 solver.cpp:228] Iteration 24850, loss = -1.07288e-06
I0506 09:18:39.404866 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:18:39.404883 26400 sgd_solver.cpp:106] Iteration 24850, lr = 1e-06
I0506 09:20:49.595317 26400 solver.cpp:228] Iteration 24900, loss = -1.03004e-06
I0506 09:20:49.595489 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:20:49.595507 26400 sgd_solver.cpp:106] Iteration 24900, lr = 1e-06
I0506 09:22:59.776608 26400 solver.cpp:228] Iteration 24950, loss = -1.01328e-06
I0506 09:22:59.776904 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:22:59.776964 26400 sgd_solver.cpp:106] Iteration 24950, lr = 1e-06
I0506 09:25:06.686426 26400 solver.cpp:337] Iteration 25000, Testing net (#0)
I0506 09:25:39.115845 26400 solver.cpp:404]     Test net output #0: loss = 0.106202 (* 1 = 0.106202 loss)
I0506 09:25:39.983822 26400 solver.cpp:228] Iteration 25000, loss = -1.017e-06
I0506 09:25:39.983880 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:25:39.983894 26400 sgd_solver.cpp:106] Iteration 25000, lr = 1e-06
I0506 09:27:49.882364 26400 solver.cpp:228] Iteration 25050, loss = -1.01142e-06
I0506 09:27:49.882519 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:27:49.882534 26400 sgd_solver.cpp:106] Iteration 25050, lr = 1e-06
I0506 09:29:59.465720 26400 solver.cpp:228] Iteration 25100, loss = 0.0637076
I0506 09:29:59.478261 26400 solver.cpp:244]     Train net output #0: loss = 0.0637086 (* 1 = 0.0637086 loss)
I0506 09:29:59.478286 26400 sgd_solver.cpp:106] Iteration 25100, lr = 1e-06
I0506 09:32:09.500080 26400 solver.cpp:228] Iteration 25150, loss = -1.01328e-06
I0506 09:32:09.500260 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:32:09.500277 26400 sgd_solver.cpp:106] Iteration 25150, lr = 1e-06
I0506 09:34:16.958663 26400 solver.cpp:337] Iteration 25200, Testing net (#0)
I0506 09:34:31.059931 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 09:34:51.341639 26400 solver.cpp:404]     Test net output #0: loss = 0.136526 (* 1 = 0.136526 loss)
I0506 09:34:52.206959 26400 solver.cpp:228] Iteration 25200, loss = 0.00273997
I0506 09:34:52.207005 26400 solver.cpp:244]     Train net output #0: loss = 0.00274102 (* 1 = 0.00274102 loss)
I0506 09:34:52.207034 26400 sgd_solver.cpp:106] Iteration 25200, lr = 1e-06
I0506 09:37:02.452287 26400 solver.cpp:228] Iteration 25250, loss = 0.0532571
I0506 09:37:02.452534 26400 solver.cpp:244]     Train net output #0: loss = 0.0532581 (* 1 = 0.0532581 loss)
I0506 09:37:02.452579 26400 sgd_solver.cpp:106] Iteration 25250, lr = 1e-06
I0506 09:39:12.115378 26400 solver.cpp:228] Iteration 25300, loss = 0.05652
I0506 09:39:12.117862 26400 solver.cpp:244]     Train net output #0: loss = 0.056521 (* 1 = 0.056521 loss)
I0506 09:39:12.117880 26400 sgd_solver.cpp:106] Iteration 25300, lr = 1e-06
I0506 09:41:22.010282 26400 solver.cpp:228] Iteration 25350, loss = 0.0504628
I0506 09:41:22.010475 26400 solver.cpp:244]     Train net output #0: loss = 0.0504638 (* 1 = 0.0504638 loss)
I0506 09:41:22.010505 26400 sgd_solver.cpp:106] Iteration 25350, lr = 1e-06
I0506 09:43:29.237344 26400 solver.cpp:337] Iteration 25400, Testing net (#0)
I0506 09:44:20.394564 26400 solver.cpp:404]     Test net output #0: loss = 0.112341 (* 1 = 0.112341 loss)
I0506 09:44:21.253653 26400 solver.cpp:228] Iteration 25400, loss = 0.0346663
I0506 09:44:21.253713 26400 solver.cpp:244]     Train net output #0: loss = 0.0346673 (* 1 = 0.0346673 loss)
I0506 09:44:21.253736 26400 sgd_solver.cpp:106] Iteration 25400, lr = 1e-06
I0506 09:46:32.018013 26400 solver.cpp:228] Iteration 25450, loss = -1.04308e-06
I0506 09:46:32.018232 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 09:46:32.018275 26400 sgd_solver.cpp:106] Iteration 25450, lr = 1e-06
I0506 09:48:42.257962 26400 solver.cpp:228] Iteration 25500, loss = 0.00982745
I0506 09:48:42.258215 26400 solver.cpp:244]     Train net output #0: loss = 0.00982849 (* 1 = 0.00982849 loss)
I0506 09:48:42.258271 26400 sgd_solver.cpp:106] Iteration 25500, lr = 1e-06
I0506 09:50:51.885421 26400 solver.cpp:228] Iteration 25550, loss = 0.0978154
I0506 09:50:51.885843 26400 solver.cpp:244]     Train net output #0: loss = 0.0978165 (* 1 = 0.0978165 loss)
I0506 09:50:51.885882 26400 sgd_solver.cpp:106] Iteration 25550, lr = 1e-06
I0506 09:52:59.244024 26400 solver.cpp:337] Iteration 25600, Testing net (#0)
I0506 09:53:19.708829 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 09:53:45.440500 26400 solver.cpp:404]     Test net output #0: loss = 0.102806 (* 1 = 0.102806 loss)
I0506 09:53:46.304500 26400 solver.cpp:228] Iteration 25600, loss = 0.0339236
I0506 09:53:46.304663 26400 solver.cpp:244]     Train net output #0: loss = 0.0339246 (* 1 = 0.0339246 loss)
I0506 09:53:46.304713 26400 sgd_solver.cpp:106] Iteration 25600, lr = 1e-06
I0506 09:55:56.752190 26400 solver.cpp:228] Iteration 25650, loss = 0.0296162
I0506 09:55:56.758992 26400 solver.cpp:244]     Train net output #0: loss = 0.0296173 (* 1 = 0.0296173 loss)
I0506 09:55:56.759028 26400 sgd_solver.cpp:106] Iteration 25650, lr = 1e-06
I0506 09:58:06.931854 26400 solver.cpp:228] Iteration 25700, loss = 0.0184034
I0506 09:58:06.932024 26400 solver.cpp:244]     Train net output #0: loss = 0.0184045 (* 1 = 0.0184045 loss)
I0506 09:58:06.932044 26400 sgd_solver.cpp:106] Iteration 25700, lr = 1e-06
I0506 10:00:16.591295 26400 solver.cpp:228] Iteration 25750, loss = -1.07661e-06
I0506 10:00:16.604754 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:00:16.604781 26400 sgd_solver.cpp:106] Iteration 25750, lr = 1e-06
I0506 10:02:23.690235 26400 solver.cpp:337] Iteration 25800, Testing net (#0)
I0506 10:03:07.771580 26400 solver.cpp:404]     Test net output #0: loss = 0.114598 (* 1 = 0.114598 loss)
I0506 10:03:08.635097 26400 solver.cpp:228] Iteration 25800, loss = 0.428037
I0506 10:03:08.635150 26400 solver.cpp:244]     Train net output #0: loss = 0.428038 (* 1 = 0.428038 loss)
I0506 10:03:08.635165 26400 sgd_solver.cpp:106] Iteration 25800, lr = 1e-06
I0506 10:05:18.471068 26400 solver.cpp:228] Iteration 25850, loss = 0.155176
I0506 10:05:18.471288 26400 solver.cpp:244]     Train net output #0: loss = 0.155177 (* 1 = 0.155177 loss)
I0506 10:05:18.471333 26400 sgd_solver.cpp:106] Iteration 25850, lr = 1e-06
I0506 10:07:28.307663 26400 solver.cpp:228] Iteration 25900, loss = -1.10269e-06
I0506 10:07:28.307868 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:07:28.307910 26400 sgd_solver.cpp:106] Iteration 25900, lr = 1e-06
I0506 10:09:38.331903 26400 solver.cpp:228] Iteration 25950, loss = 0.0177218
I0506 10:09:38.332124 26400 solver.cpp:244]     Train net output #0: loss = 0.0177229 (* 1 = 0.0177229 loss)
I0506 10:09:38.332160 26400 sgd_solver.cpp:106] Iteration 25950, lr = 1e-06
I0506 10:11:45.350977 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_26000.caffemodel
I0506 10:11:51.325142 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_26000.solverstate
I0506 10:11:51.395305 26400 solver.cpp:337] Iteration 26000, Testing net (#0)
I0506 10:12:10.990928 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 10:12:36.222934 26400 solver.cpp:404]     Test net output #0: loss = 0.121472 (* 1 = 0.121472 loss)
I0506 10:12:37.083537 26400 solver.cpp:228] Iteration 26000, loss = 0.0420636
I0506 10:12:37.083629 26400 solver.cpp:244]     Train net output #0: loss = 0.0420647 (* 1 = 0.0420647 loss)
I0506 10:12:37.083652 26400 sgd_solver.cpp:106] Iteration 26000, lr = 1e-06
I0506 10:14:47.684183 26400 solver.cpp:228] Iteration 26050, loss = -1.10455e-06
I0506 10:14:47.690985 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:14:47.691012 26400 sgd_solver.cpp:106] Iteration 26050, lr = 1e-06
I0506 10:16:57.927213 26400 solver.cpp:228] Iteration 26100, loss = 0.0822191
I0506 10:16:57.927501 26400 solver.cpp:244]     Train net output #0: loss = 0.0822202 (* 1 = 0.0822202 loss)
I0506 10:16:57.927551 26400 sgd_solver.cpp:106] Iteration 26100, lr = 1e-06
I0506 10:19:07.824851 26400 solver.cpp:228] Iteration 26150, loss = 0.010084
I0506 10:19:07.825037 26400 solver.cpp:244]     Train net output #0: loss = 0.0100851 (* 1 = 0.0100851 loss)
I0506 10:19:07.825053 26400 sgd_solver.cpp:106] Iteration 26150, lr = 1e-06
I0506 10:21:15.319701 26400 solver.cpp:337] Iteration 26200, Testing net (#0)
I0506 10:21:56.998349 26400 solver.cpp:404]     Test net output #0: loss = 0.129779 (* 1 = 0.129779 loss)
I0506 10:21:57.868319 26400 solver.cpp:228] Iteration 26200, loss = 0.0340869
I0506 10:21:57.868422 26400 solver.cpp:244]     Train net output #0: loss = 0.034088 (* 1 = 0.034088 loss)
I0506 10:21:57.868463 26400 sgd_solver.cpp:106] Iteration 26200, lr = 1e-06
I0506 10:24:08.221143 26400 solver.cpp:228] Iteration 26250, loss = -1.07288e-06
I0506 10:24:08.222878 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:24:08.222940 26400 sgd_solver.cpp:106] Iteration 26250, lr = 1e-06
I0506 10:26:18.108260 26400 solver.cpp:228] Iteration 26300, loss = 0.188614
I0506 10:26:18.108520 26400 solver.cpp:244]     Train net output #0: loss = 0.188615 (* 1 = 0.188615 loss)
I0506 10:26:18.108575 26400 sgd_solver.cpp:106] Iteration 26300, lr = 1e-06
I0506 10:28:28.032805 26400 solver.cpp:228] Iteration 26350, loss = 0.0426714
I0506 10:28:28.032933 26400 solver.cpp:244]     Train net output #0: loss = 0.0426725 (* 1 = 0.0426725 loss)
I0506 10:28:28.032950 26400 sgd_solver.cpp:106] Iteration 26350, lr = 1e-06
I0506 10:30:35.324378 26400 solver.cpp:337] Iteration 26400, Testing net (#0)
I0506 10:31:04.421458 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 10:31:06.931639 26400 solver.cpp:404]     Test net output #0: loss = 0.0964626 (* 1 = 0.0964626 loss)
I0506 10:31:07.801475 26400 solver.cpp:228] Iteration 26400, loss = 0.0061066
I0506 10:31:07.801539 26400 solver.cpp:244]     Train net output #0: loss = 0.00610767 (* 1 = 0.00610767 loss)
I0506 10:31:07.801555 26400 sgd_solver.cpp:106] Iteration 26400, lr = 1e-06
I0506 10:33:17.666589 26400 solver.cpp:228] Iteration 26450, loss = -1.06543e-06
I0506 10:33:17.669944 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:33:17.669972 26400 sgd_solver.cpp:106] Iteration 26450, lr = 1e-06
I0506 10:35:27.621809 26400 solver.cpp:228] Iteration 26500, loss = -1.06543e-06
I0506 10:35:27.622038 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:35:27.622081 26400 sgd_solver.cpp:106] Iteration 26500, lr = 1e-06
I0506 10:37:37.713738 26400 solver.cpp:228] Iteration 26550, loss = 0.257502
I0506 10:37:37.713960 26400 solver.cpp:244]     Train net output #0: loss = 0.257503 (* 1 = 0.257503 loss)
I0506 10:37:37.713996 26400 sgd_solver.cpp:106] Iteration 26550, lr = 1e-06
I0506 10:39:45.205761 26400 solver.cpp:337] Iteration 26600, Testing net (#0)
I0506 10:40:31.277493 26400 solver.cpp:404]     Test net output #0: loss = 0.133853 (* 1 = 0.133853 loss)
I0506 10:40:32.142652 26400 solver.cpp:228] Iteration 26600, loss = 0.0803329
I0506 10:40:32.142709 26400 solver.cpp:244]     Train net output #0: loss = 0.080334 (* 1 = 0.080334 loss)
I0506 10:40:32.142725 26400 sgd_solver.cpp:106] Iteration 26600, lr = 1e-06
I0506 10:42:42.814999 26400 solver.cpp:228] Iteration 26650, loss = 0.0254839
I0506 10:42:42.815186 26400 solver.cpp:244]     Train net output #0: loss = 0.0254849 (* 1 = 0.0254849 loss)
I0506 10:42:42.815224 26400 sgd_solver.cpp:106] Iteration 26650, lr = 1e-06
I0506 10:44:52.994949 26400 solver.cpp:228] Iteration 26700, loss = 0.0458544
I0506 10:44:52.996371 26400 solver.cpp:244]     Train net output #0: loss = 0.0458555 (* 1 = 0.0458555 loss)
I0506 10:44:52.996398 26400 sgd_solver.cpp:106] Iteration 26700, lr = 1e-06
I0506 10:47:03.088846 26400 solver.cpp:228] Iteration 26750, loss = 0.102306
I0506 10:47:03.089068 26400 solver.cpp:244]     Train net output #0: loss = 0.102307 (* 1 = 0.102307 loss)
I0506 10:47:03.089110 26400 sgd_solver.cpp:106] Iteration 26750, lr = 1e-06
I0506 10:49:10.489481 26400 solver.cpp:337] Iteration 26800, Testing net (#0)
I0506 10:49:40.645328 26400 solver.cpp:404]     Test net output #0: loss = 0.122193 (* 1 = 0.122193 loss)
I0506 10:49:41.517094 26400 solver.cpp:228] Iteration 26800, loss = 0.0231225
I0506 10:49:41.517151 26400 solver.cpp:244]     Train net output #0: loss = 0.0231236 (* 1 = 0.0231236 loss)
I0506 10:49:41.517164 26400 sgd_solver.cpp:106] Iteration 26800, lr = 1e-06
I0506 10:51:51.563227 26400 solver.cpp:228] Iteration 26850, loss = -1.07288e-06
I0506 10:51:51.563403 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:51:51.563428 26400 sgd_solver.cpp:106] Iteration 26850, lr = 1e-06
I0506 10:54:01.668339 26400 solver.cpp:228] Iteration 26900, loss = -1.08778e-06
I0506 10:54:01.668587 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 10:54:01.668601 26400 sgd_solver.cpp:106] Iteration 26900, lr = 1e-06
I0506 10:56:11.718930 26400 solver.cpp:228] Iteration 26950, loss = 0.125502
I0506 10:56:11.719956 26400 solver.cpp:244]     Train net output #0: loss = 0.125503 (* 1 = 0.125503 loss)
I0506 10:56:11.719982 26400 sgd_solver.cpp:106] Iteration 26950, lr = 1e-06
I0506 10:58:19.010184 26400 solver.cpp:337] Iteration 27000, Testing net (#0)
I0506 10:58:28.667847 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 10:58:49.667171 26400 solver.cpp:404]     Test net output #0: loss = 0.106983 (* 1 = 0.106983 loss)
I0506 10:58:50.544832 26400 solver.cpp:228] Iteration 27000, loss = 0.0184718
I0506 10:58:50.544878 26400 solver.cpp:244]     Train net output #0: loss = 0.0184729 (* 1 = 0.0184729 loss)
I0506 10:58:50.544904 26400 sgd_solver.cpp:106] Iteration 27000, lr = 1e-06
I0506 11:01:00.446585 26400 solver.cpp:228] Iteration 27050, loss = -1.07288e-06
I0506 11:01:00.446868 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 11:01:00.446935 26400 sgd_solver.cpp:106] Iteration 27050, lr = 1e-06
I0506 11:03:10.264072 26400 solver.cpp:228] Iteration 27100, loss = 0.181362
I0506 11:03:10.264926 26400 solver.cpp:244]     Train net output #0: loss = 0.181363 (* 1 = 0.181363 loss)
I0506 11:03:10.264945 26400 sgd_solver.cpp:106] Iteration 27100, lr = 1e-06
I0506 11:05:20.181126 26400 solver.cpp:228] Iteration 27150, loss = 0.0422141
I0506 11:05:20.194653 26400 solver.cpp:244]     Train net output #0: loss = 0.0422152 (* 1 = 0.0422152 loss)
I0506 11:05:20.194710 26400 sgd_solver.cpp:106] Iteration 27150, lr = 1e-06
I0506 11:07:27.560247 26400 solver.cpp:337] Iteration 27200, Testing net (#0)
I0506 11:07:59.003907 26400 solver.cpp:404]     Test net output #0: loss = 0.136335 (* 1 = 0.136335 loss)
I0506 11:07:59.872097 26400 solver.cpp:228] Iteration 27200, loss = 0.011625
I0506 11:07:59.872154 26400 solver.cpp:244]     Train net output #0: loss = 0.0116261 (* 1 = 0.0116261 loss)
I0506 11:07:59.872179 26400 sgd_solver.cpp:106] Iteration 27200, lr = 1e-06
I0506 11:10:09.843394 26400 solver.cpp:228] Iteration 27250, loss = 0.0606797
I0506 11:10:09.843642 26400 solver.cpp:244]     Train net output #0: loss = 0.0606809 (* 1 = 0.0606809 loss)
I0506 11:10:09.843693 26400 sgd_solver.cpp:106] Iteration 27250, lr = 1e-06
I0506 11:12:20.182329 26400 solver.cpp:228] Iteration 27300, loss = 0.0956225
I0506 11:12:20.183032 26400 solver.cpp:244]     Train net output #0: loss = 0.0956236 (* 1 = 0.0956236 loss)
I0506 11:12:20.183063 26400 sgd_solver.cpp:106] Iteration 27300, lr = 1e-06
I0506 11:14:30.050041 26400 solver.cpp:228] Iteration 27350, loss = -1.07288e-06
I0506 11:14:30.050345 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 11:14:30.050395 26400 sgd_solver.cpp:106] Iteration 27350, lr = 1e-06
I0506 11:16:37.383366 26400 solver.cpp:337] Iteration 27400, Testing net (#0)
I0506 11:17:05.652627 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 11:17:19.693994 26400 solver.cpp:404]     Test net output #0: loss = 0.157153 (* 1 = 0.157153 loss)
I0506 11:17:20.556915 26400 solver.cpp:228] Iteration 27400, loss = 0.0132653
I0506 11:17:20.556955 26400 solver.cpp:244]     Train net output #0: loss = 0.0132663 (* 1 = 0.0132663 loss)
I0506 11:17:20.556970 26400 sgd_solver.cpp:106] Iteration 27400, lr = 1e-06
I0506 11:19:30.700928 26400 solver.cpp:228] Iteration 27450, loss = -1.05798e-06
I0506 11:19:30.701095 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 11:19:30.701118 26400 sgd_solver.cpp:106] Iteration 27450, lr = 1e-06
I0506 11:21:40.766134 26400 solver.cpp:228] Iteration 27500, loss = 0.227396
I0506 11:21:40.766288 26400 solver.cpp:244]     Train net output #0: loss = 0.227397 (* 1 = 0.227397 loss)
I0506 11:21:40.766304 26400 sgd_solver.cpp:106] Iteration 27500, lr = 1e-06
I0506 11:23:51.218156 26400 solver.cpp:228] Iteration 27550, loss = 0.0551197
I0506 11:23:51.219817 26400 solver.cpp:244]     Train net output #0: loss = 0.0551208 (* 1 = 0.0551208 loss)
I0506 11:23:51.219857 26400 sgd_solver.cpp:106] Iteration 27550, lr = 1e-06
I0506 11:25:58.500692 26400 solver.cpp:337] Iteration 27600, Testing net (#0)
I0506 11:26:48.992916 26400 solver.cpp:404]     Test net output #0: loss = 0.102438 (* 1 = 0.102438 loss)
I0506 11:26:49.853803 26400 solver.cpp:228] Iteration 27600, loss = 0.174778
I0506 11:26:49.853870 26400 solver.cpp:244]     Train net output #0: loss = 0.174779 (* 1 = 0.174779 loss)
I0506 11:26:49.853914 26400 sgd_solver.cpp:106] Iteration 27600, lr = 1e-06
I0506 11:29:00.412756 26400 solver.cpp:228] Iteration 27650, loss = 0.0274909
I0506 11:29:00.425305 26400 solver.cpp:244]     Train net output #0: loss = 0.0274921 (* 1 = 0.0274921 loss)
I0506 11:29:00.425344 26400 sgd_solver.cpp:106] Iteration 27650, lr = 1e-06
I0506 11:31:10.464295 26400 solver.cpp:228] Iteration 27700, loss = 0.0433592
I0506 11:31:10.464469 26400 solver.cpp:244]     Train net output #0: loss = 0.0433603 (* 1 = 0.0433603 loss)
I0506 11:31:10.464489 26400 sgd_solver.cpp:106] Iteration 27700, lr = 1e-06
I0506 11:33:20.128139 26400 solver.cpp:228] Iteration 27750, loss = 0.0260729
I0506 11:33:20.128485 26400 solver.cpp:244]     Train net output #0: loss = 0.026074 (* 1 = 0.026074 loss)
I0506 11:33:20.128592 26400 sgd_solver.cpp:106] Iteration 27750, lr = 1e-06
I0506 11:35:27.420410 26400 solver.cpp:337] Iteration 27800, Testing net (#0)
I0506 11:35:55.978011 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 11:35:58.144438 26400 solver.cpp:404]     Test net output #0: loss = 0.126835 (* 1 = 0.126835 loss)
I0506 11:35:59.017915 26400 solver.cpp:228] Iteration 27800, loss = 0.0535578
I0506 11:35:59.017964 26400 solver.cpp:244]     Train net output #0: loss = 0.053559 (* 1 = 0.053559 loss)
I0506 11:35:59.017993 26400 sgd_solver.cpp:106] Iteration 27800, lr = 1e-06
I0506 11:38:08.943117 26400 solver.cpp:228] Iteration 27850, loss = 0.0306923
I0506 11:38:08.945129 26400 solver.cpp:244]     Train net output #0: loss = 0.0306935 (* 1 = 0.0306935 loss)
I0506 11:38:08.945147 26400 sgd_solver.cpp:106] Iteration 27850, lr = 1e-06
I0506 11:40:19.128769 26400 solver.cpp:228] Iteration 27900, loss = 0.0319385
I0506 11:40:19.128981 26400 solver.cpp:244]     Train net output #0: loss = 0.0319396 (* 1 = 0.0319396 loss)
I0506 11:40:19.129019 26400 sgd_solver.cpp:106] Iteration 27900, lr = 1e-06
I0506 11:42:29.291728 26400 solver.cpp:228] Iteration 27950, loss = 0.037373
I0506 11:42:29.291971 26400 solver.cpp:244]     Train net output #0: loss = 0.0373741 (* 1 = 0.0373741 loss)
I0506 11:42:29.292021 26400 sgd_solver.cpp:106] Iteration 27950, lr = 1e-06
I0506 11:44:36.648763 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_28000.caffemodel
I0506 11:44:40.737062 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_28000.solverstate
I0506 11:44:40.799397 26400 solver.cpp:337] Iteration 28000, Testing net (#0)
I0506 11:45:10.885566 26400 solver.cpp:404]     Test net output #0: loss = 0.112493 (* 1 = 0.112493 loss)
I0506 11:45:11.752060 26400 solver.cpp:228] Iteration 28000, loss = -1.12969e-06
I0506 11:45:11.752106 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 11:45:11.752127 26400 sgd_solver.cpp:106] Iteration 28000, lr = 1e-06
I0506 11:47:21.796360 26400 solver.cpp:228] Iteration 28050, loss = 0.0279457
I0506 11:47:21.796609 26400 solver.cpp:244]     Train net output #0: loss = 0.0279468 (* 1 = 0.0279468 loss)
I0506 11:47:21.796659 26400 sgd_solver.cpp:106] Iteration 28050, lr = 1e-06
I0506 11:49:31.644896 26400 solver.cpp:228] Iteration 28100, loss = 0.069271
I0506 11:49:31.645128 26400 solver.cpp:244]     Train net output #0: loss = 0.0692722 (* 1 = 0.0692722 loss)
I0506 11:49:31.645175 26400 sgd_solver.cpp:106] Iteration 28100, lr = 1e-06
I0506 11:51:41.659103 26400 solver.cpp:228] Iteration 28150, loss = -1.09896e-06
I0506 11:51:41.659263 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 11:51:41.659281 26400 sgd_solver.cpp:106] Iteration 28150, lr = 1e-06
I0506 11:53:49.144384 26400 solver.cpp:337] Iteration 28200, Testing net (#0)
I0506 11:54:35.240334 26400 solver.cpp:404]     Test net output #0: loss = 0.126234 (* 1 = 0.126234 loss)
I0506 11:54:36.106940 26400 solver.cpp:228] Iteration 28200, loss = 0.012715
I0506 11:54:36.107012 26400 solver.cpp:244]     Train net output #0: loss = 0.0127161 (* 1 = 0.0127161 loss)
I0506 11:54:36.107051 26400 sgd_solver.cpp:106] Iteration 28200, lr = 1e-06
I0506 11:56:46.941740 26400 solver.cpp:228] Iteration 28250, loss = 0.0339953
I0506 11:56:46.941980 26400 solver.cpp:244]     Train net output #0: loss = 0.0339964 (* 1 = 0.0339964 loss)
I0506 11:56:46.942019 26400 sgd_solver.cpp:106] Iteration 28250, lr = 1e-06
I0506 11:58:56.965525 26400 solver.cpp:228] Iteration 28300, loss = 0.0283889
I0506 11:58:56.980772 26400 solver.cpp:244]     Train net output #0: loss = 0.02839 (* 1 = 0.02839 loss)
I0506 11:58:56.980815 26400 sgd_solver.cpp:106] Iteration 28300, lr = 1e-06
I0506 12:01:06.973647 26400 solver.cpp:228] Iteration 28350, loss = 0.0360705
I0506 12:01:06.973852 26400 solver.cpp:244]     Train net output #0: loss = 0.0360717 (* 1 = 0.0360717 loss)
I0506 12:01:06.973870 26400 sgd_solver.cpp:106] Iteration 28350, lr = 1e-06
I0506 12:03:14.448802 26400 solver.cpp:337] Iteration 28400, Testing net (#0)
I0506 12:03:22.352888 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 12:04:00.058634 26400 solver.cpp:404]     Test net output #0: loss = 0.122778 (* 1 = 0.122778 loss)
I0506 12:04:00.924661 26400 solver.cpp:228] Iteration 28400, loss = -1.13249e-06
I0506 12:04:00.924726 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:04:00.924741 26400 sgd_solver.cpp:106] Iteration 28400, lr = 1e-06
I0506 12:06:11.582376 26400 solver.cpp:228] Iteration 28450, loss = 0.128572
I0506 12:06:11.582589 26400 solver.cpp:244]     Train net output #0: loss = 0.128574 (* 1 = 0.128574 loss)
I0506 12:06:11.582626 26400 sgd_solver.cpp:106] Iteration 28450, lr = 1e-06
I0506 12:08:21.433725 26400 solver.cpp:228] Iteration 28500, loss = 0.0483854
I0506 12:08:21.433995 26400 solver.cpp:244]     Train net output #0: loss = 0.0483866 (* 1 = 0.0483866 loss)
I0506 12:08:21.434042 26400 sgd_solver.cpp:106] Iteration 28500, lr = 1e-06
I0506 12:10:31.441576 26400 solver.cpp:228] Iteration 28550, loss = 0.0236067
I0506 12:10:31.441988 26400 solver.cpp:244]     Train net output #0: loss = 0.0236079 (* 1 = 0.0236079 loss)
I0506 12:10:31.442086 26400 sgd_solver.cpp:106] Iteration 28550, lr = 1e-06
I0506 12:12:38.911119 26400 solver.cpp:337] Iteration 28600, Testing net (#0)
I0506 12:13:27.786103 26400 solver.cpp:404]     Test net output #0: loss = 0.120813 (* 1 = 0.120813 loss)
I0506 12:13:28.652745 26400 solver.cpp:228] Iteration 28600, loss = -1.17067e-06
I0506 12:13:28.652803 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:13:28.652818 26400 sgd_solver.cpp:106] Iteration 28600, lr = 1e-06
I0506 12:15:39.252846 26400 solver.cpp:228] Iteration 28650, loss = -1.17719e-06
I0506 12:15:39.253010 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:15:39.253046 26400 sgd_solver.cpp:106] Iteration 28650, lr = 1e-06
I0506 12:17:49.241514 26400 solver.cpp:228] Iteration 28700, loss = 0.0256527
I0506 12:17:49.241672 26400 solver.cpp:244]     Train net output #0: loss = 0.0256539 (* 1 = 0.0256539 loss)
I0506 12:17:49.241685 26400 sgd_solver.cpp:106] Iteration 28700, lr = 1e-06
I0506 12:19:59.267997 26400 solver.cpp:228] Iteration 28750, loss = 0.0252858
I0506 12:19:59.268257 26400 solver.cpp:244]     Train net output #0: loss = 0.025287 (* 1 = 0.025287 loss)
I0506 12:19:59.268301 26400 sgd_solver.cpp:106] Iteration 28750, lr = 1e-06
I0506 12:22:06.715826 26400 solver.cpp:337] Iteration 28800, Testing net (#0)
I0506 12:22:17.883159 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 12:22:56.186976 26400 solver.cpp:404]     Test net output #0: loss = 0.131385 (* 1 = 0.131385 loss)
I0506 12:22:57.049021 26400 solver.cpp:228] Iteration 28800, loss = -1.19209e-06
I0506 12:22:57.049085 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:22:57.049101 26400 sgd_solver.cpp:106] Iteration 28800, lr = 1e-06
I0506 12:25:07.479142 26400 solver.cpp:228] Iteration 28850, loss = 0.112111
I0506 12:25:07.479565 26400 solver.cpp:244]     Train net output #0: loss = 0.112113 (* 1 = 0.112113 loss)
I0506 12:25:07.479611 26400 sgd_solver.cpp:106] Iteration 28850, lr = 1e-06
I0506 12:27:17.566874 26400 solver.cpp:228] Iteration 28900, loss = 0.00210702
I0506 12:27:17.567078 26400 solver.cpp:244]     Train net output #0: loss = 0.00210821 (* 1 = 0.00210821 loss)
I0506 12:27:17.567095 26400 sgd_solver.cpp:106] Iteration 28900, lr = 1e-06
I0506 12:29:27.563292 26400 solver.cpp:228] Iteration 28950, loss = 0.0058842
I0506 12:29:27.575961 26400 solver.cpp:244]     Train net output #0: loss = 0.00588536 (* 1 = 0.00588536 loss)
I0506 12:29:27.576005 26400 sgd_solver.cpp:106] Iteration 28950, lr = 1e-06
I0506 12:31:34.947221 26400 solver.cpp:337] Iteration 29000, Testing net (#0)
I0506 12:32:11.910281 26400 solver.cpp:404]     Test net output #0: loss = 0.113102 (* 1 = 0.113102 loss)
I0506 12:32:12.778450 26400 solver.cpp:228] Iteration 29000, loss = 0.0810875
I0506 12:32:12.778504 26400 solver.cpp:244]     Train net output #0: loss = 0.0810887 (* 1 = 0.0810887 loss)
I0506 12:32:12.778518 26400 sgd_solver.cpp:106] Iteration 29000, lr = 1e-06
I0506 12:34:22.706698 26400 solver.cpp:228] Iteration 29050, loss = 0.00114141
I0506 12:34:22.706966 26400 solver.cpp:244]     Train net output #0: loss = 0.00114259 (* 1 = 0.00114259 loss)
I0506 12:34:22.707010 26400 sgd_solver.cpp:106] Iteration 29050, lr = 1e-06
I0506 12:36:32.784536 26400 solver.cpp:228] Iteration 29100, loss = 0.127194
I0506 12:36:32.787003 26400 solver.cpp:244]     Train net output #0: loss = 0.127195 (* 1 = 0.127195 loss)
I0506 12:36:32.787039 26400 sgd_solver.cpp:106] Iteration 29100, lr = 1e-06
I0506 12:38:43.046033 26400 solver.cpp:228] Iteration 29150, loss = -1.22935e-06
I0506 12:38:43.046196 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:38:43.046212 26400 sgd_solver.cpp:106] Iteration 29150, lr = 1e-06
I0506 12:40:50.391278 26400 solver.cpp:337] Iteration 29200, Testing net (#0)
I0506 12:41:02.368513 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 12:41:24.353127 26400 solver.cpp:404]     Test net output #0: loss = 0.121323 (* 1 = 0.121323 loss)
I0506 12:41:25.221400 26400 solver.cpp:228] Iteration 29200, loss = 0.0367709
I0506 12:41:25.221462 26400 solver.cpp:244]     Train net output #0: loss = 0.0367721 (* 1 = 0.0367721 loss)
I0506 12:41:25.221480 26400 sgd_solver.cpp:106] Iteration 29200, lr = 1e-06
I0506 12:43:34.925647 26400 solver.cpp:228] Iteration 29250, loss = 0.1054
I0506 12:43:34.927775 26400 solver.cpp:244]     Train net output #0: loss = 0.105401 (* 1 = 0.105401 loss)
I0506 12:43:34.927801 26400 sgd_solver.cpp:106] Iteration 29250, lr = 1e-06
I0506 12:45:44.886106 26400 solver.cpp:228] Iteration 29300, loss = -1.2517e-06
I0506 12:45:44.886584 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:45:44.886601 26400 sgd_solver.cpp:106] Iteration 29300, lr = 1e-06
I0506 12:47:54.932286 26400 solver.cpp:228] Iteration 29350, loss = -1.2517e-06
I0506 12:47:54.932623 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:47:54.932667 26400 sgd_solver.cpp:106] Iteration 29350, lr = 1e-06
I0506 12:50:02.279009 26400 solver.cpp:337] Iteration 29400, Testing net (#0)
I0506 12:50:32.516845 26400 solver.cpp:404]     Test net output #0: loss = 0.108293 (* 1 = 0.108293 loss)
I0506 12:50:33.387287 26400 solver.cpp:228] Iteration 29400, loss = 0.00986518
I0506 12:50:33.387346 26400 solver.cpp:244]     Train net output #0: loss = 0.00986643 (* 1 = 0.00986643 loss)
I0506 12:50:33.387378 26400 sgd_solver.cpp:106] Iteration 29400, lr = 1e-06
I0506 12:52:43.362607 26400 solver.cpp:228] Iteration 29450, loss = 0.0182963
I0506 12:52:43.362900 26400 solver.cpp:244]     Train net output #0: loss = 0.0182976 (* 1 = 0.0182976 loss)
I0506 12:52:43.362995 26400 sgd_solver.cpp:106] Iteration 29450, lr = 1e-06
I0506 12:54:53.552146 26400 solver.cpp:228] Iteration 29500, loss = 0.0429859
I0506 12:54:53.552417 26400 solver.cpp:244]     Train net output #0: loss = 0.0429872 (* 1 = 0.0429872 loss)
I0506 12:54:53.552464 26400 sgd_solver.cpp:106] Iteration 29500, lr = 1e-06
I0506 12:57:03.580399 26400 solver.cpp:228] Iteration 29550, loss = -1.2815e-06
I0506 12:57:03.580591 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 12:57:03.580607 26400 sgd_solver.cpp:106] Iteration 29550, lr = 1e-06
I0506 12:59:10.804783 26400 solver.cpp:337] Iteration 29600, Testing net (#0)
I0506 12:59:26.200834 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 12:59:41.008561 26400 solver.cpp:404]     Test net output #0: loss = 0.10057 (* 1 = 0.10057 loss)
I0506 12:59:41.876328 26400 solver.cpp:228] Iteration 29600, loss = 0.0203073
I0506 12:59:41.876399 26400 solver.cpp:244]     Train net output #0: loss = 0.0203086 (* 1 = 0.0203086 loss)
I0506 12:59:41.876412 26400 sgd_solver.cpp:106] Iteration 29600, lr = 1e-06
I0506 13:01:51.864584 26400 solver.cpp:228] Iteration 29650, loss = -1.2815e-06
I0506 13:01:51.864738 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:01:51.864754 26400 sgd_solver.cpp:106] Iteration 29650, lr = 1e-06
I0506 13:04:01.891106 26400 solver.cpp:228] Iteration 29700, loss = 0.094332
I0506 13:04:01.891317 26400 solver.cpp:244]     Train net output #0: loss = 0.0943333 (* 1 = 0.0943333 loss)
I0506 13:04:01.891335 26400 sgd_solver.cpp:106] Iteration 29700, lr = 1e-06
I0506 13:06:11.958379 26400 solver.cpp:228] Iteration 29750, loss = 0.0565564
I0506 13:06:11.958745 26400 solver.cpp:244]     Train net output #0: loss = 0.0565577 (* 1 = 0.0565577 loss)
I0506 13:06:11.958796 26400 sgd_solver.cpp:106] Iteration 29750, lr = 1e-06
I0506 13:08:19.133920 26400 solver.cpp:337] Iteration 29800, Testing net (#0)
I0506 13:08:49.620468 26400 solver.cpp:404]     Test net output #0: loss = 0.110475 (* 1 = 0.110475 loss)
I0506 13:08:50.486606 26400 solver.cpp:228] Iteration 29800, loss = 0.0103512
I0506 13:08:50.486688 26400 solver.cpp:244]     Train net output #0: loss = 0.0103524 (* 1 = 0.0103524 loss)
I0506 13:08:50.486707 26400 sgd_solver.cpp:106] Iteration 29800, lr = 1e-06
I0506 13:11:00.466186 26400 solver.cpp:228] Iteration 29850, loss = -1.2666e-06
I0506 13:11:00.466392 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:11:00.466408 26400 sgd_solver.cpp:106] Iteration 29850, lr = 1e-06
I0506 13:13:10.450752 26400 solver.cpp:228] Iteration 29900, loss = -1.2815e-06
I0506 13:13:10.453649 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:13:10.453680 26400 sgd_solver.cpp:106] Iteration 29900, lr = 1e-06
I0506 13:15:20.056329 26400 solver.cpp:228] Iteration 29950, loss = 0.236174
I0506 13:15:20.056516 26400 solver.cpp:244]     Train net output #0: loss = 0.236176 (* 1 = 0.236176 loss)
I0506 13:15:20.056535 26400 sgd_solver.cpp:106] Iteration 29950, lr = 1e-06
I0506 13:17:27.407419 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_30000.caffemodel
I0506 13:17:33.211927 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_30000.solverstate
I0506 13:17:33.265977 26400 solver.cpp:337] Iteration 30000, Testing net (#0)
I0506 13:17:53.649096 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 13:18:03.156602 26400 solver.cpp:404]     Test net output #0: loss = 0.110765 (* 1 = 0.110765 loss)
I0506 13:18:04.022053 26400 solver.cpp:228] Iteration 30000, loss = 0.0232648
I0506 13:18:04.022100 26400 solver.cpp:244]     Train net output #0: loss = 0.0232661 (* 1 = 0.0232661 loss)
I0506 13:18:04.022114 26400 sgd_solver.cpp:106] Iteration 30000, lr = 1e-06
I0506 13:20:13.921746 26400 solver.cpp:228] Iteration 30050, loss = -1.2815e-06
I0506 13:20:13.922289 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:20:13.922309 26400 sgd_solver.cpp:106] Iteration 30050, lr = 1e-06
I0506 13:22:24.098589 26400 solver.cpp:228] Iteration 30100, loss = 0.0178832
I0506 13:22:24.098845 26400 solver.cpp:244]     Train net output #0: loss = 0.0178844 (* 1 = 0.0178844 loss)
I0506 13:22:24.098876 26400 sgd_solver.cpp:106] Iteration 30100, lr = 1e-06
I0506 13:24:34.104719 26400 solver.cpp:228] Iteration 30150, loss = 0.312579
I0506 13:24:34.104897 26400 solver.cpp:244]     Train net output #0: loss = 0.312581 (* 1 = 0.312581 loss)
I0506 13:24:34.104912 26400 sgd_solver.cpp:106] Iteration 30150, lr = 1e-06
I0506 13:26:41.486623 26400 solver.cpp:337] Iteration 30200, Testing net (#0)
I0506 13:27:23.262301 26400 solver.cpp:404]     Test net output #0: loss = 0.130357 (* 1 = 0.130357 loss)
I0506 13:27:24.127998 26400 solver.cpp:228] Iteration 30200, loss = 0.185763
I0506 13:27:24.128043 26400 solver.cpp:244]     Train net output #0: loss = 0.185764 (* 1 = 0.185764 loss)
I0506 13:27:24.128069 26400 sgd_solver.cpp:106] Iteration 30200, lr = 1e-06
I0506 13:29:34.427985 26400 solver.cpp:228] Iteration 30250, loss = -1.3113e-06
I0506 13:29:34.428158 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:29:34.428186 26400 sgd_solver.cpp:106] Iteration 30250, lr = 1e-06
I0506 13:31:44.387383 26400 solver.cpp:228] Iteration 30300, loss = 0.000603568
I0506 13:31:44.395398 26400 solver.cpp:244]     Train net output #0: loss = 0.000604894 (* 1 = 0.000604894 loss)
I0506 13:31:44.395439 26400 sgd_solver.cpp:106] Iteration 30300, lr = 1e-06
I0506 13:33:54.244540 26400 solver.cpp:228] Iteration 30350, loss = -1.3262e-06
I0506 13:33:54.244700 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:33:54.244717 26400 sgd_solver.cpp:106] Iteration 30350, lr = 1e-06
I0506 13:36:01.462999 26400 solver.cpp:337] Iteration 30400, Testing net (#0)
I0506 13:36:34.369191 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 13:36:46.551057 26400 solver.cpp:404]     Test net output #0: loss = 0.0977769 (* 1 = 0.0977769 loss)
I0506 13:36:47.416036 26400 solver.cpp:228] Iteration 30400, loss = 0.141041
I0506 13:36:47.416074 26400 solver.cpp:244]     Train net output #0: loss = 0.141042 (* 1 = 0.141042 loss)
I0506 13:36:47.416098 26400 sgd_solver.cpp:106] Iteration 30400, lr = 1e-06
I0506 13:38:57.878849 26400 solver.cpp:228] Iteration 30450, loss = 0.0193847
I0506 13:38:57.879045 26400 solver.cpp:244]     Train net output #0: loss = 0.019386 (* 1 = 0.019386 loss)
I0506 13:38:57.879070 26400 sgd_solver.cpp:106] Iteration 30450, lr = 1e-06
I0506 13:41:07.946154 26400 solver.cpp:228] Iteration 30500, loss = 0.0131473
I0506 13:41:07.948240 26400 solver.cpp:244]     Train net output #0: loss = 0.0131486 (* 1 = 0.0131486 loss)
I0506 13:41:07.948266 26400 sgd_solver.cpp:106] Iteration 30500, lr = 1e-06
I0506 13:43:17.894098 26400 solver.cpp:228] Iteration 30550, loss = -1.3113e-06
I0506 13:43:17.894358 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:43:17.894407 26400 sgd_solver.cpp:106] Iteration 30550, lr = 1e-06
I0506 13:45:25.005163 26400 solver.cpp:337] Iteration 30600, Testing net (#0)
I0506 13:46:03.783390 26400 solver.cpp:404]     Test net output #0: loss = 0.130817 (* 1 = 0.130817 loss)
I0506 13:46:04.648512 26400 solver.cpp:228] Iteration 30600, loss = 0.145611
I0506 13:46:04.648553 26400 solver.cpp:244]     Train net output #0: loss = 0.145612 (* 1 = 0.145612 loss)
I0506 13:46:04.648566 26400 sgd_solver.cpp:106] Iteration 30600, lr = 1e-06
I0506 13:48:14.502316 26400 solver.cpp:228] Iteration 30650, loss = -1.3113e-06
I0506 13:48:14.502604 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 13:48:14.502645 26400 sgd_solver.cpp:106] Iteration 30650, lr = 1e-06
I0506 13:50:23.993780 26400 solver.cpp:228] Iteration 30700, loss = 0.0261682
I0506 13:50:23.994060 26400 solver.cpp:244]     Train net output #0: loss = 0.0261695 (* 1 = 0.0261695 loss)
I0506 13:50:23.994122 26400 sgd_solver.cpp:106] Iteration 30700, lr = 1e-06
I0506 13:52:33.765558 26400 solver.cpp:228] Iteration 30750, loss = 0.0111055
I0506 13:52:33.765800 26400 solver.cpp:244]     Train net output #0: loss = 0.0111068 (* 1 = 0.0111068 loss)
I0506 13:52:33.765847 26400 sgd_solver.cpp:106] Iteration 30750, lr = 1e-06
I0506 13:54:41.173069 26400 solver.cpp:337] Iteration 30800, Testing net (#0)
I0506 13:55:09.144682 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 13:55:13.608134 26400 solver.cpp:404]     Test net output #0: loss = 0.140367 (* 1 = 0.140367 loss)
I0506 13:55:14.487359 26400 solver.cpp:228] Iteration 30800, loss = 0.121675
I0506 13:55:14.487469 26400 solver.cpp:244]     Train net output #0: loss = 0.121676 (* 1 = 0.121676 loss)
I0506 13:55:14.487499 26400 sgd_solver.cpp:106] Iteration 30800, lr = 1e-06
I0506 13:57:24.421203 26400 solver.cpp:228] Iteration 30850, loss = 0.0501341
I0506 13:57:24.433679 26400 solver.cpp:244]     Train net output #0: loss = 0.0501354 (* 1 = 0.0501354 loss)
I0506 13:57:24.433708 26400 sgd_solver.cpp:106] Iteration 30850, lr = 1e-06
I0506 13:59:34.375051 26400 solver.cpp:228] Iteration 30900, loss = 0.0426118
I0506 13:59:34.375767 26400 solver.cpp:244]     Train net output #0: loss = 0.0426131 (* 1 = 0.0426131 loss)
I0506 13:59:34.375784 26400 sgd_solver.cpp:106] Iteration 30900, lr = 1e-06
I0506 14:01:44.261876 26400 solver.cpp:228] Iteration 30950, loss = 0.0510559
I0506 14:01:44.262071 26400 solver.cpp:244]     Train net output #0: loss = 0.0510572 (* 1 = 0.0510572 loss)
I0506 14:01:44.262089 26400 sgd_solver.cpp:106] Iteration 30950, lr = 1e-06
I0506 14:03:51.333755 26400 solver.cpp:337] Iteration 31000, Testing net (#0)
I0506 14:04:30.781142 26400 solver.cpp:404]     Test net output #0: loss = 0.118113 (* 1 = 0.118113 loss)
I0506 14:04:31.644701 26400 solver.cpp:228] Iteration 31000, loss = 0.0137686
I0506 14:04:31.644747 26400 solver.cpp:244]     Train net output #0: loss = 0.0137698 (* 1 = 0.0137698 loss)
I0506 14:04:31.644770 26400 sgd_solver.cpp:106] Iteration 31000, lr = 1e-06
I0506 14:06:41.442011 26400 solver.cpp:228] Iteration 31050, loss = 0.230622
I0506 14:06:41.442250 26400 solver.cpp:244]     Train net output #0: loss = 0.230624 (* 1 = 0.230624 loss)
I0506 14:06:41.442289 26400 sgd_solver.cpp:106] Iteration 31050, lr = 1e-06
I0506 14:08:51.375591 26400 solver.cpp:228] Iteration 31100, loss = 0.073183
I0506 14:08:51.375746 26400 solver.cpp:244]     Train net output #0: loss = 0.0731843 (* 1 = 0.0731843 loss)
I0506 14:08:51.375759 26400 sgd_solver.cpp:106] Iteration 31100, lr = 1e-06
I0506 14:11:01.333868 26400 solver.cpp:228] Iteration 31150, loss = -1.2815e-06
I0506 14:11:01.334069 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:11:01.334098 26400 sgd_solver.cpp:106] Iteration 31150, lr = 1e-06
I0506 14:13:08.604739 26400 solver.cpp:337] Iteration 31200, Testing net (#0)
I0506 14:13:47.843076 26400 solver.cpp:404]     Test net output #0: loss = 0.122433 (* 1 = 0.122433 loss)
I0506 14:13:48.712961 26400 solver.cpp:228] Iteration 31200, loss = 0.0427014
I0506 14:13:48.713024 26400 solver.cpp:244]     Train net output #0: loss = 0.0427026 (* 1 = 0.0427026 loss)
I0506 14:13:48.713040 26400 sgd_solver.cpp:106] Iteration 31200, lr = 1e-06
I0506 14:15:58.659518 26400 solver.cpp:228] Iteration 31250, loss = -1.3113e-06
I0506 14:15:58.659729 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:15:58.659768 26400 sgd_solver.cpp:106] Iteration 31250, lr = 1e-06
I0506 14:18:08.290868 26400 solver.cpp:228] Iteration 31300, loss = 0.0297021
I0506 14:18:08.291115 26400 solver.cpp:244]     Train net output #0: loss = 0.0297034 (* 1 = 0.0297034 loss)
I0506 14:18:08.291157 26400 sgd_solver.cpp:106] Iteration 31300, lr = 1e-06
I0506 14:20:18.179128 26400 solver.cpp:228] Iteration 31350, loss = 0.0623312
I0506 14:20:18.179682 26400 solver.cpp:244]     Train net output #0: loss = 0.0623325 (* 1 = 0.0623325 loss)
I0506 14:20:18.179728 26400 sgd_solver.cpp:106] Iteration 31350, lr = 1e-06
I0506 14:22:25.247735 26400 solver.cpp:337] Iteration 31400, Testing net (#0)
I0506 14:22:30.951797 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 14:23:08.032258 26400 solver.cpp:404]     Test net output #0: loss = 0.12167 (* 1 = 0.12167 loss)
I0506 14:23:08.894351 26400 solver.cpp:228] Iteration 31400, loss = 0.0286662
I0506 14:23:08.894417 26400 solver.cpp:244]     Train net output #0: loss = 0.0286676 (* 1 = 0.0286676 loss)
I0506 14:23:08.894429 26400 sgd_solver.cpp:106] Iteration 31400, lr = 1e-06
I0506 14:25:19.241184 26400 solver.cpp:228] Iteration 31450, loss = -1.3113e-06
I0506 14:25:19.241340 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:25:19.241363 26400 sgd_solver.cpp:106] Iteration 31450, lr = 1e-06
I0506 14:27:29.422986 26400 solver.cpp:228] Iteration 31500, loss = 0.0512988
I0506 14:27:29.435425 26400 solver.cpp:244]     Train net output #0: loss = 0.0513002 (* 1 = 0.0513002 loss)
I0506 14:27:29.435456 26400 sgd_solver.cpp:106] Iteration 31500, lr = 1e-06
I0506 14:29:39.291206 26400 solver.cpp:228] Iteration 31550, loss = -1.3113e-06
I0506 14:29:39.291529 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:29:39.291559 26400 sgd_solver.cpp:106] Iteration 31550, lr = 1e-06
I0506 14:31:46.610637 26400 solver.cpp:337] Iteration 31600, Testing net (#0)
I0506 14:32:26.529870 26400 solver.cpp:404]     Test net output #0: loss = 0.114904 (* 1 = 0.114904 loss)
I0506 14:32:27.396049 26400 solver.cpp:228] Iteration 31600, loss = 0.124863
I0506 14:32:27.396121 26400 solver.cpp:244]     Train net output #0: loss = 0.124864 (* 1 = 0.124864 loss)
I0506 14:32:27.396139 26400 sgd_solver.cpp:106] Iteration 31600, lr = 1e-06
I0506 14:34:37.407332 26400 solver.cpp:228] Iteration 31650, loss = 0.0148453
I0506 14:34:37.407812 26400 solver.cpp:244]     Train net output #0: loss = 0.0148466 (* 1 = 0.0148466 loss)
I0506 14:34:37.407840 26400 sgd_solver.cpp:106] Iteration 31650, lr = 1e-06
I0506 14:36:46.926935 26400 solver.cpp:228] Iteration 31700, loss = 0.0297125
I0506 14:36:46.927156 26400 solver.cpp:244]     Train net output #0: loss = 0.0297138 (* 1 = 0.0297138 loss)
I0506 14:36:46.927199 26400 sgd_solver.cpp:106] Iteration 31700, lr = 1e-06
I0506 14:38:56.653529 26400 solver.cpp:228] Iteration 31750, loss = 0.00305429
I0506 14:38:56.653725 26400 solver.cpp:244]     Train net output #0: loss = 0.00305557 (* 1 = 0.00305557 loss)
I0506 14:38:56.653743 26400 sgd_solver.cpp:106] Iteration 31750, lr = 1e-06
I0506 14:41:03.742270 26400 solver.cpp:337] Iteration 31800, Testing net (#0)
I0506 14:41:21.819774 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 14:41:33.802528 26400 solver.cpp:404]     Test net output #0: loss = 0.125122 (* 1 = 0.125122 loss)
I0506 14:41:34.671954 26400 solver.cpp:228] Iteration 31800, loss = -1.2815e-06
I0506 14:41:34.672013 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:41:34.672044 26400 sgd_solver.cpp:106] Iteration 31800, lr = 1e-06
I0506 14:43:44.431046 26400 solver.cpp:228] Iteration 31850, loss = -1.2964e-06
I0506 14:43:44.432394 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 14:43:44.432410 26400 sgd_solver.cpp:106] Iteration 31850, lr = 1e-06
I0506 14:45:54.226845 26400 solver.cpp:228] Iteration 31900, loss = 0.0610785
I0506 14:45:54.227121 26400 solver.cpp:244]     Train net output #0: loss = 0.0610798 (* 1 = 0.0610798 loss)
I0506 14:45:54.227149 26400 sgd_solver.cpp:106] Iteration 31900, lr = 1e-06
I0506 14:48:04.026757 26400 solver.cpp:228] Iteration 31950, loss = 0.0297776
I0506 14:48:04.027037 26400 solver.cpp:244]     Train net output #0: loss = 0.0297789 (* 1 = 0.0297789 loss)
I0506 14:48:04.027083 26400 sgd_solver.cpp:106] Iteration 31950, lr = 1e-06
I0506 14:50:11.309716 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_32000.caffemodel
I0506 14:50:16.151655 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_32000.solverstate
I0506 14:50:16.211405 26400 solver.cpp:337] Iteration 32000, Testing net (#0)
I0506 14:50:44.710710 26400 solver.cpp:404]     Test net output #0: loss = 0.128897 (* 1 = 0.128897 loss)
I0506 14:50:45.574846 26400 solver.cpp:228] Iteration 32000, loss = 0.038549
I0506 14:50:45.574929 26400 solver.cpp:244]     Train net output #0: loss = 0.0385503 (* 1 = 0.0385503 loss)
I0506 14:50:45.574945 26400 sgd_solver.cpp:106] Iteration 32000, lr = 1e-06
I0506 14:52:54.951273 26400 solver.cpp:228] Iteration 32050, loss = 0.0299491
I0506 14:52:54.951503 26400 solver.cpp:244]     Train net output #0: loss = 0.0299503 (* 1 = 0.0299503 loss)
I0506 14:52:54.951534 26400 sgd_solver.cpp:106] Iteration 32050, lr = 1e-06
I0506 14:55:04.593444 26400 solver.cpp:228] Iteration 32100, loss = 0.0515069
I0506 14:55:04.606097 26400 solver.cpp:244]     Train net output #0: loss = 0.0515082 (* 1 = 0.0515082 loss)
I0506 14:55:04.606143 26400 sgd_solver.cpp:106] Iteration 32100, lr = 1e-06
I0506 14:57:14.398579 26400 solver.cpp:228] Iteration 32150, loss = 0.0113573
I0506 14:57:14.398797 26400 solver.cpp:244]     Train net output #0: loss = 0.0113587 (* 1 = 0.0113587 loss)
I0506 14:57:14.398838 26400 sgd_solver.cpp:106] Iteration 32150, lr = 1e-06
I0506 14:59:21.238457 26400 solver.cpp:337] Iteration 32200, Testing net (#0)
I0506 14:59:48.838347 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 14:59:51.404175 26400 solver.cpp:404]     Test net output #0: loss = 0.121526 (* 1 = 0.121526 loss)
I0506 14:59:52.272505 26400 solver.cpp:228] Iteration 32200, loss = 0.0317355
I0506 14:59:52.272570 26400 solver.cpp:244]     Train net output #0: loss = 0.0317369 (* 1 = 0.0317369 loss)
I0506 14:59:52.272585 26400 sgd_solver.cpp:106] Iteration 32200, lr = 1e-06
I0506 15:02:02.167475 26400 solver.cpp:228] Iteration 32250, loss = -1.37091e-06
I0506 15:02:02.169044 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:02:02.169075 26400 sgd_solver.cpp:106] Iteration 32250, lr = 1e-06
I0506 15:04:12.082458 26400 solver.cpp:228] Iteration 32300, loss = 0.143483
I0506 15:04:12.083737 26400 solver.cpp:244]     Train net output #0: loss = 0.143485 (* 1 = 0.143485 loss)
I0506 15:04:12.083753 26400 sgd_solver.cpp:106] Iteration 32300, lr = 1e-06
I0506 15:06:21.723511 26400 solver.cpp:228] Iteration 32350, loss = -1.37091e-06
I0506 15:06:21.723695 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:06:21.723714 26400 sgd_solver.cpp:106] Iteration 32350, lr = 1e-06
I0506 15:08:29.110237 26400 solver.cpp:337] Iteration 32400, Testing net (#0)
I0506 15:08:59.763166 26400 solver.cpp:404]     Test net output #0: loss = 0.136505 (* 1 = 0.136505 loss)
I0506 15:09:00.630007 26400 solver.cpp:228] Iteration 32400, loss = 0.182882
I0506 15:09:00.630076 26400 solver.cpp:244]     Train net output #0: loss = 0.182883 (* 1 = 0.182883 loss)
I0506 15:09:00.630092 26400 sgd_solver.cpp:106] Iteration 32400, lr = 1e-06
I0506 15:11:10.270102 26400 solver.cpp:228] Iteration 32450, loss = -1.40164e-06
I0506 15:11:10.270352 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:11:10.270396 26400 sgd_solver.cpp:106] Iteration 32450, lr = 1e-06
I0506 15:13:20.200500 26400 solver.cpp:228] Iteration 32500, loss = -1.46404e-06
I0506 15:13:20.200747 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:13:20.200773 26400 sgd_solver.cpp:106] Iteration 32500, lr = 1e-06
I0506 15:15:30.116559 26400 solver.cpp:228] Iteration 32550, loss = -1.49012e-06
I0506 15:15:30.116726 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:15:30.116770 26400 sgd_solver.cpp:106] Iteration 32550, lr = 1e-06
I0506 15:17:37.135435 26400 solver.cpp:337] Iteration 32600, Testing net (#0)
I0506 15:18:13.864256 26400 solver.cpp:404]     Test net output #0: loss = 0.115122 (* 1 = 0.115122 loss)
I0506 15:18:14.730058 26400 solver.cpp:228] Iteration 32600, loss = -1.53482e-06
I0506 15:18:14.730109 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:18:14.730124 26400 sgd_solver.cpp:106] Iteration 32600, lr = 1e-06
I0506 15:20:24.431725 26400 solver.cpp:228] Iteration 32650, loss = 0.0349566
I0506 15:20:24.432297 26400 solver.cpp:244]     Train net output #0: loss = 0.0349581 (* 1 = 0.0349581 loss)
I0506 15:20:24.432315 26400 sgd_solver.cpp:106] Iteration 32650, lr = 1e-06
I0506 15:22:34.207347 26400 solver.cpp:228] Iteration 32700, loss = 0.0361684
I0506 15:22:34.208974 26400 solver.cpp:244]     Train net output #0: loss = 0.0361699 (* 1 = 0.0361699 loss)
I0506 15:22:34.208992 26400 sgd_solver.cpp:106] Iteration 32700, lr = 1e-06
I0506 15:24:44.199450 26400 solver.cpp:228] Iteration 32750, loss = -1.51992e-06
I0506 15:24:44.199645 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:24:44.199661 26400 sgd_solver.cpp:106] Iteration 32750, lr = 1e-06
I0506 15:26:51.255836 26400 solver.cpp:337] Iteration 32800, Testing net (#0)
I0506 15:27:07.851325 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 15:27:35.770691 26400 solver.cpp:404]     Test net output #0: loss = 0.129015 (* 1 = 0.129015 loss)
I0506 15:27:36.637055 26400 solver.cpp:228] Iteration 32800, loss = -1.50502e-06
I0506 15:27:36.637130 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:27:36.637152 26400 sgd_solver.cpp:106] Iteration 32800, lr = 1e-06
I0506 15:29:47.124361 26400 solver.cpp:228] Iteration 32850, loss = 0.0677768
I0506 15:29:47.124562 26400 solver.cpp:244]     Train net output #0: loss = 0.0677783 (* 1 = 0.0677783 loss)
I0506 15:29:47.124593 26400 sgd_solver.cpp:106] Iteration 32850, lr = 1e-06
I0506 15:31:57.099686 26400 solver.cpp:228] Iteration 32900, loss = 0.0264038
I0506 15:31:57.099908 26400 solver.cpp:244]     Train net output #0: loss = 0.0264053 (* 1 = 0.0264053 loss)
I0506 15:31:57.099949 26400 sgd_solver.cpp:106] Iteration 32900, lr = 1e-06
I0506 15:34:07.009294 26400 solver.cpp:228] Iteration 32950, loss = 0.0436043
I0506 15:34:07.012342 26400 solver.cpp:244]     Train net output #0: loss = 0.0436058 (* 1 = 0.0436058 loss)
I0506 15:34:07.012388 26400 sgd_solver.cpp:106] Iteration 32950, lr = 1e-06
I0506 15:36:14.275708 26400 solver.cpp:337] Iteration 33000, Testing net (#0)
I0506 15:36:57.682948 26400 solver.cpp:404]     Test net output #0: loss = 0.111898 (* 1 = 0.111898 loss)
I0506 15:36:58.547174 26400 solver.cpp:228] Iteration 33000, loss = 0.090091
I0506 15:36:58.547245 26400 solver.cpp:244]     Train net output #0: loss = 0.0900925 (* 1 = 0.0900925 loss)
I0506 15:36:58.547269 26400 sgd_solver.cpp:106] Iteration 33000, lr = 1e-06
I0506 15:39:08.812501 26400 solver.cpp:228] Iteration 33050, loss = 0.100612
I0506 15:39:08.815134 26400 solver.cpp:244]     Train net output #0: loss = 0.100613 (* 1 = 0.100613 loss)
I0506 15:39:08.815161 26400 sgd_solver.cpp:106] Iteration 33050, lr = 1e-06
I0506 15:41:18.681468 26400 solver.cpp:228] Iteration 33100, loss = 0.0684781
I0506 15:41:18.681695 26400 solver.cpp:244]     Train net output #0: loss = 0.0684796 (* 1 = 0.0684796 loss)
I0506 15:41:18.681723 26400 sgd_solver.cpp:106] Iteration 33100, lr = 1e-06
I0506 15:43:28.541959 26400 solver.cpp:228] Iteration 33150, loss = -1.48267e-06
I0506 15:43:28.542145 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:43:28.542161 26400 sgd_solver.cpp:106] Iteration 33150, lr = 1e-06
I0506 15:45:35.675842 26400 solver.cpp:337] Iteration 33200, Testing net (#0)
I0506 15:45:53.308785 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 15:46:09.529742 26400 solver.cpp:404]     Test net output #0: loss = 0.146219 (* 1 = 0.146219 loss)
I0506 15:46:10.394585 26400 solver.cpp:228] Iteration 33200, loss = 0.00438998
I0506 15:46:10.394656 26400 solver.cpp:244]     Train net output #0: loss = 0.00439153 (* 1 = 0.00439153 loss)
I0506 15:46:10.394675 26400 sgd_solver.cpp:106] Iteration 33200, lr = 1e-06
I0506 15:48:20.287505 26400 solver.cpp:228] Iteration 33250, loss = 0.0687598
I0506 15:48:20.287684 26400 solver.cpp:244]     Train net output #0: loss = 0.0687615 (* 1 = 0.0687615 loss)
I0506 15:48:20.287700 26400 sgd_solver.cpp:106] Iteration 33250, lr = 1e-06
I0506 15:50:30.215735 26400 solver.cpp:228] Iteration 33300, loss = 0.056014
I0506 15:50:30.215958 26400 solver.cpp:244]     Train net output #0: loss = 0.0560156 (* 1 = 0.0560156 loss)
I0506 15:50:30.215996 26400 sgd_solver.cpp:106] Iteration 33300, lr = 1e-06
I0506 15:52:39.843761 26400 solver.cpp:228] Iteration 33350, loss = -1.60933e-06
I0506 15:52:39.843907 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 15:52:39.843935 26400 sgd_solver.cpp:106] Iteration 33350, lr = 1e-06
I0506 15:54:46.833465 26400 solver.cpp:337] Iteration 33400, Testing net (#0)
I0506 15:55:30.008280 26400 solver.cpp:404]     Test net output #0: loss = 0.101984 (* 1 = 0.101984 loss)
I0506 15:55:30.883186 26400 solver.cpp:228] Iteration 33400, loss = 0.0412544
I0506 15:55:30.883255 26400 solver.cpp:244]     Train net output #0: loss = 0.041256 (* 1 = 0.041256 loss)
I0506 15:55:30.883270 26400 sgd_solver.cpp:106] Iteration 33400, lr = 1e-06
I0506 15:57:41.088304 26400 solver.cpp:228] Iteration 33450, loss = 0.101423
I0506 15:57:41.089941 26400 solver.cpp:244]     Train net output #0: loss = 0.101424 (* 1 = 0.101424 loss)
I0506 15:57:41.089956 26400 sgd_solver.cpp:106] Iteration 33450, lr = 1e-06
I0506 15:59:51.121263 26400 solver.cpp:228] Iteration 33500, loss = 0.34545
I0506 15:59:51.121541 26400 solver.cpp:244]     Train net output #0: loss = 0.345451 (* 1 = 0.345451 loss)
I0506 15:59:51.121572 26400 sgd_solver.cpp:106] Iteration 33500, lr = 1e-06
I0506 16:02:00.883519 26400 solver.cpp:228] Iteration 33550, loss = 0.0587148
I0506 16:02:00.883694 26400 solver.cpp:244]     Train net output #0: loss = 0.0587164 (* 1 = 0.0587164 loss)
I0506 16:02:00.883710 26400 sgd_solver.cpp:106] Iteration 33550, lr = 1e-06
I0506 16:04:07.786365 26400 solver.cpp:337] Iteration 33600, Testing net (#0)
I0506 16:04:28.687644 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 16:04:41.417660 26400 solver.cpp:404]     Test net output #0: loss = 0.111126 (* 1 = 0.111126 loss)
I0506 16:04:42.285351 26400 solver.cpp:228] Iteration 33600, loss = 0.0754374
I0506 16:04:42.285399 26400 solver.cpp:244]     Train net output #0: loss = 0.075439 (* 1 = 0.075439 loss)
I0506 16:04:42.285414 26400 sgd_solver.cpp:106] Iteration 33600, lr = 1e-06
I0506 16:06:52.212532 26400 solver.cpp:228] Iteration 33650, loss = 0.0155222
I0506 16:06:52.213768 26400 solver.cpp:244]     Train net output #0: loss = 0.0155238 (* 1 = 0.0155238 loss)
I0506 16:06:52.213794 26400 sgd_solver.cpp:106] Iteration 33650, lr = 1e-06
I0506 16:09:01.969733 26400 solver.cpp:228] Iteration 33700, loss = 0.00740635
I0506 16:09:01.969897 26400 solver.cpp:244]     Train net output #0: loss = 0.00740799 (* 1 = 0.00740799 loss)
I0506 16:09:01.969913 26400 sgd_solver.cpp:106] Iteration 33700, lr = 1e-06
I0506 16:11:11.842113 26400 solver.cpp:228] Iteration 33750, loss = -1.63913e-06
I0506 16:11:11.842278 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:11:11.842294 26400 sgd_solver.cpp:106] Iteration 33750, lr = 1e-06
I0506 16:13:19.094620 26400 solver.cpp:337] Iteration 33800, Testing net (#0)
I0506 16:14:00.543653 26400 solver.cpp:404]     Test net output #0: loss = 0.0945854 (* 1 = 0.0945854 loss)
I0506 16:14:01.408241 26400 solver.cpp:228] Iteration 33800, loss = -1.65403e-06
I0506 16:14:01.408325 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:14:01.408349 26400 sgd_solver.cpp:106] Iteration 33800, lr = 1e-06
I0506 16:16:11.541987 26400 solver.cpp:228] Iteration 33850, loss = 0.0400993
I0506 16:16:11.543601 26400 solver.cpp:244]     Train net output #0: loss = 0.0401009 (* 1 = 0.0401009 loss)
I0506 16:16:11.543634 26400 sgd_solver.cpp:106] Iteration 33850, lr = 1e-06
I0506 16:18:21.385092 26400 solver.cpp:228] Iteration 33900, loss = 0.152918
I0506 16:18:21.385239 26400 solver.cpp:244]     Train net output #0: loss = 0.15292 (* 1 = 0.15292 loss)
I0506 16:18:21.385258 26400 sgd_solver.cpp:106] Iteration 33900, lr = 1e-06
I0506 16:20:31.035327 26400 solver.cpp:228] Iteration 33950, loss = 0.0244953
I0506 16:20:31.035639 26400 solver.cpp:244]     Train net output #0: loss = 0.0244969 (* 1 = 0.0244969 loss)
I0506 16:20:31.035653 26400 sgd_solver.cpp:106] Iteration 33950, lr = 1e-06
I0506 16:22:38.363263 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_34000.caffemodel
I0506 16:22:44.281461 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_34000.solverstate
I0506 16:22:44.331601 26400 solver.cpp:337] Iteration 34000, Testing net (#0)
I0506 16:23:14.610797 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 16:23:27.036911 26400 solver.cpp:404]     Test net output #0: loss = 0.115106 (* 1 = 0.115106 loss)
I0506 16:23:27.903945 26400 solver.cpp:228] Iteration 34000, loss = -1.69873e-06
I0506 16:23:27.904022 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:23:27.904057 26400 sgd_solver.cpp:106] Iteration 34000, lr = 1e-06
I0506 16:25:38.873859 26400 solver.cpp:228] Iteration 34050, loss = -1.68383e-06
I0506 16:25:38.886459 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:25:38.886523 26400 sgd_solver.cpp:106] Iteration 34050, lr = 1e-06
I0506 16:27:49.039814 26400 solver.cpp:228] Iteration 34100, loss = 0.0109727
I0506 16:27:49.039993 26400 solver.cpp:244]     Train net output #0: loss = 0.0109743 (* 1 = 0.0109743 loss)
I0506 16:27:49.040014 26400 sgd_solver.cpp:106] Iteration 34100, lr = 1e-06
I0506 16:29:58.985811 26400 solver.cpp:228] Iteration 34150, loss = -1.66893e-06
I0506 16:29:58.988198 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:29:58.988225 26400 sgd_solver.cpp:106] Iteration 34150, lr = 1e-06
I0506 16:32:06.571735 26400 solver.cpp:337] Iteration 34200, Testing net (#0)
I0506 16:32:54.733619 26400 solver.cpp:404]     Test net output #0: loss = 0.11767 (* 1 = 0.11767 loss)
I0506 16:32:55.600389 26400 solver.cpp:228] Iteration 34200, loss = 0.0264255
I0506 16:32:55.600452 26400 solver.cpp:244]     Train net output #0: loss = 0.0264271 (* 1 = 0.0264271 loss)
I0506 16:32:55.600469 26400 sgd_solver.cpp:106] Iteration 34200, lr = 1e-06
I0506 16:35:06.287317 26400 solver.cpp:228] Iteration 34250, loss = 0.00476323
I0506 16:35:06.287508 26400 solver.cpp:244]     Train net output #0: loss = 0.00476492 (* 1 = 0.00476492 loss)
I0506 16:35:06.287555 26400 sgd_solver.cpp:106] Iteration 34250, lr = 1e-06
I0506 16:37:16.271631 26400 solver.cpp:228] Iteration 34300, loss = 0.0982287
I0506 16:37:16.271927 26400 solver.cpp:244]     Train net output #0: loss = 0.0982304 (* 1 = 0.0982304 loss)
I0506 16:37:16.271952 26400 sgd_solver.cpp:106] Iteration 34300, lr = 1e-06
I0506 16:39:26.464437 26400 solver.cpp:228] Iteration 34350, loss = 0.0509169
I0506 16:39:26.464715 26400 solver.cpp:244]     Train net output #0: loss = 0.0509186 (* 1 = 0.0509186 loss)
I0506 16:39:26.464758 26400 sgd_solver.cpp:106] Iteration 34350, lr = 1e-06
I0506 16:41:33.723289 26400 solver.cpp:337] Iteration 34400, Testing net (#0)
I0506 16:42:14.285836 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 16:42:27.538019 26400 solver.cpp:404]     Test net output #0: loss = 0.120697 (* 1 = 0.120697 loss)
I0506 16:42:28.396852 26400 solver.cpp:228] Iteration 34400, loss = -1.67172e-06
I0506 16:42:28.396899 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:42:28.396914 26400 sgd_solver.cpp:106] Iteration 34400, lr = 1e-06
I0506 16:44:39.329321 26400 solver.cpp:228] Iteration 34450, loss = -1.66148e-06
I0506 16:44:39.329499 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:44:39.329524 26400 sgd_solver.cpp:106] Iteration 34450, lr = 1e-06
I0506 16:46:49.271306 26400 solver.cpp:228] Iteration 34500, loss = -1.66893e-06
I0506 16:46:49.271711 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:46:49.271728 26400 sgd_solver.cpp:106] Iteration 34500, lr = 1e-06
I0506 16:48:59.120767 26400 solver.cpp:228] Iteration 34550, loss = 0.0470713
I0506 16:48:59.120951 26400 solver.cpp:244]     Train net output #0: loss = 0.047073 (* 1 = 0.047073 loss)
I0506 16:48:59.120967 26400 sgd_solver.cpp:106] Iteration 34550, lr = 1e-06
I0506 16:51:06.487829 26400 solver.cpp:337] Iteration 34600, Testing net (#0)
I0506 16:51:36.742715 26400 solver.cpp:404]     Test net output #0: loss = 0.116539 (* 1 = 0.116539 loss)
I0506 16:51:37.615152 26400 solver.cpp:228] Iteration 34600, loss = 0.0311282
I0506 16:51:37.615206 26400 solver.cpp:244]     Train net output #0: loss = 0.0311299 (* 1 = 0.0311299 loss)
I0506 16:51:37.615221 26400 sgd_solver.cpp:106] Iteration 34600, lr = 1e-06
I0506 16:53:47.620750 26400 solver.cpp:228] Iteration 34650, loss = 0.0293517
I0506 16:53:47.633225 26400 solver.cpp:244]     Train net output #0: loss = 0.0293533 (* 1 = 0.0293533 loss)
I0506 16:53:47.633250 26400 sgd_solver.cpp:106] Iteration 34650, lr = 1e-06
I0506 16:55:57.504525 26400 solver.cpp:228] Iteration 34700, loss = -1.63913e-06
I0506 16:55:57.504740 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 16:55:57.504771 26400 sgd_solver.cpp:106] Iteration 34700, lr = 1e-06
I0506 16:58:07.442519 26400 solver.cpp:228] Iteration 34750, loss = 0.0113716
I0506 16:58:07.442867 26400 solver.cpp:244]     Train net output #0: loss = 0.0113732 (* 1 = 0.0113732 loss)
I0506 16:58:07.442961 26400 sgd_solver.cpp:106] Iteration 34750, lr = 1e-06
I0506 17:00:14.838271 26400 solver.cpp:337] Iteration 34800, Testing net (#0)
I0506 17:00:39.838579 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 17:00:45.089303 26400 solver.cpp:404]     Test net output #0: loss = 0.116614 (* 1 = 0.116614 loss)
I0506 17:00:45.956965 26400 solver.cpp:228] Iteration 34800, loss = -1.63913e-06
I0506 17:00:45.957028 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:00:45.957043 26400 sgd_solver.cpp:106] Iteration 34800, lr = 1e-06
I0506 17:02:55.957087 26400 solver.cpp:228] Iteration 34850, loss = 0.0129869
I0506 17:02:55.957329 26400 solver.cpp:244]     Train net output #0: loss = 0.0129885 (* 1 = 0.0129885 loss)
I0506 17:02:55.957361 26400 sgd_solver.cpp:106] Iteration 34850, lr = 1e-06
I0506 17:05:06.009974 26400 solver.cpp:228] Iteration 34900, loss = 0.0502224
I0506 17:05:06.010236 26400 solver.cpp:244]     Train net output #0: loss = 0.0502241 (* 1 = 0.0502241 loss)
I0506 17:05:06.010282 26400 sgd_solver.cpp:106] Iteration 34900, lr = 1e-06
I0506 17:07:16.041582 26400 solver.cpp:228] Iteration 34950, loss = 0.0397878
I0506 17:07:16.044920 26400 solver.cpp:244]     Train net output #0: loss = 0.0397894 (* 1 = 0.0397894 loss)
I0506 17:07:16.044944 26400 sgd_solver.cpp:106] Iteration 34950, lr = 1e-06
I0506 17:09:23.716948 26400 solver.cpp:337] Iteration 35000, Testing net (#0)
I0506 17:09:53.973757 26400 solver.cpp:404]     Test net output #0: loss = 0.13919 (* 1 = 0.13919 loss)
I0506 17:09:54.848498 26400 solver.cpp:228] Iteration 35000, loss = 0.0702423
I0506 17:09:54.848568 26400 solver.cpp:244]     Train net output #0: loss = 0.0702439 (* 1 = 0.0702439 loss)
I0506 17:09:54.848597 26400 sgd_solver.cpp:106] Iteration 35000, lr = 1e-06
I0506 17:12:04.713436 26400 solver.cpp:228] Iteration 35050, loss = -1.61678e-06
I0506 17:12:04.715072 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:12:04.715101 26400 sgd_solver.cpp:106] Iteration 35050, lr = 1e-06
I0506 17:14:14.429600 26400 solver.cpp:228] Iteration 35100, loss = -1.62586e-06
I0506 17:14:14.430519 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:14:14.430553 26400 sgd_solver.cpp:106] Iteration 35100, lr = 1e-06
I0506 17:16:24.332500 26400 solver.cpp:228] Iteration 35150, loss = 0.274381
I0506 17:16:24.332934 26400 solver.cpp:244]     Train net output #0: loss = 0.274383 (* 1 = 0.274383 loss)
I0506 17:16:24.332979 26400 sgd_solver.cpp:106] Iteration 35150, lr = 1e-06
I0506 17:18:31.519372 26400 solver.cpp:337] Iteration 35200, Testing net (#0)
I0506 17:19:01.375919 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 17:19:02.114894 26400 solver.cpp:404]     Test net output #0: loss = 0.131889 (* 1 = 0.131889 loss)
I0506 17:19:02.984475 26400 solver.cpp:228] Iteration 35200, loss = 0.0437295
I0506 17:19:02.984524 26400 solver.cpp:244]     Train net output #0: loss = 0.0437311 (* 1 = 0.0437311 loss)
I0506 17:19:02.984541 26400 sgd_solver.cpp:106] Iteration 35200, lr = 1e-06
I0506 17:21:13.032254 26400 solver.cpp:228] Iteration 35250, loss = 0.00616683
I0506 17:21:13.032429 26400 solver.cpp:244]     Train net output #0: loss = 0.00616845 (* 1 = 0.00616845 loss)
I0506 17:21:13.032445 26400 sgd_solver.cpp:106] Iteration 35250, lr = 1e-06
I0506 17:23:22.991420 26400 solver.cpp:228] Iteration 35300, loss = 0.0597483
I0506 17:23:22.992383 26400 solver.cpp:244]     Train net output #0: loss = 0.0597499 (* 1 = 0.0597499 loss)
I0506 17:23:22.992408 26400 sgd_solver.cpp:106] Iteration 35300, lr = 1e-06
I0506 17:25:32.995534 26400 solver.cpp:228] Iteration 35350, loss = 0.0211496
I0506 17:25:33.008059 26400 solver.cpp:244]     Train net output #0: loss = 0.0211512 (* 1 = 0.0211512 loss)
I0506 17:25:33.008076 26400 sgd_solver.cpp:106] Iteration 35350, lr = 1e-06
I0506 17:27:40.303025 26400 solver.cpp:337] Iteration 35400, Testing net (#0)
I0506 17:28:28.335167 26400 solver.cpp:404]     Test net output #0: loss = 0.119179 (* 1 = 0.119179 loss)
I0506 17:28:29.196892 26400 solver.cpp:228] Iteration 35400, loss = 0.00296799
I0506 17:28:29.196943 26400 solver.cpp:244]     Train net output #0: loss = 0.00296959 (* 1 = 0.00296959 loss)
I0506 17:28:29.196974 26400 sgd_solver.cpp:106] Iteration 35400, lr = 1e-06
I0506 17:30:40.030705 26400 solver.cpp:228] Iteration 35450, loss = -1.60187e-06
I0506 17:30:40.032760 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:30:40.032809 26400 sgd_solver.cpp:106] Iteration 35450, lr = 1e-06
I0506 17:32:50.297101 26400 solver.cpp:228] Iteration 35500, loss = 0.0929491
I0506 17:32:50.297278 26400 solver.cpp:244]     Train net output #0: loss = 0.0929507 (* 1 = 0.0929507 loss)
I0506 17:32:50.297296 26400 sgd_solver.cpp:106] Iteration 35500, lr = 1e-06
I0506 17:35:00.305624 26400 solver.cpp:228] Iteration 35550, loss = -1.60933e-06
I0506 17:35:00.311070 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:35:00.311134 26400 sgd_solver.cpp:106] Iteration 35550, lr = 1e-06
I0506 17:37:07.749579 26400 solver.cpp:337] Iteration 35600, Testing net (#0)
I0506 17:37:53.754376 26400 solver.cpp:404]     Test net output #0: loss = 0.0924537 (* 1 = 0.0924537 loss)
I0506 17:37:54.617187 26400 solver.cpp:228] Iteration 35600, loss = 0.0600863
I0506 17:37:54.617269 26400 solver.cpp:244]     Train net output #0: loss = 0.0600879 (* 1 = 0.0600879 loss)
I0506 17:37:54.617291 26400 sgd_solver.cpp:106] Iteration 35600, lr = 1e-06
I0506 17:40:05.315647 26400 solver.cpp:228] Iteration 35650, loss = -1.59442e-06
I0506 17:40:05.315918 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:40:05.315961 26400 sgd_solver.cpp:106] Iteration 35650, lr = 1e-06
I0506 17:42:15.326465 26400 solver.cpp:228] Iteration 35700, loss = 0.0711166
I0506 17:42:15.326710 26400 solver.cpp:244]     Train net output #0: loss = 0.0711182 (* 1 = 0.0711182 loss)
I0506 17:42:15.326733 26400 sgd_solver.cpp:106] Iteration 35700, lr = 1e-06
I0506 17:44:25.215307 26400 solver.cpp:228] Iteration 35750, loss = -1.56462e-06
I0506 17:44:25.216725 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:44:25.216789 26400 sgd_solver.cpp:106] Iteration 35750, lr = 1e-06
I0506 17:46:32.247630 26400 solver.cpp:337] Iteration 35800, Testing net (#0)
I0506 17:46:35.528050 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 17:47:14.107272 26400 solver.cpp:404]     Test net output #0: loss = 0.110977 (* 1 = 0.110977 loss)
I0506 17:47:14.972266 26400 solver.cpp:228] Iteration 35800, loss = 0.0672672
I0506 17:47:14.972321 26400 solver.cpp:244]     Train net output #0: loss = 0.0672688 (* 1 = 0.0672688 loss)
I0506 17:47:14.972335 26400 sgd_solver.cpp:106] Iteration 35800, lr = 1e-06
I0506 17:49:25.472839 26400 solver.cpp:228] Iteration 35850, loss = 0.0951689
I0506 17:49:25.473075 26400 solver.cpp:244]     Train net output #0: loss = 0.0951704 (* 1 = 0.0951704 loss)
I0506 17:49:25.473107 26400 sgd_solver.cpp:106] Iteration 35850, lr = 1e-06
I0506 17:51:35.417465 26400 solver.cpp:228] Iteration 35900, loss = -1.56462e-06
I0506 17:51:35.417711 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:51:35.417763 26400 sgd_solver.cpp:106] Iteration 35900, lr = 1e-06
I0506 17:53:45.465186 26400 solver.cpp:228] Iteration 35950, loss = 0.144436
I0506 17:53:45.465368 26400 solver.cpp:244]     Train net output #0: loss = 0.144437 (* 1 = 0.144437 loss)
I0506 17:53:45.465384 26400 sgd_solver.cpp:106] Iteration 35950, lr = 1e-06
I0506 17:55:53.018597 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_36000.caffemodel
I0506 17:55:58.474653 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_36000.solverstate
I0506 17:55:58.547482 26400 solver.cpp:337] Iteration 36000, Testing net (#0)
I0506 17:56:29.650979 26400 solver.cpp:404]     Test net output #0: loss = 0.112525 (* 1 = 0.112525 loss)
I0506 17:56:30.519680 26400 solver.cpp:228] Iteration 36000, loss = -1.51992e-06
I0506 17:56:30.519749 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 17:56:30.519778 26400 sgd_solver.cpp:106] Iteration 36000, lr = 1e-06
I0506 17:58:40.770750 26400 solver.cpp:228] Iteration 36050, loss = 0.0250155
I0506 17:58:40.771028 26400 solver.cpp:244]     Train net output #0: loss = 0.025017 (* 1 = 0.025017 loss)
I0506 17:58:40.771072 26400 sgd_solver.cpp:106] Iteration 36050, lr = 1e-06
I0506 18:00:50.752038 26400 solver.cpp:228] Iteration 36100, loss = 0.0125993
I0506 18:00:50.752269 26400 solver.cpp:244]     Train net output #0: loss = 0.0126009 (* 1 = 0.0126009 loss)
I0506 18:00:50.752303 26400 sgd_solver.cpp:106] Iteration 36100, lr = 1e-06
I0506 18:03:00.614960 26400 solver.cpp:228] Iteration 36150, loss = 0.146947
I0506 18:03:00.615111 26400 solver.cpp:244]     Train net output #0: loss = 0.146949 (* 1 = 0.146949 loss)
I0506 18:03:00.615130 26400 sgd_solver.cpp:106] Iteration 36150, lr = 1e-06
I0506 18:05:08.026645 26400 solver.cpp:337] Iteration 36200, Testing net (#0)
I0506 18:05:30.038856 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 18:05:38.201825 26400 solver.cpp:404]     Test net output #0: loss = 0.115538 (* 1 = 0.115538 loss)
I0506 18:05:39.070700 26400 solver.cpp:228] Iteration 36200, loss = -1.49012e-06
I0506 18:05:39.070765 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:05:39.070835 26400 sgd_solver.cpp:106] Iteration 36200, lr = 1e-06
I0506 18:07:48.960497 26400 solver.cpp:228] Iteration 36250, loss = -1.45339e-06
I0506 18:07:48.960638 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:07:48.960664 26400 sgd_solver.cpp:106] Iteration 36250, lr = 1e-06
I0506 18:09:58.788354 26400 solver.cpp:228] Iteration 36300, loss = -1.44541e-06
I0506 18:09:58.794026 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:09:58.794062 26400 sgd_solver.cpp:106] Iteration 36300, lr = 1e-06
I0506 18:12:08.917992 26400 solver.cpp:228] Iteration 36350, loss = 0.0119685
I0506 18:12:08.918180 26400 solver.cpp:244]     Train net output #0: loss = 0.0119699 (* 1 = 0.0119699 loss)
I0506 18:12:08.918196 26400 sgd_solver.cpp:106] Iteration 36350, lr = 1e-06
I0506 18:14:16.236945 26400 solver.cpp:337] Iteration 36400, Testing net (#0)
I0506 18:14:48.268805 26400 solver.cpp:404]     Test net output #0: loss = 0.10138 (* 1 = 0.10138 loss)
I0506 18:14:49.140561 26400 solver.cpp:228] Iteration 36400, loss = 0.0508796
I0506 18:14:49.140628 26400 solver.cpp:244]     Train net output #0: loss = 0.0508811 (* 1 = 0.0508811 loss)
I0506 18:14:49.140642 26400 sgd_solver.cpp:106] Iteration 36400, lr = 1e-06
I0506 18:16:59.190284 26400 solver.cpp:228] Iteration 36450, loss = -1.41561e-06
I0506 18:16:59.190464 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:16:59.190482 26400 sgd_solver.cpp:106] Iteration 36450, lr = 1e-06
I0506 18:19:08.885344 26400 solver.cpp:228] Iteration 36500, loss = 0.0129382
I0506 18:19:08.885501 26400 solver.cpp:244]     Train net output #0: loss = 0.0129397 (* 1 = 0.0129397 loss)
I0506 18:19:08.885519 26400 sgd_solver.cpp:106] Iteration 36500, lr = 1e-06
I0506 18:21:18.872990 26400 solver.cpp:228] Iteration 36550, loss = 0.10861
I0506 18:21:18.873144 26400 solver.cpp:244]     Train net output #0: loss = 0.108612 (* 1 = 0.108612 loss)
I0506 18:21:18.873159 26400 sgd_solver.cpp:106] Iteration 36550, lr = 1e-06
I0506 18:23:26.343348 26400 solver.cpp:337] Iteration 36600, Testing net (#0)
I0506 18:24:01.906576 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 18:24:08.467061 26400 solver.cpp:404]     Test net output #0: loss = 0.129579 (* 1 = 0.129579 loss)
I0506 18:24:09.327324 26400 solver.cpp:228] Iteration 36600, loss = 0.104071
I0506 18:24:09.327368 26400 solver.cpp:244]     Train net output #0: loss = 0.104073 (* 1 = 0.104073 loss)
I0506 18:24:09.327380 26400 sgd_solver.cpp:106] Iteration 36600, lr = 1e-06
I0506 18:26:19.907662 26400 solver.cpp:228] Iteration 36650, loss = -1.3411e-06
I0506 18:26:19.908534 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:26:19.908551 26400 sgd_solver.cpp:106] Iteration 36650, lr = 1e-06
I0506 18:28:30.326068 26400 solver.cpp:228] Iteration 36700, loss = 0.0113746
I0506 18:28:30.326222 26400 solver.cpp:244]     Train net output #0: loss = 0.0113759 (* 1 = 0.0113759 loss)
I0506 18:28:30.326237 26400 sgd_solver.cpp:106] Iteration 36700, lr = 1e-06
I0506 18:30:40.373994 26400 solver.cpp:228] Iteration 36750, loss = 0.0154837
I0506 18:30:40.374191 26400 solver.cpp:244]     Train net output #0: loss = 0.015485 (* 1 = 0.015485 loss)
I0506 18:30:40.374214 26400 sgd_solver.cpp:106] Iteration 36750, lr = 1e-06
I0506 18:32:47.547782 26400 solver.cpp:337] Iteration 36800, Testing net (#0)
I0506 18:33:40.930068 26400 solver.cpp:404]     Test net output #0: loss = 0.137259 (* 1 = 0.137259 loss)
I0506 18:33:41.791661 26400 solver.cpp:228] Iteration 36800, loss = -1.28895e-06
I0506 18:33:41.791718 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:33:41.791733 26400 sgd_solver.cpp:106] Iteration 36800, lr = 1e-06
I0506 18:35:52.689370 26400 solver.cpp:228] Iteration 36850, loss = -1.30385e-06
I0506 18:35:52.689571 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:35:52.689587 26400 sgd_solver.cpp:106] Iteration 36850, lr = 1e-06
I0506 18:38:02.896818 26400 solver.cpp:228] Iteration 36900, loss = 0.0211782
I0506 18:38:02.897228 26400 solver.cpp:244]     Train net output #0: loss = 0.0211796 (* 1 = 0.0211796 loss)
I0506 18:38:02.897258 26400 sgd_solver.cpp:106] Iteration 36900, lr = 1e-06
I0506 18:40:13.060503 26400 solver.cpp:228] Iteration 36950, loss = -1.3411e-06
I0506 18:40:13.060907 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:40:13.060979 26400 sgd_solver.cpp:106] Iteration 36950, lr = 1e-06
I0506 18:42:20.465183 26400 solver.cpp:337] Iteration 37000, Testing net (#0)
I0506 18:42:49.974467 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 18:42:50.659936 26400 solver.cpp:404]     Test net output #0: loss = 0.110335 (* 1 = 0.110335 loss)
I0506 18:42:51.529806 26400 solver.cpp:228] Iteration 37000, loss = -1.3411e-06
I0506 18:42:51.529866 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 18:42:51.529881 26400 sgd_solver.cpp:106] Iteration 37000, lr = 1e-06
I0506 18:45:01.702927 26400 solver.cpp:228] Iteration 37050, loss = 0.0402857
I0506 18:45:01.703632 26400 solver.cpp:244]     Train net output #0: loss = 0.040287 (* 1 = 0.040287 loss)
I0506 18:45:01.703665 26400 sgd_solver.cpp:106] Iteration 37050, lr = 1e-06
I0506 18:47:11.648862 26400 solver.cpp:228] Iteration 37100, loss = 0.040134
I0506 18:47:11.649029 26400 solver.cpp:244]     Train net output #0: loss = 0.0401353 (* 1 = 0.0401353 loss)
I0506 18:47:11.649044 26400 sgd_solver.cpp:106] Iteration 37100, lr = 1e-06
I0506 18:49:21.472424 26400 solver.cpp:228] Iteration 37150, loss = 0.117904
I0506 18:49:21.474596 26400 solver.cpp:244]     Train net output #0: loss = 0.117905 (* 1 = 0.117905 loss)
I0506 18:49:21.474632 26400 sgd_solver.cpp:106] Iteration 37150, lr = 1e-06
I0506 18:51:29.064121 26400 solver.cpp:337] Iteration 37200, Testing net (#0)
I0506 18:51:59.278375 26400 solver.cpp:404]     Test net output #0: loss = 0.119252 (* 1 = 0.119252 loss)
I0506 18:52:00.149166 26400 solver.cpp:228] Iteration 37200, loss = 0.0183158
I0506 18:52:00.149243 26400 solver.cpp:244]     Train net output #0: loss = 0.0183171 (* 1 = 0.0183171 loss)
I0506 18:52:00.149265 26400 sgd_solver.cpp:106] Iteration 37200, lr = 1e-06
I0506 18:54:10.023032 26400 solver.cpp:228] Iteration 37250, loss = 0.045528
I0506 18:54:10.035598 26400 solver.cpp:244]     Train net output #0: loss = 0.0455293 (* 1 = 0.0455293 loss)
I0506 18:54:10.035634 26400 sgd_solver.cpp:106] Iteration 37250, lr = 1e-06
I0506 18:56:19.744633 26400 solver.cpp:228] Iteration 37300, loss = 0.0516971
I0506 18:56:19.745430 26400 solver.cpp:244]     Train net output #0: loss = 0.0516984 (* 1 = 0.0516984 loss)
I0506 18:56:19.745450 26400 sgd_solver.cpp:106] Iteration 37300, lr = 1e-06
I0506 18:58:29.964020 26400 solver.cpp:228] Iteration 37350, loss = 0.0200922
I0506 18:58:29.964325 26400 solver.cpp:244]     Train net output #0: loss = 0.0200935 (* 1 = 0.0200935 loss)
I0506 18:58:29.964385 26400 sgd_solver.cpp:106] Iteration 37350, lr = 1e-06
I0506 19:00:37.190222 26400 solver.cpp:337] Iteration 37400, Testing net (#0)
I0506 19:01:08.036146 26400 solver.cpp:404]     Test net output #0: loss = 0.120929 (* 1 = 0.120929 loss)
I0506 19:01:08.910066 26400 solver.cpp:228] Iteration 37400, loss = 0.0969933
I0506 19:01:08.910122 26400 solver.cpp:244]     Train net output #0: loss = 0.0969946 (* 1 = 0.0969946 loss)
I0506 19:01:08.910135 26400 sgd_solver.cpp:106] Iteration 37400, lr = 1e-06
I0506 19:03:19.045068 26400 solver.cpp:228] Iteration 37450, loss = 0.041451
I0506 19:03:19.045289 26400 solver.cpp:244]     Train net output #0: loss = 0.0414523 (* 1 = 0.0414523 loss)
I0506 19:03:19.045326 26400 sgd_solver.cpp:106] Iteration 37450, lr = 1e-06
I0506 19:05:29.039849 26400 solver.cpp:228] Iteration 37500, loss = -1.3113e-06
I0506 19:05:29.040093 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:05:29.040139 26400 sgd_solver.cpp:106] Iteration 37500, lr = 1e-06
I0506 19:07:38.701067 26400 solver.cpp:228] Iteration 37550, loss = 0.0119767
I0506 19:07:38.701323 26400 solver.cpp:244]     Train net output #0: loss = 0.0119781 (* 1 = 0.0119781 loss)
I0506 19:07:38.701398 26400 sgd_solver.cpp:106] Iteration 37550, lr = 1e-06
I0506 19:09:46.227303 26400 solver.cpp:337] Iteration 37600, Testing net (#0)
I0506 19:10:09.692656 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 19:10:16.553814 26400 solver.cpp:404]     Test net output #0: loss = 0.102335 (* 1 = 0.102335 loss)
I0506 19:10:17.421505 26400 solver.cpp:228] Iteration 37600, loss = 0.123625
I0506 19:10:17.421563 26400 solver.cpp:244]     Train net output #0: loss = 0.123626 (* 1 = 0.123626 loss)
I0506 19:10:17.421577 26400 sgd_solver.cpp:106] Iteration 37600, lr = 1e-06
I0506 19:12:27.299093 26400 solver.cpp:228] Iteration 37650, loss = 0.055205
I0506 19:12:27.299309 26400 solver.cpp:244]     Train net output #0: loss = 0.0552064 (* 1 = 0.0552064 loss)
I0506 19:12:27.299350 26400 sgd_solver.cpp:106] Iteration 37650, lr = 1e-06
I0506 19:14:37.008138 26400 solver.cpp:228] Iteration 37700, loss = 0.0525374
I0506 19:14:37.008419 26400 solver.cpp:244]     Train net output #0: loss = 0.0525387 (* 1 = 0.0525387 loss)
I0506 19:14:37.008450 26400 sgd_solver.cpp:106] Iteration 37700, lr = 1e-06
I0506 19:16:47.199110 26400 solver.cpp:228] Iteration 37750, loss = 0.0548829
I0506 19:16:47.199301 26400 solver.cpp:244]     Train net output #0: loss = 0.0548842 (* 1 = 0.0548842 loss)
I0506 19:16:47.199319 26400 sgd_solver.cpp:106] Iteration 37750, lr = 1e-06
I0506 19:18:54.380326 26400 solver.cpp:337] Iteration 37800, Testing net (#0)
I0506 19:19:24.330251 26400 solver.cpp:404]     Test net output #0: loss = 0.122186 (* 1 = 0.122186 loss)
I0506 19:19:25.194823 26400 solver.cpp:228] Iteration 37800, loss = 0.0330455
I0506 19:19:25.196403 26400 solver.cpp:244]     Train net output #0: loss = 0.0330468 (* 1 = 0.0330468 loss)
I0506 19:19:25.196429 26400 sgd_solver.cpp:106] Iteration 37800, lr = 1e-06
I0506 19:21:35.154645 26400 solver.cpp:228] Iteration 37850, loss = 0.0512772
I0506 19:21:35.154999 26400 solver.cpp:244]     Train net output #0: loss = 0.0512785 (* 1 = 0.0512785 loss)
I0506 19:21:35.155020 26400 sgd_solver.cpp:106] Iteration 37850, lr = 1e-06
I0506 19:23:45.163141 26400 solver.cpp:228] Iteration 37900, loss = 0.201837
I0506 19:23:45.165534 26400 solver.cpp:244]     Train net output #0: loss = 0.201838 (* 1 = 0.201838 loss)
I0506 19:23:45.165575 26400 sgd_solver.cpp:106] Iteration 37900, lr = 1e-06
I0506 19:25:54.846608 26400 solver.cpp:228] Iteration 37950, loss = -1.36718e-06
I0506 19:25:54.846887 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:25:54.846971 26400 sgd_solver.cpp:106] Iteration 37950, lr = 1e-06
I0506 19:28:02.325605 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_38000.caffemodel
I0506 19:28:08.801633 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_38000.solverstate
I0506 19:28:08.863433 26400 solver.cpp:337] Iteration 38000, Testing net (#0)
I0506 19:28:37.084079 26400 solver.cpp:404]     Test net output #0: loss = 0.116858 (* 1 = 0.116858 loss)
I0506 19:28:37.950311 26400 solver.cpp:228] Iteration 38000, loss = 0.0846585
I0506 19:28:37.950362 26400 solver.cpp:244]     Train net output #0: loss = 0.08466 (* 1 = 0.08466 loss)
I0506 19:28:37.950388 26400 sgd_solver.cpp:106] Iteration 38000, lr = 1e-06
I0506 19:30:47.940791 26400 solver.cpp:228] Iteration 38050, loss = -1.48267e-06
I0506 19:30:47.940950 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:30:47.940975 26400 sgd_solver.cpp:106] Iteration 38050, lr = 1e-06
I0506 19:32:57.932296 26400 solver.cpp:228] Iteration 38100, loss = 0.0158527
I0506 19:32:57.932468 26400 solver.cpp:244]     Train net output #0: loss = 0.0158541 (* 1 = 0.0158541 loss)
I0506 19:32:57.932482 26400 sgd_solver.cpp:106] Iteration 38100, lr = 1e-06
I0506 19:35:07.939409 26400 solver.cpp:228] Iteration 38150, loss = 0.00400502
I0506 19:35:07.939656 26400 solver.cpp:244]     Train net output #0: loss = 0.00400649 (* 1 = 0.00400649 loss)
I0506 19:35:07.939702 26400 sgd_solver.cpp:106] Iteration 38150, lr = 1e-06
I0506 19:37:15.305868 26400 solver.cpp:337] Iteration 38200, Testing net (#0)
I0506 19:37:45.815418 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 19:37:46.325278 26400 solver.cpp:404]     Test net output #0: loss = 0.103565 (* 1 = 0.103565 loss)
I0506 19:37:47.190366 26400 solver.cpp:228] Iteration 38200, loss = -1.49012e-06
I0506 19:37:47.190426 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:37:47.190441 26400 sgd_solver.cpp:106] Iteration 38200, lr = 1e-06
I0506 19:39:57.119194 26400 solver.cpp:228] Iteration 38250, loss = 0.106272
I0506 19:39:57.122243 26400 solver.cpp:244]     Train net output #0: loss = 0.106273 (* 1 = 0.106273 loss)
I0506 19:39:57.122345 26400 sgd_solver.cpp:106] Iteration 38250, lr = 1e-06
I0506 19:42:07.073972 26400 solver.cpp:228] Iteration 38300, loss = 0.033024
I0506 19:42:07.074231 26400 solver.cpp:244]     Train net output #0: loss = 0.0330255 (* 1 = 0.0330255 loss)
I0506 19:42:07.074285 26400 sgd_solver.cpp:106] Iteration 38300, lr = 1e-06
I0506 19:44:16.655786 26400 solver.cpp:228] Iteration 38350, loss = -1.49012e-06
I0506 19:44:16.656021 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:44:16.656065 26400 sgd_solver.cpp:106] Iteration 38350, lr = 1e-06
I0506 19:46:23.943967 26400 solver.cpp:337] Iteration 38400, Testing net (#0)
I0506 19:46:54.512918 26400 solver.cpp:404]     Test net output #0: loss = 0.0991803 (* 1 = 0.0991803 loss)
I0506 19:46:55.379288 26400 solver.cpp:228] Iteration 38400, loss = 0.0569795
I0506 19:46:55.379333 26400 solver.cpp:244]     Train net output #0: loss = 0.056981 (* 1 = 0.056981 loss)
I0506 19:46:55.379346 26400 sgd_solver.cpp:106] Iteration 38400, lr = 1e-06
I0506 19:49:05.464308 26400 solver.cpp:228] Iteration 38450, loss = -1.49012e-06
I0506 19:49:05.464480 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 19:49:05.464498 26400 sgd_solver.cpp:106] Iteration 38450, lr = 1e-06
I0506 19:51:15.518502 26400 solver.cpp:228] Iteration 38500, loss = 0.00280126
I0506 19:51:15.531046 26400 solver.cpp:244]     Train net output #0: loss = 0.00280276 (* 1 = 0.00280276 loss)
I0506 19:51:15.531087 26400 sgd_solver.cpp:106] Iteration 38500, lr = 1e-06
I0506 19:53:25.453613 26400 solver.cpp:228] Iteration 38550, loss = 0.0249117
I0506 19:53:25.454023 26400 solver.cpp:244]     Train net output #0: loss = 0.0249132 (* 1 = 0.0249132 loss)
I0506 19:53:25.454069 26400 sgd_solver.cpp:106] Iteration 38550, lr = 1e-06
I0506 19:55:32.842604 26400 solver.cpp:337] Iteration 38600, Testing net (#0)
I0506 19:56:03.668464 26400 solver.cpp:404]     Test net output #0: loss = 0.127574 (* 1 = 0.127574 loss)
I0506 19:56:04.533843 26400 solver.cpp:228] Iteration 38600, loss = 0.0388651
I0506 19:56:04.533895 26400 solver.cpp:244]     Train net output #0: loss = 0.0388666 (* 1 = 0.0388666 loss)
I0506 19:56:04.533921 26400 sgd_solver.cpp:106] Iteration 38600, lr = 1e-06
I0506 19:58:14.450934 26400 solver.cpp:228] Iteration 38650, loss = 0.0541285
I0506 19:58:14.453061 26400 solver.cpp:244]     Train net output #0: loss = 0.0541301 (* 1 = 0.0541301 loss)
I0506 19:58:14.453078 26400 sgd_solver.cpp:106] Iteration 38650, lr = 1e-06
I0506 20:00:24.295786 26400 solver.cpp:228] Iteration 38700, loss = 0.135776
I0506 20:00:24.298765 26400 solver.cpp:244]     Train net output #0: loss = 0.135777 (* 1 = 0.135777 loss)
I0506 20:00:24.298811 26400 sgd_solver.cpp:106] Iteration 38700, lr = 1e-06
I0506 20:02:34.003429 26400 solver.cpp:228] Iteration 38750, loss = 0.219575
I0506 20:02:34.005853 26400 solver.cpp:244]     Train net output #0: loss = 0.219577 (* 1 = 0.219577 loss)
I0506 20:02:34.005916 26400 sgd_solver.cpp:106] Iteration 38750, lr = 1e-06
I0506 20:04:41.518187 26400 solver.cpp:337] Iteration 38800, Testing net (#0)
I0506 20:05:02.254566 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 20:05:12.204141 26400 solver.cpp:404]     Test net output #0: loss = 0.152605 (* 1 = 0.152605 loss)
I0506 20:05:13.072950 26400 solver.cpp:228] Iteration 38800, loss = 0.0254105
I0506 20:05:13.073052 26400 solver.cpp:244]     Train net output #0: loss = 0.025412 (* 1 = 0.025412 loss)
I0506 20:05:13.073071 26400 sgd_solver.cpp:106] Iteration 38800, lr = 1e-06
I0506 20:07:23.004376 26400 solver.cpp:228] Iteration 38850, loss = 0.0289577
I0506 20:07:23.004633 26400 solver.cpp:244]     Train net output #0: loss = 0.0289593 (* 1 = 0.0289593 loss)
I0506 20:07:23.004676 26400 sgd_solver.cpp:106] Iteration 38850, lr = 1e-06
I0506 20:09:32.934586 26400 solver.cpp:228] Iteration 38900, loss = -1.55717e-06
I0506 20:09:32.934779 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:09:32.934798 26400 sgd_solver.cpp:106] Iteration 38900, lr = 1e-06
I0506 20:11:42.814563 26400 solver.cpp:228] Iteration 38950, loss = -1.56835e-06
I0506 20:11:42.814735 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:11:42.814751 26400 sgd_solver.cpp:106] Iteration 38950, lr = 1e-06
I0506 20:13:50.143551 26400 solver.cpp:337] Iteration 39000, Testing net (#0)
I0506 20:14:20.914788 26400 solver.cpp:404]     Test net output #0: loss = 0.109265 (* 1 = 0.109265 loss)
I0506 20:14:21.779479 26400 solver.cpp:228] Iteration 39000, loss = -1.5758e-06
I0506 20:14:21.779541 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:14:21.779557 26400 sgd_solver.cpp:106] Iteration 39000, lr = 1e-06
I0506 20:16:31.753926 26400 solver.cpp:228] Iteration 39050, loss = 0.011143
I0506 20:16:31.754215 26400 solver.cpp:244]     Train net output #0: loss = 0.0111446 (* 1 = 0.0111446 loss)
I0506 20:16:31.754246 26400 sgd_solver.cpp:106] Iteration 39050, lr = 1e-06
I0506 20:18:41.654438 26400 solver.cpp:228] Iteration 39100, loss = -1.61678e-06
I0506 20:18:41.654659 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:18:41.654688 26400 sgd_solver.cpp:106] Iteration 39100, lr = 1e-06
I0506 20:20:51.506827 26400 solver.cpp:228] Iteration 39150, loss = 0.130632
I0506 20:20:51.507016 26400 solver.cpp:244]     Train net output #0: loss = 0.130634 (* 1 = 0.130634 loss)
I0506 20:20:51.507043 26400 sgd_solver.cpp:106] Iteration 39150, lr = 1e-06
I0506 20:22:58.763406 26400 solver.cpp:337] Iteration 39200, Testing net (#0)
I0506 20:23:29.944669 26400 solver.cpp:404]     Test net output #0: loss = 0.132111 (* 1 = 0.132111 loss)
I0506 20:23:30.813235 26400 solver.cpp:228] Iteration 39200, loss = 0.202185
I0506 20:23:30.813290 26400 solver.cpp:244]     Train net output #0: loss = 0.202187 (* 1 = 0.202187 loss)
I0506 20:23:30.813303 26400 sgd_solver.cpp:106] Iteration 39200, lr = 1e-06
I0506 20:25:40.650866 26400 solver.cpp:228] Iteration 39250, loss = 0.0469719
I0506 20:25:40.651039 26400 solver.cpp:244]     Train net output #0: loss = 0.0469736 (* 1 = 0.0469736 loss)
I0506 20:25:40.651062 26400 sgd_solver.cpp:106] Iteration 39250, lr = 1e-06
I0506 20:27:50.363099 26400 solver.cpp:228] Iteration 39300, loss = 0.0181208
I0506 20:27:50.363247 26400 solver.cpp:244]     Train net output #0: loss = 0.0181224 (* 1 = 0.0181224 loss)
I0506 20:27:50.363263 26400 sgd_solver.cpp:106] Iteration 39300, lr = 1e-06
I0506 20:30:00.312577 26400 solver.cpp:228] Iteration 39350, loss = -1.59536e-06
I0506 20:30:00.312795 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:30:00.312829 26400 sgd_solver.cpp:106] Iteration 39350, lr = 1e-06
I0506 20:32:07.613289 26400 solver.cpp:337] Iteration 39400, Testing net (#0)
I0506 20:32:17.594322 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 20:32:38.412344 26400 solver.cpp:404]     Test net output #0: loss = 0.109302 (* 1 = 0.109302 loss)
I0506 20:32:39.283205 26400 solver.cpp:228] Iteration 39400, loss = 0.085425
I0506 20:32:39.283267 26400 solver.cpp:244]     Train net output #0: loss = 0.0854266 (* 1 = 0.0854266 loss)
I0506 20:32:39.283290 26400 sgd_solver.cpp:106] Iteration 39400, lr = 1e-06
I0506 20:34:49.204449 26400 solver.cpp:228] Iteration 39450, loss = -1.56462e-06
I0506 20:34:49.204823 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:34:49.204855 26400 sgd_solver.cpp:106] Iteration 39450, lr = 1e-06
I0506 20:36:59.018103 26400 solver.cpp:228] Iteration 39500, loss = 0.0803357
I0506 20:36:59.018281 26400 solver.cpp:244]     Train net output #0: loss = 0.0803373 (* 1 = 0.0803373 loss)
I0506 20:36:59.018297 26400 sgd_solver.cpp:106] Iteration 39500, lr = 1e-06
I0506 20:39:08.874083 26400 solver.cpp:228] Iteration 39550, loss = -1.57859e-06
I0506 20:39:08.874510 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:39:08.874542 26400 sgd_solver.cpp:106] Iteration 39550, lr = 1e-06
I0506 20:41:16.112417 26400 solver.cpp:337] Iteration 39600, Testing net (#0)
I0506 20:41:46.360438 26400 solver.cpp:404]     Test net output #0: loss = 0.0856875 (* 1 = 0.0856875 loss)
I0506 20:41:47.224113 26400 solver.cpp:228] Iteration 39600, loss = -1.57952e-06
I0506 20:41:47.224167 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:41:47.224192 26400 sgd_solver.cpp:106] Iteration 39600, lr = 1e-06
I0506 20:43:56.927687 26400 solver.cpp:228] Iteration 39650, loss = -1.57207e-06
I0506 20:43:56.927897 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:43:56.927918 26400 sgd_solver.cpp:106] Iteration 39650, lr = 1e-06
I0506 20:46:06.785693 26400 solver.cpp:228] Iteration 39700, loss = 0.0239116
I0506 20:46:06.785938 26400 solver.cpp:244]     Train net output #0: loss = 0.0239132 (* 1 = 0.0239132 loss)
I0506 20:46:06.785984 26400 sgd_solver.cpp:106] Iteration 39700, lr = 1e-06
I0506 20:48:16.788784 26400 solver.cpp:228] Iteration 39750, loss = -1.54972e-06
I0506 20:48:16.788954 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 20:48:16.788969 26400 sgd_solver.cpp:106] Iteration 39750, lr = 1e-06
I0506 20:50:23.885469 26400 solver.cpp:337] Iteration 39800, Testing net (#0)
I0506 20:50:45.787489 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 20:50:54.429415 26400 solver.cpp:404]     Test net output #0: loss = 0.115857 (* 1 = 0.115857 loss)
I0506 20:50:55.295686 26400 solver.cpp:228] Iteration 39800, loss = 0.00224316
I0506 20:50:55.295745 26400 solver.cpp:244]     Train net output #0: loss = 0.00224472 (* 1 = 0.00224472 loss)
I0506 20:50:55.295768 26400 sgd_solver.cpp:106] Iteration 39800, lr = 1e-06
I0506 20:53:05.123414 26400 solver.cpp:228] Iteration 39850, loss = 0.0649777
I0506 20:53:05.135993 26400 solver.cpp:244]     Train net output #0: loss = 0.0649793 (* 1 = 0.0649793 loss)
I0506 20:53:05.136029 26400 sgd_solver.cpp:106] Iteration 39850, lr = 1e-06
I0506 20:55:14.909037 26400 solver.cpp:228] Iteration 39900, loss = 0.00639969
I0506 20:55:14.909201 26400 solver.cpp:244]     Train net output #0: loss = 0.0064012 (* 1 = 0.0064012 loss)
I0506 20:55:14.909214 26400 sgd_solver.cpp:106] Iteration 39900, lr = 1e-06
I0506 20:57:24.740303 26400 solver.cpp:228] Iteration 39950, loss = 0.114369
I0506 20:57:24.740499 26400 solver.cpp:244]     Train net output #0: loss = 0.114371 (* 1 = 0.114371 loss)
I0506 20:57:24.740527 26400 sgd_solver.cpp:106] Iteration 39950, lr = 1e-06
I0506 20:59:31.958405 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_40000.caffemodel
I0506 20:59:38.972466 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_40000.solverstate
I0506 20:59:39.040721 26400 solver.cpp:337] Iteration 40000, Testing net (#0)
I0506 21:00:07.923058 26400 solver.cpp:404]     Test net output #0: loss = 0.126897 (* 1 = 0.126897 loss)
I0506 21:00:08.788969 26400 solver.cpp:228] Iteration 40000, loss = -1.46031e-06
I0506 21:00:08.789024 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:00:08.789039 26400 sgd_solver.cpp:106] Iteration 40000, lr = 1e-07
I0506 21:02:18.508550 26400 solver.cpp:228] Iteration 40050, loss = 0.268648
I0506 21:02:18.508731 26400 solver.cpp:244]     Train net output #0: loss = 0.268649 (* 1 = 0.268649 loss)
I0506 21:02:18.508746 26400 sgd_solver.cpp:106] Iteration 40050, lr = 1e-07
I0506 21:04:28.429141 26400 solver.cpp:228] Iteration 40100, loss = 0.0396256
I0506 21:04:28.429381 26400 solver.cpp:244]     Train net output #0: loss = 0.039627 (* 1 = 0.039627 loss)
I0506 21:04:28.429412 26400 sgd_solver.cpp:106] Iteration 40100, lr = 1e-07
I0506 21:06:38.320520 26400 solver.cpp:228] Iteration 40150, loss = 0.0169763
I0506 21:06:38.320745 26400 solver.cpp:244]     Train net output #0: loss = 0.0169777 (* 1 = 0.0169777 loss)
I0506 21:06:38.320780 26400 sgd_solver.cpp:106] Iteration 40150, lr = 1e-07
I0506 21:08:45.475190 26400 solver.cpp:337] Iteration 40200, Testing net (#0)
I0506 21:09:15.005870 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 21:09:16.481545 26400 solver.cpp:404]     Test net output #0: loss = 0.12593 (* 1 = 0.12593 loss)
I0506 21:09:17.348119 26400 solver.cpp:228] Iteration 40200, loss = 0.0775537
I0506 21:09:17.348166 26400 solver.cpp:244]     Train net output #0: loss = 0.0775551 (* 1 = 0.0775551 loss)
I0506 21:09:17.348179 26400 sgd_solver.cpp:106] Iteration 40200, lr = 1e-07
I0506 21:11:27.470021 26400 solver.cpp:228] Iteration 40250, loss = 0.0802774
I0506 21:11:27.470312 26400 solver.cpp:244]     Train net output #0: loss = 0.0802788 (* 1 = 0.0802788 loss)
I0506 21:11:27.470352 26400 sgd_solver.cpp:106] Iteration 40250, lr = 1e-07
I0506 21:13:37.275604 26400 solver.cpp:228] Iteration 40300, loss = 0.161461
I0506 21:13:37.277510 26400 solver.cpp:244]     Train net output #0: loss = 0.161462 (* 1 = 0.161462 loss)
I0506 21:13:37.277529 26400 sgd_solver.cpp:106] Iteration 40300, lr = 1e-07
I0506 21:15:47.129279 26400 solver.cpp:228] Iteration 40350, loss = 0.0329898
I0506 21:15:47.130343 26400 solver.cpp:244]     Train net output #0: loss = 0.0329912 (* 1 = 0.0329912 loss)
I0506 21:15:47.130359 26400 sgd_solver.cpp:106] Iteration 40350, lr = 1e-07
I0506 21:17:54.458132 26400 solver.cpp:337] Iteration 40400, Testing net (#0)
I0506 21:18:25.092767 26400 solver.cpp:404]     Test net output #0: loss = 0.115836 (* 1 = 0.115836 loss)
I0506 21:18:25.964262 26400 solver.cpp:228] Iteration 40400, loss = 0.0261242
I0506 21:18:25.964365 26400 solver.cpp:244]     Train net output #0: loss = 0.0261256 (* 1 = 0.0261256 loss)
I0506 21:18:25.964404 26400 sgd_solver.cpp:106] Iteration 40400, lr = 1e-07
I0506 21:20:35.660126 26400 solver.cpp:228] Iteration 40450, loss = 0.1116
I0506 21:20:35.672726 26400 solver.cpp:244]     Train net output #0: loss = 0.111602 (* 1 = 0.111602 loss)
I0506 21:20:35.672776 26400 sgd_solver.cpp:106] Iteration 40450, lr = 1e-07
I0506 21:22:45.586268 26400 solver.cpp:228] Iteration 40500, loss = 0.0835152
I0506 21:22:45.586705 26400 solver.cpp:244]     Train net output #0: loss = 0.0835167 (* 1 = 0.0835167 loss)
I0506 21:22:45.586860 26400 sgd_solver.cpp:106] Iteration 40500, lr = 1e-07
I0506 21:24:55.443425 26400 solver.cpp:228] Iteration 40550, loss = -1.47894e-06
I0506 21:24:55.443650 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:24:55.443727 26400 sgd_solver.cpp:106] Iteration 40550, lr = 1e-07
I0506 21:27:02.665014 26400 solver.cpp:337] Iteration 40600, Testing net (#0)
I0506 21:27:33.022841 26400 solver.cpp:404]     Test net output #0: loss = 0.12029 (* 1 = 0.12029 loss)
I0506 21:27:33.888443 26400 solver.cpp:228] Iteration 40600, loss = 0.0336776
I0506 21:27:33.888492 26400 solver.cpp:244]     Train net output #0: loss = 0.033679 (* 1 = 0.033679 loss)
I0506 21:27:33.888507 26400 sgd_solver.cpp:106] Iteration 40600, lr = 1e-07
I0506 21:29:43.683584 26400 solver.cpp:228] Iteration 40650, loss = -1.49012e-06
I0506 21:29:43.683840 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:29:43.683887 26400 sgd_solver.cpp:106] Iteration 40650, lr = 1e-07
I0506 21:31:53.606837 26400 solver.cpp:228] Iteration 40700, loss = 0.00251311
I0506 21:31:53.607064 26400 solver.cpp:244]     Train net output #0: loss = 0.00251459 (* 1 = 0.00251459 loss)
I0506 21:31:53.607085 26400 sgd_solver.cpp:106] Iteration 40700, lr = 1e-07
I0506 21:34:03.542961 26400 solver.cpp:228] Iteration 40750, loss = 0.0486442
I0506 21:34:03.543162 26400 solver.cpp:244]     Train net output #0: loss = 0.0486457 (* 1 = 0.0486457 loss)
I0506 21:34:03.543198 26400 sgd_solver.cpp:106] Iteration 40750, lr = 1e-07
I0506 21:36:10.648831 26400 solver.cpp:337] Iteration 40800, Testing net (#0)
I0506 21:36:22.244258 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 21:36:40.816104 26400 solver.cpp:404]     Test net output #0: loss = 0.1259 (* 1 = 0.1259 loss)
I0506 21:36:41.682071 26400 solver.cpp:228] Iteration 40800, loss = 0.00226085
I0506 21:36:41.682133 26400 solver.cpp:244]     Train net output #0: loss = 0.00226237 (* 1 = 0.00226237 loss)
I0506 21:36:41.682149 26400 sgd_solver.cpp:106] Iteration 40800, lr = 1e-07
I0506 21:38:51.510273 26400 solver.cpp:228] Iteration 40850, loss = -1.52178e-06
I0506 21:38:51.510509 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:38:51.510553 26400 sgd_solver.cpp:106] Iteration 40850, lr = 1e-07
I0506 21:41:01.277267 26400 solver.cpp:228] Iteration 40900, loss = -1.50502e-06
I0506 21:41:01.277407 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:41:01.277433 26400 sgd_solver.cpp:106] Iteration 40900, lr = 1e-07
I0506 21:43:10.821799 26400 solver.cpp:228] Iteration 40950, loss = 0.00249235
I0506 21:43:10.822022 26400 solver.cpp:244]     Train net output #0: loss = 0.00249383 (* 1 = 0.00249383 loss)
I0506 21:43:10.822067 26400 sgd_solver.cpp:106] Iteration 40950, lr = 1e-07
I0506 21:45:18.256124 26400 solver.cpp:337] Iteration 41000, Testing net (#0)
I0506 21:45:48.404472 26400 solver.cpp:404]     Test net output #0: loss = 0.119268 (* 1 = 0.119268 loss)
I0506 21:45:49.272004 26400 solver.cpp:228] Iteration 41000, loss = 0.0174363
I0506 21:45:49.272063 26400 solver.cpp:244]     Train net output #0: loss = 0.0174378 (* 1 = 0.0174378 loss)
I0506 21:45:49.272078 26400 sgd_solver.cpp:106] Iteration 41000, lr = 1e-07
I0506 21:47:59.190739 26400 solver.cpp:228] Iteration 41050, loss = 0.0123931
I0506 21:47:59.190925 26400 solver.cpp:244]     Train net output #0: loss = 0.0123946 (* 1 = 0.0123946 loss)
I0506 21:47:59.190945 26400 sgd_solver.cpp:106] Iteration 41050, lr = 1e-07
I0506 21:50:09.057911 26400 solver.cpp:228] Iteration 41100, loss = 0.0178444
I0506 21:50:09.070418 26400 solver.cpp:244]     Train net output #0: loss = 0.0178459 (* 1 = 0.0178459 loss)
I0506 21:50:09.070436 26400 sgd_solver.cpp:106] Iteration 41100, lr = 1e-07
I0506 21:52:18.888319 26400 solver.cpp:228] Iteration 41150, loss = 0.0340555
I0506 21:52:18.888494 26400 solver.cpp:244]     Train net output #0: loss = 0.034057 (* 1 = 0.034057 loss)
I0506 21:52:18.888510 26400 sgd_solver.cpp:106] Iteration 41150, lr = 1e-07
I0506 21:54:26.054776 26400 solver.cpp:337] Iteration 41200, Testing net (#0)
I0506 21:54:46.090828 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 21:54:56.074630 26400 solver.cpp:404]     Test net output #0: loss = 0.127098 (* 1 = 0.127098 loss)
I0506 21:54:56.945955 26400 solver.cpp:228] Iteration 41200, loss = 0.0973926
I0506 21:54:56.946044 26400 solver.cpp:244]     Train net output #0: loss = 0.0973941 (* 1 = 0.0973941 loss)
I0506 21:54:56.946076 26400 sgd_solver.cpp:106] Iteration 41200, lr = 1e-07
I0506 21:57:06.751791 26400 solver.cpp:228] Iteration 41250, loss = 0.0972259
I0506 21:57:06.752090 26400 solver.cpp:244]     Train net output #0: loss = 0.0972274 (* 1 = 0.0972274 loss)
I0506 21:57:06.752127 26400 sgd_solver.cpp:106] Iteration 41250, lr = 1e-07
I0506 21:59:16.537647 26400 solver.cpp:228] Iteration 41300, loss = -1.51992e-06
I0506 21:59:16.538739 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 21:59:16.538758 26400 sgd_solver.cpp:106] Iteration 41300, lr = 1e-07
I0506 22:01:26.314239 26400 solver.cpp:228] Iteration 41350, loss = 0.121681
I0506 22:01:26.314522 26400 solver.cpp:244]     Train net output #0: loss = 0.121683 (* 1 = 0.121683 loss)
I0506 22:01:26.314576 26400 sgd_solver.cpp:106] Iteration 41350, lr = 1e-07
I0506 22:03:33.811048 26400 solver.cpp:337] Iteration 41400, Testing net (#0)
I0506 22:04:04.148850 26400 solver.cpp:404]     Test net output #0: loss = 0.105468 (* 1 = 0.105468 loss)
I0506 22:04:05.015061 26400 solver.cpp:228] Iteration 41400, loss = 0.018882
I0506 22:04:05.015112 26400 solver.cpp:244]     Train net output #0: loss = 0.0188835 (* 1 = 0.0188835 loss)
I0506 22:04:05.015135 26400 sgd_solver.cpp:106] Iteration 41400, lr = 1e-07
I0506 22:06:14.965762 26400 solver.cpp:228] Iteration 41450, loss = -1.52923e-06
I0506 22:06:14.965935 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:06:14.965950 26400 sgd_solver.cpp:106] Iteration 41450, lr = 1e-07
I0506 22:08:24.720695 26400 solver.cpp:228] Iteration 41500, loss = -1.51992e-06
I0506 22:08:24.720875 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:08:24.720893 26400 sgd_solver.cpp:106] Iteration 41500, lr = 1e-07
I0506 22:10:34.624399 26400 solver.cpp:228] Iteration 41550, loss = 0.0089558
I0506 22:10:34.624621 26400 solver.cpp:244]     Train net output #0: loss = 0.00895733 (* 1 = 0.00895733 loss)
I0506 22:10:34.624658 26400 sgd_solver.cpp:106] Iteration 41550, lr = 1e-07
I0506 22:12:41.808583 26400 solver.cpp:337] Iteration 41600, Testing net (#0)
I0506 22:13:11.738350 26400 solver.cpp:404]     Test net output #0: loss = 0.0996869 (* 1 = 0.0996869 loss)
I0506 22:13:12.607470 26400 solver.cpp:228] Iteration 41600, loss = -1.52737e-06
I0506 22:13:12.607733 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:13:12.607779 26400 sgd_solver.cpp:106] Iteration 41600, lr = 1e-07
I0506 22:15:22.426774 26400 solver.cpp:228] Iteration 41650, loss = 0.0264529
I0506 22:15:22.427048 26400 solver.cpp:244]     Train net output #0: loss = 0.0264544 (* 1 = 0.0264544 loss)
I0506 22:15:22.427094 26400 sgd_solver.cpp:106] Iteration 41650, lr = 1e-07
I0506 22:17:32.162775 26400 solver.cpp:228] Iteration 41700, loss = -1.53482e-06
I0506 22:17:32.162976 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:17:32.162991 26400 sgd_solver.cpp:106] Iteration 41700, lr = 1e-07
I0506 22:19:41.956871 26400 solver.cpp:228] Iteration 41750, loss = -1.55717e-06
I0506 22:19:41.969795 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:19:41.969841 26400 sgd_solver.cpp:106] Iteration 41750, lr = 1e-07
I0506 22:21:49.355847 26400 solver.cpp:337] Iteration 41800, Testing net (#0)
I0506 22:22:09.805791 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 22:22:19.694965 26400 solver.cpp:404]     Test net output #0: loss = 0.106502 (* 1 = 0.106502 loss)
I0506 22:22:20.562026 26400 solver.cpp:228] Iteration 41800, loss = 0.028107
I0506 22:22:20.562124 26400 solver.cpp:244]     Train net output #0: loss = 0.0281086 (* 1 = 0.0281086 loss)
I0506 22:22:20.562150 26400 sgd_solver.cpp:106] Iteration 41800, lr = 1e-07
I0506 22:24:30.459017 26400 solver.cpp:228] Iteration 41850, loss = 0.049324
I0506 22:24:30.459180 26400 solver.cpp:244]     Train net output #0: loss = 0.0493255 (* 1 = 0.0493255 loss)
I0506 22:24:30.459198 26400 sgd_solver.cpp:106] Iteration 41850, lr = 1e-07
I0506 22:26:40.458493 26400 solver.cpp:228] Iteration 41900, loss = -1.57952e-06
I0506 22:26:40.458722 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:26:40.458771 26400 sgd_solver.cpp:106] Iteration 41900, lr = 1e-07
I0506 22:28:50.460952 26400 solver.cpp:228] Iteration 41950, loss = 0.00113468
I0506 22:28:50.461136 26400 solver.cpp:244]     Train net output #0: loss = 0.00113626 (* 1 = 0.00113626 loss)
I0506 22:28:50.461153 26400 sgd_solver.cpp:106] Iteration 41950, lr = 1e-07
I0506 22:30:57.560147 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_42000.caffemodel
I0506 22:31:05.701519 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_42000.solverstate
I0506 22:31:05.773736 26400 solver.cpp:337] Iteration 42000, Testing net (#0)
I0506 22:31:34.629086 26400 solver.cpp:404]     Test net output #0: loss = 0.110086 (* 1 = 0.110086 loss)
I0506 22:31:35.494596 26400 solver.cpp:228] Iteration 42000, loss = -1.57952e-06
I0506 22:31:35.494657 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:31:35.494673 26400 sgd_solver.cpp:106] Iteration 42000, lr = 1e-07
I0506 22:33:45.562889 26400 solver.cpp:228] Iteration 42050, loss = 0.0957067
I0506 22:33:45.563144 26400 solver.cpp:244]     Train net output #0: loss = 0.0957083 (* 1 = 0.0957083 loss)
I0506 22:33:45.563190 26400 sgd_solver.cpp:106] Iteration 42050, lr = 1e-07
I0506 22:35:55.339610 26400 solver.cpp:228] Iteration 42100, loss = 0.0277867
I0506 22:35:55.340041 26400 solver.cpp:244]     Train net output #0: loss = 0.0277882 (* 1 = 0.0277882 loss)
I0506 22:35:55.340173 26400 sgd_solver.cpp:106] Iteration 42100, lr = 1e-07
I0506 22:38:05.011862 26400 solver.cpp:228] Iteration 42150, loss = -1.57952e-06
I0506 22:38:05.012043 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:38:05.012078 26400 sgd_solver.cpp:106] Iteration 42150, lr = 1e-07
I0506 22:40:12.493541 26400 solver.cpp:337] Iteration 42200, Testing net (#0)
I0506 22:40:42.580502 26400 solver.cpp:404]     Test net output #0: loss = 0.111584 (* 1 = 0.111584 loss)
I0506 22:40:43.446281 26400 solver.cpp:228] Iteration 42200, loss = 0.000814012
I0506 22:40:43.446354 26400 solver.cpp:244]     Train net output #0: loss = 0.00081558 (* 1 = 0.00081558 loss)
I0506 22:40:43.446372 26400 sgd_solver.cpp:106] Iteration 42200, lr = 1e-07
I0506 22:42:53.418808 26400 solver.cpp:228] Iteration 42250, loss = 0.100994
I0506 22:42:53.419008 26400 solver.cpp:244]     Train net output #0: loss = 0.100996 (* 1 = 0.100996 loss)
I0506 22:42:53.419033 26400 sgd_solver.cpp:106] Iteration 42250, lr = 1e-07
I0506 22:45:03.548403 26400 solver.cpp:228] Iteration 42300, loss = -1.53482e-06
I0506 22:45:03.548571 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:45:03.548589 26400 sgd_solver.cpp:106] Iteration 42300, lr = 1e-07
I0506 22:47:13.710418 26400 solver.cpp:228] Iteration 42350, loss = -1.53482e-06
I0506 22:47:13.711058 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:47:13.711088 26400 sgd_solver.cpp:106] Iteration 42350, lr = 1e-07
I0506 22:49:20.868446 26400 solver.cpp:337] Iteration 42400, Testing net (#0)
I0506 22:49:31.530417 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 22:49:51.031142 26400 solver.cpp:404]     Test net output #0: loss = 0.103087 (* 1 = 0.103087 loss)
I0506 22:49:51.896212 26400 solver.cpp:228] Iteration 42400, loss = -1.54972e-06
I0506 22:49:51.896272 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:49:51.896286 26400 sgd_solver.cpp:106] Iteration 42400, lr = 1e-07
I0506 22:52:01.773339 26400 solver.cpp:228] Iteration 42450, loss = 0.113169
I0506 22:52:01.773587 26400 solver.cpp:244]     Train net output #0: loss = 0.11317 (* 1 = 0.11317 loss)
I0506 22:52:01.773623 26400 sgd_solver.cpp:106] Iteration 42450, lr = 1e-07
I0506 22:54:11.556143 26400 solver.cpp:228] Iteration 42500, loss = -1.54972e-06
I0506 22:54:11.556831 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 22:54:11.556849 26400 sgd_solver.cpp:106] Iteration 42500, lr = 1e-07
I0506 22:56:21.443399 26400 solver.cpp:228] Iteration 42550, loss = 0.000397854
I0506 22:56:21.443693 26400 solver.cpp:244]     Train net output #0: loss = 0.000399401 (* 1 = 0.000399401 loss)
I0506 22:56:21.443742 26400 sgd_solver.cpp:106] Iteration 42550, lr = 1e-07
I0506 22:58:28.878203 26400 solver.cpp:337] Iteration 42600, Testing net (#0)
I0506 22:58:59.145669 26400 solver.cpp:404]     Test net output #0: loss = 0.109917 (* 1 = 0.109917 loss)
I0506 22:59:00.013365 26400 solver.cpp:228] Iteration 42600, loss = 0.0362882
I0506 22:59:00.013423 26400 solver.cpp:244]     Train net output #0: loss = 0.0362898 (* 1 = 0.0362898 loss)
I0506 22:59:00.013445 26400 sgd_solver.cpp:106] Iteration 42600, lr = 1e-07
I0506 23:01:09.949306 26400 solver.cpp:228] Iteration 42650, loss = 0.0101533
I0506 23:01:09.949625 26400 solver.cpp:244]     Train net output #0: loss = 0.0101549 (* 1 = 0.0101549 loss)
I0506 23:01:09.949657 26400 sgd_solver.cpp:106] Iteration 42650, lr = 1e-07
I0506 23:03:19.971242 26400 solver.cpp:228] Iteration 42700, loss = -1.55717e-06
I0506 23:03:19.973316 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:03:19.973348 26400 sgd_solver.cpp:106] Iteration 42700, lr = 1e-07
I0506 23:05:30.047989 26400 solver.cpp:228] Iteration 42750, loss = 0.0781163
I0506 23:05:30.048220 26400 solver.cpp:244]     Train net output #0: loss = 0.0781179 (* 1 = 0.0781179 loss)
I0506 23:05:30.048254 26400 sgd_solver.cpp:106] Iteration 42750, lr = 1e-07
I0506 23:07:37.257467 26400 solver.cpp:337] Iteration 42800, Testing net (#0)
I0506 23:07:58.690825 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 23:08:07.630584 26400 solver.cpp:404]     Test net output #0: loss = 0.121468 (* 1 = 0.121468 loss)
I0506 23:08:08.497556 26400 solver.cpp:228] Iteration 42800, loss = 0.025695
I0506 23:08:08.497623 26400 solver.cpp:244]     Train net output #0: loss = 0.0256966 (* 1 = 0.0256966 loss)
I0506 23:08:08.497639 26400 sgd_solver.cpp:106] Iteration 42800, lr = 1e-07
I0506 23:10:18.376699 26400 solver.cpp:228] Iteration 42850, loss = -1.51247e-06
I0506 23:10:18.376863 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:10:18.376878 26400 sgd_solver.cpp:106] Iteration 42850, lr = 1e-07
I0506 23:12:28.204336 26400 solver.cpp:228] Iteration 42900, loss = 0.101483
I0506 23:12:28.206125 26400 solver.cpp:244]     Train net output #0: loss = 0.101485 (* 1 = 0.101485 loss)
I0506 23:12:28.206179 26400 sgd_solver.cpp:106] Iteration 42900, lr = 1e-07
I0506 23:14:38.115715 26400 solver.cpp:228] Iteration 42950, loss = -1.48639e-06
I0506 23:14:38.115959 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:14:38.116008 26400 sgd_solver.cpp:106] Iteration 42950, lr = 1e-07
I0506 23:16:45.536118 26400 solver.cpp:337] Iteration 43000, Testing net (#0)
I0506 23:17:15.901562 26400 solver.cpp:404]     Test net output #0: loss = 0.119201 (* 1 = 0.119201 loss)
I0506 23:17:16.787837 26400 solver.cpp:228] Iteration 43000, loss = 0.0353261
I0506 23:17:16.787930 26400 solver.cpp:244]     Train net output #0: loss = 0.0353275 (* 1 = 0.0353275 loss)
I0506 23:17:16.787950 26400 sgd_solver.cpp:106] Iteration 43000, lr = 1e-07
I0506 23:19:26.729518 26400 solver.cpp:228] Iteration 43050, loss = 0.0609856
I0506 23:19:26.729723 26400 solver.cpp:244]     Train net output #0: loss = 0.0609871 (* 1 = 0.0609871 loss)
I0506 23:19:26.729754 26400 sgd_solver.cpp:106] Iteration 43050, lr = 1e-07
I0506 23:21:36.859622 26400 solver.cpp:228] Iteration 43100, loss = -1.50129e-06
I0506 23:21:36.859782 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:21:36.859798 26400 sgd_solver.cpp:106] Iteration 43100, lr = 1e-07
I0506 23:23:46.882815 26400 solver.cpp:228] Iteration 43150, loss = 0.055732
I0506 23:23:46.882992 26400 solver.cpp:244]     Train net output #0: loss = 0.0557335 (* 1 = 0.0557335 loss)
I0506 23:23:46.883026 26400 sgd_solver.cpp:106] Iteration 43150, lr = 1e-07
I0506 23:25:54.140352 26400 solver.cpp:337] Iteration 43200, Testing net (#0)
I0506 23:26:24.455449 26400 solver.cpp:404]     Test net output #0: loss = 0.125747 (* 1 = 0.125747 loss)
I0506 23:26:25.321058 26400 solver.cpp:228] Iteration 43200, loss = 0.0649607
I0506 23:26:25.321116 26400 solver.cpp:244]     Train net output #0: loss = 0.0649621 (* 1 = 0.0649621 loss)
I0506 23:26:25.321130 26400 sgd_solver.cpp:106] Iteration 43200, lr = 1e-07
I0506 23:28:35.149394 26400 solver.cpp:228] Iteration 43250, loss = -1.50502e-06
I0506 23:28:35.150987 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:28:35.151022 26400 sgd_solver.cpp:106] Iteration 43250, lr = 1e-07
I0506 23:30:44.860183 26400 solver.cpp:228] Iteration 43300, loss = -1.48639e-06
I0506 23:30:44.860329 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:30:44.860357 26400 sgd_solver.cpp:106] Iteration 43300, lr = 1e-07
I0506 23:32:54.881081 26400 solver.cpp:228] Iteration 43350, loss = -1.51992e-06
I0506 23:32:54.881242 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:32:54.881263 26400 sgd_solver.cpp:106] Iteration 43350, lr = 1e-07
I0506 23:35:02.338047 26400 solver.cpp:337] Iteration 43400, Testing net (#0)
I0506 23:35:19.100884 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 23:35:32.727526 26400 solver.cpp:404]     Test net output #0: loss = 0.107823 (* 1 = 0.107823 loss)
I0506 23:35:33.599800 26400 solver.cpp:228] Iteration 43400, loss = -1.49757e-06
I0506 23:35:33.599858 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:35:33.599874 26400 sgd_solver.cpp:106] Iteration 43400, lr = 1e-07
I0506 23:37:43.513583 26400 solver.cpp:228] Iteration 43450, loss = 0.0265695
I0506 23:37:43.513808 26400 solver.cpp:244]     Train net output #0: loss = 0.026571 (* 1 = 0.026571 loss)
I0506 23:37:43.513851 26400 sgd_solver.cpp:106] Iteration 43450, lr = 1e-07
I0506 23:39:53.565193 26400 solver.cpp:228] Iteration 43500, loss = 0.0136234
I0506 23:39:53.565466 26400 solver.cpp:244]     Train net output #0: loss = 0.0136249 (* 1 = 0.0136249 loss)
I0506 23:39:53.565516 26400 sgd_solver.cpp:106] Iteration 43500, lr = 1e-07
I0506 23:42:03.618386 26400 solver.cpp:228] Iteration 43550, loss = -1.47428e-06
I0506 23:42:03.618603 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:42:03.618623 26400 sgd_solver.cpp:106] Iteration 43550, lr = 1e-07
I0506 23:44:10.951510 26400 solver.cpp:337] Iteration 43600, Testing net (#0)
I0506 23:45:02.490886 26400 solver.cpp:404]     Test net output #0: loss = 0.104475 (* 1 = 0.104475 loss)
I0506 23:45:03.356937 26400 solver.cpp:228] Iteration 43600, loss = 0.0330214
I0506 23:45:03.357003 26400 solver.cpp:244]     Train net output #0: loss = 0.0330229 (* 1 = 0.0330229 loss)
I0506 23:45:03.357029 26400 sgd_solver.cpp:106] Iteration 43600, lr = 1e-07
I0506 23:47:13.316560 26400 solver.cpp:228] Iteration 43650, loss = 0.0224959
I0506 23:47:13.319211 26400 solver.cpp:244]     Train net output #0: loss = 0.0224974 (* 1 = 0.0224974 loss)
I0506 23:47:13.319247 26400 sgd_solver.cpp:106] Iteration 43650, lr = 1e-07
I0506 23:49:23.151609 26400 solver.cpp:228] Iteration 43700, loss = 0.08571
I0506 23:49:23.164187 26400 solver.cpp:244]     Train net output #0: loss = 0.0857114 (* 1 = 0.0857114 loss)
I0506 23:49:23.164224 26400 sgd_solver.cpp:106] Iteration 43700, lr = 1e-07
I0506 23:51:33.166434 26400 solver.cpp:228] Iteration 43750, loss = 0.0477781
I0506 23:51:33.166725 26400 solver.cpp:244]     Train net output #0: loss = 0.0477796 (* 1 = 0.0477796 loss)
I0506 23:51:33.166740 26400 sgd_solver.cpp:106] Iteration 43750, lr = 1e-07
I0506 23:53:40.546682 26400 solver.cpp:337] Iteration 43800, Testing net (#0)
I0506 23:54:03.080760 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0506 23:54:10.871145 26400 solver.cpp:404]     Test net output #0: loss = 0.114079 (* 1 = 0.114079 loss)
I0506 23:54:11.739383 26400 solver.cpp:228] Iteration 43800, loss = 0.0845078
I0506 23:54:11.739440 26400 solver.cpp:244]     Train net output #0: loss = 0.0845093 (* 1 = 0.0845093 loss)
I0506 23:54:11.739455 26400 sgd_solver.cpp:106] Iteration 43800, lr = 1e-07
I0506 23:56:21.565366 26400 solver.cpp:228] Iteration 43850, loss = -1.49384e-06
I0506 23:56:21.565629 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0506 23:56:21.565675 26400 sgd_solver.cpp:106] Iteration 43850, lr = 1e-07
I0506 23:58:31.388876 26400 solver.cpp:228] Iteration 43900, loss = 0.171974
I0506 23:58:31.389657 26400 solver.cpp:244]     Train net output #0: loss = 0.171975 (* 1 = 0.171975 loss)
I0506 23:58:31.389693 26400 sgd_solver.cpp:106] Iteration 43900, lr = 1e-07
I0507 00:00:41.236282 26400 solver.cpp:228] Iteration 43950, loss = -1.4957e-06
I0507 00:00:41.236445 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:00:41.236461 26400 sgd_solver.cpp:106] Iteration 43950, lr = 1e-07
I0507 00:02:48.745362 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_44000.caffemodel
I0507 00:02:56.178628 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_44000.solverstate
I0507 00:02:56.247292 26400 solver.cpp:337] Iteration 44000, Testing net (#0)
I0507 00:03:25.033452 26400 solver.cpp:404]     Test net output #0: loss = 0.111069 (* 1 = 0.111069 loss)
I0507 00:03:25.899144 26400 solver.cpp:228] Iteration 44000, loss = -1.49012e-06
I0507 00:03:25.899190 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:03:25.899205 26400 sgd_solver.cpp:106] Iteration 44000, lr = 1e-07
I0507 00:05:35.945842 26400 solver.cpp:228] Iteration 44050, loss = 0.0111451
I0507 00:05:35.946116 26400 solver.cpp:244]     Train net output #0: loss = 0.0111466 (* 1 = 0.0111466 loss)
I0507 00:05:35.946151 26400 sgd_solver.cpp:106] Iteration 44050, lr = 1e-07
I0507 00:07:46.152796 26400 solver.cpp:228] Iteration 44100, loss = -1.49012e-06
I0507 00:07:46.152952 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:07:46.152969 26400 sgd_solver.cpp:106] Iteration 44100, lr = 1e-07
I0507 00:09:55.962539 26400 solver.cpp:228] Iteration 44150, loss = 0.102065
I0507 00:09:55.964068 26400 solver.cpp:244]     Train net output #0: loss = 0.102067 (* 1 = 0.102067 loss)
I0507 00:09:55.964105 26400 sgd_solver.cpp:106] Iteration 44150, lr = 1e-07
I0507 00:12:03.309566 26400 solver.cpp:337] Iteration 44200, Testing net (#0)
I0507 00:12:33.579869 26400 solver.cpp:404]     Test net output #0: loss = 0.113649 (* 1 = 0.113649 loss)
I0507 00:12:34.445313 26400 solver.cpp:228] Iteration 44200, loss = -1.48639e-06
I0507 00:12:34.445377 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:12:34.445394 26400 sgd_solver.cpp:106] Iteration 44200, lr = 1e-07
I0507 00:14:44.376433 26400 solver.cpp:228] Iteration 44250, loss = 0.048375
I0507 00:14:44.376616 26400 solver.cpp:244]     Train net output #0: loss = 0.0483765 (* 1 = 0.0483765 loss)
I0507 00:14:44.376634 26400 sgd_solver.cpp:106] Iteration 44250, lr = 1e-07
I0507 00:16:53.929872 26400 solver.cpp:228] Iteration 44300, loss = 0.00728054
I0507 00:16:53.942461 26400 solver.cpp:244]     Train net output #0: loss = 0.00728203 (* 1 = 0.00728203 loss)
I0507 00:16:53.942502 26400 sgd_solver.cpp:106] Iteration 44300, lr = 1e-07
I0507 00:19:03.688788 26400 solver.cpp:228] Iteration 44350, loss = -1.48918e-06
I0507 00:19:03.688990 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:19:03.689010 26400 sgd_solver.cpp:106] Iteration 44350, lr = 1e-07
I0507 00:21:11.030171 26400 solver.cpp:337] Iteration 44400, Testing net (#0)
I0507 00:21:25.195569 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 00:21:41.220161 26400 solver.cpp:404]     Test net output #0: loss = 0.105955 (* 1 = 0.105955 loss)
I0507 00:21:42.084921 26400 solver.cpp:228] Iteration 44400, loss = -1.49012e-06
I0507 00:21:42.084980 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:21:42.085005 26400 sgd_solver.cpp:106] Iteration 44400, lr = 1e-07
I0507 00:23:52.157006 26400 solver.cpp:228] Iteration 44450, loss = 0.128194
I0507 00:23:52.157269 26400 solver.cpp:244]     Train net output #0: loss = 0.128196 (* 1 = 0.128196 loss)
I0507 00:23:52.157299 26400 sgd_solver.cpp:106] Iteration 44450, lr = 1e-07
I0507 00:26:02.375628 26400 solver.cpp:228] Iteration 44500, loss = -1.49757e-06
I0507 00:26:02.376508 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:26:02.376547 26400 sgd_solver.cpp:106] Iteration 44500, lr = 1e-07
I0507 00:28:12.180304 26400 solver.cpp:228] Iteration 44550, loss = 0.00948766
I0507 00:28:12.191102 26400 solver.cpp:244]     Train net output #0: loss = 0.00948915 (* 1 = 0.00948915 loss)
I0507 00:28:12.191169 26400 sgd_solver.cpp:106] Iteration 44550, lr = 1e-07
I0507 00:30:19.456020 26400 solver.cpp:337] Iteration 44600, Testing net (#0)
I0507 00:30:49.601024 26400 solver.cpp:404]     Test net output #0: loss = 0.112276 (* 1 = 0.112276 loss)
I0507 00:30:50.465821 26400 solver.cpp:228] Iteration 44600, loss = 0.0530163
I0507 00:30:50.465886 26400 solver.cpp:244]     Train net output #0: loss = 0.0530178 (* 1 = 0.0530178 loss)
I0507 00:30:50.465900 26400 sgd_solver.cpp:106] Iteration 44600, lr = 1e-07
I0507 00:33:00.528671 26400 solver.cpp:228] Iteration 44650, loss = 0.0626334
I0507 00:33:00.528916 26400 solver.cpp:244]     Train net output #0: loss = 0.0626349 (* 1 = 0.0626349 loss)
I0507 00:33:00.528971 26400 sgd_solver.cpp:106] Iteration 44650, lr = 1e-07
I0507 00:35:10.318302 26400 solver.cpp:228] Iteration 44700, loss = 0.0119971
I0507 00:35:10.318552 26400 solver.cpp:244]     Train net output #0: loss = 0.0119986 (* 1 = 0.0119986 loss)
I0507 00:35:10.318589 26400 sgd_solver.cpp:106] Iteration 44700, lr = 1e-07
I0507 00:37:20.025310 26400 solver.cpp:228] Iteration 44750, loss = 0.03135
I0507 00:37:20.025540 26400 solver.cpp:244]     Train net output #0: loss = 0.0313516 (* 1 = 0.0313516 loss)
I0507 00:37:20.025591 26400 sgd_solver.cpp:106] Iteration 44750, lr = 1e-07
I0507 00:39:27.413353 26400 solver.cpp:337] Iteration 44800, Testing net (#0)
I0507 00:39:51.550739 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 00:39:57.941354 26400 solver.cpp:404]     Test net output #0: loss = 0.119743 (* 1 = 0.119743 loss)
I0507 00:39:58.807732 26400 solver.cpp:228] Iteration 44800, loss = 0.0771861
I0507 00:39:58.807790 26400 solver.cpp:244]     Train net output #0: loss = 0.0771877 (* 1 = 0.0771877 loss)
I0507 00:39:58.807804 26400 sgd_solver.cpp:106] Iteration 44800, lr = 1e-07
I0507 00:42:08.902562 26400 solver.cpp:228] Iteration 44850, loss = -1.58045e-06
I0507 00:42:08.902743 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:42:08.902760 26400 sgd_solver.cpp:106] Iteration 44850, lr = 1e-07
I0507 00:44:19.034260 26400 solver.cpp:228] Iteration 44900, loss = -1.58697e-06
I0507 00:44:19.034459 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 00:44:19.034495 26400 sgd_solver.cpp:106] Iteration 44900, lr = 1e-07
I0507 00:46:29.013357 26400 solver.cpp:228] Iteration 44950, loss = 0.0220689
I0507 00:46:29.026275 26400 solver.cpp:244]     Train net output #0: loss = 0.0220705 (* 1 = 0.0220705 loss)
I0507 00:46:29.026387 26400 sgd_solver.cpp:106] Iteration 44950, lr = 1e-07
I0507 00:48:36.268082 26400 solver.cpp:337] Iteration 45000, Testing net (#0)
I0507 00:49:06.452937 26400 solver.cpp:404]     Test net output #0: loss = 0.116107 (* 1 = 0.116107 loss)
I0507 00:49:07.324237 26400 solver.cpp:228] Iteration 45000, loss = 0.00145335
I0507 00:49:07.324297 26400 solver.cpp:244]     Train net output #0: loss = 0.00145491 (* 1 = 0.00145491 loss)
I0507 00:49:07.324312 26400 sgd_solver.cpp:106] Iteration 45000, lr = 1e-07
I0507 00:51:17.280690 26400 solver.cpp:228] Iteration 45050, loss = 0.056918
I0507 00:51:17.280856 26400 solver.cpp:244]     Train net output #0: loss = 0.0569196 (* 1 = 0.0569196 loss)
I0507 00:51:17.280874 26400 sgd_solver.cpp:106] Iteration 45050, lr = 1e-07
I0507 00:53:27.049604 26400 solver.cpp:228] Iteration 45100, loss = 0.205185
I0507 00:53:27.049793 26400 solver.cpp:244]     Train net output #0: loss = 0.205187 (* 1 = 0.205187 loss)
I0507 00:53:27.049811 26400 sgd_solver.cpp:106] Iteration 45100, lr = 1e-07
I0507 00:55:37.080847 26400 solver.cpp:228] Iteration 45150, loss = 0.038636
I0507 00:55:37.081017 26400 solver.cpp:244]     Train net output #0: loss = 0.0386376 (* 1 = 0.0386376 loss)
I0507 00:55:37.081042 26400 sgd_solver.cpp:106] Iteration 45150, lr = 1e-07
I0507 00:58:15.310415 26400 solver.cpp:337] Iteration 45200, Testing net (#0)
I0507 01:00:19.278301 26400 solver.cpp:404]     Test net output #0: loss = 0.12469 (* 1 = 0.12469 loss)
I0507 01:00:20.135720 26400 solver.cpp:228] Iteration 45200, loss = -1.57207e-06
I0507 01:00:20.135767 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 01:00:20.135792 26400 sgd_solver.cpp:106] Iteration 45200, lr = 1e-07
I0507 01:03:16.875097 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 01:04:38.570305 26416 blocking_queue.cpp:50] Waiting for data
I0507 01:04:43.541335 26400 solver.cpp:228] Iteration 45250, loss = 0.0617669
I0507 01:04:43.541417 26400 solver.cpp:244]     Train net output #0: loss = 0.0617684 (* 1 = 0.0617684 loss)
I0507 01:04:43.541436 26400 sgd_solver.cpp:106] Iteration 45250, lr = 1e-07
I0507 01:11:11.554304 26400 solver.cpp:228] Iteration 45300, loss = 0.0458491
I0507 01:11:11.554546 26400 solver.cpp:244]     Train net output #0: loss = 0.0458507 (* 1 = 0.0458507 loss)
I0507 01:11:11.554580 26400 sgd_solver.cpp:106] Iteration 45300, lr = 1e-07
I0507 01:12:32.549310 26416 blocking_queue.cpp:50] Waiting for data
I0507 01:19:06.690927 26400 solver.cpp:228] Iteration 45350, loss = 0.0328918
I0507 01:19:06.691177 26400 solver.cpp:244]     Train net output #0: loss = 0.0328934 (* 1 = 0.0328934 loss)
I0507 01:19:06.691238 26400 sgd_solver.cpp:106] Iteration 45350, lr = 1e-07
I0507 01:24:20.929425 26416 blocking_queue.cpp:50] Waiting for data
I0507 01:32:14.101538 26400 solver.cpp:337] Iteration 45400, Testing net (#0)
I0507 01:38:42.175729 26400 solver.cpp:404]     Test net output #0: loss = 0.106084 (* 1 = 0.106084 loss)
I0507 01:38:43.031479 26400 solver.cpp:228] Iteration 45400, loss = 0.072752
I0507 01:38:43.031528 26400 solver.cpp:244]     Train net output #0: loss = 0.0727536 (* 1 = 0.0727536 loss)
I0507 01:38:43.031545 26400 sgd_solver.cpp:106] Iteration 45400, lr = 1e-07
I0507 01:48:57.148789 26416 blocking_queue.cpp:50] Waiting for data
I0507 01:56:13.481693 26400 solver.cpp:228] Iteration 45450, loss = -1.53482e-06
I0507 01:56:13.481931 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 01:56:13.481967 26400 sgd_solver.cpp:106] Iteration 45450, lr = 1e-07
I0507 02:18:15.290940 26416 blocking_queue.cpp:50] Waiting for data
I0507 02:21:15.299065 26400 solver.cpp:228] Iteration 45500, loss = -1.55345e-06
I0507 02:21:15.299232 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 02:21:15.299249 26400 sgd_solver.cpp:106] Iteration 45500, lr = 1e-07
I0507 02:53:41.560111 26400 solver.cpp:228] Iteration 45550, loss = -1.54972e-06
I0507 02:53:41.572827 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 02:53:41.572885 26400 sgd_solver.cpp:106] Iteration 45550, lr = 1e-07
I0507 02:58:01.542284 26416 blocking_queue.cpp:50] Waiting for data
I0507 03:28:20.642782 26400 solver.cpp:337] Iteration 45600, Testing net (#0)
I0507 03:33:20.732592 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 03:46:11.691412 26400 solver.cpp:404]     Test net output #0: loss = 0.102433 (* 1 = 0.102433 loss)
I0507 03:46:12.531450 26400 solver.cpp:228] Iteration 45600, loss = 0.0223277
I0507 03:46:12.531508 26400 solver.cpp:244]     Train net output #0: loss = 0.0223292 (* 1 = 0.0223292 loss)
I0507 03:46:12.531528 26400 sgd_solver.cpp:106] Iteration 45600, lr = 1e-07
I0507 03:53:57.993705 26416 blocking_queue.cpp:50] Waiting for data
I0507 04:13:30.514221 26400 solver.cpp:228] Iteration 45650, loss = -1.54972e-06
I0507 04:13:30.514873 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 04:13:30.515120 26400 sgd_solver.cpp:106] Iteration 45650, lr = 1e-07
I0507 04:32:57.268635 26416 blocking_queue.cpp:50] Waiting for data
I0507 04:42:56.422204 26400 solver.cpp:228] Iteration 45700, loss = -1.56462e-06
I0507 04:42:56.422391 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 04:42:56.422407 26400 sgd_solver.cpp:106] Iteration 45700, lr = 1e-07
I0507 05:06:58.617313 26416 blocking_queue.cpp:50] Waiting for data
I0507 05:14:00.581046 26400 solver.cpp:228] Iteration 45750, loss = 0.0146665
I0507 05:14:00.581343 26400 solver.cpp:244]     Train net output #0: loss = 0.0146681 (* 1 = 0.0146681 loss)
I0507 05:14:00.581388 26400 sgd_solver.cpp:106] Iteration 45750, lr = 1e-07
I0507 05:40:25.904144 26400 solver.cpp:337] Iteration 45800, Testing net (#0)
I0507 05:40:43.254456 26416 blocking_queue.cpp:50] Waiting for data
I0507 05:56:12.653163 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 05:57:27.976755 26400 solver.cpp:404]     Test net output #0: loss = 0.110745 (* 1 = 0.110745 loss)
I0507 05:57:28.845371 26400 solver.cpp:228] Iteration 45800, loss = 0.0215009
I0507 05:57:28.845445 26400 solver.cpp:244]     Train net output #0: loss = 0.0215025 (* 1 = 0.0215025 loss)
I0507 05:57:28.845463 26400 sgd_solver.cpp:106] Iteration 45800, lr = 1e-07
I0507 06:21:45.870499 26400 solver.cpp:228] Iteration 45850, loss = 0.163584
I0507 06:21:45.870687 26400 solver.cpp:244]     Train net output #0: loss = 0.163585 (* 1 = 0.163585 loss)
I0507 06:21:45.870702 26400 sgd_solver.cpp:106] Iteration 45850, lr = 1e-07
I0507 06:29:17.951311 26416 blocking_queue.cpp:50] Waiting for data
I0507 06:43:58.739918 26400 solver.cpp:228] Iteration 45900, loss = -1.54972e-06
I0507 06:43:58.740093 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 06:43:58.740110 26400 sgd_solver.cpp:106] Iteration 45900, lr = 1e-07
I0507 06:52:57.528045 26416 blocking_queue.cpp:50] Waiting for data
I0507 07:01:13.588018 26400 solver.cpp:228] Iteration 45950, loss = 0.0521489
I0507 07:01:13.588256 26400 solver.cpp:244]     Train net output #0: loss = 0.0521505 (* 1 = 0.0521505 loss)
I0507 07:01:13.588304 26400 sgd_solver.cpp:106] Iteration 45950, lr = 1e-07
I0507 07:03:20.363994 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_46000.caffemodel
I0507 07:03:26.039510 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_46000.solverstate
I0507 07:03:26.129828 26400 solver.cpp:337] Iteration 46000, Testing net (#0)
I0507 07:03:54.515029 26400 solver.cpp:404]     Test net output #0: loss = 0.11268 (* 1 = 0.11268 loss)
I0507 07:03:55.391206 26400 solver.cpp:228] Iteration 46000, loss = 0.0868269
I0507 07:03:55.391337 26400 solver.cpp:244]     Train net output #0: loss = 0.0868284 (* 1 = 0.0868284 loss)
I0507 07:03:55.391377 26400 sgd_solver.cpp:106] Iteration 46000, lr = 1e-07
I0507 07:06:05.570598 26400 solver.cpp:228] Iteration 46050, loss = 0.0177815
I0507 07:06:05.585762 26400 solver.cpp:244]     Train net output #0: loss = 0.0177831 (* 1 = 0.0177831 loss)
I0507 07:06:05.585811 26400 sgd_solver.cpp:106] Iteration 46050, lr = 1e-07
I0507 07:08:15.449019 26400 solver.cpp:228] Iteration 46100, loss = 0.00381143
I0507 07:08:15.449195 26400 solver.cpp:244]     Train net output #0: loss = 0.00381298 (* 1 = 0.00381298 loss)
I0507 07:08:15.449231 26400 sgd_solver.cpp:106] Iteration 46100, lr = 1e-07
I0507 07:10:25.569703 26400 solver.cpp:228] Iteration 46150, loss = -1.55345e-06
I0507 07:10:25.571347 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:10:25.571377 26400 sgd_solver.cpp:106] Iteration 46150, lr = 1e-07
I0507 07:12:32.798293 26400 solver.cpp:337] Iteration 46200, Testing net (#0)
I0507 07:13:03.502171 26400 solver.cpp:404]     Test net output #0: loss = 0.11839 (* 1 = 0.11839 loss)
I0507 07:13:04.366564 26400 solver.cpp:228] Iteration 46200, loss = -1.57952e-06
I0507 07:13:04.366614 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:13:04.366641 26400 sgd_solver.cpp:106] Iteration 46200, lr = 1e-07
I0507 07:15:14.121204 26400 solver.cpp:228] Iteration 46250, loss = 0.0125707
I0507 07:15:14.121387 26400 solver.cpp:244]     Train net output #0: loss = 0.0125723 (* 1 = 0.0125723 loss)
I0507 07:15:14.121405 26400 sgd_solver.cpp:106] Iteration 46250, lr = 1e-07
I0507 07:17:24.148721 26400 solver.cpp:228] Iteration 46300, loss = 0.0175722
I0507 07:17:24.148875 26400 solver.cpp:244]     Train net output #0: loss = 0.0175738 (* 1 = 0.0175738 loss)
I0507 07:17:24.148893 26400 sgd_solver.cpp:106] Iteration 46300, lr = 1e-07
I0507 07:19:34.100657 26400 solver.cpp:228] Iteration 46350, loss = 0.15406
I0507 07:19:34.100864 26400 solver.cpp:244]     Train net output #0: loss = 0.154062 (* 1 = 0.154062 loss)
I0507 07:19:34.100888 26400 sgd_solver.cpp:106] Iteration 46350, lr = 1e-07
I0507 07:21:41.721638 26400 solver.cpp:337] Iteration 46400, Testing net (#0)
I0507 07:21:47.438000 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 07:22:12.637449 26400 solver.cpp:404]     Test net output #0: loss = 0.111485 (* 1 = 0.111485 loss)
I0507 07:22:13.504142 26400 solver.cpp:228] Iteration 46400, loss = 0.0739925
I0507 07:22:13.504223 26400 solver.cpp:244]     Train net output #0: loss = 0.0739941 (* 1 = 0.0739941 loss)
I0507 07:22:13.504238 26400 sgd_solver.cpp:106] Iteration 46400, lr = 1e-07
I0507 07:24:23.248215 26400 solver.cpp:228] Iteration 46450, loss = 0.0105372
I0507 07:24:23.248466 26400 solver.cpp:244]     Train net output #0: loss = 0.0105388 (* 1 = 0.0105388 loss)
I0507 07:24:23.248504 26400 sgd_solver.cpp:106] Iteration 46450, lr = 1e-07
I0507 07:26:32.873509 26400 solver.cpp:228] Iteration 46500, loss = 0.097365
I0507 07:26:32.873770 26400 solver.cpp:244]     Train net output #0: loss = 0.0973666 (* 1 = 0.0973666 loss)
I0507 07:26:32.873786 26400 sgd_solver.cpp:106] Iteration 46500, lr = 1e-07
I0507 07:28:43.001345 26400 solver.cpp:228] Iteration 46550, loss = -1.60933e-06
I0507 07:28:43.001580 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:28:43.001623 26400 sgd_solver.cpp:106] Iteration 46550, lr = 1e-07
I0507 07:30:50.169306 26400 solver.cpp:337] Iteration 46600, Testing net (#0)
I0507 07:31:20.750326 26400 solver.cpp:404]     Test net output #0: loss = 0.120687 (* 1 = 0.120687 loss)
I0507 07:31:21.618566 26400 solver.cpp:228] Iteration 46600, loss = 0.0220279
I0507 07:31:21.618624 26400 solver.cpp:244]     Train net output #0: loss = 0.0220295 (* 1 = 0.0220295 loss)
I0507 07:31:21.618638 26400 sgd_solver.cpp:106] Iteration 46600, lr = 1e-07
I0507 07:33:31.727551 26400 solver.cpp:228] Iteration 46650, loss = 0.0168058
I0507 07:33:31.727774 26400 solver.cpp:244]     Train net output #0: loss = 0.0168074 (* 1 = 0.0168074 loss)
I0507 07:33:31.727792 26400 sgd_solver.cpp:106] Iteration 46650, lr = 1e-07
I0507 07:35:41.574335 26400 solver.cpp:228] Iteration 46700, loss = 0.0932587
I0507 07:35:41.574501 26400 solver.cpp:244]     Train net output #0: loss = 0.0932602 (* 1 = 0.0932602 loss)
I0507 07:35:41.574517 26400 sgd_solver.cpp:106] Iteration 46700, lr = 1e-07
I0507 07:37:51.218734 26400 solver.cpp:228] Iteration 46750, loss = 0.0915663
I0507 07:37:51.231192 26400 solver.cpp:244]     Train net output #0: loss = 0.0915678 (* 1 = 0.0915678 loss)
I0507 07:37:51.231220 26400 sgd_solver.cpp:106] Iteration 46750, lr = 1e-07
I0507 07:39:58.735529 26400 solver.cpp:337] Iteration 46800, Testing net (#0)
I0507 07:40:28.658206 26400 solver.cpp:404]     Test net output #0: loss = 0.126333 (* 1 = 0.126333 loss)
I0507 07:40:29.525022 26400 solver.cpp:228] Iteration 46800, loss = -1.53482e-06
I0507 07:40:29.525192 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:40:29.525221 26400 sgd_solver.cpp:106] Iteration 46800, lr = 1e-07
I0507 07:42:39.561040 26400 solver.cpp:228] Iteration 46850, loss = 0.0682221
I0507 07:42:39.561290 26400 solver.cpp:244]     Train net output #0: loss = 0.0682237 (* 1 = 0.0682237 loss)
I0507 07:42:39.561344 26400 sgd_solver.cpp:106] Iteration 46850, lr = 1e-07
I0507 07:44:49.322100 26400 solver.cpp:228] Iteration 46900, loss = -1.56462e-06
I0507 07:44:49.322366 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:44:49.322419 26400 sgd_solver.cpp:106] Iteration 46900, lr = 1e-07
I0507 07:46:59.291235 26400 solver.cpp:228] Iteration 46950, loss = 0.0285817
I0507 07:46:59.291486 26400 solver.cpp:244]     Train net output #0: loss = 0.0285833 (* 1 = 0.0285833 loss)
I0507 07:46:59.291541 26400 sgd_solver.cpp:106] Iteration 46950, lr = 1e-07
I0507 07:49:06.445088 26400 solver.cpp:337] Iteration 47000, Testing net (#0)
I0507 07:49:10.475718 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 07:49:36.643098 26400 solver.cpp:404]     Test net output #0: loss = 0.120811 (* 1 = 0.120811 loss)
I0507 07:49:37.508620 26400 solver.cpp:228] Iteration 47000, loss = 0.0632778
I0507 07:49:37.508663 26400 solver.cpp:244]     Train net output #0: loss = 0.0632794 (* 1 = 0.0632794 loss)
I0507 07:49:37.508679 26400 sgd_solver.cpp:106] Iteration 47000, lr = 1e-07
I0507 07:51:47.483186 26400 solver.cpp:228] Iteration 47050, loss = -1.58697e-06
I0507 07:51:47.483403 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 07:51:47.483448 26400 sgd_solver.cpp:106] Iteration 47050, lr = 1e-07
I0507 07:53:57.626744 26400 solver.cpp:228] Iteration 47100, loss = 0.0683801
I0507 07:53:57.626893 26400 solver.cpp:244]     Train net output #0: loss = 0.0683817 (* 1 = 0.0683817 loss)
I0507 07:53:57.626927 26400 sgd_solver.cpp:106] Iteration 47100, lr = 1e-07
I0507 07:56:07.468714 26400 solver.cpp:228] Iteration 47150, loss = 0.0102787
I0507 07:56:07.468880 26400 solver.cpp:244]     Train net output #0: loss = 0.0102802 (* 1 = 0.0102802 loss)
I0507 07:56:07.468896 26400 sgd_solver.cpp:106] Iteration 47150, lr = 1e-07
I0507 07:58:14.964167 26400 solver.cpp:337] Iteration 47200, Testing net (#0)
I0507 07:58:45.436724 26400 solver.cpp:404]     Test net output #0: loss = 0.131117 (* 1 = 0.131117 loss)
I0507 07:58:46.302076 26400 solver.cpp:228] Iteration 47200, loss = 0.0180614
I0507 07:58:46.302124 26400 solver.cpp:244]     Train net output #0: loss = 0.018063 (* 1 = 0.018063 loss)
I0507 07:58:46.302137 26400 sgd_solver.cpp:106] Iteration 47200, lr = 1e-07
I0507 08:00:56.125393 26400 solver.cpp:228] Iteration 47250, loss = 0.0483747
I0507 08:00:56.125566 26400 solver.cpp:244]     Train net output #0: loss = 0.0483763 (* 1 = 0.0483763 loss)
I0507 08:00:56.125591 26400 sgd_solver.cpp:106] Iteration 47250, lr = 1e-07
I0507 08:03:05.902848 26400 solver.cpp:228] Iteration 47300, loss = 0.00294484
I0507 08:03:05.903082 26400 solver.cpp:244]     Train net output #0: loss = 0.0029464 (* 1 = 0.0029464 loss)
I0507 08:03:05.903123 26400 sgd_solver.cpp:106] Iteration 47300, lr = 1e-07
I0507 08:05:15.824105 26400 solver.cpp:228] Iteration 47350, loss = -1.57207e-06
I0507 08:05:15.824260 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:05:15.824276 26400 sgd_solver.cpp:106] Iteration 47350, lr = 1e-07
I0507 08:07:22.937767 26400 solver.cpp:337] Iteration 47400, Testing net (#0)
I0507 08:07:37.132817 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 08:07:56.164337 26400 solver.cpp:404]     Test net output #0: loss = 0.109863 (* 1 = 0.109863 loss)
I0507 08:07:57.031302 26400 solver.cpp:228] Iteration 47400, loss = -1.56462e-06
I0507 08:07:57.031375 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:07:57.031391 26400 sgd_solver.cpp:106] Iteration 47400, lr = 1e-07
I0507 08:10:07.035915 26400 solver.cpp:228] Iteration 47450, loss = 0.281693
I0507 08:10:07.036149 26400 solver.cpp:244]     Train net output #0: loss = 0.281695 (* 1 = 0.281695 loss)
I0507 08:10:07.036164 26400 sgd_solver.cpp:106] Iteration 47450, lr = 1e-07
I0507 08:12:16.770079 26400 solver.cpp:228] Iteration 47500, loss = -1.57207e-06
I0507 08:12:16.770332 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:12:16.770375 26400 sgd_solver.cpp:106] Iteration 47500, lr = 1e-07
I0507 08:14:26.692096 26400 solver.cpp:228] Iteration 47550, loss = 0.0120637
I0507 08:14:26.692283 26400 solver.cpp:244]     Train net output #0: loss = 0.0120652 (* 1 = 0.0120652 loss)
I0507 08:14:26.692312 26400 sgd_solver.cpp:106] Iteration 47550, lr = 1e-07
I0507 08:16:34.049970 26400 solver.cpp:337] Iteration 47600, Testing net (#0)
I0507 08:17:04.617794 26400 solver.cpp:404]     Test net output #0: loss = 0.107307 (* 1 = 0.107307 loss)
I0507 08:17:05.483397 26400 solver.cpp:228] Iteration 47600, loss = -1.53482e-06
I0507 08:17:05.483443 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:17:05.483458 26400 sgd_solver.cpp:106] Iteration 47600, lr = 1e-07
I0507 08:19:15.328680 26400 solver.cpp:228] Iteration 47650, loss = 0.197334
I0507 08:19:15.328881 26400 solver.cpp:244]     Train net output #0: loss = 0.197335 (* 1 = 0.197335 loss)
I0507 08:19:15.328902 26400 sgd_solver.cpp:106] Iteration 47650, lr = 1e-07
I0507 08:21:25.493988 26400 solver.cpp:228] Iteration 47700, loss = -1.54227e-06
I0507 08:21:25.494364 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:21:25.494379 26400 sgd_solver.cpp:106] Iteration 47700, lr = 1e-07
I0507 08:23:35.480330 26400 solver.cpp:228] Iteration 47750, loss = 0.273728
I0507 08:23:35.480496 26400 solver.cpp:244]     Train net output #0: loss = 0.27373 (* 1 = 0.27373 loss)
I0507 08:23:35.480512 26400 sgd_solver.cpp:106] Iteration 47750, lr = 1e-07
I0507 08:25:42.533576 26400 solver.cpp:337] Iteration 47800, Testing net (#0)
I0507 08:25:58.272279 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 08:26:14.054167 26400 solver.cpp:404]     Test net output #0: loss = 0.11591 (* 1 = 0.11591 loss)
I0507 08:26:14.923060 26400 solver.cpp:228] Iteration 47800, loss = 0.0506347
I0507 08:26:14.923108 26400 solver.cpp:244]     Train net output #0: loss = 0.0506363 (* 1 = 0.0506363 loss)
I0507 08:26:14.923123 26400 sgd_solver.cpp:106] Iteration 47800, lr = 1e-07
I0507 08:28:24.927155 26400 solver.cpp:228] Iteration 47850, loss = -1.51992e-06
I0507 08:28:24.930306 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:28:24.930330 26400 sgd_solver.cpp:106] Iteration 47850, lr = 1e-07
I0507 08:30:35.015671 26400 solver.cpp:228] Iteration 47900, loss = 0.0456167
I0507 08:30:35.017362 26400 solver.cpp:244]     Train net output #0: loss = 0.0456182 (* 1 = 0.0456182 loss)
I0507 08:30:35.017398 26400 sgd_solver.cpp:106] Iteration 47900, lr = 1e-07
I0507 08:32:45.175071 26400 solver.cpp:228] Iteration 47950, loss = 0.0193532
I0507 08:32:45.175228 26400 solver.cpp:244]     Train net output #0: loss = 0.0193547 (* 1 = 0.0193547 loss)
I0507 08:32:45.175261 26400 sgd_solver.cpp:106] Iteration 47950, lr = 1e-07
I0507 08:34:52.539841 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_48000.caffemodel
I0507 08:35:02.255429 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_48000.solverstate
I0507 08:35:02.325500 26400 solver.cpp:337] Iteration 48000, Testing net (#0)
I0507 08:35:32.030128 26400 solver.cpp:404]     Test net output #0: loss = 0.115124 (* 1 = 0.115124 loss)
I0507 08:35:32.908458 26400 solver.cpp:228] Iteration 48000, loss = 0.0129014
I0507 08:35:32.908509 26400 solver.cpp:244]     Train net output #0: loss = 0.012903 (* 1 = 0.012903 loss)
I0507 08:35:32.908527 26400 sgd_solver.cpp:106] Iteration 48000, lr = 1e-07
I0507 08:37:43.328539 26400 solver.cpp:228] Iteration 48050, loss = 0.0473678
I0507 08:37:43.328660 26400 solver.cpp:244]     Train net output #0: loss = 0.0473693 (* 1 = 0.0473693 loss)
I0507 08:37:43.328675 26400 sgd_solver.cpp:106] Iteration 48050, lr = 1e-07
I0507 08:39:53.388262 26400 solver.cpp:228] Iteration 48100, loss = -1.53668e-06
I0507 08:39:53.388417 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:39:53.388432 26400 sgd_solver.cpp:106] Iteration 48100, lr = 1e-07
I0507 08:42:03.714612 26400 solver.cpp:228] Iteration 48150, loss = -1.58139e-06
I0507 08:42:03.714743 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:42:03.714761 26400 sgd_solver.cpp:106] Iteration 48150, lr = 1e-07
I0507 08:44:11.346083 26400 solver.cpp:337] Iteration 48200, Testing net (#0)
I0507 08:44:33.418294 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 08:44:42.975786 26400 solver.cpp:404]     Test net output #0: loss = 0.121127 (* 1 = 0.121127 loss)
I0507 08:44:43.844774 26400 solver.cpp:228] Iteration 48200, loss = 0.0382608
I0507 08:44:43.844832 26400 solver.cpp:244]     Train net output #0: loss = 0.0382624 (* 1 = 0.0382624 loss)
I0507 08:44:43.844846 26400 sgd_solver.cpp:106] Iteration 48200, lr = 1e-07
I0507 08:46:54.158105 26400 solver.cpp:228] Iteration 48250, loss = 0.031697
I0507 08:46:54.158301 26400 solver.cpp:244]     Train net output #0: loss = 0.0316986 (* 1 = 0.0316986 loss)
I0507 08:46:54.158345 26400 sgd_solver.cpp:106] Iteration 48250, lr = 1e-07
I0507 08:49:03.947960 26400 solver.cpp:228] Iteration 48300, loss = -1.60187e-06
I0507 08:49:03.948164 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:49:03.948207 26400 sgd_solver.cpp:106] Iteration 48300, lr = 1e-07
I0507 08:51:13.608911 26400 solver.cpp:228] Iteration 48350, loss = 0.45375
I0507 08:51:13.609067 26400 solver.cpp:244]     Train net output #0: loss = 0.453751 (* 1 = 0.453751 loss)
I0507 08:51:13.609089 26400 sgd_solver.cpp:106] Iteration 48350, lr = 1e-07
I0507 08:53:21.149673 26400 solver.cpp:337] Iteration 48400, Testing net (#0)
I0507 08:53:51.844588 26400 solver.cpp:404]     Test net output #0: loss = 0.111245 (* 1 = 0.111245 loss)
I0507 08:53:52.714973 26400 solver.cpp:228] Iteration 48400, loss = 0.115089
I0507 08:53:52.715020 26400 solver.cpp:244]     Train net output #0: loss = 0.115091 (* 1 = 0.115091 loss)
I0507 08:53:52.715046 26400 sgd_solver.cpp:106] Iteration 48400, lr = 1e-07
I0507 08:56:02.604372 26400 solver.cpp:228] Iteration 48450, loss = 0.0254772
I0507 08:56:02.604818 26400 solver.cpp:244]     Train net output #0: loss = 0.0254789 (* 1 = 0.0254789 loss)
I0507 08:56:02.604858 26400 sgd_solver.cpp:106] Iteration 48450, lr = 1e-07
I0507 08:58:12.636800 26400 solver.cpp:228] Iteration 48500, loss = -1.61305e-06
I0507 08:58:12.637087 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 08:58:12.637142 26400 sgd_solver.cpp:106] Iteration 48500, lr = 1e-07
I0507 09:00:22.867985 26400 solver.cpp:228] Iteration 48550, loss = 0.0548491
I0507 09:00:22.868185 26400 solver.cpp:244]     Train net output #0: loss = 0.0548506 (* 1 = 0.0548506 loss)
I0507 09:00:22.868237 26400 sgd_solver.cpp:106] Iteration 48550, lr = 1e-07
I0507 09:02:30.339040 26400 solver.cpp:337] Iteration 48600, Testing net (#0)
I0507 09:03:00.787463 26400 solver.cpp:404]     Test net output #0: loss = 0.119366 (* 1 = 0.119366 loss)
I0507 09:03:01.657743 26400 solver.cpp:228] Iteration 48600, loss = 0.337854
I0507 09:03:01.657815 26400 solver.cpp:244]     Train net output #0: loss = 0.337856 (* 1 = 0.337856 loss)
I0507 09:03:01.657832 26400 sgd_solver.cpp:106] Iteration 48600, lr = 1e-07
I0507 09:05:11.898494 26400 solver.cpp:228] Iteration 48650, loss = -1.60187e-06
I0507 09:05:11.910974 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 09:05:11.911006 26400 sgd_solver.cpp:106] Iteration 48650, lr = 1e-07
I0507 09:07:21.858502 26400 solver.cpp:228] Iteration 48700, loss = 0.0506875
I0507 09:07:21.858688 26400 solver.cpp:244]     Train net output #0: loss = 0.0506891 (* 1 = 0.0506891 loss)
I0507 09:07:21.858721 26400 sgd_solver.cpp:106] Iteration 48700, lr = 1e-07
I0507 09:09:31.908324 26400 solver.cpp:228] Iteration 48750, loss = 0.0535356
I0507 09:09:31.908542 26400 solver.cpp:244]     Train net output #0: loss = 0.0535372 (* 1 = 0.0535372 loss)
I0507 09:09:31.908572 26400 sgd_solver.cpp:106] Iteration 48750, lr = 1e-07
I0507 09:11:39.520412 26400 solver.cpp:337] Iteration 48800, Testing net (#0)
I0507 09:11:51.224200 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 09:12:10.470413 26400 solver.cpp:404]     Test net output #0: loss = 0.1277 (* 1 = 0.1277 loss)
I0507 09:12:11.339347 26400 solver.cpp:228] Iteration 48800, loss = 0.00257272
I0507 09:12:11.339411 26400 solver.cpp:244]     Train net output #0: loss = 0.00257427 (* 1 = 0.00257427 loss)
I0507 09:12:11.339424 26400 sgd_solver.cpp:106] Iteration 48800, lr = 1e-07
I0507 09:14:21.340386 26400 solver.cpp:228] Iteration 48850, loss = 0.0186512
I0507 09:14:21.340625 26400 solver.cpp:244]     Train net output #0: loss = 0.0186527 (* 1 = 0.0186527 loss)
I0507 09:14:21.340659 26400 sgd_solver.cpp:106] Iteration 48850, lr = 1e-07
I0507 09:16:31.332469 26400 solver.cpp:228] Iteration 48900, loss = 0.0787474
I0507 09:16:31.332639 26400 solver.cpp:244]     Train net output #0: loss = 0.0787489 (* 1 = 0.0787489 loss)
I0507 09:16:31.332677 26400 sgd_solver.cpp:106] Iteration 48900, lr = 1e-07
I0507 09:18:41.093947 26400 solver.cpp:228] Iteration 48950, loss = 0.0743031
I0507 09:18:41.094420 26400 solver.cpp:244]     Train net output #0: loss = 0.0743046 (* 1 = 0.0743046 loss)
I0507 09:18:41.094455 26400 sgd_solver.cpp:106] Iteration 48950, lr = 1e-07
I0507 09:20:48.430001 26400 solver.cpp:337] Iteration 49000, Testing net (#0)
I0507 09:21:18.796550 26400 solver.cpp:404]     Test net output #0: loss = 0.119502 (* 1 = 0.119502 loss)
I0507 09:21:19.664863 26400 solver.cpp:228] Iteration 49000, loss = 0.0395333
I0507 09:21:19.664917 26400 solver.cpp:244]     Train net output #0: loss = 0.0395349 (* 1 = 0.0395349 loss)
I0507 09:21:19.664954 26400 sgd_solver.cpp:106] Iteration 49000, lr = 1e-07
I0507 09:23:29.602165 26400 solver.cpp:228] Iteration 49050, loss = 0.00242019
I0507 09:23:29.602385 26400 solver.cpp:244]     Train net output #0: loss = 0.00242176 (* 1 = 0.00242176 loss)
I0507 09:23:29.602428 26400 sgd_solver.cpp:106] Iteration 49050, lr = 1e-07
I0507 09:25:39.662005 26400 solver.cpp:228] Iteration 49100, loss = 0.0185351
I0507 09:25:39.662204 26400 solver.cpp:244]     Train net output #0: loss = 0.0185367 (* 1 = 0.0185367 loss)
I0507 09:25:39.662250 26400 sgd_solver.cpp:106] Iteration 49100, lr = 1e-07
I0507 09:27:49.891052 26400 solver.cpp:228] Iteration 49150, loss = -1.58139e-06
I0507 09:27:49.892906 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 09:27:49.892966 26400 sgd_solver.cpp:106] Iteration 49150, lr = 1e-07
I0507 09:29:57.432785 26400 solver.cpp:337] Iteration 49200, Testing net (#0)
I0507 09:30:23.520440 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 09:30:28.075399 26400 solver.cpp:404]     Test net output #0: loss = 0.127146 (* 1 = 0.127146 loss)
I0507 09:30:28.940136 26400 solver.cpp:228] Iteration 49200, loss = 0.0131004
I0507 09:30:28.940174 26400 solver.cpp:244]     Train net output #0: loss = 0.013102 (* 1 = 0.013102 loss)
I0507 09:30:28.940196 26400 sgd_solver.cpp:106] Iteration 49200, lr = 1e-07
I0507 09:32:39.027678 26400 solver.cpp:228] Iteration 49250, loss = 0.0141406
I0507 09:32:39.027865 26400 solver.cpp:244]     Train net output #0: loss = 0.0141422 (* 1 = 0.0141422 loss)
I0507 09:32:39.027905 26400 sgd_solver.cpp:106] Iteration 49250, lr = 1e-07
I0507 09:34:49.310436 26400 solver.cpp:228] Iteration 49300, loss = 0.0154657
I0507 09:34:49.322926 26400 solver.cpp:244]     Train net output #0: loss = 0.0154674 (* 1 = 0.0154674 loss)
I0507 09:34:49.322948 26400 sgd_solver.cpp:106] Iteration 49300, lr = 1e-07
I0507 09:36:59.182852 26400 solver.cpp:228] Iteration 49350, loss = -1.60933e-06
I0507 09:36:59.183056 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 09:36:59.183097 26400 sgd_solver.cpp:106] Iteration 49350, lr = 1e-07
I0507 09:39:06.293462 26400 solver.cpp:337] Iteration 49400, Testing net (#0)
I0507 09:39:36.876570 26400 solver.cpp:404]     Test net output #0: loss = 0.111919 (* 1 = 0.111919 loss)
I0507 09:39:37.745192 26400 solver.cpp:228] Iteration 49400, loss = 0.0225508
I0507 09:39:37.745250 26400 solver.cpp:244]     Train net output #0: loss = 0.0225524 (* 1 = 0.0225524 loss)
I0507 09:39:37.745265 26400 sgd_solver.cpp:106] Iteration 49400, lr = 1e-07
I0507 09:41:47.604996 26400 solver.cpp:228] Iteration 49450, loss = 0.0467647
I0507 09:41:47.605173 26400 solver.cpp:244]     Train net output #0: loss = 0.0467663 (* 1 = 0.0467663 loss)
I0507 09:41:47.605196 26400 sgd_solver.cpp:106] Iteration 49450, lr = 1e-07
I0507 09:43:57.496402 26400 solver.cpp:228] Iteration 49500, loss = 0.0497539
I0507 09:43:57.496625 26400 solver.cpp:244]     Train net output #0: loss = 0.0497555 (* 1 = 0.0497555 loss)
I0507 09:43:57.496657 26400 sgd_solver.cpp:106] Iteration 49500, lr = 1e-07
I0507 09:46:07.790724 26400 solver.cpp:228] Iteration 49550, loss = 0.034092
I0507 09:46:07.790858 26400 solver.cpp:244]     Train net output #0: loss = 0.0340936 (* 1 = 0.0340936 loss)
I0507 09:46:07.790874 26400 sgd_solver.cpp:106] Iteration 49550, lr = 1e-07
I0507 09:48:15.221467 26400 solver.cpp:337] Iteration 49600, Testing net (#0)
I0507 09:48:46.493655 26400 solver.cpp:404]     Test net output #0: loss = 0.109059 (* 1 = 0.109059 loss)
I0507 09:48:47.356928 26400 solver.cpp:228] Iteration 49600, loss = 0.0629825
I0507 09:48:47.356976 26400 solver.cpp:244]     Train net output #0: loss = 0.0629841 (* 1 = 0.0629841 loss)
I0507 09:48:47.356988 26400 sgd_solver.cpp:106] Iteration 49600, lr = 1e-07
I0507 09:50:57.333245 26400 solver.cpp:228] Iteration 49650, loss = 0.0200282
I0507 09:50:57.333395 26400 solver.cpp:244]     Train net output #0: loss = 0.0200298 (* 1 = 0.0200298 loss)
I0507 09:50:57.333410 26400 sgd_solver.cpp:106] Iteration 49650, lr = 1e-07
I0507 09:53:07.239203 26400 solver.cpp:228] Iteration 49700, loss = 0.0452918
I0507 09:53:07.239431 26400 solver.cpp:244]     Train net output #0: loss = 0.0452934 (* 1 = 0.0452934 loss)
I0507 09:53:07.239465 26400 sgd_solver.cpp:106] Iteration 49700, lr = 1e-07
I0507 09:55:16.808229 26400 solver.cpp:228] Iteration 49750, loss = -1.607e-06
I0507 09:55:16.808394 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 09:55:16.808410 26400 sgd_solver.cpp:106] Iteration 49750, lr = 1e-07
I0507 09:57:24.011108 26400 solver.cpp:337] Iteration 49800, Testing net (#0)
I0507 09:57:39.209409 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 09:57:54.386028 26400 solver.cpp:404]     Test net output #0: loss = 0.115793 (* 1 = 0.115793 loss)
I0507 09:57:55.255452 26400 solver.cpp:228] Iteration 49800, loss = 0.00766353
I0507 09:57:55.255498 26400 solver.cpp:244]     Train net output #0: loss = 0.00766515 (* 1 = 0.00766515 loss)
I0507 09:57:55.255512 26400 sgd_solver.cpp:106] Iteration 49800, lr = 1e-07
I0507 10:00:05.030658 26400 solver.cpp:228] Iteration 49850, loss = 0.00507158
I0507 10:00:05.031025 26400 solver.cpp:244]     Train net output #0: loss = 0.00507323 (* 1 = 0.00507323 loss)
I0507 10:00:05.031114 26400 sgd_solver.cpp:106] Iteration 49850, lr = 1e-07
I0507 10:02:15.011822 26400 solver.cpp:228] Iteration 49900, loss = 0.0588203
I0507 10:02:15.012006 26400 solver.cpp:244]     Train net output #0: loss = 0.058822 (* 1 = 0.058822 loss)
I0507 10:02:15.012049 26400 sgd_solver.cpp:106] Iteration 49900, lr = 1e-07
I0507 10:04:25.119540 26400 solver.cpp:228] Iteration 49950, loss = -1.66893e-06
I0507 10:04:25.131994 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:04:25.132012 26400 sgd_solver.cpp:106] Iteration 49950, lr = 1e-07
I0507 10:06:32.352511 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_50000.caffemodel
I0507 10:06:35.680199 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_50000.solverstate
I0507 10:06:35.756862 26400 solver.cpp:337] Iteration 50000, Testing net (#0)
I0507 10:07:05.061651 26400 solver.cpp:404]     Test net output #0: loss = 0.115143 (* 1 = 0.115143 loss)
I0507 10:07:05.927386 26400 solver.cpp:228] Iteration 50000, loss = 0.0173059
I0507 10:07:05.927500 26400 solver.cpp:244]     Train net output #0: loss = 0.0173076 (* 1 = 0.0173076 loss)
I0507 10:07:05.927534 26400 sgd_solver.cpp:106] Iteration 50000, lr = 1e-07
I0507 10:09:15.818820 26400 solver.cpp:228] Iteration 50050, loss = -1.69128e-06
I0507 10:09:15.819037 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:09:15.819079 26400 sgd_solver.cpp:106] Iteration 50050, lr = 1e-07
I0507 10:11:25.528869 26400 solver.cpp:228] Iteration 50100, loss = 0.00906546
I0507 10:11:25.529096 26400 solver.cpp:244]     Train net output #0: loss = 0.00906716 (* 1 = 0.00906716 loss)
I0507 10:11:25.529131 26400 sgd_solver.cpp:106] Iteration 50100, lr = 1e-07
I0507 10:13:35.488585 26400 solver.cpp:228] Iteration 50150, loss = -1.68383e-06
I0507 10:13:35.488792 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:13:35.488826 26400 sgd_solver.cpp:106] Iteration 50150, lr = 1e-07
I0507 10:15:42.842844 26400 solver.cpp:337] Iteration 50200, Testing net (#0)
I0507 10:16:08.512827 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 10:16:13.167224 26400 solver.cpp:404]     Test net output #0: loss = 0.118999 (* 1 = 0.118999 loss)
I0507 10:16:14.036098 26400 solver.cpp:228] Iteration 50200, loss = 0.0352501
I0507 10:16:14.036159 26400 solver.cpp:244]     Train net output #0: loss = 0.0352518 (* 1 = 0.0352518 loss)
I0507 10:16:14.036190 26400 sgd_solver.cpp:106] Iteration 50200, lr = 1e-07
I0507 10:18:23.959132 26400 solver.cpp:228] Iteration 50250, loss = -1.70618e-06
I0507 10:18:23.959286 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:18:23.959322 26400 sgd_solver.cpp:106] Iteration 50250, lr = 1e-07
I0507 10:20:33.948261 26400 solver.cpp:228] Iteration 50300, loss = 0.0162023
I0507 10:20:33.948451 26400 solver.cpp:244]     Train net output #0: loss = 0.016204 (* 1 = 0.016204 loss)
I0507 10:20:33.948467 26400 sgd_solver.cpp:106] Iteration 50300, lr = 1e-07
I0507 10:22:43.934239 26400 solver.cpp:228] Iteration 50350, loss = 0.06371
I0507 10:22:43.934401 26400 solver.cpp:244]     Train net output #0: loss = 0.0637117 (* 1 = 0.0637117 loss)
I0507 10:22:43.934434 26400 sgd_solver.cpp:106] Iteration 50350, lr = 1e-07
I0507 10:24:51.150812 26400 solver.cpp:337] Iteration 50400, Testing net (#0)
I0507 10:25:22.797088 26400 solver.cpp:404]     Test net output #0: loss = 0.106835 (* 1 = 0.106835 loss)
I0507 10:25:23.662081 26400 solver.cpp:228] Iteration 50400, loss = 0.065539
I0507 10:25:23.662163 26400 solver.cpp:244]     Train net output #0: loss = 0.0655407 (* 1 = 0.0655407 loss)
I0507 10:25:23.662181 26400 sgd_solver.cpp:106] Iteration 50400, lr = 1e-07
I0507 10:27:33.257464 26400 solver.cpp:228] Iteration 50450, loss = 0.0922323
I0507 10:27:33.257733 26400 solver.cpp:244]     Train net output #0: loss = 0.092234 (* 1 = 0.092234 loss)
I0507 10:27:33.257792 26400 sgd_solver.cpp:106] Iteration 50450, lr = 1e-07
I0507 10:29:43.180780 26400 solver.cpp:228] Iteration 50500, loss = 0.128457
I0507 10:29:43.181082 26400 solver.cpp:244]     Train net output #0: loss = 0.128459 (* 1 = 0.128459 loss)
I0507 10:29:43.181124 26400 sgd_solver.cpp:106] Iteration 50500, lr = 1e-07
I0507 10:31:53.181103 26400 solver.cpp:228] Iteration 50550, loss = 0.0898967
I0507 10:31:53.193610 26400 solver.cpp:244]     Train net output #0: loss = 0.0898984 (* 1 = 0.0898984 loss)
I0507 10:31:53.193645 26400 sgd_solver.cpp:106] Iteration 50550, lr = 1e-07
I0507 10:34:00.568478 26400 solver.cpp:337] Iteration 50600, Testing net (#0)
I0507 10:34:31.371641 26400 solver.cpp:404]     Test net output #0: loss = 0.115731 (* 1 = 0.115731 loss)
I0507 10:34:32.239784 26400 solver.cpp:228] Iteration 50600, loss = 0.0454392
I0507 10:34:32.239837 26400 solver.cpp:244]     Train net output #0: loss = 0.0454409 (* 1 = 0.0454409 loss)
I0507 10:34:32.239853 26400 sgd_solver.cpp:106] Iteration 50600, lr = 1e-07
I0507 10:36:42.149778 26400 solver.cpp:228] Iteration 50650, loss = 0.0250963
I0507 10:36:42.150043 26400 solver.cpp:244]     Train net output #0: loss = 0.025098 (* 1 = 0.025098 loss)
I0507 10:36:42.150091 26400 sgd_solver.cpp:106] Iteration 50650, lr = 1e-07
I0507 10:38:51.958997 26400 solver.cpp:228] Iteration 50700, loss = 0.0821097
I0507 10:38:51.959213 26400 solver.cpp:244]     Train net output #0: loss = 0.0821114 (* 1 = 0.0821114 loss)
I0507 10:38:51.959275 26400 sgd_solver.cpp:106] Iteration 50700, lr = 1e-07
I0507 10:41:01.766504 26400 solver.cpp:228] Iteration 50750, loss = 0.135087
I0507 10:41:01.766656 26400 solver.cpp:244]     Train net output #0: loss = 0.135089 (* 1 = 0.135089 loss)
I0507 10:41:01.766680 26400 sgd_solver.cpp:106] Iteration 50750, lr = 1e-07
I0507 10:43:08.777005 26400 solver.cpp:337] Iteration 50800, Testing net (#0)
I0507 10:43:27.641541 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 10:43:39.903611 26400 solver.cpp:404]     Test net output #0: loss = 0.126456 (* 1 = 0.126456 loss)
I0507 10:43:40.769201 26400 solver.cpp:228] Iteration 50800, loss = 0.116673
I0507 10:43:40.769255 26400 solver.cpp:244]     Train net output #0: loss = 0.116674 (* 1 = 0.116674 loss)
I0507 10:43:40.769275 26400 sgd_solver.cpp:106] Iteration 50800, lr = 1e-07
I0507 10:45:50.748998 26400 solver.cpp:228] Iteration 50850, loss = -1.75834e-06
I0507 10:45:50.749217 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:45:50.749258 26400 sgd_solver.cpp:106] Iteration 50850, lr = 1e-07
I0507 10:48:00.608881 26400 solver.cpp:228] Iteration 50900, loss = 0.0421604
I0507 10:48:00.609028 26400 solver.cpp:244]     Train net output #0: loss = 0.0421622 (* 1 = 0.0421622 loss)
I0507 10:48:00.609045 26400 sgd_solver.cpp:106] Iteration 50900, lr = 1e-07
I0507 10:50:10.649735 26400 solver.cpp:228] Iteration 50950, loss = -1.74344e-06
I0507 10:50:10.649965 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 10:50:10.650004 26400 sgd_solver.cpp:106] Iteration 50950, lr = 1e-07
I0507 10:52:18.061064 26400 solver.cpp:337] Iteration 51000, Testing net (#0)
I0507 10:52:49.358402 26400 solver.cpp:404]     Test net output #0: loss = 0.119977 (* 1 = 0.119977 loss)
I0507 10:52:50.223248 26400 solver.cpp:228] Iteration 51000, loss = 0.257091
I0507 10:52:50.223304 26400 solver.cpp:244]     Train net output #0: loss = 0.257093 (* 1 = 0.257093 loss)
I0507 10:52:50.223322 26400 sgd_solver.cpp:106] Iteration 51000, lr = 1e-07
I0507 10:55:00.292681 26400 solver.cpp:228] Iteration 51050, loss = 0.176283
I0507 10:55:00.293002 26400 solver.cpp:244]     Train net output #0: loss = 0.176285 (* 1 = 0.176285 loss)
I0507 10:55:00.293035 26400 sgd_solver.cpp:106] Iteration 51050, lr = 1e-07
I0507 10:57:10.160432 26400 solver.cpp:228] Iteration 51100, loss = 0.0199578
I0507 10:57:10.160647 26400 solver.cpp:244]     Train net output #0: loss = 0.0199595 (* 1 = 0.0199595 loss)
I0507 10:57:10.160688 26400 sgd_solver.cpp:106] Iteration 51100, lr = 1e-07
I0507 10:59:19.824491 26400 solver.cpp:228] Iteration 51150, loss = 0.0185606
I0507 10:59:19.826546 26400 solver.cpp:244]     Train net output #0: loss = 0.0185623 (* 1 = 0.0185623 loss)
I0507 10:59:19.826570 26400 sgd_solver.cpp:106] Iteration 51150, lr = 1e-07
I0507 11:01:27.081560 26400 solver.cpp:337] Iteration 51200, Testing net (#0)
I0507 11:01:48.916811 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 11:01:57.550570 26400 solver.cpp:404]     Test net output #0: loss = 0.126502 (* 1 = 0.126502 loss)
I0507 11:01:58.428570 26400 solver.cpp:228] Iteration 51200, loss = 0.053697
I0507 11:01:58.428622 26400 solver.cpp:244]     Train net output #0: loss = 0.0536988 (* 1 = 0.0536988 loss)
I0507 11:01:58.428650 26400 sgd_solver.cpp:106] Iteration 51200, lr = 1e-07
I0507 11:04:08.382551 26400 solver.cpp:228] Iteration 51250, loss = -1.72853e-06
I0507 11:04:08.383031 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 11:04:08.383065 26400 sgd_solver.cpp:106] Iteration 51250, lr = 1e-07
I0507 11:06:18.292533 26400 solver.cpp:228] Iteration 51300, loss = 0.0155219
I0507 11:06:18.292856 26400 solver.cpp:244]     Train net output #0: loss = 0.0155236 (* 1 = 0.0155236 loss)
I0507 11:06:18.292937 26400 sgd_solver.cpp:106] Iteration 51300, lr = 1e-07
I0507 11:08:28.361261 26400 solver.cpp:228] Iteration 51350, loss = -1.72667e-06
I0507 11:08:28.361503 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 11:08:28.361542 26400 sgd_solver.cpp:106] Iteration 51350, lr = 1e-07
I0507 11:10:35.734902 26400 solver.cpp:337] Iteration 51400, Testing net (#0)
I0507 11:11:06.640645 26400 solver.cpp:404]     Test net output #0: loss = 0.110069 (* 1 = 0.110069 loss)
I0507 11:11:07.510221 26400 solver.cpp:228] Iteration 51400, loss = 0.0781227
I0507 11:11:07.510258 26400 solver.cpp:244]     Train net output #0: loss = 0.0781245 (* 1 = 0.0781245 loss)
I0507 11:11:07.510272 26400 sgd_solver.cpp:106] Iteration 51400, lr = 1e-07
I0507 11:13:17.595461 26400 solver.cpp:228] Iteration 51450, loss = 0.0166454
I0507 11:13:17.595628 26400 solver.cpp:244]     Train net output #0: loss = 0.0166472 (* 1 = 0.0166472 loss)
I0507 11:13:17.595655 26400 sgd_solver.cpp:106] Iteration 51450, lr = 1e-07
I0507 11:15:27.538548 26400 solver.cpp:228] Iteration 51500, loss = 0.00450265
I0507 11:15:27.539777 26400 solver.cpp:244]     Train net output #0: loss = 0.00450439 (* 1 = 0.00450439 loss)
I0507 11:15:27.539810 26400 sgd_solver.cpp:106] Iteration 51500, lr = 1e-07
I0507 11:17:37.129293 26400 solver.cpp:228] Iteration 51550, loss = 0.0366921
I0507 11:17:37.129441 26400 solver.cpp:244]     Train net output #0: loss = 0.0366939 (* 1 = 0.0366939 loss)
I0507 11:17:37.129457 26400 sgd_solver.cpp:106] Iteration 51550, lr = 1e-07
I0507 11:19:44.508924 26400 solver.cpp:337] Iteration 51600, Testing net (#0)
I0507 11:20:09.539909 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 11:20:15.093047 26400 solver.cpp:404]     Test net output #0: loss = 0.105351 (* 1 = 0.105351 loss)
I0507 11:20:15.971237 26400 solver.cpp:228] Iteration 51600, loss = 0.03409
I0507 11:20:15.971333 26400 solver.cpp:244]     Train net output #0: loss = 0.0340918 (* 1 = 0.0340918 loss)
I0507 11:20:15.971397 26400 sgd_solver.cpp:106] Iteration 51600, lr = 1e-07
I0507 11:22:25.681355 26400 solver.cpp:228] Iteration 51650, loss = 0.0154091
I0507 11:22:25.681550 26400 solver.cpp:244]     Train net output #0: loss = 0.0154109 (* 1 = 0.0154109 loss)
I0507 11:22:25.681588 26400 sgd_solver.cpp:106] Iteration 51650, lr = 1e-07
I0507 11:24:35.649535 26400 solver.cpp:228] Iteration 51700, loss = -1.78814e-06
I0507 11:24:35.649750 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 11:24:35.649792 26400 sgd_solver.cpp:106] Iteration 51700, lr = 1e-07
I0507 11:26:45.614526 26400 solver.cpp:228] Iteration 51750, loss = 0.139933
I0507 11:26:45.614666 26400 solver.cpp:244]     Train net output #0: loss = 0.139935 (* 1 = 0.139935 loss)
I0507 11:26:45.614681 26400 sgd_solver.cpp:106] Iteration 51750, lr = 1e-07
I0507 11:28:52.885718 26400 solver.cpp:337] Iteration 51800, Testing net (#0)
I0507 11:29:23.027151 26400 solver.cpp:404]     Test net output #0: loss = 0.107952 (* 1 = 0.107952 loss)
I0507 11:29:23.897239 26400 solver.cpp:228] Iteration 51800, loss = 0.0655445
I0507 11:29:23.897300 26400 solver.cpp:244]     Train net output #0: loss = 0.0655463 (* 1 = 0.0655463 loss)
I0507 11:29:23.897325 26400 sgd_solver.cpp:106] Iteration 51800, lr = 1e-07
I0507 11:31:33.993968 26400 solver.cpp:228] Iteration 51850, loss = 0.0582773
I0507 11:31:34.008397 26400 solver.cpp:244]     Train net output #0: loss = 0.058279 (* 1 = 0.058279 loss)
I0507 11:31:34.008440 26400 sgd_solver.cpp:106] Iteration 51850, lr = 1e-07
I0507 11:33:43.842214 26400 solver.cpp:228] Iteration 51900, loss = 0.0391489
I0507 11:33:43.842815 26400 solver.cpp:244]     Train net output #0: loss = 0.0391507 (* 1 = 0.0391507 loss)
I0507 11:33:43.842841 26400 sgd_solver.cpp:106] Iteration 51900, lr = 1e-07
I0507 11:35:53.652138 26400 solver.cpp:228] Iteration 51950, loss = 0.0203652
I0507 11:35:53.652345 26400 solver.cpp:244]     Train net output #0: loss = 0.0203669 (* 1 = 0.0203669 loss)
I0507 11:35:53.652390 26400 sgd_solver.cpp:106] Iteration 51950, lr = 1e-07
I0507 11:38:01.010083 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_52000.caffemodel
I0507 11:38:07.497686 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_52000.solverstate
I0507 11:38:07.564826 26400 solver.cpp:337] Iteration 52000, Testing net (#0)
I0507 11:38:37.196305 26400 solver.cpp:404]     Test net output #0: loss = 0.114553 (* 1 = 0.114553 loss)
I0507 11:38:38.063423 26400 solver.cpp:228] Iteration 52000, loss = 0.0717025
I0507 11:38:38.063479 26400 solver.cpp:244]     Train net output #0: loss = 0.0717042 (* 1 = 0.0717042 loss)
I0507 11:38:38.063493 26400 sgd_solver.cpp:106] Iteration 52000, lr = 1e-07
I0507 11:40:48.180083 26400 solver.cpp:228] Iteration 52050, loss = 0.0296951
I0507 11:40:48.180243 26400 solver.cpp:244]     Train net output #0: loss = 0.0296968 (* 1 = 0.0296968 loss)
I0507 11:40:48.180258 26400 sgd_solver.cpp:106] Iteration 52050, lr = 1e-07
I0507 11:42:58.104779 26400 solver.cpp:228] Iteration 52100, loss = 0.0469347
I0507 11:42:58.105026 26400 solver.cpp:244]     Train net output #0: loss = 0.0469365 (* 1 = 0.0469365 loss)
I0507 11:42:58.105059 26400 sgd_solver.cpp:106] Iteration 52100, lr = 1e-07
I0507 11:45:07.753808 26400 solver.cpp:228] Iteration 52150, loss = 0.0769089
I0507 11:45:07.753969 26400 solver.cpp:244]     Train net output #0: loss = 0.0769107 (* 1 = 0.0769107 loss)
I0507 11:45:07.753989 26400 sgd_solver.cpp:106] Iteration 52150, lr = 1e-07
I0507 11:47:15.150291 26400 solver.cpp:337] Iteration 52200, Testing net (#0)
I0507 11:47:38.830668 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 11:47:45.790892 26400 solver.cpp:404]     Test net output #0: loss = 0.119844 (* 1 = 0.119844 loss)
I0507 11:47:46.657544 26400 solver.cpp:228] Iteration 52200, loss = 0.00405634
I0507 11:47:46.657595 26400 solver.cpp:244]     Train net output #0: loss = 0.00405815 (* 1 = 0.00405815 loss)
I0507 11:47:46.657619 26400 sgd_solver.cpp:106] Iteration 52200, lr = 1e-07
I0507 11:49:56.516294 26400 solver.cpp:228] Iteration 52250, loss = 0.0258201
I0507 11:49:56.516698 26400 solver.cpp:244]     Train net output #0: loss = 0.0258219 (* 1 = 0.0258219 loss)
I0507 11:49:56.516739 26400 sgd_solver.cpp:106] Iteration 52250, lr = 1e-07
I0507 11:52:06.809707 26400 solver.cpp:228] Iteration 52300, loss = 0.102016
I0507 11:52:06.809927 26400 solver.cpp:244]     Train net output #0: loss = 0.102018 (* 1 = 0.102018 loss)
I0507 11:52:06.809962 26400 sgd_solver.cpp:106] Iteration 52300, lr = 1e-07
I0507 11:54:16.813649 26400 solver.cpp:228] Iteration 52350, loss = -1.80304e-06
I0507 11:54:16.815099 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 11:54:16.815134 26400 sgd_solver.cpp:106] Iteration 52350, lr = 1e-07
I0507 11:56:23.988615 26400 solver.cpp:337] Iteration 52400, Testing net (#0)
I0507 11:56:54.535262 26400 solver.cpp:404]     Test net output #0: loss = 0.105934 (* 1 = 0.105934 loss)
I0507 11:56:55.401851 26400 solver.cpp:228] Iteration 52400, loss = 0.0605798
I0507 11:56:55.401896 26400 solver.cpp:244]     Train net output #0: loss = 0.0605816 (* 1 = 0.0605816 loss)
I0507 11:56:55.401911 26400 sgd_solver.cpp:106] Iteration 52400, lr = 1e-07
I0507 11:59:05.247716 26400 solver.cpp:228] Iteration 52450, loss = 0.0063152
I0507 11:59:05.260241 26400 solver.cpp:244]     Train net output #0: loss = 0.006317 (* 1 = 0.006317 loss)
I0507 11:59:05.260267 26400 sgd_solver.cpp:106] Iteration 52450, lr = 1e-07
I0507 12:01:14.868975 26400 solver.cpp:228] Iteration 52500, loss = -1.80304e-06
I0507 12:01:14.869199 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:01:14.869232 26400 sgd_solver.cpp:106] Iteration 52500, lr = 1e-07
I0507 12:03:24.694133 26400 solver.cpp:228] Iteration 52550, loss = -1.8063e-06
I0507 12:03:24.694347 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:03:24.694380 26400 sgd_solver.cpp:106] Iteration 52550, lr = 1e-07
I0507 12:05:32.173691 26400 solver.cpp:337] Iteration 52600, Testing net (#0)
I0507 12:06:03.039468 26400 solver.cpp:404]     Test net output #0: loss = 0.115647 (* 1 = 0.115647 loss)
I0507 12:06:03.905429 26400 solver.cpp:228] Iteration 52600, loss = -1.82353e-06
I0507 12:06:03.905480 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:06:03.905500 26400 sgd_solver.cpp:106] Iteration 52600, lr = 1e-07
I0507 12:08:13.777781 26400 solver.cpp:228] Iteration 52650, loss = 0.367055
I0507 12:08:13.777927 26400 solver.cpp:244]     Train net output #0: loss = 0.367057 (* 1 = 0.367057 loss)
I0507 12:08:13.777953 26400 sgd_solver.cpp:106] Iteration 52650, lr = 1e-07
I0507 12:10:24.040984 26400 solver.cpp:228] Iteration 52700, loss = 0.0975107
I0507 12:10:24.041133 26400 solver.cpp:244]     Train net output #0: loss = 0.0975125 (* 1 = 0.0975125 loss)
I0507 12:10:24.041149 26400 sgd_solver.cpp:106] Iteration 52700, lr = 1e-07
I0507 12:12:33.982928 26400 solver.cpp:228] Iteration 52750, loss = 0.033552
I0507 12:12:33.983356 26400 solver.cpp:244]     Train net output #0: loss = 0.0335538 (* 1 = 0.0335538 loss)
I0507 12:12:33.983413 26400 sgd_solver.cpp:106] Iteration 52750, lr = 1e-07
I0507 12:14:41.252573 26400 solver.cpp:337] Iteration 52800, Testing net (#0)
I0507 12:15:12.155894 26400 solver.cpp:404]     Test net output #0: loss = 0.1275 (* 1 = 0.1275 loss)
I0507 12:15:13.023239 26400 solver.cpp:228] Iteration 52800, loss = 0.0726856
I0507 12:15:13.023285 26400 solver.cpp:244]     Train net output #0: loss = 0.0726873 (* 1 = 0.0726873 loss)
I0507 12:15:13.023299 26400 sgd_solver.cpp:106] Iteration 52800, lr = 1e-07
I0507 12:17:22.939074 26400 solver.cpp:228] Iteration 52850, loss = -1.74344e-06
I0507 12:17:22.940548 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:17:22.940583 26400 sgd_solver.cpp:106] Iteration 52850, lr = 1e-07
I0507 12:19:32.744616 26400 solver.cpp:228] Iteration 52900, loss = 0.0212299
I0507 12:19:32.746467 26400 solver.cpp:244]     Train net output #0: loss = 0.0212316 (* 1 = 0.0212316 loss)
I0507 12:19:32.746498 26400 sgd_solver.cpp:106] Iteration 52900, lr = 1e-07
I0507 12:21:42.799901 26400 solver.cpp:228] Iteration 52950, loss = 0.0302538
I0507 12:21:42.800559 26400 solver.cpp:244]     Train net output #0: loss = 0.0302555 (* 1 = 0.0302555 loss)
I0507 12:21:42.800631 26400 sgd_solver.cpp:106] Iteration 52950, lr = 1e-07
I0507 12:23:50.321972 26400 solver.cpp:337] Iteration 53000, Testing net (#0)
I0507 12:23:54.853382 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 12:24:21.485955 26400 solver.cpp:404]     Test net output #0: loss = 0.118152 (* 1 = 0.118152 loss)
I0507 12:24:22.357501 26400 solver.cpp:228] Iteration 53000, loss = 0.000576571
I0507 12:24:22.357632 26400 solver.cpp:244]     Train net output #0: loss = 0.000578271 (* 1 = 0.000578271 loss)
I0507 12:24:22.357671 26400 sgd_solver.cpp:106] Iteration 53000, lr = 1e-07
I0507 12:26:32.346652 26400 solver.cpp:228] Iteration 53050, loss = 0.00100293
I0507 12:26:32.346860 26400 solver.cpp:244]     Train net output #0: loss = 0.00100462 (* 1 = 0.00100462 loss)
I0507 12:26:32.346897 26400 sgd_solver.cpp:106] Iteration 53050, lr = 1e-07
I0507 12:28:42.263104 26400 solver.cpp:228] Iteration 53100, loss = -1.71363e-06
I0507 12:28:42.263901 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:28:42.263922 26400 sgd_solver.cpp:106] Iteration 53100, lr = 1e-07
I0507 12:30:51.989228 26400 solver.cpp:228] Iteration 53150, loss = 0.00690162
I0507 12:30:52.001775 26400 solver.cpp:244]     Train net output #0: loss = 0.00690334 (* 1 = 0.00690334 loss)
I0507 12:30:52.001811 26400 sgd_solver.cpp:106] Iteration 53150, lr = 1e-07
I0507 12:32:59.379719 26400 solver.cpp:337] Iteration 53200, Testing net (#0)
I0507 12:33:30.262837 26400 solver.cpp:404]     Test net output #0: loss = 0.122997 (* 1 = 0.122997 loss)
I0507 12:33:31.127671 26400 solver.cpp:228] Iteration 53200, loss = 0.104707
I0507 12:33:31.127717 26400 solver.cpp:244]     Train net output #0: loss = 0.104709 (* 1 = 0.104709 loss)
I0507 12:33:31.127743 26400 sgd_solver.cpp:106] Iteration 53200, lr = 1e-07
I0507 12:35:40.971730 26400 solver.cpp:228] Iteration 53250, loss = -1.66148e-06
I0507 12:35:40.971904 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:35:40.971920 26400 sgd_solver.cpp:106] Iteration 53250, lr = 1e-07
I0507 12:37:50.869844 26400 solver.cpp:228] Iteration 53300, loss = -1.65403e-06
I0507 12:37:50.870059 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:37:50.870090 26400 sgd_solver.cpp:106] Iteration 53300, lr = 1e-07
I0507 12:40:00.979265 26400 solver.cpp:228] Iteration 53350, loss = -1.65403e-06
I0507 12:40:00.979503 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:40:00.979538 26400 sgd_solver.cpp:106] Iteration 53350, lr = 1e-07
I0507 12:42:08.357928 26400 solver.cpp:337] Iteration 53400, Testing net (#0)
I0507 12:42:19.223996 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 12:42:38.432457 26400 solver.cpp:404]     Test net output #0: loss = 0.105992 (* 1 = 0.105992 loss)
I0507 12:42:39.301349 26400 solver.cpp:228] Iteration 53400, loss = 0.034554
I0507 12:42:39.301401 26400 solver.cpp:244]     Train net output #0: loss = 0.0345557 (* 1 = 0.0345557 loss)
I0507 12:42:39.301431 26400 sgd_solver.cpp:106] Iteration 53400, lr = 1e-07
I0507 12:44:49.319973 26400 solver.cpp:228] Iteration 53450, loss = 0.0292338
I0507 12:44:49.320117 26400 solver.cpp:244]     Train net output #0: loss = 0.0292354 (* 1 = 0.0292354 loss)
I0507 12:44:49.320133 26400 sgd_solver.cpp:106] Iteration 53450, lr = 1e-07
I0507 12:46:59.130537 26400 solver.cpp:228] Iteration 53500, loss = -1.60933e-06
I0507 12:46:59.132521 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:46:59.132555 26400 sgd_solver.cpp:106] Iteration 53500, lr = 1e-07
I0507 12:49:08.855015 26400 solver.cpp:228] Iteration 53550, loss = 0.0625689
I0507 12:49:08.855149 26400 solver.cpp:244]     Train net output #0: loss = 0.0625704 (* 1 = 0.0625704 loss)
I0507 12:49:08.855165 26400 sgd_solver.cpp:106] Iteration 53550, lr = 1e-07
I0507 12:51:16.338889 26400 solver.cpp:337] Iteration 53600, Testing net (#0)
I0507 12:51:46.396809 26400 solver.cpp:404]     Test net output #0: loss = 0.105608 (* 1 = 0.105608 loss)
I0507 12:51:47.267987 26400 solver.cpp:228] Iteration 53600, loss = 0.0420047
I0507 12:51:47.268043 26400 solver.cpp:244]     Train net output #0: loss = 0.0420062 (* 1 = 0.0420062 loss)
I0507 12:51:47.268056 26400 sgd_solver.cpp:106] Iteration 53600, lr = 1e-07
I0507 12:53:57.284920 26400 solver.cpp:228] Iteration 53650, loss = 0.164192
I0507 12:53:57.285060 26400 solver.cpp:244]     Train net output #0: loss = 0.164194 (* 1 = 0.164194 loss)
I0507 12:53:57.285084 26400 sgd_solver.cpp:106] Iteration 53650, lr = 1e-07
I0507 12:56:07.033079 26400 solver.cpp:228] Iteration 53700, loss = -1.52737e-06
I0507 12:56:07.033267 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:56:07.033300 26400 sgd_solver.cpp:106] Iteration 53700, lr = 1e-07
I0507 12:58:17.311302 26400 solver.cpp:228] Iteration 53750, loss = -1.51992e-06
I0507 12:58:17.311470 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 12:58:17.311486 26400 sgd_solver.cpp:106] Iteration 53750, lr = 1e-07
I0507 13:00:24.854851 26400 solver.cpp:337] Iteration 53800, Testing net (#0)
I0507 13:00:54.875099 26400 solver.cpp:404]     Test net output #0: loss = 0.110943 (* 1 = 0.110943 loss)
I0507 13:00:55.741971 26400 solver.cpp:228] Iteration 53800, loss = 0.013731
I0507 13:00:55.742017 26400 solver.cpp:244]     Train net output #0: loss = 0.0137325 (* 1 = 0.0137325 loss)
I0507 13:00:55.742046 26400 sgd_solver.cpp:106] Iteration 53800, lr = 1e-07
I0507 13:03:05.865541 26400 solver.cpp:228] Iteration 53850, loss = -1.55717e-06
I0507 13:03:05.867857 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:03:05.867888 26400 sgd_solver.cpp:106] Iteration 53850, lr = 1e-07
I0507 13:05:15.882833 26400 solver.cpp:228] Iteration 53900, loss = 0.0627092
I0507 13:05:15.883070 26400 solver.cpp:244]     Train net output #0: loss = 0.0627107 (* 1 = 0.0627107 loss)
I0507 13:05:15.883126 26400 sgd_solver.cpp:106] Iteration 53900, lr = 1e-07
I0507 13:07:25.721177 26400 solver.cpp:228] Iteration 53950, loss = 0.0201585
I0507 13:07:25.721421 26400 solver.cpp:244]     Train net output #0: loss = 0.02016 (* 1 = 0.02016 loss)
I0507 13:07:25.721454 26400 sgd_solver.cpp:106] Iteration 53950, lr = 1e-07
I0507 13:09:33.128520 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_54000.caffemodel
I0507 13:09:38.728060 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_54000.solverstate
I0507 13:09:38.805466 26400 solver.cpp:337] Iteration 54000, Testing net (#0)
I0507 13:09:47.303434 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 13:10:07.852257 26400 solver.cpp:404]     Test net output #0: loss = 0.111022 (* 1 = 0.111022 loss)
I0507 13:10:08.718325 26400 solver.cpp:228] Iteration 54000, loss = 0.206117
I0507 13:10:08.718384 26400 solver.cpp:244]     Train net output #0: loss = 0.206118 (* 1 = 0.206118 loss)
I0507 13:10:08.718399 26400 sgd_solver.cpp:106] Iteration 54000, lr = 1e-07
I0507 13:12:18.653224 26400 solver.cpp:228] Iteration 54050, loss = 0.254368
I0507 13:12:18.653434 26400 solver.cpp:244]     Train net output #0: loss = 0.254369 (* 1 = 0.254369 loss)
I0507 13:12:18.653476 26400 sgd_solver.cpp:106] Iteration 54050, lr = 1e-07
I0507 13:14:28.473410 26400 solver.cpp:228] Iteration 54100, loss = 0.0818973
I0507 13:14:28.473597 26400 solver.cpp:244]     Train net output #0: loss = 0.0818988 (* 1 = 0.0818988 loss)
I0507 13:14:28.473613 26400 sgd_solver.cpp:106] Iteration 54100, lr = 1e-07
I0507 13:16:38.307446 26400 solver.cpp:228] Iteration 54150, loss = -1.57207e-06
I0507 13:16:38.308743 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:16:38.308778 26400 sgd_solver.cpp:106] Iteration 54150, lr = 1e-07
I0507 13:18:45.672804 26400 solver.cpp:337] Iteration 54200, Testing net (#0)
I0507 13:19:15.840999 26400 solver.cpp:404]     Test net output #0: loss = 0.115795 (* 1 = 0.115795 loss)
I0507 13:19:16.709205 26400 solver.cpp:228] Iteration 54200, loss = -1.56462e-06
I0507 13:19:16.709280 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:19:16.709296 26400 sgd_solver.cpp:106] Iteration 54200, lr = 1e-07
I0507 13:21:26.568276 26400 solver.cpp:228] Iteration 54250, loss = 0.000867985
I0507 13:21:26.568449 26400 solver.cpp:244]     Train net output #0: loss = 0.000869579 (* 1 = 0.000869579 loss)
I0507 13:21:26.568466 26400 sgd_solver.cpp:106] Iteration 54250, lr = 1e-07
I0507 13:23:36.519629 26400 solver.cpp:228] Iteration 54300, loss = -1.57952e-06
I0507 13:23:36.519783 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:23:36.519798 26400 sgd_solver.cpp:106] Iteration 54300, lr = 1e-07
I0507 13:25:46.477588 26400 solver.cpp:228] Iteration 54350, loss = 0.00330526
I0507 13:25:46.477835 26400 solver.cpp:244]     Train net output #0: loss = 0.00330685 (* 1 = 0.00330685 loss)
I0507 13:25:46.477877 26400 sgd_solver.cpp:106] Iteration 54350, lr = 1e-07
I0507 13:27:53.775327 26400 solver.cpp:337] Iteration 54400, Testing net (#0)
I0507 13:28:07.541476 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 13:28:24.614197 26400 solver.cpp:404]     Test net output #0: loss = 0.10957 (* 1 = 0.10957 loss)
I0507 13:28:25.484001 26400 solver.cpp:228] Iteration 54400, loss = 0.0162269
I0507 13:28:25.484058 26400 solver.cpp:244]     Train net output #0: loss = 0.0162285 (* 1 = 0.0162285 loss)
I0507 13:28:25.484073 26400 sgd_solver.cpp:106] Iteration 54400, lr = 1e-07
I0507 13:30:35.492969 26400 solver.cpp:228] Iteration 54450, loss = -1.60933e-06
I0507 13:30:35.493196 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:30:35.493247 26400 sgd_solver.cpp:106] Iteration 54450, lr = 1e-07
I0507 13:32:45.468379 26400 solver.cpp:228] Iteration 54500, loss = 0.0214898
I0507 13:32:45.468541 26400 solver.cpp:244]     Train net output #0: loss = 0.0214914 (* 1 = 0.0214914 loss)
I0507 13:32:45.468565 26400 sgd_solver.cpp:106] Iteration 54500, lr = 1e-07
I0507 13:34:55.166409 26400 solver.cpp:228] Iteration 54550, loss = 0.0498295
I0507 13:34:55.166633 26400 solver.cpp:244]     Train net output #0: loss = 0.0498311 (* 1 = 0.0498311 loss)
I0507 13:34:55.166676 26400 sgd_solver.cpp:106] Iteration 54550, lr = 1e-07
I0507 13:37:02.437607 26400 solver.cpp:337] Iteration 54600, Testing net (#0)
I0507 13:37:32.639881 26400 solver.cpp:404]     Test net output #0: loss = 0.114854 (* 1 = 0.114854 loss)
I0507 13:37:33.507637 26400 solver.cpp:228] Iteration 54600, loss = 0.00607601
I0507 13:37:33.507704 26400 solver.cpp:244]     Train net output #0: loss = 0.00607762 (* 1 = 0.00607762 loss)
I0507 13:37:33.507719 26400 sgd_solver.cpp:106] Iteration 54600, lr = 1e-07
I0507 13:39:43.327591 26400 solver.cpp:228] Iteration 54650, loss = 0.0673841
I0507 13:39:43.327745 26400 solver.cpp:244]     Train net output #0: loss = 0.0673858 (* 1 = 0.0673858 loss)
I0507 13:39:43.327762 26400 sgd_solver.cpp:106] Iteration 54650, lr = 1e-07
I0507 13:41:53.356583 26400 solver.cpp:228] Iteration 54700, loss = 0.151692
I0507 13:41:53.356801 26400 solver.cpp:244]     Train net output #0: loss = 0.151694 (* 1 = 0.151694 loss)
I0507 13:41:53.356851 26400 sgd_solver.cpp:106] Iteration 54700, lr = 1e-07
I0507 13:44:03.168118 26400 solver.cpp:228] Iteration 54750, loss = -1.60933e-06
I0507 13:44:03.168274 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:44:03.168290 26400 sgd_solver.cpp:106] Iteration 54750, lr = 1e-07
I0507 13:46:10.439643 26400 solver.cpp:337] Iteration 54800, Testing net (#0)
I0507 13:46:29.937160 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 13:46:41.640473 26400 solver.cpp:404]     Test net output #0: loss = 0.12247 (* 1 = 0.12247 loss)
I0507 13:46:42.509394 26400 solver.cpp:228] Iteration 54800, loss = 0.0272686
I0507 13:46:42.509457 26400 solver.cpp:244]     Train net output #0: loss = 0.0272702 (* 1 = 0.0272702 loss)
I0507 13:46:42.509475 26400 sgd_solver.cpp:106] Iteration 54800, lr = 1e-07
I0507 13:48:52.469482 26400 solver.cpp:228] Iteration 54850, loss = -1.62423e-06
I0507 13:48:52.469683 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:48:52.469746 26400 sgd_solver.cpp:106] Iteration 54850, lr = 1e-07
I0507 13:51:02.298091 26400 solver.cpp:228] Iteration 54900, loss = 0.0563941
I0507 13:51:02.298364 26400 solver.cpp:244]     Train net output #0: loss = 0.0563957 (* 1 = 0.0563957 loss)
I0507 13:51:02.298411 26400 sgd_solver.cpp:106] Iteration 54900, lr = 1e-07
I0507 13:53:12.061431 26400 solver.cpp:228] Iteration 54950, loss = 0.0175473
I0507 13:53:12.061655 26400 solver.cpp:244]     Train net output #0: loss = 0.0175489 (* 1 = 0.0175489 loss)
I0507 13:53:12.061694 26400 sgd_solver.cpp:106] Iteration 54950, lr = 1e-07
I0507 13:55:19.312999 26400 solver.cpp:337] Iteration 55000, Testing net (#0)
I0507 13:55:50.127816 26400 solver.cpp:404]     Test net output #0: loss = 0.116655 (* 1 = 0.116655 loss)
I0507 13:55:50.993625 26400 solver.cpp:228] Iteration 55000, loss = -1.63913e-06
I0507 13:55:50.993675 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 13:55:50.993690 26400 sgd_solver.cpp:106] Iteration 55000, lr = 1e-07
I0507 13:58:00.747930 26400 solver.cpp:228] Iteration 55050, loss = 0.00659508
I0507 13:58:00.761543 26400 solver.cpp:244]     Train net output #0: loss = 0.0065967 (* 1 = 0.0065967 loss)
I0507 13:58:00.761582 26400 sgd_solver.cpp:106] Iteration 55050, lr = 1e-07
I0507 14:00:10.658612 26400 solver.cpp:228] Iteration 55100, loss = -1.59442e-06
I0507 14:00:10.660091 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 14:00:10.660135 26400 sgd_solver.cpp:106] Iteration 55100, lr = 1e-07
I0507 14:02:20.580142 26400 solver.cpp:228] Iteration 55150, loss = 0.0707377
I0507 14:02:20.580351 26400 solver.cpp:244]     Train net output #0: loss = 0.0707393 (* 1 = 0.0707393 loss)
I0507 14:02:20.580384 26400 sgd_solver.cpp:106] Iteration 55150, lr = 1e-07
I0507 14:04:27.875931 26400 solver.cpp:337] Iteration 55200, Testing net (#0)
I0507 14:04:58.367916 26400 solver.cpp:404]     Test net output #0: loss = 0.127337 (* 1 = 0.127337 loss)
I0507 14:04:59.235699 26400 solver.cpp:228] Iteration 55200, loss = 0.061548
I0507 14:04:59.235759 26400 solver.cpp:244]     Train net output #0: loss = 0.0615496 (* 1 = 0.0615496 loss)
I0507 14:04:59.235774 26400 sgd_solver.cpp:106] Iteration 55200, lr = 1e-07
I0507 14:07:09.138401 26400 solver.cpp:228] Iteration 55250, loss = 0.206058
I0507 14:07:09.138651 26400 solver.cpp:244]     Train net output #0: loss = 0.20606 (* 1 = 0.20606 loss)
I0507 14:07:09.138695 26400 sgd_solver.cpp:106] Iteration 55250, lr = 1e-07
I0507 14:09:19.036296 26400 solver.cpp:228] Iteration 55300, loss = 0.0155699
I0507 14:09:19.036538 26400 solver.cpp:244]     Train net output #0: loss = 0.0155715 (* 1 = 0.0155715 loss)
I0507 14:09:19.036559 26400 sgd_solver.cpp:106] Iteration 55300, lr = 1e-07
I0507 14:11:28.694074 26400 solver.cpp:228] Iteration 55350, loss = 0.0642177
I0507 14:11:28.694377 26400 solver.cpp:244]     Train net output #0: loss = 0.0642192 (* 1 = 0.0642192 loss)
I0507 14:11:28.694423 26400 sgd_solver.cpp:106] Iteration 55350, lr = 1e-07
I0507 14:13:35.832722 26400 solver.cpp:337] Iteration 55400, Testing net (#0)
I0507 14:13:40.040413 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 14:14:06.131968 26400 solver.cpp:404]     Test net output #0: loss = 0.107454 (* 1 = 0.107454 loss)
I0507 14:14:06.999655 26400 solver.cpp:228] Iteration 55400, loss = 0.306679
I0507 14:14:06.999724 26400 solver.cpp:244]     Train net output #0: loss = 0.30668 (* 1 = 0.30668 loss)
I0507 14:14:06.999738 26400 sgd_solver.cpp:106] Iteration 55400, lr = 1e-07
I0507 14:16:17.006378 26400 solver.cpp:228] Iteration 55450, loss = 0.148394
I0507 14:16:17.006542 26400 solver.cpp:244]     Train net output #0: loss = 0.148395 (* 1 = 0.148395 loss)
I0507 14:16:17.006558 26400 sgd_solver.cpp:106] Iteration 55450, lr = 1e-07
I0507 14:18:26.793787 26400 solver.cpp:228] Iteration 55500, loss = 0.0309695
I0507 14:18:26.793959 26400 solver.cpp:244]     Train net output #0: loss = 0.0309711 (* 1 = 0.0309711 loss)
I0507 14:18:26.793980 26400 sgd_solver.cpp:106] Iteration 55500, lr = 1e-07
I0507 14:20:36.693717 26400 solver.cpp:228] Iteration 55550, loss = -1.60467e-06
I0507 14:20:36.693886 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 14:20:36.693902 26400 sgd_solver.cpp:106] Iteration 55550, lr = 1e-07
I0507 14:22:43.679992 26400 solver.cpp:337] Iteration 55600, Testing net (#0)
I0507 14:23:14.197391 26400 solver.cpp:404]     Test net output #0: loss = 0.104054 (* 1 = 0.104054 loss)
I0507 14:23:15.064507 26400 solver.cpp:228] Iteration 55600, loss = 0.0477547
I0507 14:23:15.064568 26400 solver.cpp:244]     Train net output #0: loss = 0.0477563 (* 1 = 0.0477563 loss)
I0507 14:23:15.064584 26400 sgd_solver.cpp:106] Iteration 55600, lr = 1e-07
I0507 14:25:24.854446 26400 solver.cpp:228] Iteration 55650, loss = 0.00160994
I0507 14:25:24.854605 26400 solver.cpp:244]     Train net output #0: loss = 0.00161153 (* 1 = 0.00161153 loss)
I0507 14:25:24.854624 26400 sgd_solver.cpp:106] Iteration 55650, lr = 1e-07
I0507 14:27:34.614576 26400 solver.cpp:228] Iteration 55700, loss = 0.00129406
I0507 14:27:34.627091 26400 solver.cpp:244]     Train net output #0: loss = 0.00129562 (* 1 = 0.00129562 loss)
I0507 14:27:34.627115 26400 sgd_solver.cpp:106] Iteration 55700, lr = 1e-07
I0507 14:29:44.271874 26400 solver.cpp:228] Iteration 55750, loss = 0.0844489
I0507 14:29:44.272086 26400 solver.cpp:244]     Train net output #0: loss = 0.0844504 (* 1 = 0.0844504 loss)
I0507 14:29:44.272123 26400 sgd_solver.cpp:106] Iteration 55750, lr = 1e-07
I0507 14:31:51.549067 26400 solver.cpp:337] Iteration 55800, Testing net (#0)
I0507 14:32:03.059765 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 14:32:21.892603 26400 solver.cpp:404]     Test net output #0: loss = 0.112117 (* 1 = 0.112117 loss)
I0507 14:32:22.765261 26400 solver.cpp:228] Iteration 55800, loss = 0.0577247
I0507 14:32:22.765360 26400 solver.cpp:244]     Train net output #0: loss = 0.0577263 (* 1 = 0.0577263 loss)
I0507 14:32:22.765388 26400 sgd_solver.cpp:106] Iteration 55800, lr = 1e-07
I0507 14:34:32.710309 26400 solver.cpp:228] Iteration 55850, loss = 0.027955
I0507 14:34:32.710711 26400 solver.cpp:244]     Train net output #0: loss = 0.0279566 (* 1 = 0.0279566 loss)
I0507 14:34:32.710834 26400 sgd_solver.cpp:106] Iteration 55850, lr = 1e-07
I0507 14:36:42.234786 26400 solver.cpp:228] Iteration 55900, loss = 0.0102505
I0507 14:36:42.235047 26400 solver.cpp:244]     Train net output #0: loss = 0.0102521 (* 1 = 0.0102521 loss)
I0507 14:36:42.235100 26400 sgd_solver.cpp:106] Iteration 55900, lr = 1e-07
I0507 14:38:52.115258 26400 solver.cpp:228] Iteration 55950, loss = 0.0732653
I0507 14:38:52.115563 26400 solver.cpp:244]     Train net output #0: loss = 0.0732669 (* 1 = 0.0732669 loss)
I0507 14:38:52.115607 26400 sgd_solver.cpp:106] Iteration 55950, lr = 1e-07
I0507 14:40:59.302657 26400 solver.cpp:454] Snapshotting to binary proto file three_stream_triplet_loss_iter_56000.caffemodel
I0507 14:41:03.344745 26400 sgd_solver.cpp:273] Snapshotting solver state to binary proto file three_stream_triplet_loss_iter_56000.solverstate
I0507 14:41:03.442034 26400 solver.cpp:337] Iteration 56000, Testing net (#0)
I0507 14:41:31.773639 26400 solver.cpp:404]     Test net output #0: loss = 0.114773 (* 1 = 0.114773 loss)
I0507 14:41:32.640530 26400 solver.cpp:228] Iteration 56000, loss = -1.60933e-06
I0507 14:41:32.640584 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 14:41:32.640609 26400 sgd_solver.cpp:106] Iteration 56000, lr = 1e-07
I0507 14:43:42.419013 26400 solver.cpp:228] Iteration 56050, loss = 0.0234351
I0507 14:43:42.419163 26400 solver.cpp:244]     Train net output #0: loss = 0.0234366 (* 1 = 0.0234366 loss)
I0507 14:43:42.419199 26400 sgd_solver.cpp:106] Iteration 56050, lr = 1e-07
I0507 14:45:51.988831 26400 solver.cpp:228] Iteration 56100, loss = 0.00831793
I0507 14:45:51.988981 26400 solver.cpp:244]     Train net output #0: loss = 0.00831949 (* 1 = 0.00831949 loss)
I0507 14:45:51.988996 26400 sgd_solver.cpp:106] Iteration 56100, lr = 1e-07
I0507 14:48:01.655450 26400 solver.cpp:228] Iteration 56150, loss = 0.0225079
I0507 14:48:01.655634 26400 solver.cpp:244]     Train net output #0: loss = 0.0225095 (* 1 = 0.0225095 loss)
I0507 14:48:01.655650 26400 sgd_solver.cpp:106] Iteration 56150, lr = 1e-07
I0507 14:50:08.831297 26400 solver.cpp:337] Iteration 56200, Testing net (#0)
I0507 14:50:40.062610 26400 solver.cpp:404]     Test net output #0: loss = 0.116359 (* 1 = 0.116359 loss)
I0507 14:50:40.929031 26400 solver.cpp:228] Iteration 56200, loss = 0.128594
I0507 14:50:40.929087 26400 solver.cpp:244]     Train net output #0: loss = 0.128596 (* 1 = 0.128596 loss)
I0507 14:50:40.929101 26400 sgd_solver.cpp:106] Iteration 56200, lr = 1e-07
I0507 14:52:50.925395 26400 solver.cpp:228] Iteration 56250, loss = 0.0478766
I0507 14:52:50.925564 26400 solver.cpp:244]     Train net output #0: loss = 0.0478782 (* 1 = 0.0478782 loss)
I0507 14:52:50.925578 26400 sgd_solver.cpp:106] Iteration 56250, lr = 1e-07
I0507 14:55:00.624568 26400 solver.cpp:228] Iteration 56300, loss = 0.0463342
I0507 14:55:00.637226 26400 solver.cpp:244]     Train net output #0: loss = 0.0463358 (* 1 = 0.0463358 loss)
I0507 14:55:00.637262 26400 sgd_solver.cpp:106] Iteration 56300, lr = 1e-07
I0507 14:57:10.259670 26400 solver.cpp:228] Iteration 56350, loss = 0.0318003
I0507 14:57:10.259815 26400 solver.cpp:244]     Train net output #0: loss = 0.0318018 (* 1 = 0.0318018 loss)
I0507 14:57:10.259845 26400 sgd_solver.cpp:106] Iteration 56350, lr = 1e-07
I0507 14:59:17.555687 26400 solver.cpp:337] Iteration 56400, Testing net (#0)
I0507 14:59:34.877447 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 14:59:47.715584 26400 solver.cpp:404]     Test net output #0: loss = 0.105649 (* 1 = 0.105649 loss)
I0507 14:59:48.584002 26400 solver.cpp:228] Iteration 56400, loss = 0.000792854
I0507 14:59:48.584058 26400 solver.cpp:244]     Train net output #0: loss = 0.000794464 (* 1 = 0.000794464 loss)
I0507 14:59:48.584070 26400 sgd_solver.cpp:106] Iteration 56400, lr = 1e-07
I0507 15:01:58.301053 26400 solver.cpp:228] Iteration 56450, loss = -1.60933e-06
I0507 15:01:58.301275 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:01:58.301318 26400 sgd_solver.cpp:106] Iteration 56450, lr = 1e-07
I0507 15:04:08.076833 26400 solver.cpp:228] Iteration 56500, loss = 0.025184
I0507 15:04:08.077191 26400 solver.cpp:244]     Train net output #0: loss = 0.0251857 (* 1 = 0.0251857 loss)
I0507 15:04:08.077280 26400 sgd_solver.cpp:106] Iteration 56500, lr = 1e-07
I0507 15:06:18.012243 26400 solver.cpp:228] Iteration 56550, loss = 0.138722
I0507 15:06:18.012454 26400 solver.cpp:244]     Train net output #0: loss = 0.138724 (* 1 = 0.138724 loss)
I0507 15:06:18.012490 26400 sgd_solver.cpp:106] Iteration 56550, lr = 1e-07
I0507 15:08:25.346999 26400 solver.cpp:337] Iteration 56600, Testing net (#0)
I0507 15:08:57.128968 26400 solver.cpp:404]     Test net output #0: loss = 0.115996 (* 1 = 0.115996 loss)
I0507 15:08:57.994657 26400 solver.cpp:228] Iteration 56600, loss = -1.60187e-06
I0507 15:08:57.994731 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:08:57.994760 26400 sgd_solver.cpp:106] Iteration 56600, lr = 1e-07
I0507 15:11:07.968247 26400 solver.cpp:228] Iteration 56650, loss = 0.0151236
I0507 15:11:07.969378 26400 solver.cpp:244]     Train net output #0: loss = 0.0151252 (* 1 = 0.0151252 loss)
I0507 15:11:07.969398 26400 sgd_solver.cpp:106] Iteration 56650, lr = 1e-07
I0507 15:13:17.431502 26400 solver.cpp:228] Iteration 56700, loss = 0.0438493
I0507 15:13:17.431668 26400 solver.cpp:244]     Train net output #0: loss = 0.0438509 (* 1 = 0.0438509 loss)
I0507 15:13:17.431684 26400 sgd_solver.cpp:106] Iteration 56700, lr = 1e-07
I0507 15:15:27.006952 26400 solver.cpp:228] Iteration 56750, loss = -1.60839e-06
I0507 15:15:27.007226 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:15:27.007264 26400 sgd_solver.cpp:106] Iteration 56750, lr = 1e-07
I0507 15:17:34.176241 26400 solver.cpp:337] Iteration 56800, Testing net (#0)
I0507 15:17:57.563233 26400 blocking_queue.cpp:50] Data layer prefetch queue empty
I0507 15:18:04.490370 26400 solver.cpp:404]     Test net output #0: loss = 0.121033 (* 1 = 0.121033 loss)
I0507 15:18:05.362330 26400 solver.cpp:228] Iteration 56800, loss = 0.0262404
I0507 15:18:05.362402 26400 solver.cpp:244]     Train net output #0: loss = 0.026242 (* 1 = 0.026242 loss)
I0507 15:18:05.362423 26400 sgd_solver.cpp:106] Iteration 56800, lr = 1e-07
I0507 15:20:15.353267 26400 solver.cpp:228] Iteration 56850, loss = -1.60933e-06
I0507 15:20:15.353426 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:20:15.353442 26400 sgd_solver.cpp:106] Iteration 56850, lr = 1e-07
I0507 15:22:25.341559 26400 solver.cpp:228] Iteration 56900, loss = 0.181165
I0507 15:22:25.341768 26400 solver.cpp:244]     Train net output #0: loss = 0.181166 (* 1 = 0.181166 loss)
I0507 15:22:25.341802 26400 sgd_solver.cpp:106] Iteration 56900, lr = 1e-07
I0507 15:24:35.188256 26400 solver.cpp:228] Iteration 56950, loss = 0.00465792
I0507 15:24:35.200799 26400 solver.cpp:244]     Train net output #0: loss = 0.00465956 (* 1 = 0.00465956 loss)
I0507 15:24:35.200834 26400 sgd_solver.cpp:106] Iteration 56950, lr = 1e-07
I0507 15:26:42.425868 26400 solver.cpp:337] Iteration 57000, Testing net (#0)
I0507 15:27:12.787336 26400 solver.cpp:404]     Test net output #0: loss = 0.115658 (* 1 = 0.115658 loss)
I0507 15:27:13.654675 26400 solver.cpp:228] Iteration 57000, loss = 0.12462
I0507 15:27:13.654741 26400 solver.cpp:244]     Train net output #0: loss = 0.124622 (* 1 = 0.124622 loss)
I0507 15:27:13.654757 26400 sgd_solver.cpp:106] Iteration 57000, lr = 1e-07
I0507 15:29:23.501116 26400 solver.cpp:228] Iteration 57050, loss = 0.00230988
I0507 15:29:23.501384 26400 solver.cpp:244]     Train net output #0: loss = 0.00231152 (* 1 = 0.00231152 loss)
I0507 15:29:23.501433 26400 sgd_solver.cpp:106] Iteration 57050, lr = 1e-07
I0507 15:31:33.129524 26400 solver.cpp:228] Iteration 57100, loss = -1.61678e-06
I0507 15:31:33.129739 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:31:33.129786 26400 sgd_solver.cpp:106] Iteration 57100, lr = 1e-07
I0507 15:33:42.834117 26400 solver.cpp:228] Iteration 57150, loss = -1.63913e-06
I0507 15:33:42.834394 26400 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0507 15:33:42.834436 26400 sgd_solver.cpp:106] Iteration 57150, lr = 1e-07
I0507 15:35:49.962963 26400 solver.cpp:337] Iteration 57200, Testing net (#0)
I0507 15:36:20.268146 26400 solver.cpp:404]     Test net output #0: loss = 0.123201 (* 1 = 0.123201 loss)
I0507 15:36:21.135767 26400 solver.cpp:228] Iteration 57200, loss = 0.0327789
I0507 15:36:21.135835 26400 solver.cpp:244]     Train net output #0: loss = 0.0327806 (* 1 = 0.0327806 loss)
I0507 15:36:21.135851 26400 sgd_solver.cpp:106] Iteration 57200, lr = 1e-07
