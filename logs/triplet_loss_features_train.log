I0521 14:24:33.727308 15763 caffe.cpp:270] Use GPU with device ID 7
I0521 14:24:33.983537 15763 caffe.cpp:274] GPU device name: TITAN X (Pascal)
I0521 14:24:35.368366 15763 net.cpp:58] Initializing net from parameters: 
name: "C3D-Three-Streams-Deploy"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  transform_param {
    mirror: true
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/data/leo-data/Synthetic/LMDB/Triplets/train"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn"
  type: "Python"
  bottom: "fc7"
  top: "fc7_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "conv1a_pos"
  type: "NdConvolution"
  bottom: "positive"
  top: "conv1a_pos"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_pos"
  type: "ReLU"
  bottom: "conv1a_pos"
  top: "conv1a_pos"
}
layer {
  name: "pool1_pos"
  type: "NdPooling"
  bottom: "conv1a_pos"
  top: "pool1_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_pos"
  type: "NdConvolution"
  bottom: "pool1_pos"
  top: "conv2a_pos"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_pos"
  type: "ReLU"
  bottom: "conv2a_pos"
  top: "conv2a_pos"
}
layer {
  name: "pool2_pos"
  type: "NdPooling"
  bottom: "conv2a_pos"
  top: "pool2_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_pos"
  type: "NdConvolution"
  bottom: "pool2_pos"
  top: "conv3a_pos"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_pos"
  type: "ReLU"
  bottom: "conv3a_pos"
  top: "conv3a_pos"
}
layer {
  name: "pool3_pos"
  type: "NdPooling"
  bottom: "conv3a_pos"
  top: "pool3_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_pos"
  type: "NdConvolution"
  bottom: "pool3_pos"
  top: "conv4a_pos"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_pos"
  type: "ReLU"
  bottom: "conv4a_pos"
  top: "conv4a_pos"
}
layer {
  name: "pool4_pos"
  type: "NdPooling"
  bottom: "conv4a_pos"
  top: "pool4_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_pos"
  type: "NdConvolution"
  bottom: "pool4_pos"
  top: "conv5a_pos"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_pos"
  type: "ReLU"
  bottom: "conv5a_pos"
  top: "conv5a_pos"
}
layer {
  name: "pool5_pos"
  type: "NdPooling"
  bottom: "conv5a_pos"
  top: "pool5_pos"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_pos"
  type: "InnerProduct"
  bottom: "pool5_pos"
  top: "fc6_pos"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_pos"
  type: "ReLU"
  bottom: "fc6_pos"
  top: "fc6_pos"
}
layer {
  name: "drop6_pos"
  type: "Dropout"
  bottom: "fc6_pos"
  top: "fc6_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_pos"
  type: "InnerProduct"
  bottom: "fc6_pos"
  top: "fc7_pos"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_pos"
  type: "ReLU"
  bottom: "fc7_pos"
  top: "fc7_pos"
}
layer {
  name: "drop7_pos"
  type: "Dropout"
  bottom: "fc7_pos"
  top: "fc7_pos"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn_pos"
  type: "Python"
  bottom: "fc7_pos"
  top: "fc7_pos_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "conv1a_neg"
  type: "NdConvolution"
  bottom: "negative"
  top: "conv1a_neg"
  param {
    name: "conv1a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a_neg"
  type: "ReLU"
  bottom: "conv1a_neg"
  top: "conv1a_neg"
}
layer {
  name: "pool1_neg"
  type: "NdPooling"
  bottom: "conv1a_neg"
  top: "pool1_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a_neg"
  type: "NdConvolution"
  bottom: "pool1_neg"
  top: "conv2a_neg"
  param {
    name: "conv2a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a_neg"
  type: "ReLU"
  bottom: "conv2a_neg"
  top: "conv2a_neg"
}
layer {
  name: "pool2_neg"
  type: "NdPooling"
  bottom: "conv2a_neg"
  top: "pool2_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a_neg"
  type: "NdConvolution"
  bottom: "pool2_neg"
  top: "conv3a_neg"
  param {
    name: "conv3a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a_neg"
  type: "ReLU"
  bottom: "conv3a_neg"
  top: "conv3a_neg"
}
layer {
  name: "pool3_neg"
  type: "NdPooling"
  bottom: "conv3a_neg"
  top: "pool3_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a_neg"
  type: "NdConvolution"
  bottom: "pool3_neg"
  top: "conv4a_neg"
  param {
    name: "conv4a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a_neg"
  type: "ReLU"
  bottom: "conv4a_neg"
  top: "conv4a_neg"
}
layer {
  name: "pool4_neg"
  type: "NdPooling"
  bottom: "conv4a_neg"
  top: "pool4_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a_neg"
  type: "NdConvolution"
  bottom: "pool4_neg"
  top: "conv5a_neg"
  param {
    name: "conv5a_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5a_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a_neg"
  type: "ReLU"
  bottom: "conv5a_neg"
  top: "conv5a_neg"
}
layer {
  name: "pool5_neg"
  type: "NdPooling"
  bottom: "conv5a_neg"
  top: "pool5_neg"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6_neg"
  type: "InnerProduct"
  bottom: "pool5_neg"
  top: "fc6_neg"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6_neg"
  type: "ReLU"
  bottom: "fc6_neg"
  top: "fc6_neg"
}
layer {
  name: "drop6_neg"
  type: "Dropout"
  bottom: "fc6_neg"
  top: "fc6_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_neg"
  type: "InnerProduct"
  bottom: "fc6_neg"
  top: "fc7_neg"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7_neg"
  type: "ReLU"
  bottom: "fc7_neg"
  top: "fc7_neg"
}
layer {
  name: "drop7_neg"
  type: "Dropout"
  bottom: "fc7_neg"
  top: "fc7_neg"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "mvn_neg"
  type: "Python"
  bottom: "fc7_neg"
  top: "fc7_neg_norm"
  python_param {
    module: "mvn"
    layer: "MVNLayer"
  }
}
layer {
  name: "save"
  type: "Python"
  bottom: "fc7_norm"
  bottom: "fc7_pos_norm"
  bottom: "fc7_neg_norm"
  python_param {
    module: "save_features"
    layer: "SaveFeaturesLayer"
    param_str: "{\"n_samples\":\"35000\", \"filename\":\"../../features/features_triplet_loss_mvn_train.npz\"}"
  }
}
I0521 14:24:35.368891 15763 layer_factory.hpp:77] Creating layer data
I0521 14:24:35.369844 15763 net.cpp:100] Creating Layer data
I0521 14:24:35.369868 15763 net.cpp:408] data -> triplet
I0521 14:24:35.372457 15779 db_lmdb.cpp:35] Opened lmdb /data/leo-data/Synthetic/LMDB/Triplets/train
I0521 14:24:35.419466 15763 data_layer.cpp:41] output data size: 10,144,112,112
I0521 14:24:35.846151 15763 net.cpp:150] Setting up data
I0521 14:24:35.846233 15763 net.cpp:157] Top shape: 10 144 112 112 (18063360)
I0521 14:24:35.846245 15763 net.cpp:165] Memory required for data: 72253440
I0521 14:24:35.846261 15763 layer_factory.hpp:77] Creating layer slicer
I0521 14:24:35.846287 15763 net.cpp:100] Creating Layer slicer
I0521 14:24:35.846299 15763 net.cpp:434] slicer <- triplet
I0521 14:24:35.846319 15763 net.cpp:408] slicer -> anchor_stacked
I0521 14:24:35.846340 15763 net.cpp:408] slicer -> positive_stacked
I0521 14:24:35.846354 15763 net.cpp:408] slicer -> negative_stacked
I0521 14:24:35.846571 15763 net.cpp:150] Setting up slicer
I0521 14:24:35.846590 15763 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0521 14:24:35.846597 15763 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0521 14:24:35.846604 15763 net.cpp:157] Top shape: 10 48 112 112 (6021120)
I0521 14:24:35.846611 15763 net.cpp:165] Memory required for data: 144506880
I0521 14:24:35.846616 15763 layer_factory.hpp:77] Creating layer reshape_anchor
I0521 14:24:35.846650 15763 net.cpp:100] Creating Layer reshape_anchor
I0521 14:24:35.846659 15763 net.cpp:434] reshape_anchor <- anchor_stacked
I0521 14:24:35.846679 15763 net.cpp:408] reshape_anchor -> anchor
I0521 14:24:35.846740 15763 net.cpp:150] Setting up reshape_anchor
I0521 14:24:35.846752 15763 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0521 14:24:35.846757 15763 net.cpp:165] Memory required for data: 168591360
I0521 14:24:35.846763 15763 layer_factory.hpp:77] Creating layer reshape_positive
I0521 14:24:35.846773 15763 net.cpp:100] Creating Layer reshape_positive
I0521 14:24:35.846778 15763 net.cpp:434] reshape_positive <- positive_stacked
I0521 14:24:35.846791 15763 net.cpp:408] reshape_positive -> positive
I0521 14:24:35.846830 15763 net.cpp:150] Setting up reshape_positive
I0521 14:24:35.846842 15763 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0521 14:24:35.846882 15763 net.cpp:165] Memory required for data: 192675840
I0521 14:24:35.846889 15763 layer_factory.hpp:77] Creating layer reshape_negative
I0521 14:24:35.846940 15763 net.cpp:100] Creating Layer reshape_negative
I0521 14:24:35.846947 15763 net.cpp:434] reshape_negative <- negative_stacked
I0521 14:24:35.846961 15763 net.cpp:408] reshape_negative -> negative
I0521 14:24:35.847005 15763 net.cpp:150] Setting up reshape_negative
I0521 14:24:35.847023 15763 net.cpp:157] Top shape: 10 3 16 112 112 (6021120)
I0521 14:24:35.847029 15763 net.cpp:165] Memory required for data: 216760320
I0521 14:24:35.847035 15763 layer_factory.hpp:77] Creating layer conv1a
I0521 14:24:35.847061 15763 net.cpp:100] Creating Layer conv1a
I0521 14:24:35.847069 15763 net.cpp:434] conv1a <- anchor
I0521 14:24:35.847084 15763 net.cpp:408] conv1a -> conv1a
I0521 14:24:37.355268 15763 net.cpp:150] Setting up conv1a
I0521 14:24:37.355304 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:37.355309 15763 net.cpp:165] Memory required for data: 730562560
I0521 14:24:37.355326 15763 layer_factory.hpp:77] Creating layer relu1a
I0521 14:24:37.355339 15763 net.cpp:100] Creating Layer relu1a
I0521 14:24:37.355343 15763 net.cpp:434] relu1a <- conv1a
I0521 14:24:37.355352 15763 net.cpp:395] relu1a -> conv1a (in-place)
I0521 14:24:37.355597 15763 net.cpp:150] Setting up relu1a
I0521 14:24:37.355612 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:37.355623 15763 net.cpp:165] Memory required for data: 1244364800
I0521 14:24:37.355629 15763 layer_factory.hpp:77] Creating layer pool1
I0521 14:24:37.355643 15763 net.cpp:100] Creating Layer pool1
I0521 14:24:37.355651 15763 net.cpp:434] pool1 <- conv1a
I0521 14:24:37.355660 15763 net.cpp:408] pool1 -> pool1
I0521 14:24:37.356812 15763 net.cpp:150] Setting up pool1
I0521 14:24:37.356827 15763 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0521 14:24:37.356835 15763 net.cpp:165] Memory required for data: 1372815360
I0521 14:24:37.356842 15763 layer_factory.hpp:77] Creating layer conv2a
I0521 14:24:37.356860 15763 net.cpp:100] Creating Layer conv2a
I0521 14:24:37.356868 15763 net.cpp:434] conv2a <- pool1
I0521 14:24:37.356880 15763 net.cpp:408] conv2a -> conv2a
I0521 14:24:37.366673 15763 net.cpp:150] Setting up conv2a
I0521 14:24:37.366689 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:37.366696 15763 net.cpp:165] Memory required for data: 1629716480
I0521 14:24:37.366709 15763 layer_factory.hpp:77] Creating layer relu2a
I0521 14:24:37.366720 15763 net.cpp:100] Creating Layer relu2a
I0521 14:24:37.366729 15763 net.cpp:434] relu2a <- conv2a
I0521 14:24:37.366737 15763 net.cpp:395] relu2a -> conv2a (in-place)
I0521 14:24:37.366957 15763 net.cpp:150] Setting up relu2a
I0521 14:24:37.366971 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:37.366976 15763 net.cpp:165] Memory required for data: 1886617600
I0521 14:24:37.366983 15763 layer_factory.hpp:77] Creating layer pool2
I0521 14:24:37.366997 15763 net.cpp:100] Creating Layer pool2
I0521 14:24:37.367004 15763 net.cpp:434] pool2 <- conv2a
I0521 14:24:37.367014 15763 net.cpp:408] pool2 -> pool2
I0521 14:24:37.367256 15763 net.cpp:150] Setting up pool2
I0521 14:24:37.367269 15763 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0521 14:24:37.367274 15763 net.cpp:165] Memory required for data: 1918730240
I0521 14:24:37.367280 15763 layer_factory.hpp:77] Creating layer conv3a
I0521 14:24:37.367295 15763 net.cpp:100] Creating Layer conv3a
I0521 14:24:37.367302 15763 net.cpp:434] conv3a <- pool2
I0521 14:24:37.367314 15763 net.cpp:408] conv3a -> conv3a
I0521 14:24:37.399086 15763 net.cpp:150] Setting up conv3a
I0521 14:24:37.399118 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:37.399122 15763 net.cpp:165] Memory required for data: 1982955520
I0521 14:24:37.399137 15763 layer_factory.hpp:77] Creating layer relu3a
I0521 14:24:37.399150 15763 net.cpp:100] Creating Layer relu3a
I0521 14:24:37.399157 15763 net.cpp:434] relu3a <- conv3a
I0521 14:24:37.399163 15763 net.cpp:395] relu3a -> conv3a (in-place)
I0521 14:24:37.399369 15763 net.cpp:150] Setting up relu3a
I0521 14:24:37.399380 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:37.399384 15763 net.cpp:165] Memory required for data: 2047180800
I0521 14:24:37.399387 15763 layer_factory.hpp:77] Creating layer pool3
I0521 14:24:37.399399 15763 net.cpp:100] Creating Layer pool3
I0521 14:24:37.399404 15763 net.cpp:434] pool3 <- conv3a
I0521 14:24:37.399410 15763 net.cpp:408] pool3 -> pool3
I0521 14:24:37.399626 15763 net.cpp:150] Setting up pool3
I0521 14:24:37.399636 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:37.399641 15763 net.cpp:165] Memory required for data: 2055208960
I0521 14:24:37.399643 15763 layer_factory.hpp:77] Creating layer conv4a
I0521 14:24:37.399655 15763 net.cpp:100] Creating Layer conv4a
I0521 14:24:37.399660 15763 net.cpp:434] conv4a <- pool3
I0521 14:24:37.399667 15763 net.cpp:408] conv4a -> conv4a
I0521 14:24:37.463068 15763 net.cpp:150] Setting up conv4a
I0521 14:24:37.463090 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:37.463094 15763 net.cpp:165] Memory required for data: 2063237120
I0521 14:24:37.463102 15763 layer_factory.hpp:77] Creating layer relu4a
I0521 14:24:37.463112 15763 net.cpp:100] Creating Layer relu4a
I0521 14:24:37.463117 15763 net.cpp:434] relu4a <- conv4a
I0521 14:24:37.463122 15763 net.cpp:395] relu4a -> conv4a (in-place)
I0521 14:24:37.464200 15763 net.cpp:150] Setting up relu4a
I0521 14:24:37.464213 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:37.464216 15763 net.cpp:165] Memory required for data: 2071265280
I0521 14:24:37.464221 15763 layer_factory.hpp:77] Creating layer pool4
I0521 14:24:37.464233 15763 net.cpp:100] Creating Layer pool4
I0521 14:24:37.464237 15763 net.cpp:434] pool4 <- conv4a
I0521 14:24:37.464246 15763 net.cpp:408] pool4 -> pool4
I0521 14:24:37.464470 15763 net.cpp:150] Setting up pool4
I0521 14:24:37.464481 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:37.464484 15763 net.cpp:165] Memory required for data: 2072268800
I0521 14:24:37.464489 15763 layer_factory.hpp:77] Creating layer conv5a
I0521 14:24:37.464501 15763 net.cpp:100] Creating Layer conv5a
I0521 14:24:37.464506 15763 net.cpp:434] conv5a <- pool4
I0521 14:24:37.464514 15763 net.cpp:408] conv5a -> conv5a
I0521 14:24:37.518422 15763 net.cpp:150] Setting up conv5a
I0521 14:24:37.518452 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:37.518457 15763 net.cpp:165] Memory required for data: 2073272320
I0521 14:24:37.518472 15763 layer_factory.hpp:77] Creating layer relu5a
I0521 14:24:37.518484 15763 net.cpp:100] Creating Layer relu5a
I0521 14:24:37.518491 15763 net.cpp:434] relu5a <- conv5a
I0521 14:24:37.518498 15763 net.cpp:395] relu5a -> conv5a (in-place)
I0521 14:24:37.518663 15763 net.cpp:150] Setting up relu5a
I0521 14:24:37.518672 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:37.518677 15763 net.cpp:165] Memory required for data: 2074275840
I0521 14:24:37.518681 15763 layer_factory.hpp:77] Creating layer pool5
I0521 14:24:37.518689 15763 net.cpp:100] Creating Layer pool5
I0521 14:24:37.518694 15763 net.cpp:434] pool5 <- conv5a
I0521 14:24:37.518699 15763 net.cpp:408] pool5 -> pool5
I0521 14:24:37.518895 15763 net.cpp:150] Setting up pool5
I0521 14:24:37.518929 15763 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0521 14:24:37.518934 15763 net.cpp:165] Memory required for data: 2074439680
I0521 14:24:37.518936 15763 layer_factory.hpp:77] Creating layer fc6
I0521 14:24:37.518955 15763 net.cpp:100] Creating Layer fc6
I0521 14:24:37.518959 15763 net.cpp:434] fc6 <- pool5
I0521 14:24:37.518968 15763 net.cpp:408] fc6 -> fc6
I0521 14:24:37.845890 15763 net.cpp:150] Setting up fc6
I0521 14:24:37.845930 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:37.845934 15763 net.cpp:165] Memory required for data: 2074521600
I0521 14:24:37.845953 15763 layer_factory.hpp:77] Creating layer relu6
I0521 14:24:37.845966 15763 net.cpp:100] Creating Layer relu6
I0521 14:24:37.845971 15763 net.cpp:434] relu6 <- fc6
I0521 14:24:37.846001 15763 net.cpp:395] relu6 -> fc6 (in-place)
I0521 14:24:37.848532 15763 net.cpp:150] Setting up relu6
I0521 14:24:37.848572 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:37.848579 15763 net.cpp:165] Memory required for data: 2074603520
I0521 14:24:37.848588 15763 layer_factory.hpp:77] Creating layer drop6
I0521 14:24:37.848609 15763 net.cpp:100] Creating Layer drop6
I0521 14:24:37.848623 15763 net.cpp:434] drop6 <- fc6
I0521 14:24:37.848645 15763 net.cpp:395] drop6 -> fc6 (in-place)
I0521 14:24:37.848721 15763 net.cpp:150] Setting up drop6
I0521 14:24:37.848734 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:37.848744 15763 net.cpp:165] Memory required for data: 2074685440
I0521 14:24:37.848754 15763 layer_factory.hpp:77] Creating layer fc7
I0521 14:24:37.848778 15763 net.cpp:100] Creating Layer fc7
I0521 14:24:37.848783 15763 net.cpp:434] fc7 <- fc6
I0521 14:24:37.848796 15763 net.cpp:408] fc7 -> fc7
I0521 14:24:38.054977 15763 net.cpp:150] Setting up fc7
I0521 14:24:38.055027 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:38.055034 15763 net.cpp:165] Memory required for data: 2074767360
I0521 14:24:38.055054 15763 layer_factory.hpp:77] Creating layer relu7
I0521 14:24:38.055074 15763 net.cpp:100] Creating Layer relu7
I0521 14:24:38.055088 15763 net.cpp:434] relu7 <- fc7
I0521 14:24:38.055101 15763 net.cpp:395] relu7 -> fc7 (in-place)
I0521 14:24:38.055418 15763 net.cpp:150] Setting up relu7
I0521 14:24:38.055434 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:38.055445 15763 net.cpp:165] Memory required for data: 2074849280
I0521 14:24:38.055454 15763 layer_factory.hpp:77] Creating layer drop7
I0521 14:24:38.055469 15763 net.cpp:100] Creating Layer drop7
I0521 14:24:38.055479 15763 net.cpp:434] drop7 <- fc7
I0521 14:24:38.055497 15763 net.cpp:395] drop7 -> fc7 (in-place)
I0521 14:24:38.055541 15763 net.cpp:150] Setting up drop7
I0521 14:24:38.055552 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:38.055557 15763 net.cpp:165] Memory required for data: 2074931200
I0521 14:24:38.055565 15763 layer_factory.hpp:77] Creating layer mvn
I0521 14:24:39.139570 15763 net.cpp:100] Creating Layer mvn
I0521 14:24:39.139600 15763 net.cpp:434] mvn <- fc7
I0521 14:24:39.139611 15763 net.cpp:408] mvn -> fc7_norm
I0521 14:24:40.295397 15763 net.cpp:150] Setting up mvn
I0521 14:24:40.295439 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.295447 15763 net.cpp:165] Memory required for data: 2075013120
I0521 14:24:40.295461 15763 layer_factory.hpp:77] Creating layer conv1a_pos
I0521 14:24:40.295493 15763 net.cpp:100] Creating Layer conv1a_pos
I0521 14:24:40.295514 15763 net.cpp:434] conv1a_pos <- positive
I0521 14:24:40.295536 15763 net.cpp:408] conv1a_pos -> conv1a_pos
I0521 14:24:40.303020 15763 net.cpp:150] Setting up conv1a_pos
I0521 14:24:40.303064 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:40.303072 15763 net.cpp:165] Memory required for data: 2588815360
I0521 14:24:40.303086 15763 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0521 14:24:40.303098 15763 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0521 14:24:40.303107 15763 layer_factory.hpp:77] Creating layer relu1a_pos
I0521 14:24:40.303134 15763 net.cpp:100] Creating Layer relu1a_pos
I0521 14:24:40.303145 15763 net.cpp:434] relu1a_pos <- conv1a_pos
I0521 14:24:40.303158 15763 net.cpp:395] relu1a_pos -> conv1a_pos (in-place)
I0521 14:24:40.303676 15763 net.cpp:150] Setting up relu1a_pos
I0521 14:24:40.303695 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:40.303704 15763 net.cpp:165] Memory required for data: 3102617600
I0521 14:24:40.303711 15763 layer_factory.hpp:77] Creating layer pool1_pos
I0521 14:24:40.303741 15763 net.cpp:100] Creating Layer pool1_pos
I0521 14:24:40.303751 15763 net.cpp:434] pool1_pos <- conv1a_pos
I0521 14:24:40.303764 15763 net.cpp:408] pool1_pos -> pool1_pos
I0521 14:24:40.306017 15763 net.cpp:150] Setting up pool1_pos
I0521 14:24:40.306082 15763 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0521 14:24:40.306090 15763 net.cpp:165] Memory required for data: 3231068160
I0521 14:24:40.306104 15763 layer_factory.hpp:77] Creating layer conv2a_pos
I0521 14:24:40.306129 15763 net.cpp:100] Creating Layer conv2a_pos
I0521 14:24:40.306139 15763 net.cpp:434] conv2a_pos <- pool1_pos
I0521 14:24:40.306159 15763 net.cpp:408] conv2a_pos -> conv2a_pos
I0521 14:24:40.320878 15763 net.cpp:150] Setting up conv2a_pos
I0521 14:24:40.320915 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:40.320924 15763 net.cpp:165] Memory required for data: 3487969280
I0521 14:24:40.320941 15763 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0521 14:24:40.320952 15763 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0521 14:24:40.320960 15763 layer_factory.hpp:77] Creating layer relu2a_pos
I0521 14:24:40.320974 15763 net.cpp:100] Creating Layer relu2a_pos
I0521 14:24:40.320986 15763 net.cpp:434] relu2a_pos <- conv2a_pos
I0521 14:24:40.320997 15763 net.cpp:395] relu2a_pos -> conv2a_pos (in-place)
I0521 14:24:40.322896 15763 net.cpp:150] Setting up relu2a_pos
I0521 14:24:40.322935 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:40.322943 15763 net.cpp:165] Memory required for data: 3744870400
I0521 14:24:40.322950 15763 layer_factory.hpp:77] Creating layer pool2_pos
I0521 14:24:40.322984 15763 net.cpp:100] Creating Layer pool2_pos
I0521 14:24:40.322993 15763 net.cpp:434] pool2_pos <- conv2a_pos
I0521 14:24:40.323006 15763 net.cpp:408] pool2_pos -> pool2_pos
I0521 14:24:40.323426 15763 net.cpp:150] Setting up pool2_pos
I0521 14:24:40.323442 15763 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0521 14:24:40.323448 15763 net.cpp:165] Memory required for data: 3776983040
I0521 14:24:40.323458 15763 layer_factory.hpp:77] Creating layer conv3a_pos
I0521 14:24:40.323484 15763 net.cpp:100] Creating Layer conv3a_pos
I0521 14:24:40.323493 15763 net.cpp:434] conv3a_pos <- pool2_pos
I0521 14:24:40.323505 15763 net.cpp:408] conv3a_pos -> conv3a_pos
I0521 14:24:40.372876 15763 net.cpp:150] Setting up conv3a_pos
I0521 14:24:40.372916 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:40.372922 15763 net.cpp:165] Memory required for data: 3841208320
I0521 14:24:40.372933 15763 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0521 14:24:40.372941 15763 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0521 14:24:40.372947 15763 layer_factory.hpp:77] Creating layer relu3a_pos
I0521 14:24:40.372959 15763 net.cpp:100] Creating Layer relu3a_pos
I0521 14:24:40.372966 15763 net.cpp:434] relu3a_pos <- conv3a_pos
I0521 14:24:40.372974 15763 net.cpp:395] relu3a_pos -> conv3a_pos (in-place)
I0521 14:24:40.373247 15763 net.cpp:150] Setting up relu3a_pos
I0521 14:24:40.373260 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:40.373265 15763 net.cpp:165] Memory required for data: 3905433600
I0521 14:24:40.373270 15763 layer_factory.hpp:77] Creating layer pool3_pos
I0521 14:24:40.373286 15763 net.cpp:100] Creating Layer pool3_pos
I0521 14:24:40.373293 15763 net.cpp:434] pool3_pos <- conv3a_pos
I0521 14:24:40.373304 15763 net.cpp:408] pool3_pos -> pool3_pos
I0521 14:24:40.373625 15763 net.cpp:150] Setting up pool3_pos
I0521 14:24:40.373639 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:40.373643 15763 net.cpp:165] Memory required for data: 3913461760
I0521 14:24:40.373647 15763 layer_factory.hpp:77] Creating layer conv4a_pos
I0521 14:24:40.373668 15763 net.cpp:100] Creating Layer conv4a_pos
I0521 14:24:40.373678 15763 net.cpp:434] conv4a_pos <- pool3_pos
I0521 14:24:40.373692 15763 net.cpp:408] conv4a_pos -> conv4a_pos
I0521 14:24:40.449522 15763 net.cpp:150] Setting up conv4a_pos
I0521 14:24:40.449554 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:40.449559 15763 net.cpp:165] Memory required for data: 3921489920
I0521 14:24:40.449566 15763 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0521 14:24:40.449594 15763 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0521 14:24:40.449600 15763 layer_factory.hpp:77] Creating layer relu4a_pos
I0521 14:24:40.449621 15763 net.cpp:100] Creating Layer relu4a_pos
I0521 14:24:40.449630 15763 net.cpp:434] relu4a_pos <- conv4a_pos
I0521 14:24:40.449636 15763 net.cpp:395] relu4a_pos -> conv4a_pos (in-place)
I0521 14:24:40.451099 15763 net.cpp:150] Setting up relu4a_pos
I0521 14:24:40.451114 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:40.451118 15763 net.cpp:165] Memory required for data: 3929518080
I0521 14:24:40.451122 15763 layer_factory.hpp:77] Creating layer pool4_pos
I0521 14:24:40.451131 15763 net.cpp:100] Creating Layer pool4_pos
I0521 14:24:40.451134 15763 net.cpp:434] pool4_pos <- conv4a_pos
I0521 14:24:40.451145 15763 net.cpp:408] pool4_pos -> pool4_pos
I0521 14:24:40.451403 15763 net.cpp:150] Setting up pool4_pos
I0521 14:24:40.451416 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:40.451419 15763 net.cpp:165] Memory required for data: 3930521600
I0521 14:24:40.451424 15763 layer_factory.hpp:77] Creating layer conv5a_pos
I0521 14:24:40.451445 15763 net.cpp:100] Creating Layer conv5a_pos
I0521 14:24:40.451452 15763 net.cpp:434] conv5a_pos <- pool4_pos
I0521 14:24:40.451460 15763 net.cpp:408] conv5a_pos -> conv5a_pos
I0521 14:24:40.560127 15763 net.cpp:150] Setting up conv5a_pos
I0521 14:24:40.560159 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:40.560166 15763 net.cpp:165] Memory required for data: 3931525120
I0521 14:24:40.560174 15763 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0521 14:24:40.560184 15763 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0521 14:24:40.560189 15763 layer_factory.hpp:77] Creating layer relu5a_pos
I0521 14:24:40.560205 15763 net.cpp:100] Creating Layer relu5a_pos
I0521 14:24:40.560212 15763 net.cpp:434] relu5a_pos <- conv5a_pos
I0521 14:24:40.560223 15763 net.cpp:395] relu5a_pos -> conv5a_pos (in-place)
I0521 14:24:40.560552 15763 net.cpp:150] Setting up relu5a_pos
I0521 14:24:40.560569 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:40.560573 15763 net.cpp:165] Memory required for data: 3932528640
I0521 14:24:40.560578 15763 layer_factory.hpp:77] Creating layer pool5_pos
I0521 14:24:40.560591 15763 net.cpp:100] Creating Layer pool5_pos
I0521 14:24:40.560597 15763 net.cpp:434] pool5_pos <- conv5a_pos
I0521 14:24:40.560606 15763 net.cpp:408] pool5_pos -> pool5_pos
I0521 14:24:40.560979 15763 net.cpp:150] Setting up pool5_pos
I0521 14:24:40.560994 15763 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0521 14:24:40.560999 15763 net.cpp:165] Memory required for data: 3932692480
I0521 14:24:40.561004 15763 layer_factory.hpp:77] Creating layer fc6_pos
I0521 14:24:40.561025 15763 net.cpp:100] Creating Layer fc6_pos
I0521 14:24:40.561031 15763 net.cpp:434] fc6_pos <- pool5_pos
I0521 14:24:40.561043 15763 net.cpp:408] fc6_pos -> fc6_pos
I0521 14:24:40.841259 15763 net.cpp:150] Setting up fc6_pos
I0521 14:24:40.841306 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.841310 15763 net.cpp:165] Memory required for data: 3932774400
I0521 14:24:40.841325 15763 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0521 14:24:40.841332 15763 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0521 14:24:40.841347 15763 layer_factory.hpp:77] Creating layer relu6_pos
I0521 14:24:40.841359 15763 net.cpp:100] Creating Layer relu6_pos
I0521 14:24:40.841368 15763 net.cpp:434] relu6_pos <- fc6_pos
I0521 14:24:40.841374 15763 net.cpp:395] relu6_pos -> fc6_pos (in-place)
I0521 14:24:40.842645 15763 net.cpp:150] Setting up relu6_pos
I0521 14:24:40.842669 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.842672 15763 net.cpp:165] Memory required for data: 3932856320
I0521 14:24:40.842676 15763 layer_factory.hpp:77] Creating layer drop6_pos
I0521 14:24:40.842715 15763 net.cpp:100] Creating Layer drop6_pos
I0521 14:24:40.842720 15763 net.cpp:434] drop6_pos <- fc6_pos
I0521 14:24:40.842725 15763 net.cpp:395] drop6_pos -> fc6_pos (in-place)
I0521 14:24:40.842764 15763 net.cpp:150] Setting up drop6_pos
I0521 14:24:40.842772 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.842774 15763 net.cpp:165] Memory required for data: 3932938240
I0521 14:24:40.842777 15763 layer_factory.hpp:77] Creating layer fc7_pos
I0521 14:24:40.842792 15763 net.cpp:100] Creating Layer fc7_pos
I0521 14:24:40.842794 15763 net.cpp:434] fc7_pos <- fc6_pos
I0521 14:24:40.842799 15763 net.cpp:408] fc7_pos -> fc7_pos
I0521 14:24:40.968768 15763 net.cpp:150] Setting up fc7_pos
I0521 14:24:40.968814 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.968818 15763 net.cpp:165] Memory required for data: 3933020160
I0521 14:24:40.968825 15763 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0521 14:24:40.968832 15763 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0521 14:24:40.968837 15763 layer_factory.hpp:77] Creating layer relu7_pos
I0521 14:24:40.968857 15763 net.cpp:100] Creating Layer relu7_pos
I0521 14:24:40.968863 15763 net.cpp:434] relu7_pos <- fc7_pos
I0521 14:24:40.968868 15763 net.cpp:395] relu7_pos -> fc7_pos (in-place)
I0521 14:24:40.969152 15763 net.cpp:150] Setting up relu7_pos
I0521 14:24:40.969173 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.969177 15763 net.cpp:165] Memory required for data: 3933102080
I0521 14:24:40.969194 15763 layer_factory.hpp:77] Creating layer drop7_pos
I0521 14:24:40.969203 15763 net.cpp:100] Creating Layer drop7_pos
I0521 14:24:40.969209 15763 net.cpp:434] drop7_pos <- fc7_pos
I0521 14:24:40.969216 15763 net.cpp:395] drop7_pos -> fc7_pos (in-place)
I0521 14:24:40.969246 15763 net.cpp:150] Setting up drop7_pos
I0521 14:24:40.969252 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.969255 15763 net.cpp:165] Memory required for data: 3933184000
I0521 14:24:40.969259 15763 layer_factory.hpp:77] Creating layer mvn_pos
I0521 14:24:40.969362 15763 net.cpp:100] Creating Layer mvn_pos
I0521 14:24:40.969368 15763 net.cpp:434] mvn_pos <- fc7_pos
I0521 14:24:40.969373 15763 net.cpp:408] mvn_pos -> fc7_pos_norm
I0521 14:24:40.969604 15763 net.cpp:150] Setting up mvn_pos
I0521 14:24:40.969615 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:40.969619 15763 net.cpp:165] Memory required for data: 3933265920
I0521 14:24:40.969622 15763 layer_factory.hpp:77] Creating layer conv1a_neg
I0521 14:24:40.969636 15763 net.cpp:100] Creating Layer conv1a_neg
I0521 14:24:40.969640 15763 net.cpp:434] conv1a_neg <- negative
I0521 14:24:40.969648 15763 net.cpp:408] conv1a_neg -> conv1a_neg
I0521 14:24:40.973101 15763 net.cpp:150] Setting up conv1a_neg
I0521 14:24:40.973115 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:40.973129 15763 net.cpp:165] Memory required for data: 4447068160
I0521 14:24:40.973136 15763 net.cpp:493] Sharing parameters 'conv1a_w' owned by layer 'conv1a', param index 0
I0521 14:24:40.973141 15763 net.cpp:493] Sharing parameters 'conv1a_b' owned by layer 'conv1a', param index 1
I0521 14:24:40.973147 15763 layer_factory.hpp:77] Creating layer relu1a_neg
I0521 14:24:40.973155 15763 net.cpp:100] Creating Layer relu1a_neg
I0521 14:24:40.973157 15763 net.cpp:434] relu1a_neg <- conv1a_neg
I0521 14:24:40.973173 15763 net.cpp:395] relu1a_neg -> conv1a_neg (in-place)
I0521 14:24:40.973366 15763 net.cpp:150] Setting up relu1a_neg
I0521 14:24:40.973376 15763 net.cpp:157] Top shape: 10 64 16 112 112 (128450560)
I0521 14:24:40.973379 15763 net.cpp:165] Memory required for data: 4960870400
I0521 14:24:40.973383 15763 layer_factory.hpp:77] Creating layer pool1_neg
I0521 14:24:40.973392 15763 net.cpp:100] Creating Layer pool1_neg
I0521 14:24:40.973400 15763 net.cpp:434] pool1_neg <- conv1a_neg
I0521 14:24:40.973407 15763 net.cpp:408] pool1_neg -> pool1_neg
I0521 14:24:40.973628 15763 net.cpp:150] Setting up pool1_neg
I0521 14:24:40.973637 15763 net.cpp:157] Top shape: 10 64 16 56 56 (32112640)
I0521 14:24:40.973656 15763 net.cpp:165] Memory required for data: 5089320960
I0521 14:24:40.973659 15763 layer_factory.hpp:77] Creating layer conv2a_neg
I0521 14:24:40.973676 15763 net.cpp:100] Creating Layer conv2a_neg
I0521 14:24:40.973681 15763 net.cpp:434] conv2a_neg <- pool1_neg
I0521 14:24:40.973690 15763 net.cpp:408] conv2a_neg -> conv2a_neg
I0521 14:24:40.982364 15763 net.cpp:150] Setting up conv2a_neg
I0521 14:24:40.982378 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:40.982393 15763 net.cpp:165] Memory required for data: 5346222080
I0521 14:24:40.982396 15763 net.cpp:493] Sharing parameters 'conv2a_w' owned by layer 'conv2a', param index 0
I0521 14:24:40.982400 15763 net.cpp:493] Sharing parameters 'conv2a_b' owned by layer 'conv2a', param index 1
I0521 14:24:40.982403 15763 layer_factory.hpp:77] Creating layer relu2a_neg
I0521 14:24:40.982412 15763 net.cpp:100] Creating Layer relu2a_neg
I0521 14:24:40.982415 15763 net.cpp:434] relu2a_neg <- conv2a_neg
I0521 14:24:40.982419 15763 net.cpp:395] relu2a_neg -> conv2a_neg (in-place)
I0521 14:24:40.982609 15763 net.cpp:150] Setting up relu2a_neg
I0521 14:24:40.982620 15763 net.cpp:157] Top shape: 10 128 16 56 56 (64225280)
I0521 14:24:40.982622 15763 net.cpp:165] Memory required for data: 5603123200
I0521 14:24:40.982625 15763 layer_factory.hpp:77] Creating layer pool2_neg
I0521 14:24:40.982635 15763 net.cpp:100] Creating Layer pool2_neg
I0521 14:24:40.982638 15763 net.cpp:434] pool2_neg <- conv2a_neg
I0521 14:24:40.982645 15763 net.cpp:408] pool2_neg -> pool2_neg
I0521 14:24:40.983745 15763 net.cpp:150] Setting up pool2_neg
I0521 14:24:40.983759 15763 net.cpp:157] Top shape: 10 128 8 28 28 (8028160)
I0521 14:24:40.983762 15763 net.cpp:165] Memory required for data: 5635235840
I0521 14:24:40.983765 15763 layer_factory.hpp:77] Creating layer conv3a_neg
I0521 14:24:40.983777 15763 net.cpp:100] Creating Layer conv3a_neg
I0521 14:24:40.983780 15763 net.cpp:434] conv3a_neg <- pool2_neg
I0521 14:24:40.983788 15763 net.cpp:408] conv3a_neg -> conv3a_neg
I0521 14:24:41.012226 15763 net.cpp:150] Setting up conv3a_neg
I0521 14:24:41.012257 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:41.012261 15763 net.cpp:165] Memory required for data: 5699461120
I0521 14:24:41.012277 15763 net.cpp:493] Sharing parameters 'conv3a_w' owned by layer 'conv3a', param index 0
I0521 14:24:41.012284 15763 net.cpp:493] Sharing parameters 'conv3a_b' owned by layer 'conv3a', param index 1
I0521 14:24:41.012286 15763 layer_factory.hpp:77] Creating layer relu3a_neg
I0521 14:24:41.012293 15763 net.cpp:100] Creating Layer relu3a_neg
I0521 14:24:41.012296 15763 net.cpp:434] relu3a_neg <- conv3a_neg
I0521 14:24:41.012302 15763 net.cpp:395] relu3a_neg -> conv3a_neg (in-place)
I0521 14:24:41.012498 15763 net.cpp:150] Setting up relu3a_neg
I0521 14:24:41.012508 15763 net.cpp:157] Top shape: 10 256 8 28 28 (16056320)
I0521 14:24:41.012511 15763 net.cpp:165] Memory required for data: 5763686400
I0521 14:24:41.012517 15763 layer_factory.hpp:77] Creating layer pool3_neg
I0521 14:24:41.012526 15763 net.cpp:100] Creating Layer pool3_neg
I0521 14:24:41.012528 15763 net.cpp:434] pool3_neg <- conv3a_neg
I0521 14:24:41.012537 15763 net.cpp:408] pool3_neg -> pool3_neg
I0521 14:24:41.012763 15763 net.cpp:150] Setting up pool3_neg
I0521 14:24:41.012774 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:41.012778 15763 net.cpp:165] Memory required for data: 5771714560
I0521 14:24:41.012780 15763 layer_factory.hpp:77] Creating layer conv4a_neg
I0521 14:24:41.012791 15763 net.cpp:100] Creating Layer conv4a_neg
I0521 14:24:41.012796 15763 net.cpp:434] conv4a_neg <- pool3_neg
I0521 14:24:41.012804 15763 net.cpp:408] conv4a_neg -> conv4a_neg
I0521 14:24:41.069952 15763 net.cpp:150] Setting up conv4a_neg
I0521 14:24:41.069996 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:41.070000 15763 net.cpp:165] Memory required for data: 5779742720
I0521 14:24:41.070008 15763 net.cpp:493] Sharing parameters 'conv4a_w' owned by layer 'conv4a', param index 0
I0521 14:24:41.070044 15763 net.cpp:493] Sharing parameters 'conv4a_b' owned by layer 'conv4a', param index 1
I0521 14:24:41.070050 15763 layer_factory.hpp:77] Creating layer relu4a_neg
I0521 14:24:41.070060 15763 net.cpp:100] Creating Layer relu4a_neg
I0521 14:24:41.070066 15763 net.cpp:434] relu4a_neg <- conv4a_neg
I0521 14:24:41.070073 15763 net.cpp:395] relu4a_neg -> conv4a_neg (in-place)
I0521 14:24:41.070271 15763 net.cpp:150] Setting up relu4a_neg
I0521 14:24:41.070281 15763 net.cpp:157] Top shape: 10 256 4 14 14 (2007040)
I0521 14:24:41.070284 15763 net.cpp:165] Memory required for data: 5787770880
I0521 14:24:41.070291 15763 layer_factory.hpp:77] Creating layer pool4_neg
I0521 14:24:41.070307 15763 net.cpp:100] Creating Layer pool4_neg
I0521 14:24:41.070312 15763 net.cpp:434] pool4_neg <- conv4a_neg
I0521 14:24:41.070319 15763 net.cpp:408] pool4_neg -> pool4_neg
I0521 14:24:41.071679 15763 net.cpp:150] Setting up pool4_neg
I0521 14:24:41.071704 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:41.071707 15763 net.cpp:165] Memory required for data: 5788774400
I0521 14:24:41.071712 15763 layer_factory.hpp:77] Creating layer conv5a_neg
I0521 14:24:41.071722 15763 net.cpp:100] Creating Layer conv5a_neg
I0521 14:24:41.071727 15763 net.cpp:434] conv5a_neg <- pool4_neg
I0521 14:24:41.071733 15763 net.cpp:408] conv5a_neg -> conv5a_neg
I0521 14:24:41.127058 15763 net.cpp:150] Setting up conv5a_neg
I0521 14:24:41.127094 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:41.127099 15763 net.cpp:165] Memory required for data: 5789777920
I0521 14:24:41.127105 15763 net.cpp:493] Sharing parameters 'conv5a_w' owned by layer 'conv5a', param index 0
I0521 14:24:41.127113 15763 net.cpp:493] Sharing parameters 'conv5a_b' owned by layer 'conv5a', param index 1
I0521 14:24:41.127117 15763 layer_factory.hpp:77] Creating layer relu5a_neg
I0521 14:24:41.127130 15763 net.cpp:100] Creating Layer relu5a_neg
I0521 14:24:41.127135 15763 net.cpp:434] relu5a_neg <- conv5a_neg
I0521 14:24:41.127140 15763 net.cpp:395] relu5a_neg -> conv5a_neg (in-place)
I0521 14:24:41.128499 15763 net.cpp:150] Setting up relu5a_neg
I0521 14:24:41.128511 15763 net.cpp:157] Top shape: 10 256 2 7 7 (250880)
I0521 14:24:41.128532 15763 net.cpp:165] Memory required for data: 5790781440
I0521 14:24:41.128538 15763 layer_factory.hpp:77] Creating layer pool5_neg
I0521 14:24:41.128549 15763 net.cpp:100] Creating Layer pool5_neg
I0521 14:24:41.128552 15763 net.cpp:434] pool5_neg <- conv5a_neg
I0521 14:24:41.128571 15763 net.cpp:408] pool5_neg -> pool5_neg
I0521 14:24:41.128820 15763 net.cpp:150] Setting up pool5_neg
I0521 14:24:41.128831 15763 net.cpp:157] Top shape: 10 256 1 4 4 (40960)
I0521 14:24:41.128834 15763 net.cpp:165] Memory required for data: 5790945280
I0521 14:24:41.128837 15763 layer_factory.hpp:77] Creating layer fc6_neg
I0521 14:24:41.128867 15763 net.cpp:100] Creating Layer fc6_neg
I0521 14:24:41.128873 15763 net.cpp:434] fc6_neg <- pool5_neg
I0521 14:24:41.128882 15763 net.cpp:408] fc6_neg -> fc6_neg
I0521 14:24:41.434732 15763 net.cpp:150] Setting up fc6_neg
I0521 14:24:41.434772 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.434777 15763 net.cpp:165] Memory required for data: 5791027200
I0521 14:24:41.434785 15763 net.cpp:493] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0521 14:24:41.434792 15763 net.cpp:493] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0521 14:24:41.434797 15763 layer_factory.hpp:77] Creating layer relu6_neg
I0521 14:24:41.434806 15763 net.cpp:100] Creating Layer relu6_neg
I0521 14:24:41.434818 15763 net.cpp:434] relu6_neg <- fc6_neg
I0521 14:24:41.434828 15763 net.cpp:395] relu6_neg -> fc6_neg (in-place)
I0521 14:24:41.435125 15763 net.cpp:150] Setting up relu6_neg
I0521 14:24:41.435143 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.435148 15763 net.cpp:165] Memory required for data: 5791109120
I0521 14:24:41.435150 15763 layer_factory.hpp:77] Creating layer drop6_neg
I0521 14:24:41.435164 15763 net.cpp:100] Creating Layer drop6_neg
I0521 14:24:41.435196 15763 net.cpp:434] drop6_neg <- fc6_neg
I0521 14:24:41.435204 15763 net.cpp:395] drop6_neg -> fc6_neg (in-place)
I0521 14:24:41.435245 15763 net.cpp:150] Setting up drop6_neg
I0521 14:24:41.435252 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.435256 15763 net.cpp:165] Memory required for data: 5791191040
I0521 14:24:41.435261 15763 layer_factory.hpp:77] Creating layer fc7_neg
I0521 14:24:41.435269 15763 net.cpp:100] Creating Layer fc7_neg
I0521 14:24:41.435273 15763 net.cpp:434] fc7_neg <- fc6_neg
I0521 14:24:41.435282 15763 net.cpp:408] fc7_neg -> fc7_neg
I0521 14:24:41.575947 15763 net.cpp:150] Setting up fc7_neg
I0521 14:24:41.575987 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.575991 15763 net.cpp:165] Memory required for data: 5791272960
I0521 14:24:41.576000 15763 net.cpp:493] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0521 14:24:41.576006 15763 net.cpp:493] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0521 14:24:41.576011 15763 layer_factory.hpp:77] Creating layer relu7_neg
I0521 14:24:41.576023 15763 net.cpp:100] Creating Layer relu7_neg
I0521 14:24:41.576028 15763 net.cpp:434] relu7_neg <- fc7_neg
I0521 14:24:41.576035 15763 net.cpp:395] relu7_neg -> fc7_neg (in-place)
I0521 14:24:41.576337 15763 net.cpp:150] Setting up relu7_neg
I0521 14:24:41.576350 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.576354 15763 net.cpp:165] Memory required for data: 5791354880
I0521 14:24:41.576359 15763 layer_factory.hpp:77] Creating layer drop7_neg
I0521 14:24:41.576365 15763 net.cpp:100] Creating Layer drop7_neg
I0521 14:24:41.576370 15763 net.cpp:434] drop7_neg <- fc7_neg
I0521 14:24:41.576375 15763 net.cpp:395] drop7_neg -> fc7_neg (in-place)
I0521 14:24:41.576411 15763 net.cpp:150] Setting up drop7_neg
I0521 14:24:41.576418 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.576422 15763 net.cpp:165] Memory required for data: 5791436800
I0521 14:24:41.576426 15763 layer_factory.hpp:77] Creating layer mvn_neg
I0521 14:24:41.576488 15763 net.cpp:100] Creating Layer mvn_neg
I0521 14:24:41.576495 15763 net.cpp:434] mvn_neg <- fc7_neg
I0521 14:24:41.576501 15763 net.cpp:408] mvn_neg -> fc7_neg_norm
I0521 14:24:41.576666 15763 net.cpp:150] Setting up mvn_neg
I0521 14:24:41.576678 15763 net.cpp:157] Top shape: 10 2048 (20480)
I0521 14:24:41.576684 15763 net.cpp:165] Memory required for data: 5791518720
I0521 14:24:41.576688 15763 layer_factory.hpp:77] Creating layer save
I0521 14:24:41.592916 15763 net.cpp:100] Creating Layer save
I0521 14:24:41.592932 15763 net.cpp:434] save <- fc7_norm
I0521 14:24:41.592943 15763 net.cpp:434] save <- fc7_pos_norm
I0521 14:24:41.592948 15763 net.cpp:434] save <- fc7_neg_norm
I0521 14:24:41.593086 15763 net.cpp:150] Setting up save
I0521 14:24:41.593096 15763 net.cpp:165] Memory required for data: 5791518720
I0521 14:24:41.593101 15763 net.cpp:228] save does not need backward computation.
I0521 14:24:41.593106 15763 net.cpp:228] mvn_neg does not need backward computation.
I0521 14:24:41.593109 15763 net.cpp:228] drop7_neg does not need backward computation.
I0521 14:24:41.593112 15763 net.cpp:228] relu7_neg does not need backward computation.
I0521 14:24:41.593114 15763 net.cpp:228] fc7_neg does not need backward computation.
I0521 14:24:41.593118 15763 net.cpp:228] drop6_neg does not need backward computation.
I0521 14:24:41.593122 15763 net.cpp:228] relu6_neg does not need backward computation.
I0521 14:24:41.593124 15763 net.cpp:228] fc6_neg does not need backward computation.
I0521 14:24:41.593128 15763 net.cpp:228] pool5_neg does not need backward computation.
I0521 14:24:41.593132 15763 net.cpp:228] relu5a_neg does not need backward computation.
I0521 14:24:41.593135 15763 net.cpp:228] conv5a_neg does not need backward computation.
I0521 14:24:41.593138 15763 net.cpp:228] pool4_neg does not need backward computation.
I0521 14:24:41.593142 15763 net.cpp:228] relu4a_neg does not need backward computation.
I0521 14:24:41.593145 15763 net.cpp:228] conv4a_neg does not need backward computation.
I0521 14:24:41.593165 15763 net.cpp:228] pool3_neg does not need backward computation.
I0521 14:24:41.593169 15763 net.cpp:228] relu3a_neg does not need backward computation.
I0521 14:24:41.593173 15763 net.cpp:228] conv3a_neg does not need backward computation.
I0521 14:24:41.593176 15763 net.cpp:228] pool2_neg does not need backward computation.
I0521 14:24:41.593180 15763 net.cpp:228] relu2a_neg does not need backward computation.
I0521 14:24:41.593183 15763 net.cpp:228] conv2a_neg does not need backward computation.
I0521 14:24:41.593186 15763 net.cpp:228] pool1_neg does not need backward computation.
I0521 14:24:41.593190 15763 net.cpp:228] relu1a_neg does not need backward computation.
I0521 14:24:41.593194 15763 net.cpp:228] conv1a_neg does not need backward computation.
I0521 14:24:41.593196 15763 net.cpp:228] mvn_pos does not need backward computation.
I0521 14:24:41.593200 15763 net.cpp:228] drop7_pos does not need backward computation.
I0521 14:24:41.593204 15763 net.cpp:228] relu7_pos does not need backward computation.
I0521 14:24:41.593207 15763 net.cpp:228] fc7_pos does not need backward computation.
I0521 14:24:41.593210 15763 net.cpp:228] drop6_pos does not need backward computation.
I0521 14:24:41.593214 15763 net.cpp:228] relu6_pos does not need backward computation.
I0521 14:24:41.593216 15763 net.cpp:228] fc6_pos does not need backward computation.
I0521 14:24:41.593220 15763 net.cpp:228] pool5_pos does not need backward computation.
I0521 14:24:41.593224 15763 net.cpp:228] relu5a_pos does not need backward computation.
I0521 14:24:41.593226 15763 net.cpp:228] conv5a_pos does not need backward computation.
I0521 14:24:41.593230 15763 net.cpp:228] pool4_pos does not need backward computation.
I0521 14:24:41.593233 15763 net.cpp:228] relu4a_pos does not need backward computation.
I0521 14:24:41.593237 15763 net.cpp:228] conv4a_pos does not need backward computation.
I0521 14:24:41.593240 15763 net.cpp:228] pool3_pos does not need backward computation.
I0521 14:24:41.593243 15763 net.cpp:228] relu3a_pos does not need backward computation.
I0521 14:24:41.593246 15763 net.cpp:228] conv3a_pos does not need backward computation.
I0521 14:24:41.593250 15763 net.cpp:228] pool2_pos does not need backward computation.
I0521 14:24:41.593253 15763 net.cpp:228] relu2a_pos does not need backward computation.
I0521 14:24:41.593257 15763 net.cpp:228] conv2a_pos does not need backward computation.
I0521 14:24:41.593261 15763 net.cpp:228] pool1_pos does not need backward computation.
I0521 14:24:41.593266 15763 net.cpp:228] relu1a_pos does not need backward computation.
I0521 14:24:41.593271 15763 net.cpp:228] conv1a_pos does not need backward computation.
I0521 14:24:41.593278 15763 net.cpp:228] mvn does not need backward computation.
I0521 14:24:41.593284 15763 net.cpp:228] drop7 does not need backward computation.
I0521 14:24:41.593288 15763 net.cpp:228] relu7 does not need backward computation.
I0521 14:24:41.593292 15763 net.cpp:228] fc7 does not need backward computation.
I0521 14:24:41.593296 15763 net.cpp:228] drop6 does not need backward computation.
I0521 14:24:41.593298 15763 net.cpp:228] relu6 does not need backward computation.
I0521 14:24:41.593302 15763 net.cpp:228] fc6 does not need backward computation.
I0521 14:24:41.593307 15763 net.cpp:228] pool5 does not need backward computation.
I0521 14:24:41.593310 15763 net.cpp:228] relu5a does not need backward computation.
I0521 14:24:41.593313 15763 net.cpp:228] conv5a does not need backward computation.
I0521 14:24:41.593317 15763 net.cpp:228] pool4 does not need backward computation.
I0521 14:24:41.593322 15763 net.cpp:228] relu4a does not need backward computation.
I0521 14:24:41.593324 15763 net.cpp:228] conv4a does not need backward computation.
I0521 14:24:41.593327 15763 net.cpp:228] pool3 does not need backward computation.
I0521 14:24:41.593331 15763 net.cpp:228] relu3a does not need backward computation.
I0521 14:24:41.593334 15763 net.cpp:228] conv3a does not need backward computation.
I0521 14:24:41.593345 15763 net.cpp:228] pool2 does not need backward computation.
I0521 14:24:41.593349 15763 net.cpp:228] relu2a does not need backward computation.
I0521 14:24:41.593353 15763 net.cpp:228] conv2a does not need backward computation.
I0521 14:24:41.593356 15763 net.cpp:228] pool1 does not need backward computation.
I0521 14:24:41.593359 15763 net.cpp:228] relu1a does not need backward computation.
I0521 14:24:41.593363 15763 net.cpp:228] conv1a does not need backward computation.
I0521 14:24:41.593366 15763 net.cpp:228] reshape_negative does not need backward computation.
I0521 14:24:41.593369 15763 net.cpp:228] reshape_positive does not need backward computation.
I0521 14:24:41.593374 15763 net.cpp:228] reshape_anchor does not need backward computation.
I0521 14:24:41.593377 15763 net.cpp:228] slicer does not need backward computation.
I0521 14:24:41.593380 15763 net.cpp:228] data does not need backward computation.
I0521 14:24:41.619712 15763 net.cpp:283] Network initialization done.
I0521 14:24:43.502192 15763 net.cpp:761] Ignoring source layer fc7_norm_mvn_0_split
I0521 14:24:43.515161 15763 net.cpp:761] Ignoring source layer fc7_pos_norm_mvn_pos_0_split
I0521 14:24:43.528358 15763 net.cpp:761] Ignoring source layer fc7_neg_norm_mvn_neg_0_split
I0521 14:24:43.528383 15763 net.cpp:761] Ignoring source layer loss
I0521 14:24:43.528399 15763 net.cpp:761] Ignoring source layer triplet_check
I0521 14:24:43.538481 15763 caffe.cpp:285] Running for 3500 iterations.
I0521 14:27:19.049965 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:27:20.953586 15763 blocking_queue.cpp:50] Data layer prefetch queue empty
I0521 14:28:05.317816 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:28:51.030531 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:29:37.892539 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:30:27.066450 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:31:28.427049 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:32:30.353255 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:33:31.487432 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:40:47.675762 15780 blocking_queue.cpp:50] Waiting for data
I0521 14:47:31.124760 15763 caffe.cpp:313] Loss: 0
Features saved to: ../../features/features_triplet_loss_mvn_train.npz
