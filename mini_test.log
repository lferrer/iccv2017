I0404 09:46:45.643782 28191 caffe.cpp:210] Use CPU.
I0404 09:46:45.644001 28191 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.003
display: 20
max_iter: 143010
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
stepsize: 14301
snapshot: 5000
snapshot_prefix: "c3d_ucf101"
solver_mode: CPU
net: "mini_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-val"
}
I0404 09:46:45.644114 28191 solver.cpp:91] Creating training net from net file: mini_train_test.prototxt
I0404 09:46:45.644754 28191 net.cpp:58] Initializing net from parameters: 
name: "C3D-Mini"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "triplet"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
    mean_value: 65
    mean_value: 74
    mean_value: 92
  }
  data_param {
    source: "/home/lferrer/Documents/LMDB_MINI/train"
    batch_size: 5
    backend: LMDB
  }
}
layer {
  name: "slicer"
  type: "Slice"
  bottom: "triplet"
  top: "anchor_stacked"
  top: "positive_stacked"
  top: "negative_stacked"
  slice_param {
    slice_dim: 1
    slice_point: 48
    slice_point: 96
  }
}
layer {
  name: "reshape_anchor"
  type: "Reshape"
  bottom: "anchor_stacked"
  top: "anchor"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_positive"
  type: "Reshape"
  bottom: "positive_stacked"
  top: "positive"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "reshape_negative"
  type: "Reshape"
  bottom: "negative_stacked"
  top: "negative"
  reshape_param {
    shape {
      dim: 0
      dim: 3
      dim: 16
      dim: 112
      dim: 112
    }
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "anchor"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 101
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "positive"
  bottom: "negative"
}
layer {
  name: "loss"
  type: "TripletLoss"
  bottom: "fc8"
  bottom: "fc8"
  bottom: "fc8"
  top: "loss"
  threshold_param {
    threshold: 1
  }
}
I0404 09:46:45.644971 28191 layer_factory.hpp:77] Creating layer data
I0404 09:46:45.645716 28191 net.cpp:100] Creating Layer data
I0404 09:46:45.645736 28191 net.cpp:408] data -> triplet
I0404 09:46:45.659735 28194 db_lmdb.cpp:35] Opened lmdb /home/lferrer/Documents/LMDB_MINI/train
I0404 09:46:45.672719 28191 data_layer.cpp:41] output data size: 5,144,112,112
I0404 09:46:45.673049 28191 net.cpp:150] Setting up data
I0404 09:46:45.673091 28191 net.cpp:157] Top shape: 5 144 112 112 (9031680)
I0404 09:46:45.673095 28191 net.cpp:165] Memory required for data: 36126720
I0404 09:46:45.673110 28191 layer_factory.hpp:77] Creating layer slicer
I0404 09:46:45.673123 28191 net.cpp:100] Creating Layer slicer
I0404 09:46:45.673128 28191 net.cpp:434] slicer <- triplet
I0404 09:46:45.673140 28191 net.cpp:408] slicer -> anchor_stacked
I0404 09:46:45.673149 28191 net.cpp:408] slicer -> positive_stacked
I0404 09:46:45.673161 28191 net.cpp:408] slicer -> negative_stacked
I0404 09:46:45.673169 28191 net.cpp:150] Setting up slicer
I0404 09:46:45.673172 28191 net.cpp:157] Top shape: 5 48 112 112 (3010560)
I0404 09:46:45.673176 28191 net.cpp:157] Top shape: 5 48 112 112 (3010560)
I0404 09:46:45.673178 28191 net.cpp:157] Top shape: 5 48 112 112 (3010560)
I0404 09:46:45.673180 28191 net.cpp:165] Memory required for data: 72253440
I0404 09:46:45.673182 28191 layer_factory.hpp:77] Creating layer reshape_anchor
I0404 09:46:45.673192 28191 net.cpp:100] Creating Layer reshape_anchor
I0404 09:46:45.673193 28191 net.cpp:434] reshape_anchor <- anchor_stacked
I0404 09:46:45.673203 28191 net.cpp:408] reshape_anchor -> anchor
I0404 09:46:45.673218 28191 net.cpp:150] Setting up reshape_anchor
I0404 09:46:45.673221 28191 net.cpp:157] Top shape: 5 3 16 112 112 (3010560)
I0404 09:46:45.673223 28191 net.cpp:165] Memory required for data: 84295680
I0404 09:46:45.673240 28191 layer_factory.hpp:77] Creating layer reshape_positive
I0404 09:46:45.673246 28191 net.cpp:100] Creating Layer reshape_positive
I0404 09:46:45.673249 28191 net.cpp:434] reshape_positive <- positive_stacked
I0404 09:46:45.673252 28191 net.cpp:408] reshape_positive -> positive
I0404 09:46:45.673259 28191 net.cpp:150] Setting up reshape_positive
I0404 09:46:45.673261 28191 net.cpp:157] Top shape: 5 3 16 112 112 (3010560)
I0404 09:46:45.673264 28191 net.cpp:165] Memory required for data: 96337920
I0404 09:46:45.673265 28191 layer_factory.hpp:77] Creating layer reshape_negative
I0404 09:46:45.673269 28191 net.cpp:100] Creating Layer reshape_negative
I0404 09:46:45.673272 28191 net.cpp:434] reshape_negative <- negative_stacked
I0404 09:46:45.673275 28191 net.cpp:408] reshape_negative -> negative
I0404 09:46:45.673280 28191 net.cpp:150] Setting up reshape_negative
I0404 09:46:45.673283 28191 net.cpp:157] Top shape: 5 3 16 112 112 (3010560)
I0404 09:46:45.673285 28191 net.cpp:165] Memory required for data: 108380160
I0404 09:46:45.673286 28191 layer_factory.hpp:77] Creating layer conv1a
F0404 09:46:45.673312 28191 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: NdConvolution (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, Python, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, TanH, Threshold, Tile, TripletLoss, VideoData, WindowData)
*** Check failure stack trace: ***
    @     0x7f1c834a85cd  google::LogMessage::Fail()
    @     0x7f1c834aa433  google::LogMessage::SendToLog()
    @     0x7f1c834a815b  google::LogMessage::Flush()
    @     0x7f1c834aae1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f1c83a1322b  caffe::LayerRegistry<>::CreateLayer()
    @     0x7f1c83a17c6c  caffe::Net<>::Init()
    @     0x7f1c83a195d1  caffe::Net<>::Net()
    @     0x7f1c83a224aa  caffe::Solver<>::InitTrainNet()
I0404 09:46:45.684643 28195 blocking_queue.cpp:50] Waiting for data
    @     0x7f1c83a238b7  caffe::Solver<>::Init()
    @     0x7f1c83a23c5a  caffe::Solver<>::Solver()
    @     0x7f1c83a4fff3  caffe::Creator_SGDSolver<>()
    @           0x40bd1a  train()
    @           0x408618  main
    @     0x7f1c81c21830  __libc_start_main
    @           0x408ee9  _start
    @              (nil)  (unknown)
