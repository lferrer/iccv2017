net: "../../models/three_stream_triplet_loss.prototxt"
# num test samples / batch_size = 41822/10 = 4182, but only 100 iterations
# are used for testing to speed up training
# optionally run test on train set, to monitor overfitting
#test_iter: 100
#test_state: { stage: 'test-on-train' }
test_iter: 500
test_state: { stage: 'test-on-val' }
test_interval: 200
base_lr: 0.00001
momentum: 0.9
weight_decay: 0.005
lr_policy: "step"
gamma: 0.1
# original paper uses gamma of 0.1 every 4 epochs
# using batch_size=30, stepsize = 4*(107258/30) to match original results
# https://arxiv.org/pdf/1412.0767.pdf: figure 2 -- ~45% clip accuracy around
# 6th spoch
stepsize: 20000
# Display every 50 iterations
display: 50
# The maximum number of iterations: 10 epochs
max_iter: 60000
# snapshot intermediate results
snapshot: 2000
snapshot_prefix: "../../weights/three_stream_triplet_loss"
solver_mode: GPU
